{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homelabs Doc","text":"<p>Bienvenue sur Homelabs Doc, la documentation compl\u00e8te pour construire un homelab s\u00e9curis\u00e9, auto-h\u00e9berg\u00e9 et modulaire.</p>"},{"location":"#objectifs","title":"\ud83e\udde0 Objectifs","text":"<ul> <li>Cr\u00e9er une infrastructure personnelle robuste</li> <li>H\u00e9berger ses propres services (cloud, streaming, domotique\u2026)</li> <li>Int\u00e9grer la cybers\u00e9curit\u00e9 dans chaque couche</li> <li>Rester souverain sur ses donn\u00e9es</li> </ul>"},{"location":"diy/diy-cyberpack/","title":"Spectrum Master Backpack : guide du sac \u00e0 dos de hacking","text":"<p>Le Spectrum Master Backpack de Bag-Builds, con\u00e7u comme une plateforme mobile de hacking sur le terrain. Les deux faces int\u00e9rieures du sac contiennent divers modules SDR, Wi\u2011Fi et de stockage</p> <p>Le  Spectrum Master Backpack  est un sac \u00e0 dos \u00ab cyber \u00bb pens\u00e9 pour la capture de signaux sans fil et le pentesting nomade. Aliment\u00e9 par deux  Raspberry Pi 4, il embarque un vaste arsenal d\u2019outils (radio logicielle, adaptateurs Wi\u2011Fi puissants, GPS, etc.) et permet d\u2019y acc\u00e9der \u00e0 distance. En clair, l\u2019ensemble forme un v\u00e9ritable laboratoire \u00ab portable \u00bb, dans lequel le mat\u00e9riel est fix\u00e9 sur des supports imprim\u00e9s en 3D \u00e0 l\u2019int\u00e9rieur du sac. L\u2019utilisateur peut piloter le syst\u00e8me depuis son smartphone/tablette (via le r\u00e9seau interne ou un c\u00e2ble USB unique) ou depuis un ordinateur connect\u00e9 en USB. Cette configuration multi-outils est id\u00e9ale pour des activit\u00e9s vari\u00e9es : hacking \u00e9thique,  wardriving, CTF mobiles, d\u00e9monstrations de cybers\u00e9curit\u00e9, etc. En r\u00e9sum\u00e9, c\u2019est un centre d\u2019interception sans fil autonome que l\u2019on peut porter sur soi et d\u00e9ployer sur le terrain.</p>"},{"location":"diy/diy-cyberpack/#equipements-embarques","title":"\u00c9quipements embarqu\u00e9s","text":"<p>Le sac regroupe  presque tous les outils de hacking et d\u2019analyse radio  imaginables. Parmi l\u2019\u00e9quipement list\u00e9 sur le site Bag-Builds, on trouve notamment\uff1a</p> <ul> <li> <p>Radio logicielle (SDR) : un USRP B205mini, un HackRF One et deux dongles RTL\u2011SDR. Ces SDR couvrent de larges plages de fr\u00e9quences (de la bande FM aux GHz).</p> </li> <li> <p>Amplificateur de signaux : l\u2019antenne active Nooelec LaNA, pour am\u00e9liorer la port\u00e9e des r\u00e9cepteurs SDR.</p> </li> <li> <p>Wi\u2011Fi : deux adaptateurs de haute puissance ALFA (AWUS036ACM et AWUS036ACHM non car\u00e9n\u00e9s) capables de passer en mode moniteur (sniffing).</p> </li> <li> <p>Outils r\u00e9seau : l\u2019Ubertooth One pour l\u2019analyse Bluetooth, un CatSniffer (v2) pour le Wi\u2011Fi, un module GPS u\u2011blox NEO-M9N (assez courant) et un  GPSDO  (oscillateur \u00e0 stabilit\u00e9 temporelle \u00e9lev\u00e9e).</p> </li> <li> <p>Ordinateurs embarqu\u00e9s : deux Raspberry Pi 4, qui font office de c\u0153urs informatiques ex\u00e9cutant des OS de pentest (Kali Linux, etc.). Ils g\u00e8rent le traitement des donn\u00e9es et les interfaces web/SSH.</p> </li> <li> <p>Stockage : un SSD Samsung T7 externe pour conserver les captures et outils.</p> </li> <li> <p>Hub USB : deux hubs multiports (USB-A Aceele et Kensington SD5700T ouvert) pour relier tous les dongles et cartes aux Pi.</p> </li> <li> <p>R\u00e9seau \u00e9tendu : un routeur de voyage GL.iNet AX Slate (Wi\u2011Fi 6, d\u00e9carc\u00e9r\u00e9) et un modem 4G Quectel EC25-E pour la connectivit\u00e9 cellulaire. Ainsi, le sac peut cr\u00e9er son propre r\u00e9seau priv\u00e9 ou se connecter au r\u00e9seau mobile sur le terrain.</p> </li> <li> <p>Alimentation : quatre grandes batteries Anker 737 de 24\u202f000\u202fmAh chacune, plac\u00e9es en vis-\u00e0-vis des cartes informatiques. Cela offre plusieurs dizaines d\u2019heures d\u2019autonomie selon l\u2019utilisation (le Pi 4 consomme en g\u00e9n\u00e9ral quelques watts).</p> </li> <li> <p>Ventilation : deux petits ventilateurs Noctua A4x20 pour \u00e9vacuer la chaleur des Raspberry Pi et autres modules.</p> </li> </ul> <p>En plus de ces composants de base, on peut enrichir le sac avec d\u2019autres outils de pentest portables. Par exemple, Bag-Builds a souvent inclus un  Flipper Zero  et un  CatSniffer v3  dans ses kits. Un  Flipper Zero  est utile pour tester les protocoles RFID/IR et servir d\u2019outil polyvalent en pentest embarqu\u00e9. On peut aussi emporter un clavier pliable, un \u00e9cran portable (connect\u00e9 aux Pi), voire un Wi\u2011Fi Pineapple ou des dongles LoRa suppl\u00e9mentaires. L\u2019id\u00e9e est de maximiser le mat\u00e9riel disponible, tout en restant raisonnable sur le poids.</p>"},{"location":"diy/diy-cyberpack/#assemblage-et-integration","title":"Assemblage et int\u00e9gration","text":"<p>Installation des modules sur la structure interne du sac. Les Raspberry Pi sont fix\u00e9s sur une plaque principale, et les dongles/antennes sont mont\u00e9s sur les panneaux lat\u00e9raux</p> <p>Le montage commence par l\u2019impression et l\u2019installation d\u2019une  structure interne  sur mesure (panneaux et supports 3D) qui sera fix\u00e9e \u00e0 l\u2019int\u00e9rieur du sac. Cette structure comporte :</p> <ul> <li> <p>Une plaque principale (par exemple sur le panneau arri\u00e8re du sac) pour y visser les  Raspberry Pi  et l\u2019alimentation principale.</p> </li> <li> <p>Des panneaux lat\u00e9raux pour maintenir verticalement les dongles SDR, adaptateurs Wi\u2011Fi, antennes et hubs USB.</p> </li> <li> <p>Des compartiments ou poches pour glisser les batteries et le SSD.</p> </li> </ul> <p>Ensuite, on  visse chaque composant  sur son support : les Raspberry Pi sont fix\u00e9s avec leurs dissipateurs sur la plaque, puis on connecte les hubs USB aux Pi. Les dongles SDR et adaptateurs Wi\u2011Fi sont mont\u00e9s sur les panneaux lat\u00e9raux via leurs vis de fixation. Les c\u00e2bles (USB, antennes coaxiales, alimentation) sont achemin\u00e9s de mani\u00e8re propre vers les Pi. Les ventilateurs Noctua sont positionn\u00e9s pour brasser de l\u2019air frais vers les cartes (g\u00e9n\u00e9ralement accol\u00e9s aux bordures du sac).</p> <p>\u00c9tapes cl\u00e9s  (guide pas-\u00e0-pas) :</p> <ol> <li> <p>Pr\u00e9parer la base  \u2013 Imprimer/fabriquer les panneaux 3D selon le plan (disponible sur la page Bag-Builds). Fixer ces supports au sac (coutures ou velcro industriel).</p> </li> <li> <p>Monter les Pi  \u2013 Visser les deux Raspberry Pi 4 sur la plaque arri\u00e8re. Brancher les dissipateurs.</p> </li> <li> <p>Raccorder l\u2019alimentation  \u2013 Connecter les c\u00e2bles d\u2019alimentation des batteries aux Pi (par USB-C ou via un hub power).</p> </li> <li> <p>Installer les dongles SDR &amp; Wi\u2011Fi  \u2013 Visser les modules (USRP, HackRF, RTL-SDR, adaptateurs ALFA) sur les panneaux lat\u00e9raux. Connecter chaque dongle \u00e0 un port USB.</p> </li> <li> <p>Placer le stockage et le r\u00e9seau  \u2013 Installer le SSD sur un support d\u00e9di\u00e9. Fixer le routeur GL.iNet et le modem EC25-E, les relier aux Pi (g\u00e9n\u00e9ralement par USB et RJ45).</p> </li> <li> <p>Ajouter les accessoires  \u2013 Glisser le GPS et le GPSDO dans des emplacements s\u00e9curis\u00e9s. Placer les batteries dans leurs poches (id\u00e9alement en face de la plaque principale pour l\u2019\u00e9quilibre). Brancher enfin les ventilateurs sur les Pi ou sur un contr\u00f4leur de ventilateur d\u00e9di\u00e9.</p> </li> <li> <p>Tests et configuration  \u2013 V\u00e9rifier chaque connexion. Allumer les Raspberry Pi (install\u00e9s avec l\u2019OS de votre choix) et tester l\u2019acc\u00e8s r\u00e9seau : par Wi\u2011Fi interne (routeur) et par USB.</p> </li> </ol> <p>Gr\u00e2ce \u00e0 ce design modulaire imprim\u00e9 en 3D, l\u2019ensemble reste solide et bien ventil\u00e9. Un guide vid\u00e9o ou des instructions pas \u00e0 pas sont souvent fournis (par exemple sur YouTube) pour aider au montage.</p>"},{"location":"diy/diy-cyberpack/#gestion-de-lalimentation-et-autonomie","title":"Gestion de l\u2019alimentation et autonomie","text":"<p>L\u2019une des exigences du projet est la  mobilit\u00e9 et l\u2019autonomie. Les quatre batteries Anker 24\u202f000\u202fmAh suffisent \u00e0 alimenter les Raspberry Pi et la plupart des p\u00e9riph\u00e9riques plusieurs heures, voire une journ\u00e9e compl\u00e8te selon la charge de travail. On peut calculer qu\u2019un Raspberry Pi 4 tire environ 3\u20134\u202fW en charge lourde (moniteur r\u00e9seau, SDR actif) ; par cons\u00e9quent une batterie Anker (~89\u202fWh) peut alimenter un Pi plusieurs dizaines d\u2019heures \u00e0 faible charge.</p> <p>Pour maximiser l\u2019autonomie sur le terrain, on veille \u00e0 optimiser la consommation : d\u00e9sactiver les modules inutilis\u00e9s, utiliser des modes basse consommation sur les SDR/antenne, etc.  Optionnellement, on peut envisager d\u2019ajouter un petit panneau solaire USB pliable pour recharger les batteries en continu durant les missions longues. Aucune r\u00e9f\u00e9rence officielle n\u2019indique la pr\u00e9sence d\u2019un panneau solaire sur ce mod\u00e8le sp\u00e9cifique, mais de nombreux hackers utilisent des chargeurs solaires (5\u201310\u202fW) en randonn\u00e9e pour prolonger l\u2019autonomie des packs USB. Si on choisit cette option, il faudra consid\u00e9rer son poids et pr\u00e9voir des sorties USB ou USB-C compatibles pour la recharge.</p>"},{"location":"diy/diy-cyberpack/#utilisation-sur-le-terrain","title":"Utilisation sur le terrain","text":"<p>Gr\u00e2ce \u00e0 son routeur interne et \u00e0 son modem 4G, le sac peut cr\u00e9er un r\u00e9seau local priv\u00e9 permettant de contr\u00f4ler \u00e0 distance tous les appareils. Typiquement, les Raspberry Pi tournent sous Kali Linux ou un OS similaire, avec des applications comme  GNU Radio,  Wireshark,  aircrack-ng, etc. On peut alors :</p> <ul> <li> <p>Lancer une capture SDR \u00e0 distance pour analyser les ondes radio (FM, Wi-Fi, Bluetooth, LoRa, etc.).</p> </li> <li> <p>Mettre en  sniffing  les r\u00e9seaux Wi\u2011Fi alentour via les adaptateurs ALFA en mode moniteur.</p> </li> <li> <p>Utiliser le GPS pour  g\u00e9olocaliser  les sources d\u00e9tect\u00e9es.</p> </li> <li> <p>Exploiter le Flipper Zero (ajout\u00e9 au sac) pour attaquer des protocoles RFID ou infrarouges.</p> </li> <li> <p>Acc\u00e9der aux interfaces web des dongles (certains SDR ont des interfaces graphiques) ou aux terminaux SSH des Pi depuis un smartphone/tablette sur le m\u00eame r\u00e9seau.</p> </li> </ul> <p>Les c\u00e2bles USB centralis\u00e9s permettent aussi de brancher rapidement le sac \u00e0 un laptop externe comme simple bo\u00eetier de dongles. Ainsi, on peut t\u00e9l\u00e9charger rapidement les captures ou \u00e9tendre l\u2019analyse sur un ordinateur portable, sans avoir \u00e0 retirer les modules du sac.</p>"},{"location":"diy/diy-cyberpack/#conclusion","title":"Conclusion","text":"<p>Le  Spectrum Master Backpack  est un sac \u00e0 dos de hacking extr\u00eamement complet, con\u00e7u pour g\u00e9rer toutes sortes de missions sur le terrain. Son design interne repose sur un \u00ab rack \u00bb imprim\u00e9 en 3D qui organise solidement chaque outil. En cumulant des SDR, des adaptateurs r\u00e9seau puissants, un GPS et de grandes batteries, il couvre pratiquement tous les besoins en pentesting et surveillance sans fil. Comme le note la revue associ\u00e9e, il s\u2019agit d\u2019un \u00ab laboratoire portable \u00bb id\u00e9al pour l\u2019analyse des signaux sans fil. Pour un bricoleur, les plans du support 3D et la liste des composants publi\u00e9s sur bagbuilds.com servent de base ; il ne reste plus qu\u2019\u00e0 suivre les \u00e9tapes de montage et \u00e0 configurer le logiciel. Au final, vous obtenez un cyberdeck embarqu\u00e9 dans un sac \u00e0 dos, pr\u00eat \u00e0 affronter des missions d\u2019hacking sur le terrain.</p>"},{"location":"diy/esp32/","title":"Projet DIY ESP32 : capteurs de temp\u00e9rature et MQTT","text":"<p>Nous allons construire un syst\u00e8me IoT avec un ESP32, mesurant la temp\u00e9rature (et autres donn\u00e9es) via divers capteurs, et transmettant ces mesures via MQTT. L\u2019ESP32 se connecte au Wi-Fi et publie les donn\u00e9es sur un  broker  MQTT (local ou cloud). Les donn\u00e9es peuvent ensuite \u00eatre exploit\u00e9es dans un  homelab  (ex. Home Assistant, InfluxDB, Grafana) ou dans un environnement IoT autonome (services cloud). Ce guide d\u00e9taille les capteurs recommand\u00e9s, la programmation Arduino, le protocole MQTT et l\u2019int\u00e9gration avec Home Assistant/InfluxDB/Grafana.</p>"},{"location":"diy/esp32/#capteurs-recommandes","title":"Capteurs recommand\u00e9s","text":"<p>On privil\u00e9gie des capteurs populaires et fiables pour domotique et IoT :</p> <ul> <li> <p>DHT11 / DHT22 : capteurs num\u00e9riques de temp\u00e9rature et humidit\u00e9. Tr\u00e8s utilis\u00e9s par les hobbyistes. Le DHT22 offre une plus grande plage de mesure et une meilleure r\u00e9solution (jusqu\u2019\u00e0 \u00b10,5\u202f\u00b0C de pr\u00e9cision, \u201340 \u00e0 +80\u202f\u00b0C), tandis que le DHT11 est plus limit\u00e9 (0\u201350\u202f\u00b0C, \u00b12\u202f\u00b0C) mais moins cher. Ces capteurs int\u00e8grent un convertisseur analogique-num\u00e9rique et d\u00e9livrent directement des donn\u00e9es num\u00e9riques sur un seul fil (avec pull-up).</p> </li> <li> <p>DS18B20 : capteur de temp\u00e9rature num\u00e9rique \u00ab 1-Wire \u00bb, aliment\u00e9 en 3,3\u20135\u202fV. Il communique sur une seule broche de donn\u00e9es plus la masse. Chaque DS18B20 dispose d\u2019un identifiant unique 64\u202fbit, ce qui permet de cha\u00eener plusieurs sondes sur la m\u00eame ligne num\u00e9rique. C\u2019est pratique pour multiplier les points de mesure (par exemple, eau, air, radiateurs) avec un seul GPIO.</p> </li> <li> <p>BME280 : capteur 3-en-1 mesurant pression atmosph\u00e9rique, temp\u00e9rature et humidit\u00e9. On l\u2019interroge g\u00e9n\u00e9ralement en I2C (broches SDA/SCL), ce qui \u00e9conomise les broches GPIO. La mesure de pression permet d\u2019estimer l\u2019altitude, utile pour des stations m\u00e9t\u00e9o ou l\u2019optimisation du chauffage/ventilation. Ce capteur offre de bonnes pr\u00e9cisions sur ses trois param\u00e8tres et couvre de larges plages de fonctionnement.</p> </li> <li> <p>Autres capteurs domotique  (sans citation sp\u00e9cifique) : selon les besoins on peut ajouter un  d\u00e9tecteur de mouvement PIR, des  capteurs de gaz/fum\u00e9e  (MQ-2, MQ-135), des  capteurs de luminosit\u00e9  (photocellule), ou un  contacteur d\u2019ouverture  (Reed/magn\u00e9tique). Ces \u00e9l\u00e9ments \u00e9tendent l\u2019application vers la s\u00e9curit\u00e9 et la gestion d\u2019\u00e9nergie.</p> </li> </ul> <p>Fig. 1 \u2013 ESP32 branch\u00e9 \u00e0 un capteur DHT22 (blanc), mesurant temp\u00e9rature et humidit\u00e9.</p> <p>Le DHT11/DHT22 mesure la temp\u00e9rature et l\u2019humidit\u00e9, et est tr\u00e8s populaire chez les makers. On le branche sur un GPIO num\u00e9rique de l\u2019ESP32 (avec une r\u00e9sistance de tirage interne ou un pull-up externe). Le DHT22 est plus pr\u00e9cis et couvre des plages plus grandes que le DHT11, mais il rafra\u00eechit les donn\u00e9es toutes les ~2\u202fs (contre 1\u202fs pour le DHT11). Ces capteurs sont relativement lents, mais embarquent un convertisseur A/N, sortant directement des valeurs num\u00e9riques pr\u00eates \u00e0 l\u2019emploi, ce qui simplifie grandement la lecture via Arduino.</p> <p>Fig. 2 \u2013 L\u2019ESP32 affichant via une page Web la temp\u00e9rature lue par un capteur DS18B20.</p> <p>Le capteur  DS18B20  est un thermom\u00e8tre num\u00e9rique 1-wire. Il se connecte \u00e0 une seule broche de donn\u00e9es (plus la masse), et peut \u00eatre aliment\u00e9 en 5\u202fV ou 3,3\u202fV. Ce capteur est pr\u00e9cis (environ \u00b10,5\u202f\u00b0C) et robuste. De plus, chaque DS18B20 a un code interne \u00e0 64\u202fbits, ce qui permet de mettre plusieurs sondes sur le m\u00eame fil de donn\u00e9es. On peut ainsi connecter plusieurs DS18B20 (par exemple dans diff\u00e9rentes pi\u00e8ces ou dans de l\u2019eau) \u00e0 un seul GPIO de l\u2019ESP32, et lire successivement la temp\u00e9rature de chacun.</p> <p>Fig. 3 \u2013 Module capteur BME280 (temp\u00e9rature, pression, humidit\u00e9) utilis\u00e9 comme station m\u00e9t\u00e9o embarqu\u00e9e.</p> <p>Le  BME280  combine trois mesures : pression atmosph\u00e9rique, temp\u00e9rature et humidit\u00e9 relative. Il communique g\u00e9n\u00e9ralement en I2C (broches SDA/SCL), ce qui r\u00e9duit l\u2019occupation de GPIO sur l\u2019ESP32. La pression mesur\u00e9e permet d\u2019estimer l\u2019altitude locale, ce qui est utile pour les applications m\u00e9t\u00e9o ou de contr\u00f4le environnemental. Ce capteur, tr\u00e8s r\u00e9pandu en IoT, offre de bonnes pr\u00e9cisions sur ses mesures et supporte de larges plages de temp\u00e9ratures et de pressions. On l\u2019utilise souvent dans des stations m\u00e9t\u00e9o ou des syst\u00e8mes domotiques n\u00e9cessitant des donn\u00e9es environnementales compl\u00e8tes.</p>"},{"location":"diy/esp32/#programmation-de-lesp32-arduino-ide","title":"Programmation de l\u2019ESP32 (Arduino IDE)","text":"<p>Nous utiliserons l\u2019IDE Arduino (C++) pour programmer l\u2019ESP32. Il faut inclure les biblioth\u00e8ques Wi-Fi (<code>WiFi.h</code>) et MQTT (<code>PubSubClient.h</code>  par exemple) ainsi que celles sp\u00e9cifiques aux capteurs : Adafruit DHT pour DHT11/22, OneWire + DallasTemperature pour DS18B20, Adafruit BME280, etc. Dans le  <code>setup()</code>, on configure la connexion Wi-Fi (SSID + mot de passe), puis on initialise la connexion MQTT au broker (adresse IP/URL, port, login).</p> <p>Dans la boucle  <code>loop()</code>, on lit p\u00e9riodiquement les capteurs (par exemple toutes les 10 secondes), puis on publie les valeurs sur des  topics  MQTT d\u00e9di\u00e9s. Par exemple, pour un DHT22 on peut \u00e9crire en C++ :</p> <pre><code>mqttClient.publish(MQTT_PUB_TEMP, String(temperature).c_str());\nmqttClient.publish(MQTT_PUB_HUM,  String(humidity).c_str());\n</code></pre> <p>Cette ligne fait appel \u00e0  <code>mqttClient.publish(topic, payload)</code>  de la librairie PubSubClient. Elle envoie les mesures sous forme de cha\u00eenes de caract\u00e8res sur les topics d\u00e9finis (ex.  <code>\"esp32/dht/temp\"</code>). Dans l\u2019exemple ci-dessous, l\u2019ESP32 publie successivement la temp\u00e9rature et l\u2019humidit\u00e9 lues. En ouvrant le moniteur s\u00e9rie on v\u00e9rifie que l\u2019ESP32 se connecte au broker et diffuse bien les messages sur les topics appropri\u00e9s.</p> <p>Ainsi, chaque mesure est mise en  payload  d\u2019un message MQTT. On peut configurer le  QoS  (qualit\u00e9 de service) et le flag  retain  selon les besoins (par d\u00e9faut QoS 0,  retain  peut \u00eatre activ\u00e9 pour conserver la derni\u00e8re valeur). Par ailleurs, on g\u00e8re la reconnexion automatique au broker si n\u00e9cessaire. Tout le code reste en Arduino C++ (sans microPython ici, comme demand\u00e9).</p>"},{"location":"diy/esp32/#broker-mqtt-comparatif","title":"Broker MQTT : comparatif","text":"<p>Le  broker MQTT  relaie les messages entre \u00e9diteurs et abonn\u00e9s. Le choix du broker d\u00e9pend du sc\u00e9nario :</p> <ul> <li> <p>Mosquitto  (open-source) : extr\u00eamement l\u00e9ger et populaire. Supporte MQTT v5, TLS/SSL et l\u2019authentification basique. On peut l\u2019installer sur un serveur local (Raspberry Pi, VM, NAS) ou via un conteneur Docker.</p> </li> <li> <p>Mosquitto (Home Assistant) : Home Assistant propose un  add-on  Mosquitto tout configur\u00e9. C\u2019est l\u2019option la plus simple pour un homelab HA. L\u2019add-on g\u00e9n\u00e8re automatiquement un utilisateur/sujet s\u00e9curis\u00e9 pour HA, facilitant l\u2019int\u00e9gration.</p> </li> <li> <p>Brokers SaaS (cloud) : AWS IoT Core, Google Cloud IoT, HiveMQ Cloud, CloudMQTT, etc. Ces solutions fournissent un broker MQTT hautement disponible et g\u00e9r\u00e9 (authentification avanc\u00e9e, TLS mutualis\u00e9, quotas, etc.). Elles sont pratiques si l\u2019ESP32 doit transmettre sur Internet sans serveur local (par exemple depuis l\u2019ext\u00e9rieur du r\u00e9seau domestique), mais requi\u00e8rent souvent un abonnement payant.</p> </li> <li> <p>Autres (Enterprise) : des brokers comme EMQX, RabbitMQ avec plugin MQTT ou ActiveMQ existent, mais Home Assistant ne les recommande pas (bugs connus).</p> </li> </ul> <p>Pour r\u00e9sumer : un broker local (ex. Mosquitto sur Raspberry Pi) est gratuit et facile \u00e0 g\u00e9rer en homelab. Un broker cloud (AWS, CloudMQTT\u2026) simplifie l\u2019acc\u00e8s externe et la mont\u00e9e en charge. Home Assistant souligne que l\u2019option la plus priv\u00e9e est un broker auto-h\u00e9berg\u00e9 (ex. Mosquitto en local), mais proposer un broker cloud reste possible pour un projet mobile/autonome.</p>"},{"location":"diy/esp32/#integration-home-assistant-et-stockage","title":"Int\u00e9gration Home Assistant et stockage","text":"<p>Dans Home Assistant (HA), on installe d\u2019abord l\u2019int\u00e9gration MQTT en renseignant l\u2019h\u00f4te et les identifiants du broker (par exemple,  <code>core-mosquitto</code>  si on utilise l\u2019add-on). Les capteurs publi\u00e9s sur MQTT deviennent alors accessibles : on peut configurer des  MQTT Sensors  soit via l\u2019interface (MQTT Discovery) soit manuellement dans  <code>configuration.yaml</code>. Chaque capteur MQTT appara\u00eet alors comme une entit\u00e9 HA (ex.  <code>sensor.temperature_salon</code>).</p> <p>Pour la persistance des donn\u00e9es, HA peut \u00eatre combin\u00e9 avec  InfluxDB  et  Grafana. InfluxDB est une base de donn\u00e9es  time-series  open-source id\u00e9ale pour stocker de grandes quantit\u00e9s de mesures horodat\u00e9es. Par exemple, l\u2019add-on InfluxDB d\u2019HA capture automatiquement les entit\u00e9s MQTT et enregistre chaque valeur dans la base. Grafana peut ensuite se connecter \u00e0 InfluxDB et tracer des courbes temporelles personnalis\u00e9es. Comme l\u2019a not\u00e9 David Essenius,  les graphiques int\u00e9gr\u00e9s de HA ne sont pas tr\u00e8s param\u00e9trables et les donn\u00e9es ne sont pas conserv\u00e9es ind\u00e9finiment; il pr\u00e9conise donc l\u2019usage d\u2019InfluxDB+Grafana pour des visualisations avanc\u00e9es et un historique complet. Gr\u00e2ce \u00e0 cette architecture, on peut disposer de beaux tableaux de bord dynamiques (interpolation, moyennes, alertes, etc.) bas\u00e9s sur les capteurs de l\u2019ESP32.</p> <p>En r\u00e9sum\u00e9, le flux de donn\u00e9es peut \u00eatre :  ESP32 \u2192 Broker MQTT (Mosquitto)  \u2192 1) Home Assistant (pour supervision/automatisation) et 2) InfluxDB/Grafana (pour stockage/visualisation). Dans HA on peut \u00e9galement d\u00e9clencher des automatismes sur seuils de temp\u00e9rature, allumer un ventilateur, etc. L\u2019ESP32 publie de son c\u00f4t\u00e9 de mani\u00e8re ind\u00e9pendante les donn\u00e9es via MQTT, et HA se contente de les consommer.</p>"},{"location":"diy/esp32/#homelab-vs-projet-autonome-iot","title":"Homelab vs projet autonome IoT","text":"<p>Le sc\u00e9nario \u00ab homelab \u00bb implique que l\u2019ensemble reste sur le r\u00e9seau local. Par exemple, on installe Mosquitto, HA, InfluxDB et Grafana sur un Raspberry Pi ou un NAS. L\u2019avantage est la  compl\u00e8te ma\u00eetrise  des donn\u00e9es et leur s\u00e9curit\u00e9 (pas d\u2019envoi ext\u00e9rieur), ainsi qu\u2019un faible co\u00fbt. En revanche, pour un projet IoT autonome (ex. capteur embarqu\u00e9, exposition), on choisira un broker accessible publiquement. On peut exposer son broker Mosquitto via une IP/DNS statique, ou utiliser un service cloud (AWS IoT, CloudMQTT\u2026). De m\u00eame, on peut opter pour InfluxDB Cloud ou Grafana Cloud afin de visualiser les donn\u00e9es depuis n\u2019importe o\u00f9. Dans tous les cas, il faut pr\u00e9voir l\u2019authentification et le chiffrement (MQTT sur TLS) si on traverse Internet. HA conseille en g\u00e9n\u00e9ral d\u2019h\u00e9berger soi-m\u00eame le broker quand cela est possible, mais un mode  IoT mobile  peut l\u00e9gitimement reposer sur des services externes (broker SaaS, bases de donn\u00e9es cloud).</p>"},{"location":"domotique/homeassistant/","title":"Installation et configuration de Home Assistant","text":"<p>Home Assistant est une plateforme domotique open source puissante. Elle peut \u00eatre install\u00e9e de plusieurs fa\u00e7ons selon vos besoins et votre infrastructure.  Home Assistant Operating System (HassOS)  est la m\u00e9thode recommand\u00e9e pour la plupart des utilisateurs : il s\u2019agit d\u2019un syst\u00e8me minimal d\u00e9di\u00e9 qui s\u2019ex\u00e9cute sur SBC ou VM et prend en charge nativement les  add-ons  (extensions)  . Les autres options comprennent l\u2019installation en conteneur Docker  (requiert un syst\u00e8me h\u00f4te Linux et ne supporte pas les add-ons int\u00e9gr\u00e9s) et les machines virtuelles. Chaque m\u00e9thode a ses avantages en termes de maintenance, de performances et d\u2019isolation.</p> <ul> <li> <p>Home Assistant OS  : s\u2019installe sur Raspberry Pi, NUC, VM, etc. Pr\u00e9voyez au minimum 2\u202fGo de RAM et ~32\u202fGo de stockage (SSD recommand\u00e9)  . L\u2019OS minimalifie les mises \u00e0 jour et int\u00e8gre la gestion d\u2019add-ons (MOSQUITTO, Node-RED, etc.)  . Sur Proxmox, on d\u00e9ploie souvent HA OS en VM (notamment pour la compatibilit\u00e9 avec les  dongles  USB)  .</p> </li> <li> <p>Container (Docker)  : installer le conteneur officiel  ghcr.io/home-assistant/home-assistant:stable. Par exemple :</p> </li> </ul> <pre><code>docker run -d --name homeassistant --restart=unless-stopped \\\n  -e TZ=Europe/Paris \\\n  -v /PATH_CONFIG:/config \\\n  --network=host \\\n  ghcr.io/home-assistant/home-assistant:stable\n</code></pre> <ul> <li> <p>Ce mode ne g\u00e8re pas les add-ons internes  . Il est id\u00e9al si vous voulez superviser manuellement l\u2019instance via Docker. Pensez \u00e0 utiliser  --network=host  et \u00e0 exposer les p\u00e9riph\u00e9riques USB (--device /dev/ttyUSB0) pour Zigbee/Z-Wave  .</p> </li> <li> <p>VM Proxmox  : d\u00e9ployer HA OS dans une VM KVM. L\u2019interface Proxmox (KVM) permet le passthrough USB (utile pour les dongles Zigbee/Z-Wave  ). On peut automatiser l\u2019installation avec des scripts (par ex. tteck/Proxmox Helper) pour cr\u00e9er une VM HA OS en quelques commandes  . L\u2019avantage : on peut isoler HA du reste (ex. VLAN d\u00e9di\u00e9) tout en profitant des snapshots de VM.</p> </li> <li> <p>LXC Proxmox  : HA Supervised (Core + Supervisor) peut fonctionner dans un conteneur LXC, mais ce mode est d\u00e9sormais  d\u00e9conseill\u00e9  et instable  . Il offre toutefois un d\u00e9marrage plus rapide et moins de surcharge qu\u2019une VM. Si vous optez pour LXC, assurez-vous qu\u2019il a acc\u00e8s aux p\u00e9riph\u00e9riques (lxc.cgroup.devices.allow = c 188:* rwm  pour MQTT USB, etc.).</p> </li> <li> <p>Stockage  : pr\u00e9f\u00e9rez un SSD ou un volume RAID pour la fiabilit\u00e9 (\u00e9vitez les SD cards \u00e0 bas co\u00fbt). Home Assistant stocke la config, la base de donn\u00e9es (SQLite ou MariaDB), les images, etc. Sur une VM ou conteneur, r\u00e9servez assez d\u2019espace disque selon le nombre d\u2019entit\u00e9s et de journaux que vous collectez. Activez la compression TRIM (ex.  --storagectl --discard on  pour VirtualBox  ) pour optimiser l\u2019espace.</p> </li> <li> <p>Isolement r\u00e9seau  : dans un homelab s\u00e9curitaire, on recommande de segmenter le r\u00e9seau IoT. Par exemple, placez HA dans un VLAN distinct. Les \u201cthings\u201d (capteurs, lampes, etc.) sont alors isol\u00e9s du LAN principal. Les VLAN permettent d\u2019isoler les appareils et de s\u00e9curiser le r\u00e9seau, car chaque r\u00e9seau virtuel est ind\u00e9pendant  . Home Assistant doit pouvoir communiquer avec les deux domaines (ex. via plusieurs interfaces ou r\u00e8gles de pare-feu). En pratique, on cr\u00e9e un VLAN \u201cIoT\u201d o\u00f9 r\u00e9sident les appareils, et un VLAN \u201cServeur\u201d pour HA, en autorisant uniquement les flux strictement n\u00e9cessaires (MQTT, HTTP, etc.)  . Pensez \u00e0 mettre en place un pare-feu (p. ex. pfSense) pour contr\u00f4ler ces \u00e9changes (un exemple de r\u00e8gles typiques\u202f: autoriser le VLAN IoT vers HA sur le port MQTT, bloquer le reste du LAN)  .</p> </li> </ul> <p>TABLEAU</p>"},{"location":"domotique/homeassistant/#integration-mqtt","title":"Int\u00e9gration MQTT","text":"<p>L\u2019utilisation d\u2019un  broker MQTT  est au c\u0153ur de nombreux sc\u00e9narios domotiques. Le choix le plus simple et open-source est  Mosquitto. On peut l\u2019installer soit comme add-on (sur HA OS/Supervised), soit dans un conteneur d\u00e9di\u00e9 Docker/LXC. Home Assistant propose un add-on officiel  Mosquitto Broker  qui automatise la configuration initiale (il g\u00e9n\u00e8re un utilisateur/s\u00e9same s\u00e9curis\u00e9)  . En alternative, des brokers MQTT tels qu\u2019EMQX,  VerneMQ, ou  NanoMQ  sont open-source et scalables (tableau comparatif ci-dessous).</p> <p>TABLEAU</p>"},{"location":"domotique/homeassistant/#deploiement-du-broker-mosquitto","title":"D\u00e9ploiement du broker (Mosquitto)","text":"<p>Installez Mosquitto (ex.  apt-get install mosquitto) ou utilisez le  Add-on  dans HA OS. Configurez l\u2019authentification en cr\u00e9ant un utilisateur MQTT propre (ex.  mqtt_user  et mot de passe)  . Exemple de connexion dans Home Assistant (via Int\u00e9grations) :  h\u00f4te = IP du broker, port 1883, et les identifiants choisis. Activez l\u2019option TLS si vous voulez chiffrer les \u00e9changes : cela n\u00e9cessite un certificat (Let\u2019s Encrypt ou auto-sign\u00e9) et l\u2019activation de TLS sur le broker  . Sur Mosquitto, \u00e9ditez  /etc/mosquitto/mosquitto.conf  pour ajouter :</p> <pre><code>listener 8883\ncafile /etc/mosquitto/certs/ca.crt\ncertfile /etc/mosquitto/certs/server.crt\nkeyfile /etc/mosquitto/certs/server.key\nrequire_certificate false\n</code></pre> <p>et cr\u00e9ez des utilisateurs via  mosquitto_passwd. Red\u00e9marrez le service. Home Assistant se connectera alors sur le port 8883 avec TLS activ\u00e9  .</p>"},{"location":"domotique/homeassistant/#appareils-iot-zigbee2mqtt-shelly-esphome-tasmota","title":"Appareils IoT (Zigbee2MQTT, Shelly, ESPHome, Tasmota)","text":"<p>Une fois le broker en place, on peut brancher divers p\u00e9riph\u00e9riques  via MQTT  :</p> <ul> <li>Zigbee2MQTT : requiert un dongle Zigbee (CC2531, CC2652, etc.) branch\u00e9 sur le serveur ou le LXC conteneur. Zigbee2MQTT collecte les donn\u00e9es Zigbee et les publie sur MQTT (topiques  zigbee2mqtt/device/friendly_name). Activez le  discover  dans la config de Zigbee2MQTT (homeassistant: enabled: true). Ensuite, dans HA, activer l\u2019int\u00e9gration MQTT Discovery : Zigbee2MQTT d\u00e9tectera automatiquement ses \u00e9quipements et les publiera dans HA  . Exemple de configuration  configuration.yaml  de Zigbee2MQTT :</li> </ul> <pre><code>homeassistant:\n  mqtt:\n    base_topic: zigbee2mqtt\n    server: 'mqtt://192.168.1.100:1883'\n  serial:\n    port: /dev/ttyUSB0\n</code></pre> <ul> <li> <p>Cela cr\u00e9e des entit\u00e9s HA pr\u00eates \u00e0 l\u2019emploi via MQTT Discovery  .</p> </li> <li> <p>Shelly  : ces appareils Wi-Fi prennent en charge MQTT nativement. Dans l\u2019interface Web de chaque Shelly, allez dans  Connectivity &gt; MQTT, et activez l\u2019MQTT (mettez l\u2019IP du broker HA, et les identifiants MQTT). Ainsi les messages de l\u2019appareil (temp\u00e9rature, relais, etc.) seront publi\u00e9s sur  shellies//.... Home Assistant poss\u00e8de \u00e9galement une int\u00e9gration native pour Shelly (bas\u00e9e sur CoAP/WebSocket) qui \u00e9vite MQTT. Mais dans un homelab o\u00f9 l\u2019on pr\u00f4ne l\u2019auto-h\u00e9bergement, on peut utiliser MQTT pour centraliser la communication. Par exemple, le capteur Shelly Relee coupera un circuit quand HA envoie  cmnd/shelly1-abc123/relay/0 = OFF  sur MQTT. <li> <p>ESPHome  : on programme les microcontr\u00f4leurs ESP32/ESP8266 via  ESPHome  (firmware custom). Les appareils ESPHome communiquent id\u00e9alement en API native (port 6053) avec HA  , mais ils supportent aussi MQTT (en ajoutant un bloc  mqtt:  dans leur YAML). Pour les int\u00e9grer, utilisez l\u2019int\u00e9gration  ESPHome  dans HA. Soit le device est d\u00e9couvert automatiquement (MDNS), soit vous l\u2019ajoutez manuellement en fournissant son IP/port  . Exemple de configuration ESPHome (light_switch.yaml) :</p> </li> <pre><code>esphome:\n  name: light_switch\nwifi:\n  ssid: \"...\"\n  password: \"...\"\nmqtt:\n  broker: 192.168.1.100\n  username: mqtt_user\n  password: mqtt_pass\nswitch:\n  - platform: gpio\n    pin: GPIO5\n    name: \"Lampe Salon\"\n</code></pre> <ul> <li> <p>Ici l\u2019ESP send ses \u00e9tats sur MQTT (homeassistant/light/lamp_salon/state  etc.), mais on peut aussi utiliser l\u2019API native d\u2019ESPHome qui \u00e9vite MQTT.</p> </li> <li> <p>Tasmota  : si vous avez flash\u00e9 des modules Sonoff en Tasmota, l\u2019int\u00e9gration HA Tasmota via MQTT est simple. Activez MQTT dans la page de configuration web de l\u2019appareil : entrez l\u2019adresse du broker et les identifiants (il vaut mieux cr\u00e9er un utilisateur HA d\u00e9di\u00e9 pour Tasmota)  . Sur l\u2019int\u00e9gration HA  Tasmota, s\u00e9lectionnez votre device d\u00e9couvert (ou ajoutez-le manuellement). Les \u00e9quipements Tasmota (relais, capteurs, interrupteurs) seront expos\u00e9s comme entit\u00e9s HA (switch, light, sensor\u2026). Par exemple,  cmnd/tasmota123/POWER  contr\u00f4le le relais, et  stat/tasmota123/POWER  contient l\u2019\u00e9tat  . Notez que  SetOption19 0  active la d\u00e9couverte automatique dans HA.</p> </li> </ul>"},{"location":"domotique/homeassistant/#securite-mqtt","title":"S\u00e9curit\u00e9 MQTT","text":"<ul> <li> <p>Authentification  : N\u2019utilisez jamais un broker ouvert sans mot de passe\u202f! Configurez des utilisateurs MQTT et attribuez-leur des permissions limit\u00e9es. Par exemple, un utilisateur \u00ab homeassistant \u00bb avec les droits pour tous les sujets. Sur Mosquitto, d\u00e9finissez un fichier  passwd  via  mosquitto_passwd  et assurez-vous d\u2019ajouter  allow_anonymous false  dans  mosquitto.conf. Home Assistant lui-m\u00eame peut g\u00e9n\u00e9rer un user/s\u00e9same pour l\u2019int\u00e9gration  .</p> </li> <li> <p>Chiffrement TLS  : pour chiffrer les donn\u00e9es MQTT (m\u00eame en LAN, c\u2019est recommand\u00e9 en zone non fiable), g\u00e9n\u00e9rez un certificat SSL et configurez Mosquitto en TLS (ports 8883). Dans Home Assistant, activez la validation du certificat sur la connexion MQTT  . Vous pouvez aussi forcer l\u2019usage de MQTT over WebSockets (port 8083) avec TLS.</p> </li> <li> <p>Pare-feu  : de la m\u00eame fa\u00e7on que pour HA, isolez l\u2019acc\u00e8s MQTT par VLAN ou pare-feu. Par exemple, n\u2019autorisez que votre serveur HA \u00e0 se connecter au broker (ou mieux : utilisez des ACL Mosquitto pour restreindre les topics/clients).</p> </li> </ul>"},{"location":"domotique/homeassistant/#tableaux-de-bord-lovelace-et-automatisations","title":"Tableaux de bord Lovelace et automatisations","text":"<p>Home Assistant dispose d\u2019une interface web de  tableaux de bord (Lovelace)  tr\u00e8s flexible. Un dashboard Lovelace est compos\u00e9 de  cartes  (cards) pr\u00e9configur\u00e9es ou personnalisables  . On peut afficher capteurs, graphiques, commandes de lumi\u00e8res, cam\u00e9ras, etc. Par exemple, les cartes  Sensor,  History Graph,  Entities,  Media Player, ou  Energy  sont natives  .</p> <ul> <li> <p>Ajouter des cartes  : en mode \u00e9dition, cliquez sur \u201cAjouter une carte\u201d, puis choisissez le type (ex.  Card type -&gt; Entities), s\u00e9lectionnez des entit\u00e9s, et sauvegardez  . Vous pouvez aussi cr\u00e9er des vues (onglets) et regrouper des cartes avec des dispositions (verticale, grille). Chaque carte peut avoir des actions au clic (d\u00e9finir  tap_action,  hold_action) et des conditions de visibilit\u00e9 (uniquement si un capteur x est vrai)  .</p> </li> <li> <p>Cartes personnalis\u00e9es  : via le gestionnaire de communaut\u00e9s HACS (Home Assistant Community Store), on peut installer des  custom cards  (d\u00e9velopp\u00e9es par la communaut\u00e9). Par exemple,  Mini Graph Card  (graphiques avanc\u00e9s),  Button Card  (boutons riches en ic\u00f4nes),  Gauge Card, etc. Ces cartes offrent plus de flexibilit\u00e9 visuelle que les cartes de base. Apr\u00e8s installation HACS, il suffit d\u2019ajouter la ressource (JS) et de d\u00e9clarer  type: \"custom:mini-graph-card\"  dans votre YAML de tableau de bord.</p> </li> <li> <p>Automatisations  : Home Assistant propose un \u00e9diteur visuel pour cr\u00e9er des automatismes (\u201cAutomations\u201d) ou on peut directement \u00e9diter le YAML. Chaque automatisation combine des  d\u00e9clencheurs  (triggers),  conditions(facultatives) et  actions. Par exemple, pour une alerte de mouvement :</p> </li> </ul> <pre><code>trigger:\n  platform: state\n  entity_id: binary_sensor.detecteur_mouvement\n  to: \"on\"\ncondition:\n  condition: state\n  entity_id: person.jean\n  state: \"not_home\"\naction:\n  - service: camera.snapshot\n    target: { entity_id: camera.camera_salon }\n    data: { filename: '/config/www/snapshot_{{now().timestamp()}}.jpg' }\n  - service: telegram_bot.send_photo\n    data:\n      file: '/config/www/snapshot_{{now().timestamp()}}.jpg'\n      caption: 'Mouvement d\u00e9tect\u00e9 !'\n</code></pre> <ul> <li>Ici, on capture un clich\u00e9 via  camera.snapshot  et on envoie la photo sur Telegram (bot HA)  . Ce snippet illustre comment combiner YAML et services HA pour des sc\u00e9narios de s\u00e9curit\u00e9. De m\u00eame, l\u2019interface graphique permet d\u2019encha\u00eener ces \u00e9tapes sans \u00e9crire une ligne, avec des choix menus pour les entit\u00e9s et actions.</li> </ul>"},{"location":"domotique/homeassistant/#cas-dusage-concrets-en-homelab","title":"Cas d\u2019usage concrets en homelab","text":"<ul> <li> <p>Surveillance (cam\u00e9ras, capteurs) : int\u00e9grez des cam\u00e9ras IP (ONVIF, MJPEG) avec l\u2019int\u00e9gration  Camera  de HA. Coupl\u00e9e \u00e0 un d\u00e9tecteur de mouvement (capteur PIR, NTGR24, etc.) ou \u00e0 un add-on NVR comme  Frigate  ou  MotionEye, vous pouvez d\u00e9clencher des actions. Par exemple, d\u00e8s que le capteur signale un mouvement, Home Assistant peut prendre une photo (camera.snapshot) et l\u2019envoyer par notification (Telegram, email)  . On peut aussi lancer un enregistrement vid\u00e9o court. Des solutions de d\u00e9tection  on-device  (Frigate bas\u00e9 sur DeepStack ou TensorFlow) sont opensource et s\u2019int\u00e8grent \u00e0 HA pour r\u00e9duire les faux positifs.</p> </li> <li> <p>S\u00e9curit\u00e9 : HA peut s\u2019int\u00e9grer \u00e0 des alarmes DIY ou syst\u00e8mes plus \u00e9labor\u00e9s. Par exemple, relier un capteur door/window (via Zigbee/ MQTT) et d\u00e9clencher une sir\u00e8ne ou envoyer une alerte. On peut utiliser  Notifations Telegram  pour recevoir des alertes s\u00e9curis\u00e9es. L\u2019automatisation ci-dessus en est un exemple. De plus, l\u2019application mobile HA (iOS/Android) peut d\u00e9tecter votre pr\u00e9sence (via GPS ou r\u00e9seau), permettant de n\u2019alerter que si personne n\u2019est \u00e0 la maison.</p> </li> <li> <p>Pilotage \u00e9nerg\u00e9tique  : la fonction  Energy  de HA offre un tableau de bord pour suivre la conso \u00e9lectrique, la prod solaire, etc. On y int\u00e8gre des capteurs de courant (par ex. Shelly EM, S0-compteurs) et on lie un onduleur PV (via son API) pour suivre la production. Home Assistant fournit des graphiques d\u2019autoconsommation et permet d\u2019automatiser la charge/decharge d\u2019une batterie si disponible  . On peut aussi piloter les thermostats (par ex. thermostat DIY via ESPHome ou Nest/Starling via int\u00e9gration) et les prises intelligentes (Shelly, Tasmota) pour optimiser la charge. Par exemple, couper automatiquement certains appareils en cas de surconso ou allumer le chauffage quand le tarif heures creuses d\u00e9marre. Les donn\u00e9es collect\u00e9es alimentent le tableau de bord d\u2019\u00e9nergie  , avec analyse des tendances et pr\u00e9visions.</p> </li> <li> <p>Sauvegarde / restauration  : en homelab, il est crucial de backuper r\u00e9guli\u00e8rement. Home Assistant propose des snapshots complets (config, base de donn\u00e9es, add-ons) via l\u2019UI (\u00ab  Settings &gt; Syst\u00e8me &gt; Backups  \u00bb) ou l\u2019int\u00e9gration  Backup. On peut automatiser la cr\u00e9ation de ces snapshots gr\u00e2ce \u00e0 une automation programmant  backup.create  la nuit  . Stockez ces fichiers sur un partage r\u00e9seau ou Nextcloud (via add-on Samba/SSHFS). Pour restaurer, utilisez l\u2019UI de restauration (ou remontez l\u2019archive dans un nouvel HA). Exemple d\u2019automatisation YAML pour un backup quotidien \u00e0 3h du mat  : <pre><code>automation:\n  - alias: \"Backup HA tous les jours 3h\"\n    trigger:\n      - platform: time\n        at: \"03:00:00\"\n    action:\n      - service: backup.create\n</code></pre> Toutes ces solutions n\u2019utilisent que des logiciels open source et auto-h\u00e9berg\u00e9s. En combinant Home Assistant avec MQTT, Zigbee2MQTT, Tasmota/ESPHome, on cr\u00e9e un \u00e9cosyst\u00e8me puissant et s\u00e9curis\u00e9, id\u00e9al pour un homelab de passionn\u00e9 en cybers\u00e9curit\u00e9.</p> </li> </ul>"},{"location":"domotique/surveillance/","title":"Vid\u00e9osurveillance open\u2010source pour homelab","text":"<p>Dans un environnement homelab (auto-h\u00e9berg\u00e9) orient\u00e9 cybers\u00e9curit\u00e9, on privil\u00e9gie des solutions de vid\u00e9osurveillance respectueuses de la vie priv\u00e9e, l\u00e9g\u00e8res et extensibles. Trois solutions courantes sont  Frigate,  Shinobi  et  ZoneMinder. Elles sont toutes open source et permettent de traiter localement les flux cam\u00e9ras. Ce document compare leurs performances, facilit\u00e9 de configuration, compatibilit\u00e9 mat\u00e9rielle et capacit\u00e9s de d\u00e9tection d\u2019objet par IA. Il d\u00e9taille \u00e9galement des cas d\u2019usage typiques (surveillance p\u00e9rim\u00e9trique, d\u00e9tection d\u2019intrusion, alertes), l\u2019utilisation des acc\u00e9l\u00e9rateurs mat\u00e9riels Google Coral (USB, M.2/PCIe), le choix de cam\u00e9ras (ONVIF/RTSP, PoE/Wi\u2011Fi, qualit\u00e9 vs budget) et donne des instructions d\u2019installation (Docker, LXC), d\u2019int\u00e9gration avec Home Assistant et d\u2019optimisation (zones, objets, alertes).</p>"},{"location":"domotique/surveillance/#1-comparaison-frigate-vs-shinobi-vs-zoneminder","title":"1. Comparaison : Frigate vs Shinobi vs ZoneMinder","text":"<p>TABLEAU</p> <p>En r\u00e9sum\u00e9,  Frigate  est centr\u00e9 sur la d\u00e9tection d\u2019objets IA locale avec acc\u00e9l\u00e9rateur (Coral, GPU)  , son interface est sobre mais l\u2019int\u00e9gration dans Home Assistant est native.  Shinobi  mise sur la performance brute et la flexibilit\u00e9 (gestion multi\u2011flux, clustering, support CUDA/Jetson)  .  ZoneMinder  est la solution historique ultra\u2011complet, plus lourde en CPU et requ\u00e9rant des extensions pour l\u2019IA  , mais proposant de riches possibilit\u00e9s de configuration de d\u00e9tection, d\u2019alertes et de stockage. Les choix d\u00e9pendent des besoins : Frigate pour une d\u00e9tection IA simple et rapide, Shinobi pour une solution l\u00e9g\u00e8re et \u00e9volutive, Zoneminder pour un contr\u00f4le granulaire et des sc\u00e9narios d\u2019entreprise.</p>"},{"location":"domotique/surveillance/#2-cas-dusage-typiques-en-homelab-securite","title":"2. Cas d\u2019usage typiques en homelab (s\u00e9curit\u00e9)","text":"<p>Dans un homelab d\u2019ing\u00e9nieur cybers\u00e9curit\u00e9, la vid\u00e9osurveillance sert avant tout \u00e0  s\u00e9curiser les locaux  et  compl\u00e9ter la d\u00e9tection d\u2019intrusion. Exemples de sc\u00e9narios :</p> <ul> <li> <p>Surveillance p\u00e9rim\u00e9trique  : cam\u00e9ras ext\u00e9rieures mont\u00e9es sur la fa\u00e7ade, grillage ou cl\u00f4ture, couvrant l\u2019acc\u00e8s principal. D\u00e9tection de mouvements d\u2019intrus en bordure de propri\u00e9t\u00e9 (personne, v\u00e9hicule). On d\u00e9clenche des alertes lors d\u2019un franchissement de zone dangereuse (zone interdite). Frigate/Shinobi d\u00e9clencheront une notification push ou e-mail quand un humain/voiture entre dans la zone surveill\u00e9e.</p> </li> <li> <p>Cam\u00e9ras int\u00e9rieures (zone sensible)  : surveillance de la salle serveurs ou local r\u00e9seau. D\u00e9tection de pr\u00e9sence non autoris\u00e9e (biom\u00e9trique ou objet suspect comme sac \u00e0 dos). Par exemple, si quelqu\u2019un essaie de p\u00e9n\u00e9trer dans l\u2019armoire serveur, on veut une  alerte imm\u00e9diate  (via Telegram/HA). Les syst\u00e8mes peuvent associer la d\u00e9tection d\u2019intrusion \u00e0 des scripts (verrouillage, sir\u00e8ne, enregistrement vid\u00e9o).</p> </li> <li> <p>D\u00e9tection d\u2019intrusion g\u00e9n\u00e9rale  : lorsqu\u2019un capteur de mouvement (ou un IDS r\u00e9seau) signale une anomalie, la cam\u00e9ra valide visuellement. Frigate, Shinobi ou ZoneMinder peuvent \u00eatre coupl\u00e9s \u00e0 des capteurs tiers (via MQTT/API) : une alerte de type  pr\u00e9sence  ne d\u00e9clenche un enregistrement ou une alarm qu\u2019apr\u00e8s v\u00e9rification video (ex: un objet humain d\u00e9tect\u00e9 par IA). On peut aussi utiliser la reconnaissance de plaque ou de visage pour identifier les v\u00e9hicules/personnes autoris\u00e9s.</p> </li> <li> <p>Alertes cybers\u00e9curit\u00e9 via liaison physique  : en cas d\u2019alarme logicielle (attaque, ransomware) on peut d\u00e9clencher une br\u00e8ve surveillance renforc\u00e9e (par exemple augmenter la sensibilit\u00e9 ou prendre en compte de nouveaux objets comme \u00ab\u2009tentative d\u2019ouverture de baie\u2009\u00bb si un capteur magn\u00e9tique s\u2019active). L\u2019id\u00e9e est de corr\u00e9ler les \u00e9v\u00e9nements r\u00e9seau avec la vid\u00e9o.</p> </li> <li> <p>R\u00e9tention vid\u00e9o et preuves  : configurer un enregistrement 24/7 (ou circulaire) et extraire automatiquement les rushes quand un \u00e9v\u00e9nement IA survient  . Par exemple, Frigate peut ne conserver que les segments vid\u00e9o o\u00f9 un \u00ab objet voulu \u00bb (personne, v\u00e9hicule, animal, etc.) a \u00e9t\u00e9 d\u00e9tect\u00e9, r\u00e9duisant le stockage.</p> </li> </ul> <p>Ces usages sont g\u00e9r\u00e9s via des r\u00e9glages de zones et d\u2019objets pour limiter les fausses alertes (ex : configurer Frigate pour n\u2019alerter que si une personne entre dans l\u2019all\u00e9e de parking)  . Le syst\u00e8me peut alors envoyer des notifications (e-mail, webhook, MQTT, Home Assistant) en cas d\u2019intrusion d\u00e9tect\u00e9e. Par exemple, Frigate envoie chaque d\u00e9tection via MQTT pour s\u2019int\u00e9grer facilement dans HA  .</p>"},{"location":"domotique/surveillance/#3-google-coral-edge-tpu-accelerateur-ia","title":"3. Google Coral Edge TPU : acc\u00e9l\u00e9rateur IA","text":"<p>Le  Coral Edge TPU  de Google est un coprocesseur ASIC sp\u00e9cialis\u00e9 pour l\u2019inf\u00e9rence d\u2019IA (TensorFlow Lite) en p\u00e9riph\u00e9rie. Il existe en trois formats :  USB,  mini PCIe  (format court) et  M.2 E-key  (format 2230). Tous contiennent le m\u00eame circuit Edge TPU, capable d\u2019environ  4 TOPS  (t\u00e9ra-op\u00e9rations int8) chacun, soit environ  400 images/sec  sur un mod\u00e8le MobileNet V2, avec ~2 W de consommation  . La version M.2 \u201cDual Edge TPU\u201d int\u00e8gre deux de ces co-processeurs en parall\u00e8le (8 TOPS total)  . Concr\u00e8tement, cela permet de traiter de nombreux flux vid\u00e9os en temps r\u00e9el sans charger le CPU, par exemple Frigate peut d\u00e9passer 100 fps par flux avec un Coral tout en gardant un usage CPU tr\u00e8s bas  .</p> <ul> <li> <p>Version USB  : dongle USB3.0 (Type-C) facile \u00e0 installer sur tout syst\u00e8me Linux/Windows/Mac (dont Raspberry Pi)  . Tendance au prototypage ou usage ponctuel.  Limitation  : sous forte charge ou sur certains Linux (RPi), on pr\u00e9f\u00e8re souvent le M.2/PCIe pour la stabilit\u00e9 et la vitesse.</p> </li> <li> <p>Versions M.2 / Mini PCIe  : modules internes que l\u2019on ins\u00e8re sur une carte m\u00e8re offrant un slot M.2 E-key ou mini PCIe. Ils n\u00e9cessitent le driver PCIe d\u2019EdgeTPU (guide Coral) et offrent le m\u00eame Edge TPU, voire en double (8 TOPS)  . Ces versions sont recommand\u00e9es pour les d\u00e9ploiements permanents : \u00ab la version M.2 ou mini PCIe est conseill\u00e9e plut\u00f4t que USB, car l\u2019USB est plut\u00f4t pour le prototypage, pas la production \u00bb  . Par exemple, dans Docker Frigate on passe le p\u00e9riph\u00e9rique Coral avec  --device /dev/bus/usb:/dev/bus/usb  pour l\u2019USB, ou  /dev/apex_0:/dev/apex_0  pour le PCIe (cf. docs)  .</p> </li> </ul> <p>Avantages  : l\u2019Edge TPU acc\u00e9l\u00e8re massivement l\u2019inf\u00e9rence sans alourdir le CPU ni consommer beaucoup d\u2019\u00e9nergie. On peut alors multiplier les d\u00e9tections IA (personnes, v\u00e9hicules\u2026) sur plusieurs cam\u00e9ras simultan\u00e9es. Par exemple, deux Edge TPU permettent de doubler les inf\u00e9rences (en parall\u00e8le ou en pipeline)  . Dans Frigate ou Shinobi, un Coral supprime le goulot d\u2019\u00e9tranglement CPU de l\u2019analyse vid\u00e9o, rendant la d\u00e9tection d\u2019objets IA  vraiment temps r\u00e9el  . Sans acc\u00e9l\u00e9rateur, on peut utiliser un GPU Nvidia (TensorRT) ou Hailo, mais le Coral est simple, peu co\u00fbteux (~$60) et largement support\u00e9.</p>"},{"location":"domotique/surveillance/#4-choix-des-cameras-compatibles-onvif-rtsp-poe-wifi","title":"4. Choix des cam\u00e9ras compatibles (ONVIF, RTSP, PoE, Wi\u2011Fi)","text":"<p>Pour un homelab, on pr\u00e9f\u00e8re des cam\u00e9ras  IP ouvertes  supportant ONVIF ou RTSP pour une int\u00e9gration facile dans Frigate/Shinobi/ZoneMinder. Quelques recommandations :</p> <ul> <li> <p>Protocole  : ONVIF assure l\u2019interop\u00e9rabilit\u00e9 (d\u00e9couverte, PTZ) tandis que RTSP fournit le flux vid\u00e9o. Frigate/Shinobi pr\u00e9f\u00e8rent des flux H.264+AAC (bons pour la compatibilit\u00e9)  . Shinobi, par exemple, g\u00e8re HTTP/HTTPS, RTP/RTSP et ONVIF nativement  , ce qui le rend compatible avec la plupart des cam\u00e9ras IP. ZoneMinder accepte tout protocole support\u00e9 (MJPEG, FFmpeg, ONVIF, RTSP\u2026)  .</p> </li> <li> <p>Qualit\u00e9 d\u2019image  : privil\u00e9giez un capteur de taille moyenne/grande (1/2\u201d, 1/1.8\u201d) pour de bonnes performances en faible luminosit\u00e9. Exemples courants : cam\u00e9ras Dahua/Hikvision ou leurs r\u00e9pliques (Amcrest, Hikvision \u201cColorVu\u201d pour vision de nuit en couleur) offrent 2\u20134 MP et bonne IR  . Les cam\u00e9ras 4K (8 MP) peuvent sembler attractives, mais attention : la documentation Frigate note que les mod\u00e8les 4K, notamment chez Reolink, posent souvent probl\u00e8me (flux instable) et conseille de rester sur du 5 MP ou moins  .</p> </li> <li> <p>Budget vs gamme :</p> <ul> <li> <p>Entr\u00e9e de gamme (&lt; 50 \u20ac)  : cam\u00e9ras Wi\u2011Fi (Tapo, TP-Link, Wyze, etc.) ou PoE bon march\u00e9 (Reolink 4 MP, Dahua basique). Elles font le job en jour, mais ont souvent un SoC limit\u00e9 (faible perf. en nuit). Certains mod\u00e8les Wi\u2011Fi n\u00e9cessitent d\u2019activer RTSP manuellement (ex : cam\u00e9ras Ezviz par d\u00e9faut d\u00e9sactivent RTSP).</p> </li> <li> <p>Milieu de gamme (50\u2013150 \u20ac)  : cam\u00e9ras PoE \u00e0 capteur plus grand (Reolink 5 MP, Amcrest 4 MP, HIK-IP 4 MP), avec support ONVIF complet. Elles combinent image correcte, fiabilit\u00e9 r\u00e9seau et aisance d\u2019installation (PoE).</p> </li> <li> <p>Haut de gamme (150 \u20ac+)  : Axis, Bosch, Dahua 4K, etc. Offrent du 4K ou plus, meilleur capteur, optical zoom/PTZ, mais \u00e0 co\u00fbt \u00e9lev\u00e9. Pour un homelab, ce niveau n\u2019est pas toujours n\u00e9cessaire.</p> </li> </ul> </li> <li> <p>Connectivit\u00e9  : la  PoE  (Power over Ethernet) est \u00e0 privil\u00e9gier pour les cam\u00e9ras fixes ext\u00e9rieures/int\u00e9rieures : elle fournit courant et donn\u00e9es sur un seul c\u00e2ble, garantissant stabilit\u00e9 et reach (jusqu\u2019\u00e0 100 m). L\u2019Ethernet d\u00e9di\u00e9 r\u00e9duit les risques d\u2019interf\u00e9rences. Le Wi\u2011Fi peut \u00eatre utilis\u00e9 pour des cam\u00e9ras mobiles ou en repeater, mais il est  moins fiable  (pertes de paquets)  . Frigate d\u00e9conseille d\u2019ailleurs les cam\u00e9ras Wi\u2011Fi pour cette raison. Des cam\u00e9ras 4G LTE existent (D-link, Reolink Argus) mais restent ch\u00e8res et d\u00e9pendent d\u2019un op\u00e9rateur.</p> </li> <li> <p>Recommandations sp\u00e9cifiques  : les docs Frigate sugg\u00e8rent les marques  Dahua, Hikvision, Amcrest  pour leur fiabilit\u00e9 et leurs sous-flux multiples  . Par exemple :</p> <ul> <li> <p>Dahua IPC-T5xx  (5 MP, PoE) ou  Hikvision DS-2CD  (4 MP, PoE) pour ext\u00e9rieur, IR.</p> </li> <li> <p>Amcrest 4 MP  (PoE) ou  Reolink RLC-410/RLC-811  (PoE) comme bons compromis qualit\u00e9/prix.</p> </li> <li> <p>Cam\u00e9ra Wi-Fi int\u00e9rieur  : Tapo C200 (1080p) ou Reolink E1 Pro (2K) \u2013 pratique mais limiter le nombre.</p> </li> <li> <p>\u00c9viter les cam\u00e9ras \u00ab cloud only \u00bb (Nest, Arlo, etc.) sans RTSP/ONVIF, car elles ne fonctionnent pas sur Frigate/Shinobi.</p> </li> </ul> </li> </ul> <p>En r\u00e9sum\u00e9, choisissez des cam\u00e9ras H.264 compatible ONVIF/RTSP avec des connecteurs RJ45 PoE pour la fiabilit\u00e9. V\u00e9rifiez la documentation pour activer RTSP si n\u00e9cessaire. Un tableau r\u00e9capitulatif peut \u00eatre utilis\u00e9 :</p> <p>TABLEAU</p> <p>(Les prix sont indicatifs en 2025. Les marques cit\u00e9es sont exemplaires \u2013 de nombreuses autres respectent les normes ONVIF/RTSP.)</p>"},{"location":"domotique/surveillance/#5-installation-et-optimisation","title":"5. Installation et optimisation","text":"<p>D\u00e9ploiement (Docker/LXC)  \u2013 Frigate et Shinobi proposent des images Docker officielles. L\u2019installation recommand\u00e9e pour Frigate est via Docker Compose (voir exemple ci-dessous)  . On passe les volumes (config, stockage m\u00e9dias) et les p\u00e9riph\u00e9riques pour le TPU : par exemple  --device /dev/bus/usb:/dev/bus/usb  pour une cl\u00e9 Coral USB, ou  /dev/apex_0:/dev/apex_0  pour un Coral PCIe  . On n\u2019oublie pas les ports (Frigate : 8554 pour RTSP, 8971 pour l\u2019interface). En LXC (Proxmox ou autre), le passage d\u2019USB/Passthrough est d\u00e9licat ; beaucoup optent pour une VM si on veut utiliser un Coral USB. Shinobi a aussi une image Docker (requiert Node, MySQL). ZoneMinder est souvent install\u00e9 via paquet Linux (apt install zoneminder) ou Docker (image dlandon/Zoneminder), ce qui simplifie la mise \u00e0 jour.</p> <p>Exemple d\u2019extrait docker-compose.yml pour Frigate  (GHCR stable)  :</p> <pre><code>services:\n  frigate:\n    image: ghcr.io/blakeblackshear/frigate:stable\n    container_name: frigate\n    privileged: true          # n\u00e9cessaire pour le passthrough\n    shm_size: \"512mb\"\n    devices:\n      - /dev/bus/usb:/dev/bus/usb    # Coral USB\n      - /dev/apex_0:/dev/apex_0      # Coral PCIe (voir guide)\n      - /dev/dri/renderD128:/dev/dri/renderD128  # HW accel Intel\n    volumes:\n      - /path/to/config:/config    # config YML de Frigate\n      - /path/to/media:/media/frigate\n      - type: tmpfs\n        target: /tmp/cache\n        tmpfs:\n          size: 1000000000  # cache en RAM (1GB)\n    ports:\n      - \"8554:8554\"   # RTSP entr\u00e9es\n      - \"8971:8971\"   # UI web\n    environment:\n      FRIGATE_RTSP_PASSWORD: \"mon_motdepasse\"\n</code></pre> <p>On adaptera bien s\u00fbr les chemins, devices et ressources selon son mat\u00e9riel.</p> <p>Int\u00e9gration Home Assistant  \u2013 Frigate dispose d\u2019un add-on officiel (\u00ab Frigate NVR \u00bb) \u00e0 installer depuis le d\u00e9p\u00f4t GitHub de Blake Blackshear. Cet add-on facilite le lancement sans Docker manuel et cr\u00e9e automatiquement les entit\u00e9s cam\u00e9ra et d\u00e9tection dans HA. Notez toutefois les limites de HA OS : le stockage m\u00e9dia r\u00e9seau n\u2019\u00e9tait pas support\u00e9 avant 2023, et les GPU externes (Nvidia, AMD) ne sont pas reconnus dans les add-ons  . En contrepartie, l\u2019int\u00e9gration fournie (bas\u00e9e MQTT) expose tous les \u00e9v\u00e9nements de d\u00e9tection, les entit\u00e9s de classes d\u2019objets d\u00e9tect\u00e9s et les snapshots/vignettes. Pour Shinobi/ZM, on utilise le plugin  zmeventnotifications  (pour ZM) ou  Home Assistant Integration pour Shinobi  afin de r\u00e9cup\u00e9rer les alertes via MQTT ou webhook.</p> <p>Optimisation des d\u00e9tections  \u2013 Pour \u00e9viter les fausses alertes, configurez dans le fichier de configuration :</p> <ul> <li> <p>Zones de d\u00e9tection  : d\u00e9limitez par polygones les zones critiques (ex : all\u00e9e, porte) et ne d\u00e9clenchez une alerte que si un objet p\u00e9n\u00e8tre cette zone  . Par exemple, dans Frigate on liste  required_zones  sous  alerts  pour n\u2019alerter qu\u2019\u00e0 l\u2019int\u00e9rieur de \u201cjardin_entier\u201d  .</p> </li> <li> <p>Filtrage par objet  : sp\u00e9cifiez les classes d\u2019objets \u00e0 surveiller dans chaque zone. On peut par exemple n\u2019autoriser que les  person  dans la zone entr\u00e9e et les  car  sur l\u2019all\u00e9e de garage  . Seuls ces objets d\u00e9clencheront les enregistrements/alertes dans leurs zones respectives.</p> </li> <li> <p>D\u00e9tection de mouvement l\u00e9g\u00e8re  : Frigate/Shinobi effectuent d\u2019abord une d\u00e9tection de mouvement basique pour limiter la charge (n\u2019appellent l\u2019analyse IA que si du mouvement est d\u00e9tect\u00e9)  . Ajustez la sensibilit\u00e9 (bruit, objets animaliers) via les masques ou seuils.</p> </li> <li> <p>R\u00e9tention et lecture  : configurez la r\u00e9tention vid\u00e9o bas\u00e9e sur les d\u00e9tections (ex : n\u2019enregistrer en totalit\u00e9 qu\u2019en cas de d\u00e9tection et conserver X jours). Par d\u00e9faut Frigate peut enregistrer 24/7, mais on optimise en conservant uniquement les \u00e9v\u00e9nements importants  .</p> </li> </ul> <p>Enfin, reliez les alertes IA aux notifications : Frigate envoie les \u00e9v\u00e9nements (classe de l\u2019objet, minuteur) via MQTT  , permettant \u00e0 Home Assistant d\u2019envoyer des push (Telegram, e-mail, mobile) ou de d\u00e9clencher des automatismes (sir\u00e8ne, envoi d\u2019une vue cam\u00e9ra).</p>"},{"location":"domotique/zigbee/","title":"Comparatif Zigbee2MQTT, ZHA et deCONZ","text":"<ul> <li> <p>Zigbee2MQTT  fonctionne comme un service autonome (souvent en conteneur ou add-on) reliant le coordinator Zigbee \u00e0 un  broker  MQTT. Il n\u00e9cessite donc une infrastructure MQTT (Mosquitto, etc.) s\u00e9par\u00e9e. Cet outil offre une interface Web riche (cartographie du r\u00e9seau, logs) et s\u2019int\u00e8gre \u00e0 Home Assistant via MQTT ou une int\u00e9gration d\u00e9di\u00e9e. Il prend en charge une  liste \u00e9tendue d\u2019appareils  Zigbee et de coordinateurs (cl\u00e9s CC* ou autres)  . Une fois configur\u00e9, il est  tr\u00e8s stable  . En contrepartie, sa configuration est plus \u201cgeek\u201d (fichier YAML, mise \u00e0 jour de firmware manuelle) et il ajoute une couche MQTT qui peut l\u00e9g\u00e8rement compliquer le debug.</p> </li> <li> <p>ZHA (Zigbee Home Automation)  est l\u2019int\u00e9gration Zigbee native de Home Assistant. Elle fonctionne \u201cnativement\u201d dans HA sans add-on externe  , ce qui lib\u00e8re des ressources (pas de conteneur suppl\u00e9mentaire) et garantit une r\u00e9activit\u00e9 maximale. ZHA utilise la biblioth\u00e8que  zigpy  et g\u00e8re directement de nombreux coordinateurs (ConBee, Sonoff, CC2652, HUSBZB-1, etc.). Elle supporte un bon nombre de p\u00e9riph\u00e9riques courants (IKEA, Aqara, Xiaomi, Osram, etc.), bien que Zigbee2MQTT en supporte souvent  encore plus  . L\u2019installation et l\u2019ajout de capteurs se font via l\u2019interface HA (pas de ligne de commande), simplifiant la prise en main.</p> </li> <li> <p>deCONZ/Phoscon  est la solution de Dresden Elektronik autour du dongle ConBee/RaspBee. Elle fonctionne comme un add-on ou service s\u00e9par\u00e9 (et n\u00e9cessite l\u2019interface Phoscon). L\u2019environnement requis est une cl\u00e9 ConBee (ou module RaspBee) et l\u2019addon Phoscon. L\u2019interface graphique de Phoscon permet d\u2019associer et g\u00e9rer les appareils Zigbee sans toucher \u00e0 du code, ce qui est  tr\u00e8s accessible aux d\u00e9butants  . DeConz a une bonne compatibilit\u00e9 avec les appareils courants (notamment IKEA et Philips Hue) mais d\u00e9pend du timing de mises \u00e0 jour de Dresden. Sur les forums, ZHA et Zigbee2MQTT sont souvent cit\u00e9s comme plus r\u00e9actifs ou r\u00e9guli\u00e8rement mis \u00e0 jour que deCONZ, mais ce dernier reste  tr\u00e8s stable pour les mat\u00e9riels support\u00e9s.</p> </li> </ul> <p>Sur l\u2019aspect  OTA (firmwares)  : Zigbee2MQTT propose son propre m\u00e9canisme d\u2019OTA (via MQTT) o\u00f9 les capteurs Zigbee peuvent demander une mise \u00e0 jour et on pilote l\u2019op\u00e9ration par des topics  . ZHA dispose d\u00e9sormais d\u2019une interface OTA int\u00e9gr\u00e9e dans HA : elle d\u00e9tecte les updates disponibles (pour quelques marques majeures) et propose un bouton de mise \u00e0 jour dans l\u2019interface  . En revanche, ZHA ne t\u00e9l\u00e9charge pas automatiquement les firmwares ; il faut fournir manuellement les fichiers (sauf pour IKEA/OSRAM/Sonoff activ\u00e9s par d\u00e9faut)  . DeCONZ g\u00e8re l\u2019OTA via un plugin OTAU o\u00f9 l\u2019on charge soi-m\u00eame les images de mise \u00e0 jour (fichiers fournis par le fabricant) et on lance l\u2019update depuis l\u2019interface Phoscon  .</p> <p>En r\u00e9sum\u00e9,  Zigbee2MQTT  est plus \u201cpower user\u201d (n\u00e9cessite MQTT) mais extr\u00eamement complet (plus de devices support\u00e9s, flexibilit\u00e9 Node-RED, etc.)  .  ZHA  est plus int\u00e9gr\u00e9 et simple (\u00ab natif \u00bb HA, pas d\u2019addon)  .  deCONZ  brille par sa simplicit\u00e9 d\u2019installation et son interface graphique, au prix d\u2019une compatibilit\u00e9 hardware restreinte (principalement ConBee) et de d\u00e9pendances sur Phoscon.</p>"},{"location":"domotique/zigbee/#materiel-compatible-dongles-et-coordinateurs-zigbee","title":"Mat\u00e9riel compatible : dongles et coordinateurs Zigbee","text":"<p>Voici quelques coordinateurs Zigbee populaires, leur chipset, et points forts/faibles :</p> <p>TABLEAU</p>"},{"location":"domotique/zigbee/#cas-dusage-concrets-en-homelab","title":"Cas d\u2019usage concrets en homelab","text":"<p>Dans un  homelab s\u00e9curis\u00e9, on privil\u00e9gie souvent les \u00e9quipements auto-h\u00e9berg\u00e9s et locaux. Zigbee s\u2019y pr\u00eate bien pour l\u2019IoT non critique (\u00e9clairage, capteurs) tout en offrant un r\u00e9seau s\u00e9par\u00e9 du Wi\u2011Fi. Par exemple :</p> <ul> <li> <p>Automatisation de l\u2019\u00e9clairage  : ampoules et rubans LED Philips Hue, Osram/LEDVANCE ou Ikea TR\u00c5DFRI, pilot\u00e9s depuis Home Assistant. Un simple bouton Zigbee (Xiaomi/Aqara) peut commander un groupe de lampes via une automatisation HA, \u00e9vitant la d\u00e9pendance aux cloud des fabricants.</p> </li> <li> <p>Capteurs environnementaux  : capteurs de temp\u00e9rature/humidit\u00e9, qualit\u00e9 d\u2019air (Sonoff, Xiaomi, etc.), plac\u00e9s dans les racks ou pi\u00e8ces critiques. Leur remont\u00e9e locale dans HA permet des alertes (ex : \u00ab r\u00e9servoir trop chaud \u00bb) ou pilotage de ventilateurs/cooling.</p> </li> <li> <p>S\u00e9curit\u00e9 p\u00e9rim\u00e9trique  : d\u00e9tecteurs d\u2019ouverture de portes/fen\u00eatres (Aqara, Sonoff) et d\u00e9tecteurs de mouvement Zigbee peuvent alimenter un syst\u00e8me d\u2019alarme local. Gr\u00e2ce aux  endpoints  Zigbee, on peut lier des d\u00e9tecteurs directement \u00e0 un sir\u00e8ne Zigbee, ou faire remonter les \u00e9v\u00e9nements instantan\u00e9ment dans HA, sans cloud tiers.</p> </li> <li> <p>Gestion d\u2019\u00e9nergie  : prises intelligentes Zigbee (Ikea, Tuya/Sonoff avec MCUs Zigbee, etc.) mesurent la consommation et peuvent couper l\u2019alimentation en cas d\u2019anomalie. On peut ainsi surveiller l\u2019\u00e9nergie du lab (serveurs, NAS) et archiver les donn\u00e9es localement.</p> </li> <li> <p>Autres usages  : automatisation d\u2019ouverture/fermeture de volets roulants, contr\u00f4le de pompes \u00e0 eau en syst\u00e8mes de sauvegarde, etc. L\u2019important est que tout reste dans l\u2019infrastructure r\u00e9seau priv\u00e9e (Home Assistant auto-h\u00e9berg\u00e9), en coh\u00e9rence avec la politique de s\u00e9curit\u00e9 du homelab.</p> </li> </ul>"},{"location":"domotique/zigbee/#topologie-du-reseau-zigbee-et-bonnes-pratiques","title":"Topologie du r\u00e9seau Zigbee et bonnes pratiques","text":"<p>Zigbee est un r\u00e9seau  maill\u00e9  (mesh) 2,4 GHz. Seul le  coordinateur  (stick USB) amorce le r\u00e9seau. Les autres appareils se r\u00e9partissent en deux r\u00f4les :</p> <ul> <li> <p>Routeurs (mains)  : tous les appareils toujours sous tension (prises, ampoules, onduleurs Zigbee, etc.) servent de  routeurs/relais. Ils \u00e9tendent la port\u00e9e en relayant les messages. Certains appareils (comme certains plugs ou lampes) sont de meilleurs routeurs que d\u2019autres (voir documentation), il est conseill\u00e9 d\u2019en disperser dans la maison.</p> </li> <li> <p>End devices (piles)  : capteurs sur piles (d\u00e9tecteurs, t\u00e9l\u00e9commandes, etc.) communiquent g\u00e9n\u00e9ralement uniquement avec leur parent. Ils ne relaient pas le trafic.</p> </li> </ul> <p>Une bonne topologie consiste \u00e0 placer le coordinateur au centre du maillage (par exemple sur un long c\u00e2ble USB isol\u00e9) et \u00e0 s\u2019assurer de plusieurs  routeurs strategic  r\u00e9partis g\u00e9ographiquement. Par exemple :</p> <pre><code>    Coordinateur (dongle USB) \u2013\u2013 Router A \u2013\u2013 Sensor 1 (pile)\n                 |                     \n                 +\u2013 Router B \u2013\u2013 Router C \u2013\u2013 Light 1 (maison haut)\n                                  +\u2013 Light 2\n                                 Sensor 2 (sous-sol)\n</code></pre> <p>Quelques conseils cl\u00e9s :</p> <ul> <li> <p>Port\u00e9e &amp; antenne  : utiliser une antenne externe ou un dongle avec PA (+20 dBm) augmente drastiquement la port\u00e9e (ex. CC2652P vs CC2652RB). \u00c9viter de brancher directement le dongle sur un port USB 3.0 du serveur (les ports USB 3 g\u00e9n\u00e8rent beaucoup de bruit RF). Placer le dongle sur un  c\u00e2ble USB 2.0 prolongateur blind\u00e9  \u00e9loign\u00e9 du PC pour r\u00e9duire les interf\u00e9rences  .</p> </li> <li> <p>Canal radio  : Zigbee a 16 canaux (11-26) dans le 2,4 GHz. Choisir un canal \u00e9loign\u00e9 du Wi\u2011Fi est crucial. En pratique, on pr\u00e9f\u00e8re souvent  canal 25  (en UE) ou  20  (aux US) car ils recouvrent moins les bandes Wi\u2011Fi courantes  . Changer de canal Zigbee apr\u00e8s que les appareils sont appair\u00e9s demande de les r\u00e9appairer, donc le configurer d\u00e8s le d\u00e9but est important  .</p> </li> <li> <p>\u00c9viter l\u2019interf\u00e9rence  : les r\u00e9seaux Wi\u2011Fi (2,4 GHz), Bluetooth et m\u00eame certains dongles USB sans fil peuvent brouiller Zigbee. Si instable, tester de bouger le r\u00e9seau Wi\u2011Fi \u00e0 d\u2019autres canaux (1, 6, 11) et garder le Zigbee \u00e9loign\u00e9 des sources bruyantes. Les documentations recommandent explicitement d\u2019exp\u00e9rimenter l\u2019orientation/position du dongle USB  : parfois tourner la cl\u00e9 ou la d\u00e9caler de quelques centim\u00e8tres am\u00e9liore le lien.</p> </li> <li> <p>Maillage  : un coordinateur seul ne g\u00e9rera qu\u2019un nombre limit\u00e9 d\u2019appareils (~30\u00d7; ZHA/zigpy limite \u00e0 32 enfants directs)  . Pour supporter de nombreux capteurs, on comptabilise les routeurs. Par exemple, un CC2652 (32 enfants direct - 3 routeurs = 29) + 3 routeurs CC2530 (16 p\u00e9riph\u00e9riques chacun) permet th\u00e9oriquement ~77 appareils au total  . En pratique, il faut multiplier les routeurs pour atteindre un grand nombre de devices et couvrir toutes les zones.</p> </li> <li> <p>Firmware  : Mettre \u00e0 jour le firmware du coordinateur et des routeurs (si possible). Par exemple, flasher un CC2652P (Sonoff ou TubeZB) avec le dernier Z-Stack permet d\u2019atteindre +20 dBm. Certains routeurs DIY (CC2530/CC2531) peuvent \u00eatre reflash\u00e9s pour am\u00e9liorer leur r\u00f4le de r\u00e9p\u00e9teur.</p> </li> </ul> <p>En respectant ces bonnes pratiques, on obtient un maillage Zigbee robuste et sans \u201ctrou\u201d de couverture. Les utilisateurs rapportent que des sticks bien plac\u00e9s (avec antenne, loin de l\u2019USB3) peuvent alimenter de grands r\u00e9seaux (&gt;60 capteurs) sans perte de paquet  .</p>"},{"location":"infrastructure/lxc-vs-vm/","title":"LXC vs VM : choix techniques selon les cas d\u2019usage","text":""},{"location":"infrastructure/lxc-vs-vm/#introduction","title":"Introduction","text":"<p>Dans le domaine de l\u2019infrastructure informatique, deux approches de virtualisation coexistent : les  machines virtuelles (VM)  d\u2019un c\u00f4t\u00e9, et les  conteneurs Linux (LXC, Docker)  de l\u2019autre. Ces technologies permettent toutes deux d\u2019isoler des environnements et des applications, mais selon des m\u00e9canismes diff\u00e9rents. Le choix entre d\u00e9ployer un service dans une VM ou dans un conteneur d\u00e9pend de nombreux crit\u00e8res (performances, s\u00e9curit\u00e9, maintenance) et du cas d\u2019usage vis\u00e9. En tant que professionnel IT sp\u00e9cialis\u00e9 en cybers\u00e9curit\u00e9, il est crucial de comprendre ces diff\u00e9rences afin de choisir la solution la plus adapt\u00e9e \u00e0 chaque contexte (h\u00e9bergement web, laboratoire de test, base de donn\u00e9es sensible, etc.). Machines virtuelles vs conteneurs :  Sur le plan technique, une machine virtuelle embarque un syst\u00e8me d\u2019exploitation complet pour chaque instance, tournant sur un hyperviseur, tandis qu\u2019un conteneur partage le noyau de l\u2019OS h\u00f4te et isole seulement l\u2019espace utilisateur et les processus  . Ce contraste est illustr\u00e9 ci-dessus : chaque VM inclut son propre OS invit\u00e9, alors que plusieurs conteneurs peuvent partager un m\u00eame OS h\u00f4te. En cons\u00e9quence, les VM offrent une isolation tr\u00e8s forte (\u00e9mulation du mat\u00e9riel, OS ind\u00e9pendant), au prix d\u2019une  surcharge de ressources  plus importante. Les conteneurs, eux, sont bien plus  l\u00e9gers  et rapides, puisque l\u2019OS n\u2019est pas dupliqu\u00e9 \u2013 mais cette efficacit\u00e9 s\u2019accompagne d\u2019une isolation moins compl\u00e8te, toutes les instances partageant le m\u00eame noyau. Il ne s\u2019agit donc pas de solutions concurrentes \u00e0 sens unique : chacune a ses avantages et ses inconv\u00e9nients qu\u2019il convient d\u2019examiner en d\u00e9tail  .</p> <p>Dans cet article, nous d\u00e9finirons d\u2019abord bri\u00e8vement ces deux technologies (VM et conteneurs LXC, en \u00e9voquant aussi Docker/Kubernetes), puis nous comparerons leurs m\u00e9rites selon plusieurs crit\u00e8res  cl\u00e9s  \u2013  performance,  s\u00e9curit\u00e9,  maintenance  \u2013 avant d\u2019illustrer  les cas d\u2019usage types  pour un professionnel de la cybers\u00e9curit\u00e9.</p>"},{"location":"infrastructure/lxc-vs-vm/#machines-virtuelles-vm-virtualisation-complete","title":"Machines virtuelles (VM) : virtualisation compl\u00e8te","text":"<p>Une  machine virtuelle  est un environnement isol\u00e9 qui \u00e9mule un mat\u00e9riel complet via un hyperviseur (par ex. KVM, VMware ESXi, Hyper-V). Chaque VM tourne avec  son propre syst\u00e8me d\u2019exploitation  invit\u00e9, ind\u00e9pendant de l\u2019h\u00f4te. En pratique, une VM fonctionne comme un \u201cordinateur dans l\u2019ordinateur\u201d : le syst\u00e8me invit\u00e9 croit tourner sur du mat\u00e9riel r\u00e9el, ignorant qu\u2019il est simul\u00e9 par l\u2019hyperviseur  .</p> <p>Atouts des VM :  L\u2019isolation est maximale, car chaque VM est totalement s\u00e9par\u00e9e des autres et de l\u2019OS h\u00f4te au niveau kernel. Cela permet d\u2019ex\u00e9cuter  n\u2019importe quel OS  (Linux, Windows, BSD\u2026) et des configurations logicielles vari\u00e9es sur une m\u00eame machine physique  . Cette ind\u00e9pendance garantit une excellente compatibilit\u00e9 applicative : tout logiciel qui fonctionne sur un serveur physique fonctionnera de m\u00eame dans une VM \u00e9quivalente, sans modifications  . Les VM conviennent bien aux applications legacy ou sp\u00e9cifiques, par exemple un ancien syst\u00e8me n\u00e9cessitant un kernel particulier ou un OS obsol\u00e8te \u2013 cas dans lesquels la VM est souvent la seule option viable  . De plus, les VM offrent la  sauvegarde facile  d\u2019un serveur entier sous forme d\u2019image unique (snapshot), pouvant \u00eatre d\u00e9plac\u00e9e ou dupliqu\u00e9e ais\u00e9ment pour de la reprise d\u2019activit\u00e9 ou des tests  . Enfin, c\u00f4t\u00e9 s\u00e9curit\u00e9, la forte isolation limite les interactions : un crash ou une compromission dans une VM a peu de chances d\u2019affecter l\u2019h\u00f4te ou les autres VM.</p> <p>Inconv\u00e9nients des VM :  Cette isolation et flexibilit\u00e9 ont un co\u00fbt en  ressources. Chaque VM embarquant un OS complet, elle consomme plus de CPU, de RAM et d\u2019espace disque qu\u2019un conteneur \u00e9quivalent  . Les VMs sont  lourdes  (plusieurs gigaoctets souvent) et d\u00e9marrent plus lentement qu\u2019un conteneur, car il faut booter tout un OS invit\u00e9  . Malgr\u00e9 les progr\u00e8s de la virtualisation mat\u00e9rielle (hyperviseurs optimis\u00e9s), il y a une l\u00e9g\u00e8re surcharge par rapport \u00e0 l\u2019ex\u00e9cution directe sur l\u2019h\u00f4te \u2013 typiquement une VM est un peu plus lente qu\u2019un processus natif, m\u00eame si la diff\u00e9rence est aujourd\u2019hui minime gr\u00e2ce aux optimisations CPU (VT-x/AMD-V)  . Enfin, utiliser des VM multiplie les environnements \u00e0  maintenir  : chaque machine virtuelle n\u00e9cessite une administration propre, des mises \u00e0 jour syst\u00e8me, des correctifs de s\u00e9curit\u00e9, etc., ce qui complexifie la gestion lorsqu\u2019on en d\u00e9ploie beaucoup  . Nous reviendrons sur ces aspects de maintenance.</p>"},{"location":"infrastructure/lxc-vs-vm/#conteneurs-linux-lxc-et-ecosysteme-des-conteneurs","title":"Conteneurs Linux (LXC) et \u00e9cosyst\u00e8me des conteneurs","text":"<p>Un  conteneur Linux  (LXC) est une forme de virtualisation au niveau du syst\u00e8me d\u2019exploitation. Plut\u00f4t que d\u2019\u00e9muler un mat\u00e9riel complet, un conteneur s\u2019appuie sur le  noyau Linux de l\u2019h\u00f4te  et isole uniquement les applications dans un espace d\u00e9di\u00e9 (via les  namespaces  et  cgroups  du kernel). On parle souvent de  virtualisation l\u00e9g\u00e8re  : un conteneur n\u2019inclut pas de kernel propre, il partage celui de l\u2019h\u00f4te, ce qui le rend beaucoup plus  l\u00e9ger et rapide  \u00e0 instancier qu\u2019une VM  . On obtient ainsi un environnement clos (avec son syst\u00e8me de fichiers, ses processus et utilisateurs isol\u00e9s), mais d\u00e9pendant du noyau de l\u2019h\u00f4te.</p> <p>Atouts des conteneurs LXC :  La  performance  et l\u2019efficience sont les principaux avantages. Comme il n\u2019y a pas besoin de dupliquer un OS entier, la consommation en CPU, m\u00e9moire et stockage est drastiquement r\u00e9duite par rapport \u00e0 une VM  . On peut faire tourner un grand nombre de conteneurs sur le m\u00eame serveur physique (haute densit\u00e9) l\u00e0 o\u00f9 seulement quelques VM lourdes auraient tenu  . Le d\u00e9marrage est quasi-instantan\u00e9 (quelques secondes tout au plus), contre plusieurs dizaines de secondes pour booter un OS complet dans une VM  . Les applications tournent quasiment \u00e0 la vitesse native du fait de l\u2019absence d\u2019hyperviseur interm\u00e9diaire \u2013 on parle de performance  near-native  . LXC permet ainsi de  maximiser l\u2019utilisation des ressources  mat\u00e9rielles disponibles en mutualisant le kernel entre instances. Par ailleurs, les conteneurs offrent une isolation suffisante pour que des services diff\u00e9rents cohabitent sans interf\u00e9rer : chaque conteneur a ses propres processus, r\u00e9seau, utilisateurs, montages\u2026 Une faille ou un crash dans un conteneur ne doit pas affecter les autres (en th\u00e9orie), ce qui assure une certaine stabilit\u00e9 globale  . En somme, LXC constitue un moyen flexible et peu gourmand d\u2019isoler des applications ou micro-services sur un m\u00eame h\u00f4te. Il est par exemple courant d\u2019h\u00e9berger  plusieurs sites websur un seul serveur en cr\u00e9ant un conteneur par site, assurant \u00e0 chacun son environnement d\u00e9di\u00e9 en termes de ressources et de configuration  .</p> <p>Limitations des conteneurs LXC :  L\u2019isolation, bien que r\u00e9elle (via l\u2019isolement des processus), reste inf\u00e9rieure \u00e0 celle d\u2019une VM compl\u00e8te. Puisque tous les conteneurs partagent le noyau unique de l\u2019h\u00f4te, une compromission de ce noyau aurait un impact sur  tous  les conteneurs. En cas de vuln\u00e9rabilit\u00e9 kernel ou de mauvaise configuration de s\u00e9curit\u00e9, un attaquant pourrait \u00e9chapper au conteneur et acc\u00e9der \u00e0 l\u2019h\u00f4te  . En pratique, un conteneur LXC non privil\u00e9gi\u00e9 offre une bonne s\u00e9curit\u00e9, mais il n\u2019atteint pas le niveau d\u2019\u00e9tanch\u00e9it\u00e9 d\u2019une VM o\u00f9 le kernel lui-m\u00eame est isol\u00e9  . Autre contrainte : les conteneurs sont  d\u00e9pendants de l\u2019OS h\u00f4te. On ne peut ex\u00e9cuter dans un conteneur Linux  que  des applications compatibles Linux. Il est impossible de faire tourner un OS diff\u00e9rent (pas de Windows dans un LXC sur noyau Linux, par exemple), ni un kernel divergent \u2013 les applications qui n\u00e9cessitent un module kernel sp\u00e9cial ou une version pr\u00e9cise du noyau imposent alors d\u2019utiliser une VM  . Enfin, l\u2019isolation \u00e9tant au niveau user-space, certaines applications qui s\u2019attendent \u00e0 \u00eatre en environnement \u00ab bare-metal \u00bb ou qui font des appels syst\u00e8me \u00e9tendus peuvent mal se comporter en conteneur. Il arrive aussi qu\u2019on n\u2019ait pas un  contr\u00f4le total du syst\u00e8me  dans un conteneur (acc\u00e8s limit\u00e9 aux param\u00e8tres noyau, aux p\u00e9riph\u00e9riques hardware, etc.), ce qui rend cette solution inad\u00e9quate pour certains besoins bas niveau  .</p> <p>Docker et autres \u00e9cosyst\u00e8mes de conteneurs :  Il existe d\u2019autres solutions de conteneurisation b\u00e2ties sur le m\u00eame principe d\u2019OS partag\u00e9s.  Docker  est la plateforme de conteneurs la plus populaire. Techniquement, Docker utilise aussi les fonctionnalit\u00e9s LXC/namespace du noyau Linux pour isoler les applications, mais il apporte tout un \u00e9cosyst\u00e8me (format d\u2019images standard, registres d\u2019images Docker Hub, outils CLI, API) facilitant le packaging et le d\u00e9ploiement d\u2019applications en conteneur  . Docker se concentre sur des conteneurs applicatifs \u00e9ph\u00e9m\u00e8res (un processus principal par conteneur, approche  microservices). De son c\u00f4t\u00e9,  LXC/LXD  est souvent qualifi\u00e9 de conteneur \u00ab syst\u00e8me \u00bb : on peut y faire tourner plusieurs processus comme dans une petite VM, et il est couramment utilis\u00e9 sur des plateformes comme Proxmox ou LXD pour h\u00e9berger des services de mani\u00e8re persistante. En r\u00e9sum\u00e9, Docker et LXC reposent sur des bases similaires, la diff\u00e9rence tenant plus aux outils et \u00e0 la philosophie (Docker pour la portabilit\u00e9 des apps et le DevOps, LXC pour administrer des environnements proches de la VM). \u00c0 noter que Docker a initialement utilis\u00e9 LXC en back-end, avant de d\u00e9velopper son propre moteur (libcontainer). Aujourd\u2019hui, les deux coexistent et r\u00e9pondent \u00e0 des besoins voisins.</p> <p>Enfin, l\u2019essor des conteneurs a entra\u00een\u00e9 l\u2019apparition d\u2019outils d\u2019orchestration. En production, lorsqu\u2019on g\u00e8re des dizaines ou centaines de conteneurs, souvent r\u00e9partis sur plusieurs serveurs, des orchestrateurs comme  Kubernetes  sont indispensables. Kubernetes automatise le d\u00e9ploiement, la mont\u00e9e en charge, la r\u00e9partition et la r\u00e9silience des conteneurs \u00e0 grande \u00e9chelle  . Il s\u2019int\u00e8gre bien avec Docker ou LXC pour assurer, par exemple, que si un conteneur tombe, un autre est relanc\u00e9 ailleurs, ou pour \u00e9quilibrer la charge entre instances. Des outils comme  Portainer  offrent \u00e9galement une interface web unifi\u00e9e pour g\u00e9rer les environnements de conteneurs (Docker, Swarm, Kubernetes, Podman, etc.) de mani\u00e8re s\u00e9curis\u00e9e et centralis\u00e9e  . L\u2019adoption de ces plateformes fait souvent partie des consid\u00e9rations techniques lorsqu\u2019on choisit les conteneurs : pour les exploiter au mieux en entreprise, il faut pr\u00e9voir la gestion centralis\u00e9e et la s\u00e9curit\u00e9 de ces multiples instances.</p> <p>Apr\u00e8s ce tour d\u2019horizon, comparons plus en d\u00e9tail les VM et les conteneurs sur les aspects cruciaux de  performance, de  s\u00e9curit\u00e9  et de  maintenance, avant de voir dans quels cas d\u2019usage l\u2019un pr\u00e9vaut sur l\u2019autre.</p>"},{"location":"infrastructure/lxc-vs-vm/#performance-efficacite-et-densite","title":"Performance, efficacit\u00e9 et densit\u00e9","text":"<p>Du point de vue des performances pures et de l\u2019empreinte sur les ressources, les conteneurs ont l\u2019avantage sur les VM dans la plupart des sc\u00e9narios. Voici les principales diff\u00e9rences :</p> <ul> <li> <p>Surcharge et utilisation des ressources :  Une VM n\u00e9cessite de faire tourner un OS complet par instance, ce qui consomme une portion non n\u00e9gligeable de CPU, m\u00e9moire et stockage juste pour le syst\u00e8me invit\u00e9. \u00c0 l\u2019inverse, un conteneur mutualise le noyau et n\u2019embarque que les biblioth\u00e8ques et fichiers strictement n\u00e9cessaires \u00e0 l\u2019application. R\u00e9sultat : les conteneurs sont  beaucoup plus l\u00e9gers  \u2013 mesur\u00e9s en quelques Mo pour une image de base \u2013 l\u00e0 o\u00f9 une VM se compte en Go  . Un conteneur utilise moins de RAM et met moins de pression sur le host, car il \u00e9vite la redondance du syst\u00e8me d\u2019exploitation  . En pratique, on \u00e9value souvent l\u2019overhead d\u2019un conteneur \u00e0 seulement quelques pourcents (proche des perfs natives), alors qu\u2019une VM a un surco\u00fbt un peu sup\u00e9rieur d\u00fb \u00e0 l\u2019hyperviseur et aux duplications d\u2019OS. Les progr\u00e8s r\u00e9cents (para-virtualisation, VirtIO, etc.) ont r\u00e9duit ce surco\u00fbt VM \u00e0 un niveau tr\u00e8s acceptable  , mais il demeure l\u00e9g\u00e8rement plus \u00e9lev\u00e9 que pour un conteneur Linux \u00e9quivalent.</p> </li> <li> <p>Densit\u00e9 et scalabilit\u00e9 :  Gr\u00e2ce \u00e0 leur l\u00e9g\u00e8ret\u00e9, les conteneurs permettent une  haute densit\u00e9  de d\u00e9ploiement. On peut lancer  bien plus d\u2019instances  sur un m\u00eame h\u00f4te physique compar\u00e9 aux VM  . Par exemple, un serveur de 32 Go de RAM pourrait h\u00e9berger des dizaines de conteneurs applicatifs, alors qu\u2019il ne supporterait peut-\u00eatre que 4 ou 5 VM classiques. Cette densit\u00e9 est particuli\u00e8rement utile pour les architectures \u00e0 microservices ou les environnements o\u00f9 l\u2019on segmente beaucoup d\u2019applications. L\u2019efficacit\u00e9 des conteneurs en fait un choix privil\u00e9gi\u00e9 pour maximiser l\u2019utilisation d\u2019un hardware co\u00fbteux ou pour g\u00e9rer des pics de charge en multipliant rapidement les instances.  C\u00f4t\u00e9 VM, la densit\u00e9 est limit\u00e9e par la m\u00e9moire et le CPU qu\u2019il faut allouer \u00e0 chaque machine virtuelle (souvent plusieurs Go de RAM chacun). On r\u00e9serve typiquement des ressources fixes par VM, ce qui rend le scaling moins fluide. Les VM offrent cependant d\u2019autres leviers (overcommitment de ressources, migration \u00e0 chaud entre h\u00f4tes\u2026) pour la scalabilit\u00e9, mais ils restent plus lourds \u00e0 g\u00e9rer qu\u2019une flottille de conteneurs orchestr\u00e9s.</p> </li> <li> <p>D\u00e9marrage et r\u00e9activit\u00e9 :  Un autre atout majeur des conteneurs est leur  rapidit\u00e9 de d\u00e9marrage. Lancer un nouveau conteneur LXC ou Docker prend g\u00e9n\u00e9ralement  quelques secondes  tout au plus, car il s\u2019agit simplement de d\u00e9marrer un ou quelques processus dans l\u2019espace isol\u00e9 (le kernel \u00e9tant d\u00e9j\u00e0 l\u00e0). Au contraire, d\u00e9marrer une VM implique de booter tout un OS invit\u00e9 (chargement du kernel, des services syst\u00e8me, etc.), ce qui prend plus de temps \u2013 parfois  plusieurs minutes  selon le syst\u00e8me  . Cette diff\u00e9rence se fait sentir lorsqu\u2019il faut scaler vite (par exemple monter de 5 \u00e0 50 instances sous forte charge) : les conteneurs permettront de r\u00e9pondre quasiment en temps r\u00e9el, l\u00e0 o\u00f9 des VM pourraient mettre un certain temps \u00e0 \u00eatre toutes op\u00e9rationnelles. Dans des environnements de CI/CD ou de test o\u00f9 l\u2019on cr\u00e9e et d\u00e9truit fr\u00e9quemment des environnements isol\u00e9s, la v\u00e9locit\u00e9 des conteneurs acc\u00e9l\u00e8re \u00e9norm\u00e9ment les cycles. Les VM sont plut\u00f4t privil\u00e9gi\u00e9es pour des charges de longue dur\u00e9e en production, o\u00f9 le temps de boot importe moins que la stabilit\u00e9 continue.</p> </li> </ul> <p>En somme, pour  l\u2019efficience et la performance, avantage aux conteneurs dans la plupart des cas. Les conteneurs LXC consomment peu et d\u00e9livrent des performances proches du natif gr\u00e2ce \u00e0 l\u2019absence d\u2019abstraction mat\u00e9rielle lourde  . Les VM offrent des performances tout \u00e0 fait honorables (notamment avec l\u2019aide de la virtualisation mat\u00e9rielle) mais subissent un l\u00e9ger co\u00fbt d\u2019isolation en plus. Cela se justifie pleinement pour des besoins de s\u00e9curit\u00e9 ou de compatibilit\u00e9, mais si l\u2019objectif premier est d\u2019ex\u00e9cuter  le plus d\u2019applications possible par serveur  avec le moins de surco\u00fbt, la containerisation est souvent le choix technique gagnant  .</p>"},{"location":"infrastructure/lxc-vs-vm/#isolation-et-securite","title":"Isolation et s\u00e9curit\u00e9","text":"<p>L\u2019isolation  des environnements est un crit\u00e8re essentiel, notamment en cybers\u00e9curit\u00e9. Ici, les machines virtuelles ont g\u00e9n\u00e9ralement la r\u00e9putation d\u2019offrir une s\u00e9curit\u00e9 plus robuste que les conteneurs, du fait de leur s\u00e9paration plus franche. Examinons les diff\u00e9rences :</p> <ul> <li> <p>Couche d\u2019isolation :  Une VM forme une  sandbox compl\u00e8te au niveau mat\u00e9riel. Chaque VM a son kernel propre et ne voit le mat\u00e9riel que via l\u2019hyperviseur. Si un attaquant compromise une VM, il reste enferm\u00e9 dans ce syst\u00e8me invit\u00e9 \u2013 il lui faut ensuite casser l\u2019hyperviseur pour atteindre l\u2019h\u00f4te, ce qui est difficile et rare. En revanche, un conteneur repose sur le  m\u00eame noyau  que l\u2019h\u00f4te. Par cons\u00e9quent, une compromission du noyau Linux de l\u2019h\u00f4te signifie la chute de toutes les protections entre conteneurs. Un conteneur mal configur\u00e9 (par exemple lanc\u00e9 en mode privil\u00e9gi\u00e9, ou avec des permissions larges) peut donner \u00e0 un processus malveillant une voie pour escalader ses privil\u00e8ges jusqu\u2019\u00e0 l\u2019h\u00f4te.  En bref :  les VM offrent une isolation plus forte au niveau OS, tandis que les conteneurs ont une isolation au niveau processus moins \u00e9tanche  . C\u2019est pourquoi  pour des charges non fiables ou expos\u00e9es(serveurs en zone DMZ, applications potentiellement vuln\u00e9rables), on recommande souvent de privil\u00e9gier des VM, ajoutant une couche de s\u00e9curit\u00e9 en profondeur  . Un expert Proxmox r\u00e9sume :  \u201csi la s\u00e9curit\u00e9 est une pr\u00e9occupation, les VM sont mieux isol\u00e9es\u2026 Un service web public devrait id\u00e9alement tourner dans sa propre VM\u201d  . De fait, les VM sont souvent utilis\u00e9es comme  sandbox  pour du code non fiable (analyse de malware, honeypots\u2026), car m\u00eame si le conteneur Linux a fait de grands progr\u00e8s en isolation (namespaces, seccomp, AppArmor/SELinux, etc.), le risque d\u2019\u00e9vasion de conteneur existe toujours plus que l\u2019\u00e9vasion d\u2019hyperviseur.</p> </li> <li> <p>Surface d\u2019attaque et vuln\u00e9rabilit\u00e9s :  Le revers de la m\u00e9daille est que les VM ont une surface d\u2019attaque plus large en termes de code : un hyperviseur est complexe, de m\u00eame que les pilotes virtualis\u00e9s. Des vuln\u00e9rabilit\u00e9s dans KVM, VMware ou VirtualBox peuvent (rarement) permettre des  VM escape  \u00e9galement. Toutefois, ces composants \u00e9tant plus petits que tout un kernel Linux, et souvent mieux cloisonn\u00e9s, le consensus est que l\u2019isolation VM est un peu plus robuste \u00ab par d\u00e9faut \u00bb. Les conteneurs d\u00e9pendent enti\u00e8rement de la s\u00e9curit\u00e9 du kernel h\u00f4te : or le kernel Linux est \u00e9norme (des millions de lignes de code  ), donc potentiellement riche en failles exploitables si pas \u00e0 jour. En pratique, pour s\u00e9curiser des conteneurs, on s\u2019appuie sur des  best practices  : conteneurs non privil\u00e9gi\u00e9s, restriction des capacit\u00e9s Linux (capabilities), utilisation de SECCOMP pour limiter les appels syst\u00e8me autoris\u00e9s, etc.  . Bien appliqu\u00e9es, ces mesures rendent les conteneurs assez s\u00fbrs pour de nombreux usages. Mais un administrateur prudent consid\u00e8rera qu\u2019un conteneur reste une isolation  logicielle  moins fiable qu\u2019une virtualisation  mat\u00e9rielle  via hyperviseur. Ainsi,  les charges de travail multi-locataires critiques  (ex : cloud public, h\u00e9bergement de clients isol\u00e9s) auront tendance \u00e0 fonctionner sur VM pour \u00e9viter qu\u2019une br\u00e8che chez un locataire n\u2019affecte les autres  . A contrario, dans un environnement ma\u00eetris\u00e9 o\u00f9 tous les conteneurs sont sous le contr\u00f4le de la m\u00eame \u00e9quipe, le niveau de s\u00e9curit\u00e9 du container peut \u00eatre jug\u00e9 suffisant, ce qui permet de b\u00e9n\u00e9ficier de son efficience.</p> </li> <li> <p>Permissions et interactions :  Dans un conteneur, on peut choisir tr\u00e8s finement les ressources expos\u00e9es : monter ou non certains volumes, autoriser l\u2019acc\u00e8s r\u00e9seau ou pas, limiter la m\u00e9moire, CPU, etc. Cette  granularit\u00e9  permet de r\u00e9duire l\u2019impact d\u2019une compromission (par exemple, un conteneur compromis n\u2019aura acc\u00e8s qu\u2019aux fichiers mont\u00e9s et aux ports r\u00e9seau qu\u2019on lui a donn\u00e9s). De plus, les processus dans un conteneur tournent souvent avec un utilisateur restreint, et l\u2019isolation par  namespace  les emp\u00eache de voir les autres processus syst\u00e8mes  . C\u2019est un atout des conteneurs : ils poussent \u00e0 un paradigme de moindre privil\u00e8ge par d\u00e9faut. Dans une VM, par contre, si un attaquant entre avec un compte root dans la VM, il a compromis l\u2019int\u00e9gralit\u00e9 de cette VM (mais pas l\u2019hyperviseur). Donc l\u2019impact horizontal est moindre, mais l\u2019impact vertical dans la VM est total. En cybers\u00e9curit\u00e9, on combine souvent ces approches : par exemple faire tourner chaque service critique dans un conteneur d\u00e9di\u00e9 (pour cloisonner les processus entre eux),  et  isoler ces conteneurs dans une VM sp\u00e9cifique (pour ajouter la barri\u00e8re hyperviseur vis-\u00e0-vis de l\u2019h\u00f4te principal). Cette approche  d\u00e9fense en profondeur  assure qu\u2019une faille applicative donne acc\u00e8s au conteneur, mais doit encore franchir la VM pour atteindre le reste du syst\u00e8me.</p> </li> <li> <p>Images et supply chain security :  Un point souvent moins discut\u00e9 mais important : la s\u00e9curit\u00e9 des  images de conteneurs. Docker et LXC encouragent l\u2019utilisation d\u2019images pr\u00e9construites (disponibles sur Docker Hub, etc.). Cela facilite \u00e9norm\u00e9ment le d\u00e9ploiement, mais introduit un risque de confiance : une image publique peut contenir des malwares ou des portes d\u00e9rob\u00e9es si elle n\u2019est pas officielle. Utiliser des images non v\u00e9rifi\u00e9es constitue une menace (ex. crypto-mineur cach\u00e9 dans une image MongoDB trafiqu\u00e9e). En environnement de production critique, il faut donc maintenir un registre d\u2019images de confiance et mettre \u00e0 jour r\u00e9guli\u00e8rement ces images pour corriger les failles applicatives. Avec des VM, ce risque se pose diff\u00e9remment : on installe un OS \u00e0 partir d\u2019une ISO officielle, puis des logiciels \u2013 le processus est plus contr\u00f4l\u00e9, m\u00eame s\u2019il peut y avoir des backdoors dans des templates VM aussi. En somme, l\u2019approche conteneur impose une vigilance sur la  cha\u00eene d\u2019approvisionnement logicielle(DevSecOps, scan d\u2019images) pour garantir l\u2019int\u00e9grit\u00e9 et la mise \u00e0 jour des composants embarqu\u00e9s.</p> </li> </ul> <p>En conclusion sur la s\u00e9curit\u00e9 : les  VM l\u2019emportent pour une isolation maximale  et sont privil\u00e9gi\u00e9es pour ex\u00e9cuter des \u00e9l\u00e9ments non fiables ou fortement cloisonn\u00e9s  . Les  conteneurs  offrent une isolation logicielle suffisamment solide pour de nombreux cas, surtout si l\u2019on suit les bonnes pratiques de configuration ; ils pr\u00e9sentent une surface d\u2019attaque un peu plus large au niveau noyau partag\u00e9, mais restent  s\u00e9par\u00e9s  des autres conteneurs par les m\u00e9canismes Linux. En cybers\u00e9curit\u00e9, on consid\u00e8re souvent les conteneurs adapt\u00e9s aux environnements contr\u00f4l\u00e9s et homog\u00e8nes (services internes, microservices cloud natifs), tandis que les VM restent incontournables pour des besoins d\u2019isolement strict (par exemple, \u00e9muler un poste utilisateur infect\u00e9, h\u00e9berger des services de diff\u00e9rents clients, ou se pr\u00e9munir d\u2019exploits kernel). Notons qu\u2019id\u00e9alement, les deux peuvent \u00eatre combin\u00e9s pour cumuler avantages : par exemple d\u00e9ployer des conteneurs \u00e0 l\u2019int\u00e9rieur de VM (beaucoup de stacks Kubernetes en production fonctionnent sur des n\u0153uds eux-m\u00eames isol\u00e9s dans des VM cloud, afin d\u2019ajouter la couche de s\u00e9curit\u00e9 hyperviseur en plus de l\u2019orchestrateur).</p>"},{"location":"infrastructure/lxc-vs-vm/#maintenance-et-gestion-operationnelle","title":"Maintenance et gestion op\u00e9rationnelle","text":"<p>Le troisi\u00e8me axe de comparaison concerne la  maintenance, l\u2019administration au quotidien et les efforts n\u00e9cessaires pour garder l\u2019infrastructure \u00e0 jour et stable. Il y a ici des diff\u00e9rences significatives entre VM et conteneurs :</p> <ul> <li> <p>Mises \u00e0 jour syst\u00e8me :  Avec des machines virtuelles, chaque VM comporte un OS complet qu\u2019il faut  maintenir individuellement. Autrement dit, si vous avez 10 VM Ubuntu, vous devrez appliquer les mises \u00e0 jour de s\u00e9curit\u00e9 sur les 10 syst\u00e8mes s\u00e9par\u00e9ment (que ce soit manuellement ou via un outil type Ansible). Il en va de m\u00eame pour les backups : chaque VM a son disque virtuel qu\u2019il faut sauvegarder, surveiller, etc. Les conteneurs simplifient cet aspect en mutualisant l\u2019OS :  seul l\u2019OS de l\u2019h\u00f4te  a besoin d\u2019\u00eatre patch\u00e9 pour couvrir le kernel de toutes les instances  . Par exemple, un correctif de s\u00e9curit\u00e9 du noyau Linux n\u2019aura qu\u2019une installation unique (sur l\u2019h\u00f4te) au lieu d\u2019\u00eatre appliqu\u00e9 dans chaque VM. Ceci  r\u00e9duit consid\u00e9rablement l\u2019effort de maintenance  sur les mises \u00e0 jour syst\u00e8me  . Toutefois, il ne faut pas oublier que les conteneurs ont tout de m\u00eame leur espace utilisateur : dans le cas de LXC, chaque conteneur est un mini-syst\u00e8me fichier qui peut contenir des paquets applicatifs \u00e0 mettre \u00e0 jour (librairies, serveurs web, etc.). Dans une approche Docker, on reconstruit r\u00e9guli\u00e8rement les images pour embarquer les derni\u00e8res versions logicielles \u2013 ce qui d\u00e9porte l\u2019effort de mise \u00e0 jour vers le pipeline CI/CD plut\u00f4t que l\u2019administration syst\u00e8me classique. En somme, l\u2019OS noyau est unique \u00e0 g\u00e9rer (avantage conteneur), mais les applications contenues peuvent \u00eatre multiples \u00e0 maintenir (d\u2019o\u00f9 l\u2019importance d\u2019automatiser la  build  d\u2019images et le d\u00e9ploiement continu pour garder les conteneurs \u00e0 jour). \u00c0 l\u2019inverse, avec des VM, on peut \u00e9ventuellement mutualiser certaines mises \u00e0 jour via des templates et des outils d\u2019orchestration, mais in fine chaque VM reste un entit\u00e9 s\u00e9par\u00e9e (pets vs cattle).</p> </li> <li> <p>Gestion des configurations et d\u00e9ploiements :  Les conteneurs s\u2019int\u00e8grent g\u00e9n\u00e9ralement dans des workflows DevOps modernes. On d\u00e9crit l\u2019environnement via un  Dockerfile  ou un fichier de config LXD, on peut recr\u00e9er un conteneur \u00e0 l\u2019identique sur une autre machine tr\u00e8s facilement. Cela apporte une  portabilit\u00e9  et une reproductibilit\u00e9 accrues \u2013 utile pour passer de la dev \u00e0 la prod sans surprises, ou pour d\u00e9ployer rapidement un service sur un nouveau serveur. Les VM sont moins portables (une image de VM est volumineuse, li\u00e9e \u00e0 un hyperviseur donn\u00e9, etc., bien qu\u2019il existe OVF et autres formats standards). De plus, chaque VM a souvent une configuration manuelle (sauf \u00e0 utiliser massivement l\u2019Infrastructure as Code pour tout automatiser, ce que peu d\u2019\u00e9quipes font compl\u00e8tement en pratique). Les conteneurs, eux, incitent \u00e0 un d\u00e9ploiement automatis\u00e9 stateless : on peut \u00e9liminer les divergences de configuration, ce qui  facilite la maintenance  applicative (moins de \u00ab fonctionne sur ma machine, pas en prod \u00bb). Par ailleurs, la  mise \u00e0 l\u2019\u00e9chelle  ou la reconfiguration d\u2019une application conteneuris\u00e9e se g\u00e8re souvent via l\u2019orchestrateur (ex: changer une variable d\u2019environnement et red\u00e9ployer le conteneur). Avec des VM, changer la config d\u2019une app implique de se connecter \u00e0 la VM, d\u2019\u00e9diter, etc., sauf outillage de gestion de configuration. En r\u00e9sum\u00e9, administrer 100 conteneurs via Kubernetes ou Portainer peut s\u2019av\u00e9rer plus simple qu\u2019administrer 100 VM via SSH manuellement.</p> </li> <li> <p>Sauvegardes et reprise :  Les VM ayant des disques virtuels d\u00e9di\u00e9s, les backups sont plus segment\u00e9s \u2013 on peut sauvegarder une VM sans affecter une autre, et restaurer ind\u00e9pendamment. Pour les conteneurs, souvent on externalise les donn\u00e9es persistantes hors du conteneur (volumes mont\u00e9s, bases de donn\u00e9es externes) afin que le conteneur puisse \u00eatre recr\u00e9\u00e9 \u00e0 neuf si besoin. La maintenance d\u2019un conteneur consiste parfois \u00e0  d\u00e9truire/recr\u00e9er_plut\u00f4t qu\u2019\u00e0 faire des corrections in-situ. Cela correspond \u00e0 la philosophie  _immutable infrastructure  : on n\u2019upgrade pas un serveur en place, on red\u00e9ploie un nouveau conteneur \u00e0 jour. Cette approche, coupl\u00e9e \u00e0 un orchestrateur, donne une grande robustesse (rollbacks faciles, d\u00e9ploiements blue/green). Avec des VM traditionnelles, on peut \u00e9galement automatiser des redeploiements immuables (notamment dans le cloud avec des images), mais c\u2019est moins int\u00e9gr\u00e9 d\u2019office. En cybers\u00e9curit\u00e9, rendre les environnements \u00e9ph\u00e9m\u00e8res (infrastructure immuable) est un atout pour \u00e9liminer la persistance des malwares, etc., ce qui plaide en faveur des conteneurs + orchestrateurs pour certaines infrastructures.</p> </li> <li> <p>Complexit\u00e9 d\u2019exploitation :  D\u2019un c\u00f4t\u00e9, les conteneurs ajoutent une couche logicielle (le moteur de conteneurs, l\u2019orchestrateur) qu\u2019il faut ma\u00eetriser, ce qui peut complexifier le troubleshooting (il faut diagnostiquer non seulement l\u2019OS h\u00f4te mais aussi les interactions conteneur, r\u00e9seau overlay, etc.). De l\u2019autre, les VM peuvent faire tourner des syst\u00e8mes h\u00e9t\u00e9rog\u00e8nes et plus lourds, ce qui peut aussi \u00eatre complexe \u00e0 d\u00e9panner (ex: un bug sur un Windows Server dans une VM sur un h\u00f4te Linux\u2026). La maintenance des VM exige des comp\u00e9tences syst\u00e8me sur chaque OS invit\u00e9, tandis que la maintenance des conteneurs exige des comp\u00e9tences sur les outils de containerisation. Selon les \u00e9quipes en place, l\u2019un peut \u00eatre plus ais\u00e9 que l\u2019autre.  Portainer, par exemple, vise \u00e0 simplifier l\u2019administration des conteneurs en offrant une interface web centralis\u00e9e pour contr\u00f4ler les containers Docker/Kubernetes (d\u00e9marrer, arr\u00eater, d\u00e9ployer de nouvelles images, monitorer la consommation, etc.)  . De m\u00eame, des solutions comme Proxmox VE ou VMware vCenter facilitent la gestion centralis\u00e9e des VM (mod\u00e8les, migrations \u00e0 chaud, etc.). On peut consid\u00e9rer que pour quelques instances, administrer quelques VM Linux classiques est plus simple que mettre en place tout un orchestrateur conteneur. Mais \u00e0 grande \u00e9chelle, les outils de conteneurs apportent une  automatisationtr\u00e8s pr\u00e9cieuse pour r\u00e9duire la charge op\u00e9rationnelle.</p> </li> </ul> <p>En synth\u00e8se, sur la maintenance :  les conteneurs r\u00e9duisent l\u2019overhead de maintenance syst\u00e8me  en mutualisant l\u2019OS et en s\u2019int\u00e9grant bien dans les pipelines d\u2019automatisation (DevOps)  . Ils permettent une approche \u201cinfra as code\u201d plus aboutie, avec d\u00e9ploiements reproductibles et orchestrables.  Les VM demandent plus d\u2019effort  car chaque instance est un syst\u00e8me complet \u00e0 g\u00e9rer (mises \u00e0 jour, config, etc.)  , mais elles restent indispensables pour certains besoins et peuvent \u00eatre outill\u00e9es via d\u2019autres moyens. Pour un professionnel en s\u00e9curit\u00e9, il est important de noter que la  gestion des correctifs de s\u00e9curit\u00e9  peut \u00eatre plus rapide via des conteneurs (puisqu\u2019on red\u00e9ploie des images \u00e0 jour r\u00e9guli\u00e8rement) \u2013 \u00e0 condition d\u2019avoir un pipeline DevSecOps fiable. Avec des VM, il faut s\u2019assurer d\u2019appliquer les patches manuellement ou via WSUS/Ansible, etc., ce qui prend du temps et peut laisser des fen\u00eatres de vuln\u00e9rabilit\u00e9 plus longues si mal g\u00e9r\u00e9.</p>"},{"location":"infrastructure/lxc-vs-vm/#cas-dusage-quel-choix-pour-quel-besoin","title":"Cas d\u2019usage : quel choix pour quel besoin ?","text":"<p>En pratique, le choix entre VM et conteneur se fait  cas par cas. Voici un panorama de diff\u00e9rents sc\u00e9narios typiques pour un professionnel IT (notamment en cybers\u00e9curit\u00e9) et les recommandations associ\u00e9es :</p> <ul> <li> <p>H\u00e9bergement de services web et applications :  Pour d\u00e9ployer des applications web (sites, API, microservices), les conteneurs sont tr\u00e8s populaires. Ils permettent d\u2019isoler chaque service, de le packager avec ses d\u00e9pendances, et de le d\u00e9ployer uniform\u00e9ment de la dev \u00e0 la prod. Un serveur web, par exemple Nginx ou Apache, tourne tr\u00e8s bien en conteneur Docker ; cela facilite sa r\u00e9partition sur plusieurs h\u00f4tes, sa scalabilit\u00e9 dynamique, et sa mise \u00e0 jour (on remplace le conteneur par une nouvelle version)  . Les conteneurs sont quasiment con\u00e7us pour les architectures  microservices  : chaque microservice peut vivre dans son container, communicant avec les autres via le r\u00e9seau, et Kubernetes peut orchestrer le tout. En cybers\u00e9curit\u00e9, segmenter une application en conteneurs a aussi l\u2019avantage de limiter l\u2019impact d\u2019une intrusion \u2013 p. ex., un attaquant compromettant le conteneur d\u2019un microservice n\u2019acc\u00e8de pas directement aux autres composants.  Quand privil\u00e9gier les VM ?  Si votre application est monolithique, lourde, ou n\u00e9cessite un environnement particulier, une VM peut \u00eatre indiqu\u00e9e. Par exemple, l\u2019h\u00e9bergement d\u2019un ancien site PHP sur Windows Server avec IIS sera plus simple dans une VM Windows, puisque Docker sur Windows est moins courant en production. De m\u00eame, si chaque application doit \u00eatre strictement s\u00e9par\u00e9e pour des raisons de conformit\u00e9 (clients diff\u00e9rents), on pourra opter pour une VM par application/client afin de garantir qu\u2019aucune fuite de donn\u00e9es ne soit possible entre elles. En g\u00e9n\u00e9ral toutefois, pour les services web modernes, la containerisation l\u2019emporte gr\u00e2ce \u00e0 la  flexibilit\u00e9  et la  scalabilit\u00e9  qu\u2019elle offre.</p> </li> <li> <p>Bases de donn\u00e9es et syst\u00e8mes de gestion de donn\u00e9es :  Faut-il conteneuriser ses bases de donn\u00e9es ? La question fait d\u00e9bat. D\u2019un c\u00f4t\u00e9, des bases comme  MySQL, PostgreSQL, MongoDB  tournent tout \u00e0 fait bien dans des conteneurs Docker \u2013 de nombreuses entreprises le font en production, notamment pour b\u00e9n\u00e9ficier de l\u2019orchestration (par ex. d\u00e9ployer rapidement plusieurs n\u0153uds de DB en cluster). L\u00e9g\u00e8ret\u00e9 des conteneurs oblige, on peut les cloner pour du scaling horizontal, et les int\u00e9grer dans des solutions type  Database as a Service. D\u2019un autre c\u00f4t\u00e9, une base de donn\u00e9es a souvent besoin de stockage persistant et de performances IO optimales. Un conteneur ajoute une couche d\u2019abstraction (syst\u00e8me de fichiers copy-on-write, volumes mont\u00e9s\u2026) qui peut introduire de la complexit\u00e9 pour la persistance et \u00e9ventuellement un l\u00e9ger overhead.  Recommandation :  pour des bases distribu\u00e9es ou in-memory (ex:  Redis  cache, base  NoSQL  horizontale), les conteneurs conviennent bien \u2013 on profite de leur portabilit\u00e9, on peut orchestrer la mont\u00e9e en charge automatique, etc. En revanche, pour une base de donn\u00e9es transactionnelle centrale (ex: un gros SQL Server ou Oracle), souvent on privil\u00e9gie une  VM d\u00e9di\u00e9e ou un serveur bare-metal, afin d\u2019\u00e9viter toute instabilit\u00e9. Une VM permet d\u2019allouer clairement des ressources (vCPU, RAM, disque) \u00e0 la base et de s\u2019assurer que rien d\u2019autre ne les consomme. C\u2019est plus  pr\u00e9visible  en termes de performance, ce qui est important pour une base de prod. De plus, la VM isolera la base des autres services \u2013 consid\u00e9rant que les BDD contiennent des donn\u00e9es sensibles, c\u2019est un plus niveau s\u00e9curit\u00e9. En cybers\u00e9curit\u00e9, le principe de segmentation forte s\u2019applique souvent aux bases : on isolera la base de donn\u00e9es critique dans sa VM (ou son cluster de VM) s\u00e9par\u00e9e du reste, pour qu\u2019aucune compromission applicative n\u2019entra\u00eene un acc\u00e8s direct \u00e0 la base. En somme : conteneur possible pour DB l\u00e9g\u00e8res ou microservices  stateful, VM conseill\u00e9e pour les bases critiques monolithiques (vertical scaling) qui requi\u00e8rent stabilit\u00e9 et isolement. Notons que si on conteneurise une DB, il faut porter une attention particuli\u00e8re \u00e0 la strat\u00e9gie de  persistence  (volumes externes, sauvegardes hors conteneur) car les conteneurs sont par nature \u00e9ph\u00e9m\u00e8res.</p> </li> <li> <p>Laboratoires de s\u00e9curit\u00e9, tests et sandboxing :  Dans un contexte de lab ou de test en cybers\u00e9curit\u00e9, on a souvent besoin de reproduire des environnements vuln\u00e9rables, de tester des exploits ou d\u2019analyser des malwares.  Les machines virtuelles  sont ici l\u2019outil classique : par exemple, on va faire tourner une VM Windows 10 infect\u00e9e pour observer un ransomware, ou d\u00e9ployer une VM Metasploitable Linux pleine de failles pour s\u2019entra\u00eener. Les VM sont id\u00e9ales car on peut prendre  des snapshots  avant/apr\u00e8s attaque, isoler le r\u00e9seau de la VM pour \u00e9viter toute propagation, et restaurer l\u2019\u00e9tat initial facilement. De plus, on peut avoir besoin de syst\u00e8mes non-Linux (Windows, etc.) que seul un hyperviseur peut fournir.  Les conteneurs, toutefois, trouvent aussi leur place en lab s\u00e9curit\u00e9 : il existe de nombreuses images Docker pr\u00e9-construites pour s\u2019entra\u00eener (par ex. DVWA \u2013 Damn Vulnerable Web App \u2013 est disponible en image Docker, ce qui permet de la lancer en un seul  docker run  au lieu de configurer un LAMP vuln\u00e9rable manuellement). Pour monter rapidement un environnement de CTF ou de pentest, les conteneurs sont tr\u00e8s pratiques : on peut orchestrer via  docker-compose  plusieurs services vuln\u00e9rables interconnect\u00e9s, ce qui fait gagner du temps.  En r\u00e9sum\u00e9 :  utilisez des VM pour tout ce qui est  simulation d\u2019OS complet ou analyse de malware  (surtout Windows) \u2013 les VM offrent la flexibilit\u00e9 d\u2019ex\u00e9cuter n\u2019importe quel code dans un bac \u00e0 sable r\u00e9initialisable. Utilisez des conteneurs pour des  sc\u00e9narios applicatifs cibl\u00e9s  (d\u00e9ployer en masse plusieurs instances vuln\u00e9rables d\u2019un service web, isoler des composants type challenges CTF, etc.). Et souvent, combiner les deux a du sens : ex\u00e9cuter Docker \u00e0 l\u2019int\u00e9rieur d\u2019une VM labo, ainsi si un conteneur est compromis, on peut jeter la VM enti\u00e8re apr\u00e8s coup. Cela limite aussi l\u2019impact sur l\u2019h\u00f4te r\u00e9el (ne jamais faire tourner des conteneurs vuln\u00e9rables directement sur son poste sans isolation suppl\u00e9mentaire, par pr\u00e9caution).</p> </li> <li> <p>Compatibilit\u00e9 OS et logiciels legacy :  Comme mentionn\u00e9, si vous devez faire tourner un logiciel qui  n\u2019est support\u00e9 que sur un certain OS, le choix est vite fait. Par exemple, un contr\u00f4leur de domaine Active Directory Windows Server  doit  tourner sur Windows \u2013 on utilisera donc une VM Windows si l\u2019h\u00f4te est Linux (ou inversement, une VM Linux sur un host Windows, bien que Linux sur Windows puisse aussi se faire via WSL2 container maintenant, mais c\u2019est un autre sujet). De m\u00eame, si un logiciel n\u00e9cessite un  acc\u00e8s bas niveau au mat\u00e9rielou un module kernel sp\u00e9cifique, il ne fonctionnera pas dans un conteneur o\u00f9 l\u2019acc\u00e8s au kernel est restreint. Une VM permet de charger des pilotes virtuels ou de faire du passthrough mat\u00e9riel (passer une carte PCI dans la VM, etc.), ce qui est impossible en LXC pur. Donc pour tout usage tr\u00e8s sp\u00e9cifique (par ex. virtualiser un vieil OS 32-bit pour utiliser un ancien outil, ou tester un kernel module), la VM est l\u2019option n\u00e9cessaire. En revanche, si tout votre stack applicatif est Linux et moderne, les conteneurs pourront la supporter.  Cas particulier des environnements bureautiques isol\u00e9s (VDI, sandbox utilisateur) :  on privil\u00e9gie l\u00e0 des VM (voire des conteneurs de type  application streaming  mais c\u2019est plus rare) afin de fournir un OS d\u00e9di\u00e9 par utilisateur, avec une grosse isolation pour \u00e9viter qu\u2019un utilisateur malveillant n\u2019acc\u00e8de \u00e0 l\u2019host.</p> </li> <li> <p>Environnements multi-tenants et h\u00e9bergement de clients :  Supposons que vous fournissiez un service h\u00e9berg\u00e9 \u00e0 plusieurs clients avec des instances d\u00e9di\u00e9es (par exemple, vous h\u00e9bergez l\u2019application web de plusieurs entreprises sur votre infrastructure). Deux approches :  multitenant conteneurs  ou  multitenant VM.  Approche VM :  cr\u00e9er une VM par client assure que les donn\u00e9es et process de chaque client sont totalement s\u00e9par\u00e9s. M\u00eame en cas d\u2019attaque, un client ne peut pas sortir de sa VM pour aller espionner un autre. C\u2019est rassurant d\u2019un point de vue contractualisation et isolation r\u00e9seau (on peut mettre chaque VM dans un VLAN). En revanche, c\u2019est co\u00fbteux en ressources si chaque client n\u2019utilise qu\u2019une fraction de sa VM \u2013 on g\u00e2che potentiellement de la RAM/CPU idle.  Approche conteneur :  on peut lancer un conteneur par client sur un m\u00eame host, ce qui utilise beaucoup moins de ressources globalement, mais les clients partagent le noyau. S\u2019il y a un risque d\u2019hostilit\u00e9 entre clients (clients mutuellement non confiants), c\u2019est d\u00e9licat car une \u00e9vasion de conteneur pourrait compromettre l\u2019isolation. N\u00e9anmoins, pour des clients de confiance ou internes, c\u2019est une option viable qui am\u00e9liore la densit\u00e9. En cybers\u00e9curit\u00e9, la r\u00e8gle est de ne  jamais m\u00e9langer  des niveaux de confiance diff\u00e9rents sur un m\u00eame noyau. Donc on \u00e9vitera de mettre en conteneurs sur le m\u00eame OS un service front expos\u00e9 \u00e0 tous et un autre contenant des donn\u00e9es ultra-sensibles. Soit on les s\u00e9pare sur des hosts physiques distincts, soit au minimum sur des VM distinctes pour cloisonner. Ainsi, pour un h\u00e9bergeur, la VM par client reste standard (ex: offre VPS). Par contre, pour un service cloud natif, on peut avoir du multi-tenant conteneur si l\u2019architecture l\u2019isole suffisamment (typiquement via Kubernetes avec  Network Policies, et en lancant les pods des clients dans des VM worker s\u00e9par\u00e9es, ce qui revient \u00e0 combiner les deux mondes).</p> </li> <li> <p>Dev/Test, CI/CD et flexibilit\u00e9 :  Dans les cycles de d\u00e9veloppement et test, les conteneurs se sont impos\u00e9s car ils offrent un environnement jetable facile \u00e0 recr\u00e9er. Un d\u00e9veloppeur peut avoir besoin de tester une application sur diff\u00e9rentes versions de d\u00e9pendances : avec Docker, il peut tourner un conteneur avec telle version, puis le d\u00e9truire, etc., sans polluer sa machine. Les pipelines d\u2019int\u00e9gration continue lancent fr\u00e9quemment des conteneurs pour ex\u00e9cuter les tests unitaires ou builder une application dans un environnement isol\u00e9 puis jettent le conteneur. Tout cela serait possible avec des VM mais serait nettement plus lent et lourd \u00e0 orchestrer. Donc pour tout ce qui est  environnements transitoires,  sandboxes de d\u00e9veloppement, simulations courtes, les conteneurs sont id\u00e9aux. \u00c0 l\u2019oppos\u00e9, si vous avez besoin d\u2019un environnement de test qui reproduit exactement un syst\u00e8me de production legacy (par ex. un serveur SAP sur Solaris\u2026), vous utiliserez une VM (voire un \u00e9mulateur). Mais c\u2019est l\u2019exception.</p> </li> <li> <p>Infrastructure cloud et d\u00e9ploiements \u00e0 grande \u00e9chelle :  Aujourd\u2019hui, le  cloud  propose les deux mod\u00e8les : des  VM cloud (IaaS)  et des  contener services (CaaS). Si vous construisez une plateforme scalable moderne, les conteneurs orchestr\u00e9s sont souvent le choix par d\u00e9faut (ex: d\u00e9ployer sur AWS EKS \u2013 Elastic Kubernetes Service \u2013 une application microservices). Cela permet une  meilleure utilisation des ressources  en payant seulement pour ce qui tourne, et une  \u00e9lasticit\u00e9  quasiment automatique. Les VM cloud conviennent mieux pour des charges stables ou des besoins sp\u00e9cifiques (installer son propre OS custom, isolation d\u00e9di\u00e9e, etc.). Beaucoup d\u2019architectures hybrides combinent VM et conteneurs : par exemple, on d\u00e9ploie un cluster Kubernetes sur 5 VM cloud, et \u00e0 l\u2019int\u00e9rieur on g\u00e8re des douzaines de conteneurs applicatifs. Cette strat\u00e9gie permet de b\u00e9n\u00e9ficier de l\u2019isolation des VM (chaque node du cluster est une VM s\u00e9par\u00e9e) et de l\u2019efficacit\u00e9 des conteneurs pour les workloads. En tant que professionnel s\u00e9curit\u00e9, il faudra penser \u00e0 s\u00e9curiser \u00e0 la fois le niveau VM (durcissement de l\u2019OS h\u00f4te, pare-feu entre VM) et le niveau conteneur (politiques r\u00e9seau Kubernetes, scans d\u2019images, etc.). Le choix ici n\u2019est pas exclusif, mais il est guid\u00e9 par le mod\u00e8le d\u2019exploitation :  DevOps/cloud-native  \u27f6 conteneurs ;  IT traditionnel/monolithique  \u27f6 VM.</p> </li> </ul> <p>En r\u00e9sum\u00e9,  il n\u2019y a pas de solution universellement meilleure, tout d\u00e9pend du contexte d\u2019utilisation et des priorit\u00e9s. Les recommandations g\u00e9n\u00e9rales suivantes peuvent \u00eatre retenues :</p> <ul> <li> <p>Si la  priorit\u00e9 est la performance pure et l\u2019efficacit\u00e9  (exploiter au mieux le mat\u00e9riel, d\u00e9marrer/arr\u00eater fr\u00e9quemment, g\u00e9rer de multiples instances l\u00e9g\u00e8res), les  conteneurs  sont \u00e0 privil\u00e9gier  .</p> </li> <li> <p>Si la  priorit\u00e9 est la s\u00e9curit\u00e9 et l\u2019isolation totale  (g\u00e9rer du code non fiable, des utilisateurs non approuv\u00e9s, des environnements h\u00e9t\u00e9rog\u00e8nes), les  VM  offrent un cloisonnement plus robuste out-of-the-box  .</p> </li> <li> <p>Pour des  besoins de compatibilit\u00e9 ou d\u2019ind\u00e9pendance OS  (syst\u00e8mes d\u2019exploitation diff\u00e9rents, applications legacy n\u00e9cessitant un kernel particulier), la VM est la seule option viable  . Pour des  applications Linux cloud-native  et portables, les conteneurs suffisent et \u00e9vitent la lourdeur des VM.</p> </li> <li> <p>En termes de  maintenance, si vous disposez d\u2019une bonne cha\u00eene DevOps et que vous souhaitez r\u00e9duire l\u2019overhead des mises \u00e0 jour, les conteneurs vous simplifieront la vie (un seul OS h\u00f4te \u00e0 g\u00e9rer)  . Si au contraire votre organisation est plus \u00e0 l\u2019aise avec la gestion classique de serveurs, les VM resteront dans la continuit\u00e9 (m\u00eames outils d\u2019admin qu\u2019avec des serveurs physiques, mais en virtuel).</p> </li> <li> <p>Consid\u00e9rez enfin les  outils  \u00e0 votre disposition : si vous envisagez d\u2019utiliser Kubernetes, alors vous vous orientez clairement vers la containerisation \u00e0 grande \u00e9chelle. Si vous avez d\u00e9j\u00e0 une infrastructure VMware/Proxmox bien rod\u00e9e, int\u00e9grer LXC \u00e0 c\u00f4t\u00e9 des VM peut \u00eatre int\u00e9ressant pour certains usages l\u00e9gers, mais vous garderez peut-\u00eatre des VM pour le reste, selon vos besoins. Les deux approches ne sont pas mutuellement exclusives et peuvent cohabiter de mani\u00e8re compl\u00e9mentaire  .</p> </li> </ul> <p>En conclusion,  LXC vs VM  n\u2019est pas un combat avec un gagnant unique, mais plut\u00f4t un choix d\u2019outil selon l\u2019objectif. Un professionnel de la cybers\u00e9curit\u00e9 saura \u00e9valuer le niveau d\u2019isolation n\u00e9cessaire, la surface d\u2019attaque acceptable, et les contraintes de performance pour d\u00e9cider de la technologie appropri\u00e9e. Ma\u00eetriser les deux approches permet d\u2019allier la puissance de la virtualisation compl\u00e8te et la flexibilit\u00e9 de la containerisation  afin de construire des infrastructures \u00e0 la fois efficaces, s\u00e9curis\u00e9es et faciles \u00e0 g\u00e9rer  . En comprenant les avantages et limites de chacun, vous pourrez tirer le meilleur parti de ces solutions de virtualisation dans vos diff\u00e9rents cas d\u2019usage professionnels.</p>"},{"location":"infrastructure/proxmox/","title":"Proxmox dans un homelab s\u00e9curis\u00e9 et auto-h\u00e9berg\u00e9","text":"<p>Proxmox VE (Virtual Environment) est une plateforme de virtualisation open-source de type  bare metal. Elle permet d\u2019ex\u00e9cuter des  machines virtuelles (VM)  et des  conteneurs Linux (LXC)  sur un ou plusieurs serveurs, le tout g\u00e9rable via une interface web centralis\u00e9e. Proxmox est bas\u00e9e sur Debian Linux et int\u00e8gre l\u2019hyperviseur KVM pour la virtualisation compl\u00e8te, ainsi que LXC pour la virtualisation l\u00e9g\u00e8re de conteneurs  . Tr\u00e8s utilis\u00e9e en entreprise comme en homelab, Proxmox offre un riche ensemble de fonctionnalit\u00e9s pr\u00eates \u00e0 l\u2019emploi pour cr\u00e9er un environnement auto-h\u00e9berg\u00e9 \u00e0 la fois flexible et s\u00e9curis\u00e9.</p> <p>(Suggestion de capture d\u2019\u00e9cran : Interface web de Proxmox VE affichant le tableau de bord des VMs et conteneurs.)</p>"},{"location":"infrastructure/proxmox/#introduction-a-proxmox-ve","title":"Introduction \u00e0 Proxmox VE","text":"<p>Proxmox VE (Virtual Environment)  est une solution libre (licence AGPLv3) permettant de transformer un serveur x86_64 en un hyperviseur complet. Installable directement sur le mat\u00e9riel (type 1), Proxmox utilise  KVM  pour cr\u00e9er des machines virtuelles isol\u00e9es (compatibles Windows, Linux, BSD, etc.) et  LXC*  pour cr\u00e9er des conteneurs Linux l\u00e9gers partageant le noyau de l\u2019h\u00f4te  . L\u2019administration se fait via une interface web intuitive, sans n\u00e9cessiter de ligne de commande pour les t\u00e2ches courantes. Un seul serveur Proxmox peut h\u00e9berger de nombreuses VM et conteneurs, optimisant ainsi l\u2019utilisation des ressources de votre machine.</p> <p>En contexte  homelab  (laboratoire personnel h\u00e9berg\u00e9 chez soi), Proxmox brille par sa  polyvalence. Il permet de consolider sur une m\u00eame machine plusieurs services auto-h\u00e9berg\u00e9s tout en assurant leur isolation. Par exemple, on pourra faire tourner simultan\u00e9ment un serveur domotique, un serveur web, un NAS virtuel, etc., chacun dans une VM ou un conteneur s\u00e9par\u00e9. Proxmox offre aussi des outils int\u00e9gr\u00e9s de sauvegarde, de snapshot et de haute disponibilit\u00e9, ce qui en fait un choix de premier plan pour un homelab fiable et  secure by design.</p> <p>(Suggestion de capture d\u2019\u00e9cran : \u00c9cran de connexion \u00e0 l\u2019interface Proxmox VE avec option 2FA.)</p>"},{"location":"infrastructure/proxmox/#cas-dusage-pour-un-homelab","title":"Cas d\u2019usage pour un homelab","text":"<p>Quels usages concrets peut-on attendre de Proxmox dans un homelab s\u00e9curis\u00e9 ? En voici les principaux cas d\u2019utilisation :</p> <ul> <li> <p>Machines virtuelles (VM) : H\u00e9bergez plusieurs syst\u00e8mes d\u2019exploitation en parall\u00e8le (Linux, Windows, etc.) pour segmenter vos services. Par exemple, une VM Debian pour un serveur web et une VM Windows pour un logiciel sp\u00e9cifique. Chaque VM dispose de ses ressources d\u00e9di\u00e9es (CPU, RAM, disque) et est isol\u00e9e des autres, ce qui renforce la s\u00e9curit\u00e9.</p> </li> <li> <p>Conteneurs LXC : D\u00e9ployez des conteneurs Linux l\u00e9gers pour vos services moins gourmands. Les conteneurs partagent le noyau de l\u2019h\u00f4te, consomment peu de ressources et d\u00e9marrent en quelques secondes. Id\u00e9al pour h\u00e9berger un Pi-hole, un serveur DNS, un petit service web ou une base de donn\u00e9es  lightweight  sous Alpine Linux, etc.</p> </li> <li> <p>Stockage centralis\u00e9 : Proxmox peut g\u00e9rer diff\u00e9rentes solutions de stockage pour vos donn\u00e9es. Vous pouvez utiliser du  stockage local  sur le serveur (disques SSD NVMe, HDD, RAID, ZFS\u2026), monter un stockage r\u00e9seau de type  NAS  (partage NFS/SMB) ou m\u00eame d\u00e9ployer du  stockage distribu\u00e9  avec Ceph. Cela permet d\u2019adapter les performances de stockage selon les besoins : par exemple, du SSD pour les VM critiques et du disque dur m\u00e9canique pour l\u2019archivage.</p> </li> <li> <p>R\u00e9seau virtualis\u00e9 : Proxmox facilite la cr\u00e9ation de r\u00e9seaux virtuels isol\u00e9s ou bridg\u00e9s vers votre LAN. Vous pouvez d\u00e9finir des  bridges  pour connecter des VM \u00e0 votre r\u00e9seau local, des  VLAN  pour segmenter le trafic (par exemple s\u00e9parer une DMZ des services internes), ou utiliser le module  SDN  (Software Defined Network) de Proxmox pour des configurations r\u00e9seau avanc\u00e9es. Tout cela se configure facilement depuis l\u2019UI, permettant de reproduire une topologie r\u00e9seau complexe \u00e0 des fins de test ou de s\u00e9curit\u00e9.</p> </li> <li> <p>Snapshots et sauvegardes : Avant une mise \u00e0 jour risqu\u00e9e ou une manipulation, prenez un  snapshot  de la VM/LXC afin de pouvoir revenir en arri\u00e8re instantan\u00e9ment en cas de probl\u00e8me. Proxmox g\u00e8re les snapshots (sur syst\u00e8mes de fichiers compatibles comme ZFS) et propose une planification de  sauvegardes  automatis\u00e9es de vos VM/CT vers un stockage de votre choix (NAS, disque USB, Proxmox Backup Server, etc.). Ces sauvegardes peuvent \u00eatre incr\u00e9mentales et compress\u00e9es pour gagner de l\u2019espace. En homelab, cela permet de tester sans crainte de \u201ccasser\u201d son environnement, et d\u2019avoir des backups pr\u00eats en cas de panne mat\u00e9rielle.</p> </li> </ul> <p>(Suggestion de capture d\u2019\u00e9cran : Vue d\u2019une VM en cours d\u2019ex\u00e9cution dans Proxmox, avec ses ressources CPU/RAM affich\u00e9es.)</p>"},{"location":"infrastructure/proxmox/#fonctionnalites-cles-de-proxmox-ve","title":"Fonctionnalit\u00e9s cl\u00e9s de Proxmox VE","text":"<p>Proxmox VE apporte par d\u00e9faut un  large \u00e9ventail de fonctionnalit\u00e9s  appr\u00e9ciables dans un homelab, alliant simplicit\u00e9 d\u2019utilisation et options avanc\u00e9es :</p> <ul> <li> <p>Gestion centralis\u00e9e via Web UI : L\u2019interface web de Proxmox (accessible sur le port 8006) offre un tableau de bord unifi\u00e9 pour g\u00e9rer toutes vos VM et conteneurs, m\u00eame sur plusieurs n\u0153uds. On peut cr\u00e9er, configurer, d\u00e9marrer/arr\u00eater les VMs, consulter les m\u00e9triques, le tout depuis un navigateur  . L\u2019UI int\u00e8gre \u00e9galement un  _shell_Web pour acc\u00e9der \u00e0 la console des VM/CT, et supporte plusieurs utilisateurs avec r\u00f4les si n\u00e9cessaire.</p> </li> <li> <p>Clustering et Haute Disponibilit\u00e9 (HA) : Proxmox permet de former un  cluster  en regroupant plusieurs serveurs physiques. Le cluster offre une gestion commune via l\u2019UI (vue datacenter) et permet des fonctionnalit\u00e9s avanc\u00e9es comme la  migration \u00e0 chaud  des VM d\u2019un n\u0153ud \u00e0 l\u2019autre sans interruption  . En configurant la HA, une VM critique pourra red\u00e9marrer automatiquement sur un autre n\u0153ud en cas de panne du serveur h\u00f4te.  (Pour tirer parti de la HA, un stockage partag\u00e9 ou une r\u00e9plication Ceph/ZFS est g\u00e9n\u00e9ralement requis.)</p> </li> <li> <p>Support natif de ZFS et stockage avanc\u00e9 : Proxmox VE s\u2019int\u00e8gre nativement avec le syst\u00e8me de fichiers  ZFS, d\u00e8s l\u2019installation vous pouvez choisir ZFS pour le stockage principal. ZFS apporte  compression transparente, snapshots rapides et r\u00e9plication. Proxmox facilite la gestion des volumes ZFS via l\u2019interface  . En mode cluster, Proxmox propose \u00e9galement une int\u00e9gration directe de  Ceph  depuis l\u2019UI pour d\u00e9ployer un stockage distribu\u00e9 et redondant  . En plus de ZFS/Ceph, Proxmox g\u00e8re de multiples types de stockage : LVM, r\u00e9pertoires ext4, partages  NFS, cibles  iSCSI, GlusterFS, etc.  .</p> </li> <li> <p>Snapshots et sauvegardes int\u00e9gr\u00e9s : L\u2019hyperviseur inclut des outils int\u00e9gr\u00e9s pour  snapshoter  un syst\u00e8me (s\u2019il est sur un stockage compatible, ex. ZFS ou LVM-Thin) et pour  sauvegarder  les VM/CT. Les sauvegardes peuvent \u00eatre planifi\u00e9es (mode  cron) et envoy\u00e9es vers un stockage local ou distant. Proxmox prend en charge la suspension du syst\u00e8me invit\u00e9 (freeze) lors des sauvegardes pour assurer la coh\u00e9rence. La restauration d\u2019une VM depuis une sauvegarde se fait en quelques clics, am\u00e9liorant nettement la r\u00e9silience de votre homelab.</p> </li> <li> <p>Fonctions r\u00e9seau et pare-feu : Proxmox VE supporte les  bridges Linux  classiques mais aussi  Open vSwitch  pour les cas complexes, et offre un module  SDN  depuis la version 7+ pour d\u00e9finir des r\u00e9seaux virtuels plus \u00e9labor\u00e9s. Chaque interface r\u00e9seau de VM/CT peut \u00eatre attach\u00e9e \u00e0 un bridge ou VLAN tagu\u00e9. De plus, Proxmox embarque un  firewall  configurable par VM, par h\u00f4te et au niveau datacenter. On peut ainsi appliquer des r\u00e8gles (au niveau IP, port, protocoles) pour segmenter le trafic entre VMs ou vers l\u2019ext\u00e9rieur, directement depuis l\u2019interface de Proxmox.</p> </li> <li> <p>Open Source &amp; Communaut\u00e9 : Proxmox VE est enti\u00e8rement open-source et gratuit \u00e0 utiliser. Le code source est public, et une  vaste communaut\u00e9  d\u2019utilisateurs contribue via le forum officiel, des wikis et des tutoriels. Des mises \u00e0 jour r\u00e9guli\u00e8res am\u00e9liorent sans cesse la plateforme. Pour les entreprises ou utilisateurs exigeants, Proxmox propose un abonnement  support entreprise  (payant) donnant acc\u00e8s \u00e0 un d\u00e9p\u00f4t stable et une assistance technique  \u2013 optionnel pour un homelab, car la version gratuite est pleinement fonctionnelle (seules les MAJ se font via le d\u00e9p\u00f4t communautaire).</p> </li> </ul> <p>(Suggestion de capture d\u2019\u00e9cran : Onglet de configuration du stockage ZFS dans Proxmox, montrant un pool ZFS et ses volumes.)</p>"},{"location":"infrastructure/proxmox/#comparaison-avec-dautres-solutions-open-source","title":"Comparaison avec d\u2019autres solutions open source","text":"<p>Plusieurs alternatives open source \u00e0 Proxmox existent pour la virtualisation en homelab, chacune avec ses sp\u00e9cificit\u00e9s. Ci-dessous un tableau comparatif de Proxmox VE avec trois solutions populaires :  XCP-ng,  TrueNAS SCALE  et  Harvester.</p> Solution Technologie (Hyperviseur) Support Conteneurs Clustering / HA Gestion du Stockage Interface Orientation Proxmox VE Type 1 Linux (Debian + KVM/QEMU) + LXC Oui  (LXC natif pour Linux) Optionnel  (cluster multi-n\u0153uds, HA possible si stockage partag\u00e9 ou Ceph) Local (dir, LVM,  ZFS), externe (NFS, iSCSI), distribu\u00e9 (Ceph  int\u00e9gr\u00e9) Interface web unifi\u00e9e (Proxmox GUI) Hyperviseur polyvalent (VM + conteneurs sur une infra unifi\u00e9e) XCP-ng Type 1 Xen (bas\u00e9 sur XenServer) Non  (pas de conteneurs natifs) Oui  (pool de n\u0153uds Xen, HA et migration via Xen Orchestra) Local (LVM/ext), externe (NFS, iSCSI), pas de ZFS natif int\u00e9gr\u00e9 Xen Orchestra  (web, \u00e0 d\u00e9ployer s\u00e9par\u00e9ment) ou outil Windows (XCP-ng Center) Hyperviseur pur pour VM (fork libre de Citrix XenServer) TrueNAS SCALE OS hyperconverg\u00e9 (Debian + KVM + Kubernetes) Oui  (Apps Docker via Kubernetes) Limit\u00e9  (fonction  scale-out  en cours, clustering GlusterFS possible pour le stockage) Local uniquement (ZFS  natif pour NAS, RAID-Z), partage r\u00e9seau (SMB, NFS, iSCSI int\u00e9gr\u00e9s) Interface web compl\u00e8te (NAS + VMs + Apps Docker) NAS orient\u00e9 services  (stockage centralis\u00e9 avec possibilit\u00e9 de VMs/containers suppl\u00e9mentaires) Harvester HCI Type 1 hyperconverg\u00e9 (SUSE Linux + KVM via KubeVirt) Oui  (conteneurs via Kubernetes sous-jacent) Oui  (con\u00e7u pour cluster HCI \u22653 n\u0153uds, HA natif) Stockage distribu\u00e9 int\u00e9gr\u00e9 (Longhorn  \u2013 n\u00e9cessite disques SSD sur chaque n\u0153ud) Interface web (int\u00e9gr\u00e9e \u00e0 Rancher) Infra  hyperconverg\u00e9e cloud-native  (VM orchestr\u00e9es par Kubernetes, approches type VMware vSphere) <p>Remarques :  Proxmox et XCP-ng sont des hyperviseurs \u201cclassiques\u201d similaires \u00e0 VMware ESXi ou Hyper-V, install\u00e9s sur bare metal pour h\u00e9berger principalement des VMs.  XCP-ng  utilise l\u2019hyperviseur Xen (syst\u00e8me diff\u00e9rent de KVM) et n\u00e9cessite Xen Orchestra pour une gestion web compl\u00e8te; il offre une stabilit\u00e9 et des performances solides, mais sans conteneurs int\u00e9gr\u00e9s et avec davantage de configurations en CLI pour certaines fonctions avanc\u00e9es (ex: passthrough GPU ou ZFS sur l\u2019h\u00f4te)  .  TrueNAS SCALE, \u00e0 l\u2019inverse, est d\u2019abord pens\u00e9 comme un NAS haut de gamme utilisant ZFS \u2013 il excelle pour le stockage et les services de fichiers. TrueNAS int\u00e8gre quand m\u00eame KVM pour les VM et surtout un orchestrateur Kubernetes pour d\u00e9ployer des applications Docker en quelques clics (catalogue d\u2019applications). C\u2019est donc un excellent  appliance de stockage  enrichi de virtualisation l\u00e9g\u00e8re, mais moins flexible qu\u2019un hyperviseur pur pour multiplier les VM  .  Harvester, enfin, est une solution tr\u00e8s r\u00e9cente d\u2019infrastructure hyperconverg\u00e9e open-source (projet SUSE/Rancher) visant \u00e0 combiner virtualisation et conteneurs de fa\u00e7on transparente. Bas\u00e9 sur Kubernetes (k3s) et KubeVirt, il propose une approche moderne similaire aux clouds priv\u00e9s (avec SDN, gestion int\u00e9gr\u00e9e du stockage via Longhorn, etc.), mais il est plus complexe \u00e0 mettre en place et  consomme davantage de ressources \u00e0 l\u2019\u00e9tat idle  qu\u2019une solution comme Proxmox  . Harvester est encore jeune et moins r\u00e9pandu dans les homelabs, bien qu\u2019il soit prometteur pour l\u2019avenir.</p> <p>En r\u00e9sum\u00e9,  Proxmox VE se distingue par son \u00e9quilibre  entre  richesse fonctionnelle  (VM + conteneurs, clustering, ZFS, etc.) et  simplicit\u00e9 d\u2019utilisation, ce qui le rend tr\u00e8s adapt\u00e9 \u00e0 un homelab polyvalent. XCP-ng pourra convenir pour un usage orient\u00e9 pure virtualisation Xen, TrueNAS SCALE brillera si le stockage NAS est prioritaire, et Harvester s\u2019adresse aux lab plus exp\u00e9riment\u00e9s cherchant \u00e0 explorer l\u2019approche Kubernetes int\u00e9gr\u00e9e.</p>"},{"location":"infrastructure/proxmox/#avantages-et-inconvenients-de-proxmox-ve","title":"Avantages et inconv\u00e9nients de Proxmox VE","text":""},{"location":"infrastructure/proxmox/#avantages","title":"Avantages","text":"<ul> <li> <p>Open-source et gratuit  \u2013 Proxmox VE est libre d\u2019utilisation sans limitation de fonctionnalit\u00e9s. La communaut\u00e9 est active et publie r\u00e9guli\u00e8rement des mises \u00e0 jour et correctifs. L\u2019absence de co\u00fbts de licence est un plus pour un homelab.</p> </li> <li> <p>Interface unifi\u00e9e et simplicit\u00e9  \u2013 Toute l\u2019administration se fait via une interface web ergonomique, centralisant VM, conteneurs, stockage, r\u00e9seau, etc. Pour un d\u00e9butant, Proxmox est l\u2019une des solutions les plus faciles \u00e0 prendre en main pour cr\u00e9er et g\u00e9rer des VMs  . De nombreuses op\u00e9rations (cr\u00e9ation de VM, ajout de disques, snapshots\u2026) sont r\u00e9alisables en quelques clics.</p> </li> <li> <p>VM et conteneurs sur la m\u00eame plateforme  \u2013 Pas besoin de choisir entre virtualisation traditionnelle et conteneurs : Proxmox offre les deux nativement. On peut ainsi faire tourner des conteneurs LXC pour les services Linux l\u00e9gers, tout en h\u00e9bergeant des VM (y compris Windows) sur le m\u00eame serveur. Cette polyvalence est un atout majeur par rapport \u00e0 des hyperviseurs qui ne g\u00e8rent pas les conteneurs.</p> </li> <li> <p>\u00c9cosyst\u00e8me complet (clustering, ZFS, Ceph, backups\u2026)  \u2013 Proxmox int\u00e8gre out-of-the-box des fonctionnalit\u00e9s normalement r\u00e9serv\u00e9es aux solutions d\u2019entreprise : gestion multi-n\u0153uds avec quorum, support du stockage distribu\u00e9 Ceph, snapshots, planification des backups, gestion fine du r\u00e9seau (VLAN, firewall, SDN), etc. Cela \u00e9vite d\u2019assembler soi-m\u00eame plusieurs outils externes : tout est pr\u00eat \u00e0 l\u2019emploi.</p> </li> <li> <p>Performance et efficacit\u00e9  \u2013 Bas\u00e9 sur Debian Linux et KVM, Proxmox offre des performances proches du natif pour les VM. La gestion des ressources est efficace, avec prise en charge de l\u2019oversubscription (overcommit) contr\u00f4l\u00e9e de la RAM et des vCPU. L\u2019overhead syst\u00e8me est relativement faible, ce qui permet d\u2019exploiter au maximum le mat\u00e9riel, m\u00eame modeste. De plus, la prise en charge de technologies comme  virtIO  (pilotes paravirt) et  SPICE  pour l\u2019affichage optimise les performances des syst\u00e8mes invit\u00e9s.</p> </li> <li> <p>Support \u00e9tendu et options pro  \u2013 Bien que gratuit, Proxmox propose des abonnements support pour ceux qui le souhaitent, ainsi qu\u2019une documentation officielle exhaustive. La communaut\u00e9 (forums, wiki) r\u00e9pond rapidement aux questions. On trouve pl\u00e9thore de tutoriels et de retours d\u2019exp\u00e9rience en ligne (y compris en fran\u00e7ais) \u00e9tant donn\u00e9 la popularit\u00e9 de la solution en homelab.</p> </li> </ul>"},{"location":"infrastructure/proxmox/#inconvenients","title":"Inconv\u00e9nients","text":"<ul> <li> <p>Courbe d\u2019apprentissage sur les fonctions avanc\u00e9es  \u2013 Les bases de Proxmox sont simples, mais exploiter des fonctionnalit\u00e9s comme Ceph, la haute dispo ou le SDN demande une certaine expertise. Un d\u00e9butant pourra se sentir un peu d\u00e9pass\u00e9 en configurant un cluster 3 n\u0153uds ou en optimisant ZFS. Il faut accepter de se documenter et parfois de passer par la ligne de commande pour les ajustements pointus.</p> </li> <li> <p>Pas de fonctions NAS int\u00e9gr\u00e9es  \u2013 Contrairement \u00e0 TrueNAS, Proxmox n\u2019embarque pas de service de fichiers pr\u00eat \u00e0 l\u2019emploi. Il n\u2019y a pas de partage SMB/NFS int\u00e9gr\u00e9  by design. L\u2019hyperviseur se concentre sur les VM/containers, et part du principe que si un NAS est requis, il sera install\u00e9  dans  une VM ou conteneur s\u00e9par\u00e9 (par ex. une VM TrueNAS, ou un conteneur SAMBA)  . Cela demande un peu plus de travail pour mettre en place un serveur de fichiers ou de m\u00e9dias.</p> </li> <li> <p>Gestion des conteneurs limit\u00e9e aux Linux  \u2013 Les conteneurs LXC de Proxmox ne peuvent ex\u00e9cuter que des syst\u00e8mes Linux. Si vous devez virtualiser d\u2019autres syst\u00e8mes (Windows, *BSD), il faudra n\u00e9cessairement cr\u00e9er une VM. De plus, certains logiciels ne fonctionnent pas bien dans des conteneurs (notamment s\u2019ils requi\u00e8rent un acc\u00e8s bas niveau ou un kernel module sp\u00e9cifique). Dans ces cas-l\u00e0, la solution sera de passer par une VM, plus lourde en ressources.</p> </li> <li> <p>\u00c9cosyst\u00e8me moins cloud-native  \u2013 Par rapport \u00e0 une approche Kubernetes (comme Harvester ou m\u00eame TrueNAS SCALE), Proxmox n\u2019int\u00e8gre pas de gestion des conteneurs applicatifs Docker au niveau de l\u2019hyperviseur. Chaque VM/CT est une entit\u00e9 s\u00e9par\u00e9e \u00e0 administrer. Il n\u2019y a pas de catalogue d\u2019applications en un clic. Pour un homelab classique cela n\u2019est pas vraiment un probl\u00e8me, mais si l\u2019on cherche une plateforme style PaaS, il faudra installer des outils suppl\u00e9mentaires (ex: Kubernetes sur Proxmox).</p> </li> <li> <p>Abonnement requis pour le d\u00e9p\u00f4t stable  \u2013 Ce n\u2019est pas un frein majeur, mais \u00e0 noter : sans abonnement payant, les mises \u00e0 jour de Proxmox se font via le d\u00e9p\u00f4t \u00ab non-subscription \u00bb (communautaire). Il contient les m\u00eames packages mais avec potentiellement un peu moins de validation approfondie. Dans les faits, il est tout \u00e0 fait utilisable en homelab. Un simple message d\u2019avertissement s\u2019affiche dans l\u2019UI si vous n\u2019avez pas de souscription, message que l\u2019on peut masquer manuellement.</p> </li> <li> <p>Impossibilit\u00e9 de downgrader  \u2013 Une fois Proxmox install\u00e9 ou mis \u00e0 niveau, il est difficile de revenir \u00e0 une version ant\u00e9rieure sans tout r\u00e9installer. Il faut donc bien tester les mises \u00e0 jour majeures sur un environnement de test ou attendre les retours de la communaut\u00e9 avant de sauter le pas en production (homelab avanc\u00e9). Heureusement, les migrations de version sont g\u00e9n\u00e9ralement bien document\u00e9es et fiables.</p> </li> </ul> <p>(Suggestion de capture d\u2019\u00e9cran : Fen\u00eatre de configuration du firewall Proxmox montrant des r\u00e8gles filtrant l\u2019acc\u00e8s aux VMs.)</p>"},{"location":"infrastructure/proxmox/#bonnes-pratiques-de-configuration-securite-performances","title":"Bonnes pratiques de configuration (s\u00e9curit\u00e9 &amp; performances)","text":"<p>Pour tirer le meilleur parti de Proxmox dans un homelab s\u00e9curis\u00e9, voici quelques conseils de configuration couvrant la  s\u00e9curit\u00e9  et les  performances.</p>"},{"location":"infrastructure/proxmox/#securite","title":"S\u00e9curit\u00e9","text":"<ul> <li> <p>Segmenter les r\u00e9seaux : Isolez votre hyperviseur et vos VMs sensibles sur des r\u00e9seaux/VLAN distincts. Par exemple, placez l\u2019interface management de Proxmox sur un VLAN admin inaccessible depuis le Wi-Fi invit\u00e9 ou Internet. De m\u00eame, les VMs expos\u00e9es au web (serveur web, Nextcloud\u2026) devraient r\u00e9sider dans une  DMZ  s\u00e9par\u00e9e du LAN personnel. Un routeur/pare-feu (OPNsense, pfSense) pourra g\u00e9rer ces VLAN et filtrer le trafic entre eux.  (Suggestion de capture d\u2019\u00e9cran : Sch\u00e9ma r\u00e9seau avec firewall OPNsense s\u00e9parant VLAN LAN, DMZ services et Lab).  Ceci emp\u00eache qu\u2019une VM compromise dans la DMZ n\u2019acc\u00e8de \u00e0 vos appareils du LAN.</p> </li> <li> <p>Configurer le pare-feu Proxmox : Proxmox VE inclut un firewall applicatif. Activez-le et d\u00e9finissez des r\u00e8gles par d\u00e9faut restrictives. Par exemple, au niveau datacenter, on peut bloquer tout trafic entrant non n\u00e9cessaire vers l\u2019hyperviseur (seuls SSH, HTTPS 8006, et \u00e9ventuellement 5900-5999 pour la console VNC, devraient \u00eatre autoris\u00e9s depuis le LAN admin). Pour chaque VM, n\u2019ouvrir que les ports requis (HTTP/HTTPS, etc.). Le firewall Proxmox comprend aussi des  Security Groups  pour r\u00e9utiliser des r\u00e8gles facilement.</p> </li> <li> <p>Mises \u00e0 jour r\u00e9guli\u00e8res : Maintenez Proxmox et vos VM \u00e0 jour. Les mises \u00e0 jour de s\u00e9curit\u00e9 du noyau Linux, de l\u2019hyperviseur ou des conteneurs corrigent des vuln\u00e9rabilit\u00e9s critiques. Sur Proxmox, il suffit d\u2019ex\u00e9cuter r\u00e9guli\u00e8rement  apt update &amp;&amp; apt full-upgrade  (ou via l\u2019UI) pour appliquer les patchs disponibles. Astuce : souscrire au flux RSS des annonces Proxmox pour \u00eatre alert\u00e9 des nouvelles versions.</p> </li> <li> <p>Authentification renforc\u00e9e : Par d\u00e9faut, l\u2019authentification se fait avec le compte  root  de Proxmox. Il est recommand\u00e9 d\u2019activer la  double authentification (2FA)  pour l\u2019acc\u00e8s \u00e0 l\u2019interface web (Proxmox supporte TOTP \u2013 par ex. avec Google Authenticator). Envisagez de cr\u00e9er des comptes administrateurs non-root pour l\u2019usage courant, afin de d\u00e9sactiver les connexions root directes sur l\u2019UI et SSH. Utilisez des mots de passe forts ou des cl\u00e9s SSH pour le compte root. Si possible, limitez l\u2019acc\u00e8s SSH \u00e0 Proxmox aux seules adresses IP de confiance (via  /etc/hosts.allow  ou le firewall).</p> </li> <li> <p>Ne pas exposer Proxmox directement \u00e0 Internet : \u00c9vitez de rendre l\u2019interface web accessible depuis le web public. Si vous avez besoin d\u2019y acc\u00e9der \u00e0 distance, privil\u00e9giez une connexion VPN vers votre r\u00e9seau local, ou \u00e9ventuellement un tunnel SSH s\u00e9curis\u00e9. Proxmox n\u2019est pas con\u00e7u pour \u00eatre plac\u00e9 en frontal sur Internet et un acc\u00e8s direct augmenterait la surface d\u2019attaque.</p> </li> <li> <p>Limiter les services sur l\u2019h\u00f4te : N\u2019installez pas de services additionnels (serveur web, base de donn\u00e9es, etc.) directement sur l\u2019OS Proxmox. Gardez l\u2019hyperviseur \u00e9pur\u00e9 pour r\u00e9duire les risques. Toute application doit id\u00e9alement tourner dans une VM ou un conteneur, jamais sur l\u2019h\u00f4te lui-m\u00eame (sauf outils de monitoring l\u00e9gers). Cela suit le principe de  s\u00e9paration des r\u00f4les : l\u2019hyperviseur fait de la virtualisation, les services tournent  dans  les machines virtuelles.</p> </li> <li> <p>Sauvegardes externes et chiffr\u00e9es : Stockez les sauvegardes de vos VM sur un stockage externe (NAS, disque USB chiffr\u00e9, cloud) et non uniquement sur le serveur Proxmox lui-m\u00eame. En cas de compromission de l\u2019hyperviseur ou de ransomware, il faut pouvoir restaurer ses donn\u00e9es \u00e0 partir d\u2019un emplacement s\u00fbr. Proxmox Backup Server (PBS) peut \u00eatre une bonne solution : il d\u00e9duplique et chiffre les sauvegardes  . \u00c0 d\u00e9faut, un simple export vers un NAS TrueNAS via NFS, avec snapshots ZFS sur le NAS, peut convenir.</p> </li> </ul>"},{"location":"infrastructure/proxmox/#performances","title":"Performances","text":"<ul> <li> <p>Bien dimensionner la RAM (surtout avec ZFS) : Si vous utilisez ZFS sur Proxmox, rappelez-vous que ZFS adore la RAM (cache ARC). Pour un serveur avec 16 Go par exemple, il est raisonnable de r\u00e9server 4 \u00e0 8 Go pour ZFS et le syst\u00e8me, le reste pour les VM. Il est possible de limiter la taille de l\u2019ARC ZFS (zfs_arc_max) pour \u00e9viter qu\u2019il n\u2019utilise toute la m\u00e9moire. Adapter la RAM en fonction du nombre de VM et de leur usage (base de donn\u00e9es, JVM et autres applis consommatrices).</p> </li> <li> <p>Utiliser les SSD/NVMe pour les VM critiques : Installez Proxmox et vos images de VM sur des  SSD  ou NVMe si possible, en particulier pour les OS et applications n\u00e9cessitant beaucoup d\u2019I/O (base de donn\u00e9es, HAProxy, etc.). Les temps d\u2019acc\u00e8s r\u00e9duits am\u00e9lioreront nettement la r\u00e9activit\u00e9 des services. Vous pouvez d\u00e9dier un pool ZFS miroir de deux SSD NVMe pour les volumes de VM, et garder les disques durs classiques pour du stockage de masse ou des backups.</p> </li> <li> <p>RAID mat\u00e9riel vs ZFS : Si vous optez pour ZFS, \u00e9vitez d\u2019utiliser un RAID mat\u00e9riel en dessous \u2013 ZFS pr\u00e9f\u00e8re avoir un acc\u00e8s direct aux disques (HBA en JBOD). Laissez ZFS g\u00e9rer la redondance (RAID-Z, miroir) pour b\u00e9n\u00e9ficier de ses capacit\u00e9s de correction d\u2019erreurs et surveillance d\u2019int\u00e9grit\u00e9. En revanche, si vous utilisez du  LVM-thin  sur un RAID mat\u00e9riel existant, assurez-vous que le contr\u00f4leur RAID dispose de cache prot\u00e9g\u00e9 (BBU) pour de bonnes performances en \u00e9criture.</p> </li> <li> <p>Configurer le cache des disques virtuels : Dans Proxmox, chaque disque virtuel d\u2019une VM a un mode de cache (No cache, WriteBack, etc.). Pour les volumes de syst\u00e8mes d\u2019exploitation, le mode  Write Back  avec  cache directfonctionne bien et acc\u00e9l\u00e8re les I/O (en assumant que l\u2019h\u00f4te a une protection d\u2019alimentation ou que la perte de quelques secondes de donn\u00e9es est acceptable). En revanche, pour une VM de base de donn\u00e9es o\u00f9 la coh\u00e9rence prime, on peut rester en  Write Through  (par d\u00e9faut) pour garantir que les \u00e9critures sont directement flush sur le stockage.</p> </li> <li> <p>virtIO et agents invit\u00e9s : Utilisez les  pilotes virtIO  pour les p\u00e9riph\u00e9riques virtuels (disque, r\u00e9seau) dans vos VM Linux et Windows \u2013 ils offrent de bien meilleures performances que l\u2019\u00e9mulation IDE/E1000. Proxmox propose d\u2019office virtIO pour les nouvelles VM Linux. Pour Windows, installez les  Drivers virtIO  fournis par Red Hat. De plus, pensez \u00e0 installer l\u2019agent QEMU Guest  dans chaque VM (paquet  qemu-guest-agent) : cela permet une meilleure interaction (arr\u00eat propre depuis l\u2019UI, informations IP remont\u00e9es, etc.).</p> </li> <li> <p>Surveillance et affinage : Mettez en place un monitoring de base de votre hyperviseur (Proxmox exporte des m\u00e9triques CPU, RAM, r\u00e9seau par VM dans l\u2019UI). Pour aller plus loin, des outils comme  Zabbix, Prometheus, Grafana  ou  Glances  peuvent \u00eatre utilis\u00e9s pour surveiller l\u2019utilisation des ressources en continu. Vous pourrez ainsi rep\u00e9rer une VM consommatrice qui swap ou un conteneur qui sature le CPU, et ajuster les ressources allou\u00e9es en cons\u00e9quence (RAM max, limites CPU, etc.).</p> </li> <li> <p>\u00c9viter la surallocation excessive : Proxmox autorise de surallouer la RAM (ballooning) et les vCPU (sur plusieurs VM) par rapport au physique. Un l\u00e9ger surcommit peut passer si toutes les VM ne sont pas actives en m\u00eame temps. Cependant, en homelab, il est plus s\u00fbr d\u2019\u00e9viter une surallocation trop optimiste, car en cas de pic simultan\u00e9, vous risquez du swap (ralentissements drastiques) ou une contention CPU. Gardez une petite marge de ressources libres pour l\u2019hyperviseur lui-m\u00eame.</p> </li> <li> <p>Optimisations sp\u00e9cifiques : Activez  l\u2019IOMMU  dans le BIOS/UEFI de votre machine pour permettre le  pass-through  de p\u00e9riph\u00e9riques (GPU, USB contr\u00f4leur) vers les VM si vous en avez besoin (par ex. une VM media center avec GPU pour transcodage). Assurez-vous que la fonction VT-x/AMD-V est activ\u00e9e \u00e9galement pour les VMs. Si vous utilisez un cluster multi-n\u0153uds, configurez un r\u00e9seau d\u00e9di\u00e9 Gigabit+ (ou mieux 10 Gb) pour le trafic de synchronisation (Corosync, Ceph) et un autre pour les VMs, afin d\u2019\u00e9viter les saturations. Enfin, en environnement domestique, un onduleur (UPS) communiquant avec l\u2019hyperviseur est conseill\u00e9 pour envoyer une commande d\u2019arr\u00eat propre en cas de coupure prolong\u00e9e \u2013 il existe des connecteurs NUT ou APCUPSd que l\u2019on peut installer sur Proxmox pour cela.</p> </li> </ul>"},{"location":"infrastructure/proxmox/#gestion-du-stockage-nvmecold-storage-sur-hdd-integration-truenas-etc","title":"Gestion du stockage : NVMe,cold storage sur HDD, int\u00e9gration TrueNAS, etc.","text":"<p>La configuration du stockage est un \u00e9l\u00e9ment cl\u00e9 d\u2019un homelab. Proxmox offre la flexibilit\u00e9 de combiner diff\u00e9rentes cat\u00e9gories de disques et m\u00eame des solutions externes pour obtenir le meilleur compromis entre performance, capacit\u00e9 et r\u00e9silience :</p> <ul> <li> <p>Utiliser les SSD NVMe pour les workloads actifs : Les disques NVMe (ou SSD SATA) offrent des IOPS \u00e9lev\u00e9es et une faible latence. Il est judicieux d\u2019y stocker les  disques syst\u00e8me  de vos VM et conteneurs, ainsi que les bases de donn\u00e9es et services n\u00e9cessitant beaucoup d\u2019acc\u00e8s disques. Par exemple, votre VM Home Assistant ou votre base PostgreSQL b\u00e9n\u00e9ficieront grandement d\u2019\u00eatre sur NVMe. Vous pouvez cr\u00e9er un  pool ZFS en miroir  de deux NVMe pour la fiabilit\u00e9 (tol\u00e9rance \u00e0 la panne d\u2019un disque). Si la capacit\u00e9 NVMe est limit\u00e9e, ne mettez que les OS et donn\u00e9es \u201cchaudes\u201d dessus.</p> </li> <li> <p>Stockage \u201cfroid\u201d sur disques durs : Pour les donn\u00e9es volumineuses et moins fr\u00e9quemment acc\u00e9d\u00e9es (m\u00e9dias, backups, archives), les disques durs classiques (HDD) conviennent et co\u00fbtent moins cher au To. Vous pouvez soit les int\u00e9grer au serveur Proxmox (par ex. un deuxi\u00e8me pool ZFS en RAID-Z sur 3-4 HDD pour stocker les sauvegardes de VM, les vid\u00e9os, etc.), soit les h\u00e9berger sur un NAS s\u00e9par\u00e9. Proxmox peut tout \u00e0 fait acc\u00e9der \u00e0 un NAS via NFS ou iSCSI pour y stocker des donn\u00e9es  . N\u2019h\u00e9sitez pas \u00e0 utiliser la  compression ZFS  (lz4) sur les stockages HDD pour r\u00e9duire la taille des archives et backups (elle est rapide et souvent transparente en co\u00fbt CPU).</p> </li> <li> <p>Cache et tiering : Si vous combinez SSD et HDD, pensez \u00e0 exploiter les SSD comme cache. ZFS permet par exemple d\u2019ajouter un  cache L2ARC  (lecture) sur SSD pour acc\u00e9l\u00e9rer l\u2019acc\u00e8s aux donn\u00e9es souvent lues depuis un pool HDD, et un  disque de log (SLOG)  sur SSD pour fiabiliser/acc\u00e9l\u00e9rer les \u00e9critures synchrones d\u2019un pool HDD (utile pour un serveur de fichiers ou VM base de donn\u00e9es sur HDD). Dans Proxmox, ces op\u00e9rations se font en ligne de commande (commande  zpool add  pour ajouter cache ou log). Veillez toutefois \u00e0 utiliser des SSD de qualit\u00e9 pour le SLOG (haute endurance) et une capacit\u00e9 de L2ARC raisonnable (pas plus de 5x la RAM typiquement, sinon l\u2019empreinte m\u00e9moire du cache metadata devient contre-productive).</p> </li> <li> <p>Int\u00e9gration avec un NAS (TrueNAS ou autre) : De nombreux homelab ont un NAS d\u00e9di\u00e9 pour stocker documents, m\u00e9dias, sauvegardes, etc. Proxmox s\u2019int\u00e8gre bien avec ces solutions. Le cas le plus courant :  monter un partage NFS du NAS dans Proxmox  pour y d\u00e9poser les backups de VM ou m\u00eame h\u00e9berger certaines VM non critiques. Par exemple, un NAS TrueNAS SCALE (qui excelle en ZFS) peut exposer un dataset en NFS, ajout\u00e9 comme stockage dans Proxmox en quelques clics. On peut alors sauvegarder les VM vers ce NAS, ou y h\u00e9berger des disques de VM moins sensibles aux latences du r\u00e9seau  . Alternativement, le NAS peut pr\u00e9senter une cible  iSCSI  que Proxmox utilisera comme LUN de stockage (souvent coupl\u00e9 \u00e0 LVM c\u00f4t\u00e9 Proxmox). L\u2019iSCSI offre de bonnes performances mais une configuration un peu plus complexe (et n\u00e9cessite une gestion soigneuse si plusieurs n\u0153uds y acc\u00e8dent simultan\u00e9ment, via un gestionnaire de volume partag\u00e9).</p> </li> <li> <p>TrueNAS en VM sur Proxmox : Une autre int\u00e9gration possible, si vous n\u2019avez qu\u2019un seul serveur physique, est d\u2019installer TrueNAS (Core ou SCALE) dans une VM Proxmox. Dans ce sc\u00e9nario, on passe un contr\u00f4leur HBA (SATA/SAS) en  passthrough  \u00e0 la VM TrueNAS, qui a ainsi un acc\u00e8s direct aux disques durs. TrueNAS g\u00e8re son pool ZFS et sert de NAS, tandis que Proxmox g\u00e8re la VM TrueNAS comme n\u2019importe quelle VM. Cette approche permet de b\u00e9n\u00e9ficier de l\u2019interface de TrueNAS pour le partage de fichiers, tout en profitant des snapshots et backups Proxmox au niveau de la VM compl\u00e8te.  Attention  toutefois : en cas d\u2019arr\u00eat de la VM ou de Proxmox, le NAS devient indisponible. De plus, le passthrough demande que votre mat\u00e9riel supporte bien l\u2019IOMMU. Certains homelabers pr\u00e9f\u00e8rent cette solution \u201c2-en-1\u201d pour \u00e9conomiser du mat\u00e9riel, mais elle complexifie un peu la maintenance. Si vous optez pour cela, assurez-vous que Proxmox ne tente pas d\u2019utiliser les disques d\u00e9di\u00e9s TrueNAS (ne pas les int\u00e9grer dans un pool Proxmox).</p> </li> <li> <p>Proxmox Backup Server (PBS) : Pour le stockage des sauvegardes, l\u2019outil recommand\u00e9 est PBS \u2013 qui peut tourner sur une machine s\u00e9par\u00e9e ou sur une VM/container. PBS d\u00e9duplique et compresse fortement les backups, \u00e9conomisant de l\u2019espace. Une strat\u00e9gie courante est d\u2019avoir un petit serveur (ou une VM sur un autre n\u0153ud) avec des disques HDD qui sert de PBS, recevant les backups quotidiens chiffr\u00e9s depuis le Proxmox principal  . En cas de besoin, on peut restaurer granulairement des fichiers ou VM enti\u00e8res depuis PBS via l\u2019UI Proxmox. Si votre homelab est modeste, un simple disque USB externe mont\u00e9 sur Proxmox pour y copier les backups r\u00e9guli\u00e8rement peut suffire, mais pensez \u00e0 la d\u00e9connecter quand elle n\u2019est pas en cours d\u2019utilisation (pour \u00e9viter qu\u2019un ransomware qui infecterait une VM ne chiffre aussi vos sauvegardes mont\u00e9es).</p> </li> </ul> <p>En combinant judicieusement NVMe, SSD, HDD et stockage r\u00e9seau, vous assurez \u00e0 votre homelab Proxmox \u00e0 la fois des  performances \u00e9lev\u00e9es  pour les services critiques et une  grande capacit\u00e9 de stockage  pour les donn\u00e9es volumineuses, le tout avec des sauvegardes s\u00e9curis\u00e9es. Cette hybridation des stockages est un des grands atouts d\u2019une solution auto-h\u00e9berg\u00e9e : vous pouvez ajuster au mieux en fonction de votre budget et de vos besoins.</p>"},{"location":"infrastructure/proxmox/#integration-avec-docker-portainer-home-assistant-etc","title":"Int\u00e9gration avec Docker, Portainer, Home Assistant, etc.","text":"<p>Proxmox VE, en tant qu\u2019hyperviseur, sert de base pour d\u00e9ployer d\u2019autres couches de services. Voici comment tirer parti de Proxmox pour int\u00e9grer des technologies populaires de self-hosting comme Docker/Portainer ou Home Assistant.</p>"},{"location":"infrastructure/proxmox/#heberger-des-conteneurs-docker-avec-ou-sans-portainer","title":"H\u00e9berger des conteneurs Docker (avec ou sans Portainer)","text":"<p>Beaucoup d\u2019utilisateurs de homelab souhaitent utiliser  Docker  pour d\u00e9ployer des applications (Nextcloud, MariaDB, Jellyfin, etc.). Docker n\u2019est pas fourni en natif sur Proxmox (il ne faut pas l\u2019installer directement sur l\u2019h\u00f4te Proxmox, ce n\u2019est pas recommand\u00e9). \u00c0 la place, deux approches s\u2019offrent \u00e0 vous pour utiliser Docker  sur  Proxmox :</p> <ul> <li> <p>LXC Docker : Cr\u00e9er un conteneur LXC sous Proxmox et y installer Docker. Cette m\u00e9thode utilise peu de ressources (pas de surcouche OS lourde) et offre des performances quasi natives, puisque l\u2019LXC partage le noyau de Proxmox. Il faut pour cela activer certaines options sur le conteneur (notamment les cgroups et le nesting) afin que Docker puisse tourner \u00e0 l\u2019int\u00e9rieur. De nombreux homelabers utilisent par exemple un conteneur Debian LXC d\u00e9di\u00e9 comme h\u00f4te Docker.  Avantages:  l\u00e9g\u00e8ret\u00e9, efficacit\u00e9.  Inconv\u00e9nients:  Pas de vraie isolation kernel (moins s\u00e9curis\u00e9 qu\u2019une VM) et  pas de migration \u00e0 chaud possible  pour ce conteneur Docker (les conteneurs LXC ne supportent pas la live migration facilement). \u00c0 noter que Proxmox recommande plut\u00f4t la seconde approche pour Docker  , mais l\u2019approche LXC fonctionne et est pratique sur petite infra.</p> </li> <li> <p>VM Docker : Cr\u00e9er une VM (par ex. Debian, Ubuntu Server) sur Proxmox et y installer le moteur Docker + \u00e9ventuellement  Portainer  pour l\u2019administration web des containers. Cette VM servira de \u201chost Docker\u201d classique. Par rapport \u00e0 l\u2019option LXC, on a l\u2019avantage d\u2019une isolation compl\u00e8te (noyau s\u00e9par\u00e9), la possibilit\u00e9 de snapshots et migrations  comme pour n\u2019importe quelle VM, au prix d\u2019une l\u00e9g\u00e8re surcouche de ressources (une VM consomme plus de RAM/CPU qu\u2019un LXC minimal). C\u2019est la m\u00e9thode pr\u00e9conis\u00e9e pour une fiabilit\u00e9 maximale  . Vous pourriez par exemple avoir une VM Ubuntu 22.04 avec 2 vCPU et 4 Go de RAM qui fait tourner Docker + Portainer, h\u00e9bergeant vos divers services conteuneuris\u00e9s.</p> </li> </ul> <p>Portainer  s\u2019int\u00e8gre dans ce contexte comme un conteneur Docker facultatif offrant une UI pour piloter vos autres conteneurs. Si vous souhaitez l\u2019utiliser, d\u00e9ployez-le dans l\u2019environnement Docker de votre choix (VM ou LXC). Portainer permettra de g\u00e9rer et superviser vos conteneurs via le navigateur, ce qui compl\u00e8te bien Proxmox (Portainer ne g\u00e8re que le niveau Docker, tandis que Proxmox g\u00e8re la VM/CT h\u00f4te). Vous pouvez m\u00eame ajouter plusieurs  Endpoints  dans Portainer (par ex. si plus tard vous avez plusieurs h\u00f4tes Docker sur diff\u00e9rentes VM ou machines).</p> <p>En somme, Proxmox sert ici de  couche d\u2019orchestration basse  : on cr\u00e9e une VM ou CT d\u00e9di\u00e9s qui deviennent notre \u201cserveur Docker\u201d. Cette s\u00e9paration assure que Docker n\u2019interf\u00e8re pas avec l\u2019hyperviseur et que les bonnes pratiques sont respect\u00e9es (on ne transforme pas Proxmox en machine \u00e0 tout faire, on cloisonne). Les deux approches sont valables; pour d\u00e9buter, la VM Docker+Portainer est souvent plus simple \u00e0 mettre en \u0153uvre et \u00e0 maintenir \u00e0 jour (car identique \u00e0 n\u2019importe quel Ubuntu standard, avec les docs Docker officielles applicables).</p> <p>(Suggestion de capture d\u2019\u00e9cran : Interface Portainer montrant la liste des containers en fonctionnement, h\u00e9berg\u00e9e dans une VM Proxmox.)</p>"},{"location":"infrastructure/proxmox/#executer-home-assistant-sur-proxmox","title":"Ex\u00e9cuter Home Assistant sur Proxmox","text":"<p>Home Assistant  est une application phare en domotique, que de nombreux utilisateurs souhaitent auto-h\u00e9berger. Proxmox est un excellent h\u00f4te pour Home Assistant, car il permet de faire tourner  Home Assistant OS  (la distribution d\u00e9di\u00e9e officielle) dans une VM avec la possibilit\u00e9 de faire des snapshots avant mise \u00e0 jour, de restaurer rapidement en cas de crash, etc.</p> <p>Plusieurs m\u00e9thodes s\u2019offrent \u00e0 vous pour Home Assistant (HA) sur Proxmox :</p> <ul> <li> <p>VM Home Assistant OS : La m\u00e9thode recommand\u00e9e consiste \u00e0 installer Home Assistant OS dans une VM KVM. L\u2019\u00e9quipe HA fournit une image disque (fichier .qcow2 ou .vdi) pr\u00eate \u00e0 l\u2019emploi. On cr\u00e9e une VM dans Proxmox (2 vCPU, 2 Go RAM par exemple), on importe le disque fourni et on d\u00e9marre. En quelques minutes, Home Assistant est op\u00e9rationnel et accessible sur le r\u00e9seau. Cette VM d\u00e9di\u00e9e tourne 24/7 pour votre domotique. L\u2019avantage est que HA OS inclut le superviseur, ce qui permet d\u2019installer facilement les add-ons, et Proxmox permet de  snapshoter  la VM avant une mise \u00e0 jour Home Assistant, ou de planifier des sauvegardes automatiques de la VM compl\u00e8te.</p> </li> <li> <p>Home Assistant Container ou Core : Alternativement, si vous ne voulez pas de VM, vous pourriez faire tourner Home Assistant sous forme de conteneur Docker (m\u00e9thode dite \u201cHome Assistant Core\u201d ou via l\u2019image Docker) \u00e0 l\u2019int\u00e9rieur soit d\u2019un LXC, soit d\u2019une VM Linux comme discut\u00e9 plus haut. Cette approche peut convenir si vous avez d\u00e9j\u00e0 une infra Docker et que HA n\u2019a pas besoin d\u2019acc\u00e9der \u00e0 du hardware particulier. Cependant, vous perdez la simplicit\u00e9 du  superviseur  HA et des add-ons. En g\u00e9n\u00e9ral, la communaut\u00e9 recommande l\u2019approche VM HA OS pour une exp\u00e9rience la plus simple et compl\u00e8te.</p> </li> </ul> <p>Avec Home Assistant sur Proxmox, quelques  bonnes pratiques  sp\u00e9cifiques :</p> <ul> <li> <p>Pensez \u00e0  activer l\u2019USB passthrough  si vous avez des dongles Zigbee/Z-Wave ou autre mat\u00e9riel domotique branch\u00e9 au serveur. Proxmox permet d\u2019attacher un p\u00e9riph\u00e9rique USB physique \u00e0 une VM (via l\u2019UID ou le port). Vous pourrez ainsi rendre visible le dongle Zigbee dans Home Assistant (la VM) comme s\u2019il y \u00e9tait branch\u00e9 directement.</p> </li> <li> <p>Allouez suffisamment de ressources \u00e0 la VM HA (2 \u00e0 4 Go RAM selon la taille de votre installation, et 1 \u00e0 2 vCPU minimum). Home Assistant OS est bas\u00e9 sur un Linux Alpine avec Docker, il n\u2019est pas tr\u00e8s lourd, mais les add-ons comme Node-RED, Zigbee2MQTT, etc. consomment un peu de RAM.</p> </li> <li> <p>Isolez le r\u00e9seau de la VM HA si possible (par exemple, dans un VLAN sp\u00e9cifique domotique) surtout si vous exposez Home Assistant \u00e0 Internet (via Nabu Casa ou autre). M\u00eame si Home Assistant est relativement s\u00fbr, une segmentation limite les impacts en cas d\u2019intrusion.</p> </li> <li> <p>Profitez des  snapshots Proxmox  : avant de faire une grosse modification dans Home Assistant (mise \u00e0 jour majeure, ajout d\u2019une int\u00e9gration exp\u00e9rimentale), prenez un snapshot \u00e0 chaud de la VM. Si quelque chose va mal, vous pourrez en quelques secondes revenir \u00e0 l\u2019\u00e9tat ant\u00e9rieur connu.</p> </li> <li> <p>Configurez des  backup automatis\u00e9s  de Home Assistant : soit \u00e0 l\u2019int\u00e9rieur de Home Assistant (il peut faire des sauvegardes de sa config), soit au niveau Proxmox (sauvegarde programm\u00e9e de la VM HA comme n\u2019importe quelle VM). Id\u00e9alement, exportez ces backups hors du serveur (par ex. copie vers un NAS via un script).</p> </li> </ul> <p>En adoptant cette approche, Proxmox devient la fondation stable sur laquelle Home Assistant tourne de mani\u00e8re quasi transparente, tout en offrant un filet de s\u00e9curit\u00e9 (snapshots, backups faciles) tr\u00e8s appr\u00e9ci\u00e9 des power users.</p> <p>(Suggestion de capture d\u2019\u00e9cran : Console Proxmox affichant Home Assistant OS en cours de d\u00e9marrage dans une VM.)</p>"},{"location":"infrastructure/proxmox/#utilisation-des-templates-debian-ubuntu-alpine-pour-deployer-rapidement-des-services","title":"Utilisation des templates (Debian, Ubuntu, Alpine\u2026) pour d\u00e9ployer rapidement des services","text":"<p>L\u2019un des avantages de Proxmox pour gagner du temps est sa prise en charge des  templates de conteneurs LXC  et des  mod\u00e8les de VM. Plut\u00f4t que d\u2019installer \u00e0 la main un OS \u00e0 chaque nouvelle VM ou container, on peut s\u2019appuyer sur ces mod\u00e8les pr\u00e9configur\u00e9s pour d\u00e9ployer un service en quelques secondes.</p>"},{"location":"infrastructure/proxmox/#templates-lxc-tout-prets","title":"Templates LXC tout pr\u00eats","text":"<p>Dans l\u2019interface Proxmox, lorsque vous cr\u00e9ez un nouveau conteneur (CT), il est propos\u00e9 de t\u00e9l\u00e9charger un  _template_depuis la biblioth\u00e8que officielle Proxmox. Ces templates sont des images minimales d\u2019OS Linux courants, maintenues \u00e0 jour, par ex.  Debian 11/12 Standard,  Ubuntu 22.04 LTS,  Alpine 3.17,  CentOS/AlmaLinux 8, etc. (et m\u00eame des appliances TurnKey avec des applications pr\u00e9install\u00e9es). Une fois le template (tarball) t\u00e9l\u00e9charg\u00e9 sur votre n\u0153ud, d\u00e9ployer un nouveau conteneur revient essentiellement \u00e0 cloner cette image.</p> <p>Exemple d\u2019utilisation : vous voulez rapidement un petit conteneur pour h\u00e9berger un serveur web Nginx sur Alpine. Depuis Proxmox, cliquez  Cr\u00e9er CT, choisissez le template Alpine Linux (t\u00e9l\u00e9chargeable s\u2019il ne l\u2019est pas), quelques param\u00e8tres (CPU, RAM, mot de passe root) et validez. En 10 secondes le conteneur est cr\u00e9\u00e9 et en cours d\u2019ex\u00e9cution, avec Alpine pr\u00eat \u00e0 l\u2019emploi. Il ne reste plus qu\u2019\u00e0  apk add nginx  via la console, et votre serveur web tourne. Cette v\u00e9locit\u00e9 de d\u00e9ploiement est impossible \u00e0 battre compar\u00e9 \u00e0 une installation manuelle d\u2019OS.</p> <p>La m\u00eame logique s\u2019applique pour Debian ou Ubuntu : si vous avez l\u2019habitude de ces distributions, utiliser le  template Debian Standard  vous donne un conteneur minimal (quelques centaines de Mo) en moins d\u2019une minute, sur lequel vous installez uniquement les paquets requis pour votre service (ex:  apt install mariadb-server  si c\u2019est une base MariaDB).  Alpine  est excellente pour les tout petits services (tr\u00e8s l\u00e9ger, quelques packages de base),  Debian/Ubuntu  offrent plus de confort (systemd, glibc) pour des applications plus complexes.</p> <p>Les  templates TurnKey Linux  disponibles sont aussi int\u00e9ressants pour tester rapidement une application : il y a par exemple des CT TurnKey  Nextcloud,  WordPress,  GitLab  etc., qui viennent pr\u00e9configur\u00e9s. En quelques clics on peut avoir une instance Nextcloud fonctionnelle. Cependant, pour un usage p\u00e9renne en homelab, on pr\u00e9f\u00e8re souvent d\u00e9ployer manuellement sur un OS propre pour mieux contr\u00f4ler la config. \u00c0 vous de voir.</p> <p>Les conteneurs LXC Proxmox sont des  containeurs syst\u00e8me  (OS complet) et non juste des conteneurs applicatifs type Docker  . Cela signifie que chaque conteneur se comporte comme une mini distrib Linux isol\u00e9e. On peut s\u2019y connecter en root (ou via un utilisateur si configur\u00e9) et l\u2019administrer comme un petit serveur. Proxmox facilite grandement cette gestion gr\u00e2ce \u00e0  pct, l\u2019outil en ligne de commande, ou via l\u2019interface pour modifier ressources, r\u00e9seau, montages, etc.  . Les conteneurs s\u2019int\u00e8grent aux m\u00e9canismes Proxmox (backups, snapshots, firewall, etc. fonctionnent aussi pour eux).</p>"},{"location":"infrastructure/proxmox/#modeles-et-clones-de-vm","title":"Mod\u00e8les et clones de VM","text":"<p>Outre les LXC, Proxmox permet \u00e9galement de travailler avec des  templates de VM. L\u2019id\u00e9e ici est de cr\u00e9er une VM de base (par ex. une Debian 12 minimale install\u00e9e avec les bons r\u00e9glages), puis de la  convertir en mod\u00e8le. Ce mod\u00e8le ne sera pas d\u00e9marr\u00e9 directement, mais pourra \u00eatre  clon\u00e9  \u00e0 la demande pour cr\u00e9er de nouvelles VM identiques. En homelab, cela sert si vous avez besoin de d\u00e9ployer plusieurs VM similaires rapidement (par exemple, 5 VM Ubuntu pour tester un cluster, ou simplement gagner du temps \u00e0 ne pas r\u00e9p\u00e9ter l\u2019installation OS). La fonction  Clone  de Proxmox, surtout en mode  clone complet, permet d\u2019obtenir en quelques minutes une copie ind\u00e9pendante d\u2019une VM mod\u00e8le.</p> <p>Un usage pratique : vous avez une VM  Windows 10  configur\u00e9e (g\u00e9n\u00e9r\u00e9e via  Sysprep  pour avoir un SID unique \u00e0 la clone). Vous la convertissez en  Template. Lorsqu\u2019un jour vous avez besoin d\u2019une nouvelle VM Windows pour tester un logiciel, vous faites  Cloner  -&gt;  Cr\u00e9er VM clon\u00e9e, et en 2-3 minutes la nouvelle VM Windows est pr\u00eate, sans devoir r\u00e9installer depuis l\u2019ISO et passer 30 min de configuration. Il faudra juste l\u2019activer avec votre licence et la renommer.</p> <p>Pour Linux, le gain est moindre (car l\u2019installation est rapide), mais \u00e7a reste utile si vous avez personnalis\u00e9 un mod\u00e8le avec des outils communs \u00e0 toutes vos VM (par ex. une Debian mod\u00e8le avec  sudo,  vim, les d\u00e9p\u00f4ts non-free activ\u00e9s, l\u2019agent QEMU install\u00e9, etc.). Chaque nouvelle VM clon\u00e9e h\u00e9ritera de ces pr\u00e9paratifs.</p> <p>Enfin, notez que Proxmox g\u00e8re  Cloud-Init  pour les VM : vous pouvez t\u00e9l\u00e9charger des images  cloud  (Ubuntu Cloud, Alpine Cloud, etc.), les utiliser comme base de VM, et via l\u2019outil Cloud-Init de Proxmox, injecter automatiquement un utilisateur, un mot de passe ou une cl\u00e9 SSH, une configuration r\u00e9seau, etc. Cela facilite le d\u00e9ploiement automatis\u00e9 de VM pr\u00eates \u00e0 l\u2019emploi, surtout si vous orchestrez votre homelab avec des outils comme Terraform ou Ansible. Pour un d\u00e9butant, ce n\u2019est pas indispensable, mais c\u2019est bon de savoir que la fonctionnalit\u00e9 existe pour le jour o\u00f9 l\u2019on veut automatiser davantage.</p> <p>En r\u00e9sum\u00e9, exploitez les templates mis \u00e0 disposition par Proxmox pour  acc\u00e9l\u00e9rer vos d\u00e9ploiements. Non seulement cela vous fait gagner du temps, mais en plus vous obtenez des installations propres et coh\u00e9rentes (toutes bas\u00e9es sur l\u2019image officielle de la distrib choisie). La gestion ult\u00e9rieure s\u2019en retrouve facilit\u00e9e et homog\u00e8ne \u00e0 travers vos conteneurs et VMs.</p> <p>(Suggestion de capture d\u2019\u00e9cran : Menu Proxmox montrant la liste des templates LXC disponibles au t\u00e9l\u00e9chargement.)</p>"},{"location":"infrastructure/proxmox/#ressources-officielles-et-communautes-utiles","title":"Ressources officielles et communaut\u00e9s utiles","text":"<p>Pour aller plus loin avec Proxmox VE et obtenir de l\u2019aide, voici quelques liens utiles :</p> <ul> <li> <p>Site Officiel Proxmox VE  \u2013 Page officielle avec pr\u00e9sentation des fonctionnalit\u00e9s, t\u00e9l\u00e9chargements de l\u2019ISO, informations sur les offres de support, etc. (disponible en anglais et autres langues).  proxmox.com</p> </li> <li> <p>Documentation Officielle (Wiki)  \u2013 Le wiki de Proxmox VE contient le guide d\u2019administration complet, les notes de version, et de nombreux articles techniques (r\u00e9seau, stockage, etc.). C\u2019est la r\u00e9f\u00e9rence \u00e0 consulter pour les d\u00e9tails pointus.  pve.proxmox.com/wiki</p> </li> <li> <p>Forum Communautaire Proxmox  \u2013 Forum officiel o\u00f9 \u00e9changent les d\u00e9veloppeurs et utilisateurs. Tr\u00e8s actif, on y trouve des sections par th\u00e9matiques et langue (une cat\u00e9gorie fran\u00e7aise existe pour l\u2019aide dans la langue de Moli\u00e8re). Id\u00e9al pour poser vos questions ou chercher si quelqu\u2019un a d\u00e9j\u00e0 r\u00e9solu un probl\u00e8me similaire.  forum.proxmox.com</p> </li> <li> <p>Proxmox VE sur GitHub  \u2013 Le code source de Proxmox VE et de ses composants (QEMU custom, GUI, etc.) est accessible sur GitHub. Utile pour les contributeurs ou pour signaler des bugs sur Bugzilla.  github.com/proxmox</p> </li> <li> <p>Communaut\u00e9s &amp; tutoriels  \u2013 En dehors des ressources officielles, de nombreuses communaut\u00e9s homelab abordent Proxmox : par exemple le subreddit  r/Proxmox  (en anglais) regorge de retours d\u2019exp\u00e9rience, le subreddit  _r/homelab_discute souvent de Proxmox vs autres solutions, et il existe des groupes Facebook francophones d\u00e9di\u00e9s \u00e0 Proxmox. N\u2019h\u00e9sitez pas \u00e0 consulter des blogs sp\u00e9cialis\u00e9s (par ex.  tutos-info.fr,  blog.stephane-robert.info  en fran\u00e7ais) ou des cha\u00eenes YouTube (Techno Tim, Level1Techs, \u2026) qui proposent des tutoriels et comparatifs sur Proxmox et son \u00e9cosyst\u00e8me.</p> </li> </ul>"},{"location":"infrastructure/reseau/","title":"Plan de r\u00e9seau Homelab : VLAN, Segmentation et Passerelles","text":""},{"location":"infrastructure/reseau/#introduction-pourquoi-segmenter-son-reseau","title":"Introduction : Pourquoi segmenter son r\u00e9seau ?","text":"<p>Segmenter un r\u00e9seau domestique en  VLAN  (Virtual LAN) consiste \u00e0 cr\u00e9er des sous-r\u00e9seaux logiques isol\u00e9s les uns des autres, m\u00eame s\u2019ils partagent le m\u00eame mat\u00e9riel physique (commutateurs, points d\u2019acc\u00e8s, etc.). Cette isolation pr\u00e9sente de nombreux avantages : am\u00e9lioration de la  s\u00e9curit\u00e9  (limiter qu\u2019un appareil compromis n\u2019affecte les autres), meilleure  ma\u00eetrise du trafic  avec des  r\u00e8gles firewall  plus fines, r\u00e9duction du  broadcast  inutile, etc.  . Dans un homelab o\u00f9 coexistent divers \u00e9quipements (serveurs de production personnelle, \u00e9quipements domotiques, cam\u00e9ras IP, labos de cybers\u00e9curit\u00e9, NAS de sauvegarde, etc.), les VLAN permettent de  \u201ccloisonner\u201d chaque cat\u00e9gorie d\u2019\u00e9quipements  dans son propre r\u00e9seau \u00e9tanche. Par exemple, les appareils IoT (domotique) souvent peu s\u00e9curis\u00e9s ne pourront pas acc\u00e9der \u00e0 vos PC personnels sensibles  , et vos exp\u00e9rimentations en lab s\u00e9curit\u00e9 ne risqueront pas de perturber votre r\u00e9seau principal.</p> <p>En bref, un VLAN est un  segment de r\u00e9seau isol\u00e9. Les appareils au sein d\u2019un m\u00eame VLAN communiquent librement (comme s\u2019ils \u00e9taient sur un m\u00eame switch), mais ne \u201cvoient\u201d pas ceux des autres VLAN sans passer par un routeur/pare-feu qui fait respecter des r\u00e8gles d\u2019acc\u00e8s  . Cette isolation par VLAN est un  principe cl\u00e9 de la d\u00e9fense en profondeur  en r\u00e9seau domestique : on limite drastiquement les communications non n\u00e9cessaires entre les diff\u00e9rentes  zones de confiancedu homelab.</p>"},{"location":"infrastructure/reseau/#topologie-generale-et-materiel-requis","title":"Topologie g\u00e9n\u00e9rale et mat\u00e9riel requis","text":"<p>Pour mettre en place des VLAN chez soi, il faut du mat\u00e9riel r\u00e9seau prenant en charge 802.1Q (standard des VLAN). En pratique, il vous faudra :</p> <ul> <li> <p>Un routeur/pare-feu  central capable de g\u00e9rer des interfaces VLAN et de filtrer le trafic entre elles (par exemple un PC ou appliance avec OPNsense ou pfSense). Ces syst\u00e8mes supportent nativement les VLAN 802.1Q et le firewall \u00e0 \u00e9tats, ce qui est id\u00e9al pour impl\u00e9menter la segmentation  .</p> </li> <li> <p>Un commutateur manageable  (switch g\u00e9r\u00e9) qui supporte la configuration de VLAN. C\u2019est indispensable pour brancher plusieurs appareils en isolant leurs ports par VLAN, surtout si le routeur n\u2019a que peu de ports physiques  . Le switch fera transiter les trames VLAN \u201ctagg\u00e9es\u201d entre le routeur et les \u00e9quipements.</p> </li> <li> <p>(Optionnel)  Des points d\u2019acc\u00e8s Wi-Fi compatibles VLAN, si vous souhaitez avoir des SSID Wi-Fi distincts pour diff\u00e9rentes VLAN (ex : un SSID pour le r\u00e9seau principal, un pour les invit\u00e9s, un pour l\u2019IoT\u2026). De nombreux AP prosumer (Unifi, Omada, OpenWrt, etc.) permettent d\u2019associer chaque SSID \u00e0 un VLAN ID sp\u00e9cifique.</p> </li> </ul> <p>La topologie typique dans un homelab VLAN est la suivante :  le routeur/pare-feu est reli\u00e9 en tronc (trunk) au switch principal  via un lien Ethernet sur lequel  tous  les VLAN sont autoris\u00e9s (trame 802.1Q tagg\u00e9es)  . Le routeur agit comme  passerelle par d\u00e9faut  pour chaque VLAN (il a une interface virtuelle dans chacun, avec une IP de gateway). Le switch, lui, connecte les diff\u00e9rents appareils et applique l\u2019appartenance VLAN  sur chaque port. Les ports du switch reli\u00e9s \u00e0 des appareils ordinaires (PC, cam\u00e9ras, etc.) sont configur\u00e9s en  VLAN \u201cuntagged\u201d  d\u2019un VLAN sp\u00e9cifique (on parle de port access non tagg\u00e9) \u2013 le p\u00e9riph\u00e9rique n\u2019a pas conscience du VLAN, il re\u00e7oit juste du trafic de son sous-r\u00e9seau  . En revanche, le port du switch reli\u00e9 au routeur est configur\u00e9 en  trunk tagg\u00e9  pour  tous  les VLAN : il transporte les trames avec leur identifiant VLAN jusqu\u2019au routeur, qui peut ainsi router/filtrer entre VLAN  . De m\u00eame, un port vers un point d\u2019acc\u00e8s Wi-Fi multi-SSID sera souvent un trunk tagg\u00e9 transportant les VLAN des diff\u00e9rents SSID vers l\u2019AP. Exemple de topologie r\u00e9seau Homelab avec VLAN multiples (r\u00e9seau management, primaire, IoT, invit\u00e9s, etc.) et un routeur OPNsense interconnect\u00e9 en trunk au switch principal.</p> <p>Sur le sch\u00e9ma ci-dessus (inspir\u00e9 d\u2019un cas r\u00e9el), on distingue plusieurs VLAN isol\u00e9s : un VLAN  MGMT  pour la gestion, un VLAN  Primary  (r\u00e9seau principal), un VLAN  IoT  pour les objets connect\u00e9s, un VLAN  Guests  pour les invit\u00e9s, etc., chacun avec son plan d\u2019adressage IP d\u00e9di\u00e9  . Le routeur OPNsense (en haut) est la passerelle reliant ces VLAN et appliquant des r\u00e8gles de pare-feu entre eux. Le switch (TP-Link) a des ports assign\u00e9s \u00e0 chaque VLAN (soit en untagged pour des \u00e9quipements sp\u00e9cifiques, soit en trunk vers le routeur et les points d\u2019acc\u00e8s). Par exemple, un  NAS ou serveurpeut \u00eatre connect\u00e9 \u00e0 un port du switch configur\u00e9 en VLAN \u201cServices\u201d, tandis qu\u2019une  cam\u00e9ra IP  sera sur un port attribu\u00e9 au VLAN \u201cCCTV\u201d. Le lien entre le routeur et le switch transporte tous les VLAN tagg\u00e9s, permettant au routeur de voir chaque sous-r\u00e9seau. Avec cette architecture, chaque cat\u00e9gorie d\u2019\u00e9quipements communique principalement avec le routeur, qui d\u00e9cide si telle VLAN a le droit de joindre telle autre ou d\u2019acc\u00e9der \u00e0 Internet, selon des r\u00e8gles pr\u00e9d\u00e9finies.</p>"},{"location":"infrastructure/reseau/#configuration-des-vlan-sur-le-pare-feu-opnsensepfsense","title":"Configuration des VLAN sur le pare-feu (OPNsense/pfSense)","text":"<p>La mise en place concr\u00e8te des VLAN dans OPNsense/pfSense se fait en plusieurs \u00e9tapes. Voici un guide pas-\u00e0-pas synth\u00e9tique :</p> <ol> <li> <p>D\u00e9finir les VLAN dans le routeur : Sur OPNsense/pfSense, commencez par cr\u00e9er les VLAN (menu Interfaces &gt; Other &gt; VLANs). Pour chaque VLAN, on sp\u00e9cifie un identifiant num\u00e9rique (VID, entre 1 et 4094) et l\u2019interface physique parent (par ex. votre port LAN connect\u00e9 au switch)  . Exemple : VLAN 10 \u201cProd\u201d, VLAN 20 \u201cLab\u201d, VLAN 30 \u201cDomotique\u201d, etc.  Veillez \u00e0 choisir des IDs coh\u00e9rents et uniques. Une bonne pratique est de faire correspondre le num\u00e9ro du VLAN avec le troisi\u00e8me octet de son r\u00e9seau IP (ex: VLAN 10 \u2192 192.168.10.0/24)  , afin de s\u2019y retrouver facilement.</p> </li> <li> <p>Assigner les interfaces : Une fois VLANs d\u00e9finis, il faut les associer \u00e0 des interfaces logiques dans le pare-feu. Dans pfSense/OPNsense, on va dans  Interfaces &gt; Assignments  et on ajoute chaque VLAN comme nouvelle interface. Donnez-leur un nom significatif (LAN_PROD, LAN_IoT, etc.), puis activez-les. Assignez une  plage d\u2019adresses IP  \u00e0 chaque interface VLAN (typiquement /24). Par exemple : VLAN 10 (Prod) pourrait avoir 192.168.10.1/24 comme IP de gateway (le routeur se positionne sur .1), VLAN 20 (Lab) en 192.168.20.1/24, etc. Chaque VLAN est ainsi un sous-r\u00e9seau IP distinct avec sa passerelle  .</p> </li> <li> <p>DHCP et DNS : Configurez un serveur  DHCP  sur chaque interface VLAN pour distribuer automatiquement les IP aux h\u00f4tes de ce r\u00e9seau. Sur OPNsense/pfSense, on peut copier la config DHCP du LAN principal puis ajuster la plage. De m\u00eame, vous pouvez activer le service DNS (Unbound) pour qu\u2019il \u00e9coute sur tous les VLAN, afin que les clients utilisent le routeur comme r\u00e9solveur DNS. Attention toutefois : pensez \u00e0 autoriser le trafic DNS vers le routeur sur chaque VLAN (voir r\u00e8gles plus bas).</p> </li> <li> <p>Configuration du switch : Du c\u00f4t\u00e9 du commutateur manageable, cr\u00e9ez les VLAN avec les m\u00eames IDs. Ensuite, attribuez chaque  port du switch  au VLAN appropri\u00e9.</p> <ul> <li> <p>Le port reli\u00e9 au routeur doit \u00eatre configur\u00e9 en  trunk/tagg\u00e9 sur tous les VLAN  (ou au moins sur tous ceux utilis\u00e9s). Ainsi, les trames sortant du routeur avec un tag VLAN seront accept\u00e9es et propag\u00e9es sur le switch  .</p> </li> <li> <p>Les ports reli\u00e9s \u00e0 des dispositifs finaux (PC, cam\u00e9ra, IoT, etc.) seront mis en mode  access (non tagg\u00e9)  dans le VLAN correspondant \u00e0 cet appareil. Par exemple, si un PC principal doit \u00eatre dans le VLAN Prod (10), on met son port en VLAN 10 untagged (et aucun autre VLAN sur ce port). De cette mani\u00e8re, le switch ajoutera/retirera le tag VLAN automatiquement pour ce port, et le PC n\u2019aura aucune configuration sp\u00e9ciale \u00e0 conna\u00eetre  .</p> </li> <li> <p>Si un port du switch est connect\u00e9 \u00e0 un point d\u2019acc\u00e8s Wi-Fi multi-SSID ou \u00e0 un hyperviseur accueillant plusieurs VLAN, ce port devra \u00eatre configur\u00e9 en  tagg\u00e9 (trunk)  pour les VLAN n\u00e9cessaires (ex: tagg\u00e9 VLAN 10,20,30 sur le port d\u2019un AP qui diffuse trois SSID isol\u00e9s)  .</p> </li> <li> <p>Pour les  ports inutilis\u00e9s  sur le switch, par mesure de s\u00e9curit\u00e9, vous pouvez les d\u00e9sactiver ou les assigner \u00e0 un VLAN \u201cpoubelle\u201d non rout\u00e9 (ex: VLAN 999) pour \u00e9viter qu\u2019un appareil non autoris\u00e9 ne se connecte \u00e0 votre insu  .</p> </li> </ul> </li> <li> <p>R\u00e8gles de firewall inter-VLAN : Par d\u00e9faut, sur pfSense/OPNsense, chaque interface VLAN nouvellement cr\u00e9\u00e9e n\u2019a  aucune r\u00e8gle autorisant le trafic entrant, ce qui signifie qu\u2019aucune communication  depuis  ce VLAN n\u2019est permise (tout est bloqu\u00e9 par le policy  default deny). Il convient donc d\u2019ajouter des r\u00e8gles pour permettre au moins l\u2019acc\u00e8s \u00e0 Internet depuis chaque VLAN, tout en  bloquant l\u2019acc\u00e8s aux autres VLAN. Une m\u00e9thode simple consiste \u00e0 bloquer toute destination correspondant aux r\u00e9seaux priv\u00e9s locaux (RFC1918) pour chaque VLAN, sauf exceptions n\u00e9cessaires  . Concr\u00e8tement, sur l\u2019onglet firewall de chaque VLAN :</p> <ul> <li> <p>On cr\u00e9e en haut une r\u00e8gle autorisant le trafic de ce VLAN vers l\u2019IP de  passerelle du routeur  (son adresse dans ce VLAN) pour les services indispensables comme DNS ou DHCP. Par exemple, autoriser  VLAN10_net -&gt; 192.168.10.1 (port 53)  pour permettre aux clients du VLAN 10 d\u2019interroger le DNS du routeur  .</p> </li> <li> <p>En deuxi\u00e8me r\u00e8gle, on ajoute un  Bloc  de tout le trafic de  VLAN10_net  vers l\u2019alias \u201cRFC1918\u201d (regroupant les plages priv\u00e9es 10.0.0.0/8, 192.168.0.0/16, etc.), afin d\u2019emp\u00eacher ce VLAN d\u2019atteindre  tout r\u00e9seau local interne  autre que le sien  . C\u2019est cette r\u00e8gle qui interdit l\u2019inter-VLAN par d\u00e9faut.</p> </li> <li> <p>En troisi\u00e8me position (apr\u00e8s le bloc inter-VLAN donc), on met une r\u00e8gle  Autoriser  de  VLAN10_net  vers \u201c*\u201d (any) pour permettre l\u2019acc\u00e8s Internet. Gr\u00e2ce \u00e0 l\u2019ordre, le trafic vers Internet (destinations publiques) passera, tandis que toute tentative vers IP priv\u00e9es sera match\u00e9e par la r\u00e8gle de bloc au-dessus et donc interdite  .  NB:  si votre pare-feu a l\u2019option \u201cBlock private networks\u201d activ\u00e9e sur l\u2019interface WAN, il filtrera d\u00e9j\u00e0 l\u2019entr\u00e9e depuis internet des IP priv\u00e9es externes, mais ici il s\u2019agit du trafic sortant inter-LAN.</p> </li> </ul> <p>Avec ce sch\u00e9ma de r\u00e8gles, chaque VLAN peut acc\u00e9der au WAN mais pas aux autres LAN, sauf cas particulier. Pour ces  exceptions, on ajoutera des r\u00e8gles sp\u00e9cifiques  au-dessus  du bloc RFC1918. Par ex., si l\u2019on veut permettre au VLAN Sauvegarde de joindre le NAS sur VLAN Prod sur le port NFS, on cr\u00e9erait une r\u00e8gle autorisant  Source: VLAN_Sauvegarde_net -&gt; Dest: NAS_IP (port 2049)  plac\u00e9e avant la r\u00e8gle de bloc g\u00e9n\u00e9ral. De m\u00eame, on peut vouloir qu\u2019un VLAN \u201cManagement\u201d ait le droit de joindre l\u2019interface de gestion d\u2019\u00e9quipements sur d\u2019autres VLAN \u2013 il faut alors pr\u00e9voir ces autorisations explicitement, ou utiliser des groupes d\u2019interfaces pour simplifier (pfsense permet de cr\u00e9er un groupe contenant toutes les interfaces internes et d\u00e9finir une r\u00e8gle une fois)  .</p> </li> <li> <p>V\u00e9rifications : Une fois la configuration appliqu\u00e9e, connectez des appareils dans chaque VLAN et testez : chaque VLAN doit obtenir des IP correctes via DHCP, avoir acc\u00e8s \u00e0 Internet si pr\u00e9vu, et  ne pas  pouvoir atteindre les machines des autres VLAN (par ex., un PC en VLAN 10 ne doit pas ping un PC en VLAN 20). Testez \u00e9galement les cas autoris\u00e9s (ping de la passerelle, r\u00e9solution DNS, etc.). Ajustez les r\u00e8gles firewall si n\u00e9cessaire en cas de service l\u00e9gitime bloqu\u00e9 (ex: autoriser le VLAN IoT \u00e0 contacter un serveur domotique sur VLAN Prod, mais uniquement sur le port de l\u2019API requis).</p> </li> </ol> <p>En r\u00e9sum\u00e9, le routeur/pare-feu multi-VLAN joue le r\u00f4le de  passerelle et filtre  entre les segments. Le switch assure que la s\u00e9paration niveau 2 est respect\u00e9e (pas de fuite de trames entre VLAN), et le routeur contr\u00f4le au niveau 3 ce qui est autoris\u00e9 ou non entre les VLAN.</p>"},{"location":"infrastructure/reseau/#notions-avancees-et-meilleures-pratiques","title":"Notions avanc\u00e9es et meilleures pratiques","text":"<p>Dans un homelab bien segment\u00e9, certaines notions plus pointues peuvent entrer en jeu pour optimiser le fonctionnement ou la s\u00e9curit\u00e9 :</p>"},{"location":"infrastructure/reseau/#vlan-tagges-vs-non-tagges-trunkaccess","title":"VLAN tagg\u00e9s vs non tagg\u00e9s (trunk/access)","text":"<p>Il est crucial de bien comprendre la diff\u00e9rence entre un port  tagg\u00e9 (trunk)  et  non tagg\u00e9 (access)  sur le switch. Un port  untagged  dans un VLAN signifie que le p\u00e9riph\u00e9rique connect\u00e9 n\u2019envoie ni ne re\u00e7oit de trames VLAN marqu\u00e9es \u2013 le switch int\u00e8gre l\u2019appareil dans le VLAN en interne, en ajoutant/retirant le tag 802.1Q lui-m\u00eame. Ce mode est destin\u00e9 aux \u00e9quipements \u201cnormaux\u201d (PC, imprimante, cam\u00e9ra, etc.) qui ne connaissent pas les VLAN  . En revanche, un port  tagged trunk  transporte les trames avec leurs identifiants VLAN inchang\u00e9s. Il sert pour relier deux \u00e9quipements VLAN-aware : par exemple la liaison entre le routeur et le switch, ou entre deux switches, ou vers un AP multi-SSID. Ces \u00e9quipements comprennent les tags et peuvent appartenir \u00e0 plusieurs VLAN simultan\u00e9ment.  R\u00e8gle d\u2019or : un port trunk peut v\u00e9hiculer plusieurs VLAN (tagg\u00e9s), un port access ne doit appartenir qu\u2019\u00e0 un seul VLAN et pr\u00e9sente ce VLAN en \u201cnon tagg\u00e9\u201d au device connect\u00e9.</p> <p>Dans la configuration, veillez \u00e0  coh\u00e9rer les tags  de bout en bout : si le VLAN 20 est utilis\u00e9 pour la domotique, le routeur taggue ce trafic VLAN20 sur l\u2019interface trunk, le switch doit avoir VLAN20 activ\u00e9 sur le port trunk et les ports des objets domotiques en VLAN20 untagged. Une erreur de tag (ex: VLAN ID mismatch) se traduit par un appareil incapable de communiquer au-del\u00e0 de son switch.</p>"},{"location":"infrastructure/reseau/#acl-et-controle-de-trafic-intra-vlan-ou-sur-switch","title":"ACL et contr\u00f4le de trafic intra-VLAN ou sur switch","text":"<p>En environnement professionnel, on utilise parfois des  ACL (Access Control Lists)  sur les commutateurs de niveau 3 ou m\u00eame niveau 2 pour filtrer le trafic  au sein  du r\u00e9seau, ind\u00e9pendamment du pare-feu central. Dans un homelab, si vous disposez d\u2019un switch L3 avanc\u00e9, vous pourriez mettre en \u0153uvre des ACL pour bloquer certaines communications inter-VLAN directement au niveau du switch, en compl\u00e9ment ou \u00e0 la place des r\u00e8gles du routeur. Cependant, dans la plupart des cas, votre pare-feu OPNsense/pfSense remplit d\u00e9j\u00e0 ce r\u00f4le (ses r\u00e8gles agissent en fait comme des ACL de niveau 3/4). L\u2019utilisation d\u2019ACL sur le switch peut \u00eatre utile si vous faites du routage local sur un switch L3 pour d\u00e9charger le routeur (cependant, ceci est rarement n\u00e9cessaire \u00e0 l\u2019\u00e9chelle d\u2019un homelab). Retenez qu\u2019ACL ou firewall reviennent \u00e0 d\u00e9finir des r\u00e8gles : commencez simple (tout inter-VLAN bloqu\u00e9 sauf exceptions), puis affinez au besoin avec des r\u00e8gles sp\u00e9cifiques ou ACL pour des cas tr\u00e8s pr\u00e9cis. Un adepte r\u00e9sume ainsi son approche maison : isoler les VLAN, puis  \u201couvrir des br\u00e8ches avec des ACL pour des dispositifs sp\u00e9cifiques\u201d  selon les besoins  .</p>"},{"location":"infrastructure/reseau/#igmp-snooping-et-trafic-multicast","title":"IGMP Snooping et trafic multicast","text":"<p>Les r\u00e9seaux locaux modernes, surtout avec domotique, Chromecast, cam\u00e9ras, etc., utilisent du  multicast  (mDNS, SSDP, streaming vid\u00e9o). Par d\u00e9faut, une trame multicast est envoy\u00e9e en broadcast sur un VLAN, ce qui peut saturer inutilement les ports. La fonction  IGMP Snooping  des switches veille \u00e0 \u00e9couter les abonnements IGMP des appareils pour ne forwarder le trafic multicast qu\u2019aux ports qui en ont besoin. Il est recommand\u00e9 d\u2019activer l\u2019IGMP Snooping sur chaque VLAN concern\u00e9 afin d\u2019\u00e9viter la diffusion de flux multicast vers tous les ports  du VLAN  . Par exemple, sur un VLAN Cam\u00e9ras IP avec NVR, le switch n\u2019enverra le flux vid\u00e9o multicast qu\u2019au port du NVR et \u00e9ventuellement aux quelques clients inscrits, plut\u00f4t qu\u2019\u00e0 tous les dispositifs du VLAN. Attention, IGMP Snooping implique qu\u2019il y ait un  querier IGMP  sur le r\u00e9seau (g\u00e9n\u00e9ralement le routeur multicast). OPNsense/pfSense peut faire office de querier si activ\u00e9.</p> <p>Un autre d\u00e9fi fr\u00e9quent en environnement VLAN est la d\u00e9couverte mDNS/Bonjour (pour imprimantes, Chromecasts, assistants vocaux, etc.) : par design, ces protocoles ne passent pas les fronti\u00e8res VLAN. Deux approches : soit regrouper sur un m\u00eame VLAN les appareils qui doivent se d\u00e9couvrir (solution simple mais reniant l\u2019isolation), soit utiliser un  m\u00e9canisme de relay/reflecteur mDNS  (par ex. le service Avahi) qui r\u00e9p\u00e8te certaines annonces entre VLAN choisis. OPNsense inclut un plugin \u201cos-avahi\u201d qui peut \u00eatre configur\u00e9 pour refl\u00e9ter mDNS entre un VLAN IoT et le VLAN principal, afin que vos Chromecast (IoT) apparaissent sur votre smartphone (LAN principal) sans ouvrir tout le trafic entre ces VLAN. Cette configuration avanc\u00e9e am\u00e9liore le confort d\u2019usage tout en maintenant l\u2019isolation du reste des communications.</p>"},{"location":"infrastructure/reseau/#pare-feu-inter-vlan-vs-intra-vlan","title":"Pare-feu inter-VLAN vs intra-VLAN","text":"<p>Dans notre sc\u00e9nario, on consid\u00e8re g\u00e9n\u00e9ralement que les appareils  au sein d\u2019un m\u00eame VLAN  sont de confiance similaire, donc on ne filtre pas leur communication mutuelle (ils peuvent dialoguer librement dans le VLAN). Si ce n\u2019est pas souhait\u00e9 (ex: VLAN Invit\u00e9s o\u00f9 m\u00eame les clients ne doivent pas se voir), on parle d\u2019isolation client  au niveau 2 : certaines bornes Wi-Fi permettent d\u2019isoler les clients entre eux, ou on peut utiliser des fonctionnalit\u00e9s de switch (PVLAN, port isolation) pour emp\u00eacher des ports du m\u00eame VLAN de communiquer directement. C\u2019est utile surtout pour un VLAN invit\u00e9 ou public. Dans la plupart des VLAN priv\u00e9s (Prod, IoT\u2026), laisser les appareils se voir peut \u00eatre n\u00e9cessaire (ex: votre smartphone pilote une ampoule sur VLAN IoT \u2013 ils doivent pouvoir communiquer  si  dans le m\u00eame VLAN IoT). Retenez donc : on cloisonne fortement  entre  VLAN diff\u00e9rents (firewall L3), et on peut \u00e9ventuellement cloisonner  \u00e0 l\u2019int\u00e9rieur  d\u2019un m\u00eame VLAN (isolation L2) selon les cas d\u2019usage sp\u00e9cifiques.</p>"},{"location":"infrastructure/reseau/#segmentation-par-zone-vlan-proposes-pour-le-homelab","title":"Segmentation par zone : VLAN propos\u00e9s pour le homelab","text":"<p>Passons en revue les diff\u00e9rentes  zones VLAN  qu\u2019on peut mettre en place dans un homelab bien organis\u00e9, en fonction des besoins \u00e9voqu\u00e9s (production personnelle, s\u00e9curit\u00e9, domotique, stockage, etc.). Chaque VLAN correspond \u00e0 un  cas d\u2019usage  et aura ses propres r\u00e8gles de trafic.</p>"},{"location":"infrastructure/reseau/#vlan","title":"VLAN","text":""},{"location":"infrastructure/reseau/#production","title":"Production","text":""},{"location":"infrastructure/reseau/#lan-principal-personnel","title":"(LAN principal personnel)","text":"<p>C\u2019est le r\u00e9seau principal pour vos \u00e9quipements  de confiance  et critiques (PC personnels, laptop de travail \u2013 sauf si politique entreprise l\u2019interdit, serveurs de prod auto-h\u00e9berg\u00e9s, etc.). Il peut s\u2019agir du VLAN  10  par exemple, 192.168.10.0/24. Ce r\u00e9seau a g\u00e9n\u00e9ralement  un acc\u00e8s complet \u00e0 Internet  et peut, si n\u00e9cessaire, initier des connexions vers certains services dans d\u2019autres VLAN (ex: acc\u00e9der au NAS de sauvegarde, consulter les flux des cam\u00e9ras, etc.). En revanche, on bloque l\u2019acc\u00e8s  entrant  depuis les autres VLAN vers ce r\u00e9seau pour le prot\u00e9ger. Vous traiterez ce VLAN un peu comme un r\u00e9seau \u201cinterne s\u00e9curis\u00e9 d\u2019entreprise\u201d. Vous pouvez aussi y segmenter en deux VLAN distincts si vous h\u00e9bergez des applications client/serveur sensibles : par exemple VLAN \u201cProd-Serveurs\u201d s\u00e9par\u00e9 du VLAN \u201cProd-Clients\u201d. Mais pour un homelab, un seul VLAN prod suffit souvent, d\u2019autant qu\u2019il est plus ais\u00e9 de g\u00e9rer quelques r\u00e8gles ponctuelles \u00e0 l\u2019int\u00e9rieur que de multiplier les segments. Veillez simplement \u00e0  ne pas connecter d\u2019appareils peu fiables  (IoT, etc.) sur ce r\u00e9seau.</p>"},{"location":"infrastructure/reseau/#vlan_1","title":"VLAN","text":""},{"location":"infrastructure/reseau/#lab-securite","title":"Lab S\u00e9curit\u00e9","text":""},{"location":"infrastructure/reseau/#red-team-blue-team","title":"(Red Team / Blue Team)","text":"<p>Pour vos besoins de labo cyber (pentest, forensic\u2026), il est conseill\u00e9 de cr\u00e9er un VLAN d\u00e9di\u00e9  hautement isol\u00e9  du reste. Par exemple VLAN  40  = 192.168.40.0/24. Vous pouvez y faire tourner des VMs vuln\u00e9rables, des attaques simul\u00e9es, etc., sans risque pour votre LAN principal. Ce VLAN Lab peut m\u00eame \u00eatre subdivis\u00e9 en plusieurs segments selon vos sc\u00e9narios : un VLAN  \u201cRed\u201d  pour les machines d\u2019attaque (attaquant) et un VLAN  \u201cBlue\u201d  pour les cibles et la surveillance (d\u00e9fenseur). Dans ce cas, vous pourriez introduire un  pare-feu interm\u00e9diaire  entre Red et Blue pour reproduire un environnement d\u2019entreprise (ou utiliser OPNsense lui-m\u00eame avec des r\u00e8gles sp\u00e9cifiques entre ces deux VLAN). Toutefois, si c\u2019est un lab local purement pour exercice, un seul VLAN isol\u00e9 peut suffire, ou deux VLAN isol\u00e9s de tout sauf d\u2019une connexion contr\u00f4l\u00e9e entre eux. Par d\u00e9faut, le VLAN Lab n\u2019a  pas acc\u00e8s aux VLAN prod/domotique/etc., et potentiellement m\u00eame  pas d\u2019acc\u00e8s Internet  si vous voulez tester des malwares en contenant (vous pourrez activer l\u2019acc\u00e8s WAN ponctuellement via une r\u00e8gle ou via un proxy/VPN d\u00e9di\u00e9 pour le lab). L\u2019id\u00e9e est de minimiser les ponts avec l\u2019ext\u00e9rieur. Vous pourriez autoriser seulement la machine de l\u2019analyste (sur VLAN Prod par ex.) \u00e0 se connecter en RDP/SSH vers le VLAN Lab Blue Team pour y faire de l\u2019investigation, mais rien de plus. Ce VLAN est votre bac \u00e0 sable dangereux : traitez-le comme une  DMZ locale  tr\u00e8s verrouill\u00e9e.</p>"},{"location":"infrastructure/reseau/#vlan_2","title":"VLAN","text":""},{"location":"infrastructure/reseau/#domotiqueiot","title":"Domotique/IoT","text":"<p>Tous les \u00e9quipements  domotiques, IoT et multim\u00e9dia  peu s\u00e9curis\u00e9s vont dans ce r\u00e9seau isol\u00e9. Par exemple VLAN  30  = 192.168.30.0/24. On y met les ampoules connect\u00e9es, assistants vocaux, t\u00e9l\u00e9visions intelligentes, prises Wi-Fi, thermostats, etc. Ce sont typiquement des appareils qui  requi\u00e8rent un acc\u00e8s Internet  (pour leurs services cloud) mais n\u2019ont aucune raison de communiquer avec vos PC/serveurs personnels. On configure donc ce VLAN IoT de sorte que ses appareils puissent sortir vers Internet (HTTP, MQTT\u2026 selon les besoins), mais  ne puissent pas initier de connexion vers les VLAN sensibles  (Prod, Sauvegarde\u2026). Inversement, on peut autoriser quelques flux entrants ma\u00eetris\u00e9s : par exemple, votre smartphone (VLAN Prod) doit pouvoir envoyer des commandes vers l\u2019API locale d\u2019une ampoule sur VLAN IoT. Une fa\u00e7on propre de faire cela est de d\u00e9ployer un  serveur domotique central (type Home Assistant)  qui a deux interfaces r\u00e9seau \u2013 une dans le VLAN IoT pour parler aux objets, et une dans le VLAN Prod pour que vous puissiez le contr\u00f4ler. Si ce n\u2019est pas possible, on ouvrira finement sur le firewall les acc\u00e8s n\u00e9cessaires (ex: autoriser IP_du_PC \u2192 IP_ampoule port TCP sp\u00e9cifique). Gardez ce VLAN IoT aussi ferm\u00e9 que possible, car ces appareils sont souvent les plus vuln\u00e9rables. Il est d\u2019usage \u00e9galement de  refuser toute connexion sortante inutile  depuis IoT (filtrage par liste blanche de domaines via DNS ou r\u00e8gles par IP si possible) afin d\u2019\u00e9viter qu\u2019un objet bavard n\u2019envoie des donn\u00e9es \u00e0 des tiers. En r\u00e9sum\u00e9, VLAN IoT = Internet oui, acc\u00e8s aux autres VLAN non (sauf exceptions minimales), acc\u00e8s entrants tr\u00e8s limit\u00e9s.</p> <p>Notez enfin que les  protocoles multicast  type mDNS, SSDP sont massivement utilis\u00e9s en IoT (pour la d\u00e9couverte plug-and-play). Comme expliqu\u00e9, ceux-ci ne traversent pas les VLAN, donc si par exemple votre Google Home (VLAN IoT) doit \u00eatre contr\u00f4l\u00e9 par votre t\u00e9l\u00e9phone (VLAN Prod), vous aurez besoin d\u2019un m\u00e9canisme comme Avahi (reflecteur mDNS) ou, plus simplement, placer le t\u00e9l\u00e9phone sur le VLAN IoT le temps de l\u2019utilisation (moins s\u00e9curis\u00e9). \u00c0 vous de voir le bon compromis entre  confort  et  cloisonnement.</p>"},{"location":"infrastructure/reseau/#vlan_3","title":"VLAN","text":""},{"location":"infrastructure/reseau/#cameras-ip","title":"Cam\u00e9ras IP","text":""},{"location":"infrastructure/reseau/#surveillance-cctv","title":"(Surveillance CCTV)","text":"<p>Les cam\u00e9ras de surveillance r\u00e9seau m\u00e9ritent souvent leur propre VLAN (par ex. VLAN  50  = 192.168.50.0/24), bien qu\u2019on pourrait les mettre dans l\u2019IoT. Elles g\u00e9n\u00e8rent du trafic vid\u00e9o continu et peuvent pr\u00e9senter des vuln\u00e9rabilit\u00e9s s\u00e9rieuses. Dans un homelab, on cr\u00e9e un VLAN Cam\u00e9ras isol\u00e9  sans acc\u00e8s Internet direct  (sauf si la cam\u00e9ra a absolument besoin de NTP ou de mises \u00e0 jour par le web, mais id\u00e9alement on \u00e9vite les cam\u00e9ras cloud). Ce VLAN ne doit communiquer qu\u2019avec votre  NVR/serveur d\u2019enregistrement vid\u00e9o. Par exemple, autoriser les flux  de  cam\u00e9ras \u2192 vers NVR sur les ports RTSP, et peut-\u00eatre le NVR \u2192 cam\u00e9ras sur HTTP (pour les configurer). En dehors de cela, pas de passage. Ainsi, m\u00eame si une cam\u00e9ra est compromise, l\u2019attaquant ne pourra pas rebondir sur le reste de votre r\u00e9seau. Un retour d\u2019exp\u00e9rience de homelab recommande que les cam\u00e9ras n\u2019aient  aucune  id\u00e9e d\u2019Internet :  \u00abCCTV \u2013 no access to outside world, cameras get time from internal NTP, and can send flux au NVR uniquement\u00bb  . C\u2019est une sage pr\u00e9caution. Si vous devez acc\u00e9der \u00e0 vos cam\u00e9ras depuis l\u2019ext\u00e9rieur, faites-le via le NVR (qui serait lui-m\u00eame soit dans un VLAN DMZ, soit via VPN). Enfin, c\u00f4t\u00e9 performance, les cam\u00e9ras et NVR peuvent consommer de la bande passante en continu : assurez-vous que votre switch supporte le d\u00e9bit cumul\u00e9, et envisagez \u00e9ventuellement un  switch PoE d\u00e9di\u00e9  pour alimenter les cam\u00e9ras, raccord\u00e9 en trunk sur le VLAN cam\u00e9ras du switch principal.</p>"},{"location":"infrastructure/reseau/#vlan_4","title":"VLAN","text":""},{"location":"infrastructure/reseau/#stockage-iscsi","title":"Stockage (iSCSI)","text":"<p>Pour les besoins de stockage partag\u00e9 (par exemple exposer un disque iSCSI depuis un NAS vers vos hyperviseurs Proxmox/ESXi), il est fortement recommand\u00e9 de d\u00e9dier un VLAN sp\u00e9cifique au  trafic de stockage. On peut le nommer VLAN  iSCSI  ou  SAN. Souvent, ce VLAN n\u2019a m\u00eame  pas  de passerelle vers le routeur (pas rout\u00e9) : il s\u2019agit juste d\u2019un r\u00e9seau L2 isol\u00e9 entre votre NAS/stockage et vos serveurs, pour le traffic iSCSI ou NFS. Par exemple VLAN  20  = 10.0.20.0/24, sans sortie internet. On attribue des IP fixes aux interfaces SAN de chaque h\u00f4te et du NAS. Ce r\u00e9seau \u00e9tant isol\u00e9, on \u00e9vite toute pollution par d\u2019autres flux, ce qui am\u00e9liore les performances et la s\u00e9curit\u00e9 (un client du VLAN Prod n\u2019a aucune raison d\u2019acc\u00e9der directement au VLAN iSCSI). En pratique, il faut que vos serveurs et NAS aient chacun  deux interfaces r\u00e9seau  (ou une interface VLAN tagg\u00e9e c\u00f4t\u00e9 hyperviseur) : l\u2019une pour le LAN normal, l\u2019autre pour le VLAN stockage. Les \u00e9changes iSCSI se font ainsi directement, sans passer par le routeur.</p> <p>Si toutefois vous avez besoin que ce VLAN iSCSI soit rout\u00e9 (par ex. pour acc\u00e9der \u00e0 l\u2019interface d\u2019admin du NAS depuis un PC), vous pouvez lui attribuer une interface sur OPNsense, mais dans ce cas filtrez rigoureusement l\u2019acc\u00e8s (ex: seul le PC admin peut joindre l\u2019IP de management du NAS sur ce VLAN). Beaucoup choisissent de ne  pas  router le VLAN SAN du tout, for\u00e7ant l\u2019acc\u00e8s administrateur via un jump host sur ce VLAN ou via le LAN principal du NAS. Quoiqu\u2019il en soit, on  n\u2019autorise pas Internet  sur ce VLAN, il doit \u00eatre totalement interne. Pensez \u00e9galement \u00e0 activer les  Jumbo Frames (MTU 9000)  sur ce VLAN si tous vos \u00e9quipements le supportent, afin d\u2019optimiser le d\u00e9bit de gros flux iSCSI/NFS (toutes les interfaces du NAS, serveurs et switch impliqu\u00e9s doivent avoir MTU 9000). Les VLAN de stockage peuvent aussi inclure les trafics de virtualisation type vMotion, replication, etc., qui b\u00e9n\u00e9ficient d\u2019un r\u00e9seau \u00e0 part.</p>"},{"location":"infrastructure/reseau/#vlan_5","title":"VLAN","text":""},{"location":"infrastructure/reseau/#sauvegardes","title":"Sauvegardes","text":""},{"location":"infrastructure/reseau/#backup","title":"(Backup)","text":"<p>Proche du VLAN stockage, vous pourriez d\u00e9ployer un VLAN distinct pour la sauvegarde de vos donn\u00e9es. Par exemple si vous avez un serveur de backup ou un NAS o\u00f9 les diff\u00e9rentes machines viennent d\u00e9poser leurs sauvegardes, il peut \u00eatre judicieux de l\u2019isoler. Cependant, deux approches existent :</p> <ul> <li> <p>Approche 1 : Le serveur de sauvegarde (NAS, etc.) r\u00e9side  uniquement  dans ce VLAN Sauvegarde, et on autorise chaque VLAN source \u00e0 envoyer des donn\u00e9es vers lui (sur les ports de backup) via le pare-feu. Par exemple, VLAN Prod peut joindre l\u2019adresse du NAS (VLAN Backup) sur le port 873 (rsync) ou 443 (agent de backup), etc. Cela maintient la s\u00e9paration, mais le trafic passe par le routeur et subit \u00e9ventuellement son goulot d\u2019\u00e9tranglement.</p> </li> <li> <p>Approche 2 : Le serveur de sauvegarde a  une interface dans chaque VLAN  qui le concerne (ou au moins dans VLAN Prod et VLAN Backup). C\u2019est plus complexe et augmente la surface, donc on pr\u00e9f\u00e8re la premi\u00e8re solution g\u00e9n\u00e9ralement.</p> </li> </ul> <p>Un VLAN Backup d\u00e9di\u00e9 prend son sens si les sauvegardes repr\u00e9sentent beaucoup de trafic et qu\u2019on peut le s\u00e9parer physiquement/logiquement. Si vos sauvegardes se font la nuit, saturer le LAN principal n\u2019est pas un gros probl\u00e8me, donc un VLAN s\u00e9par\u00e9 n\u2019apporte pas \u00e9norm\u00e9ment en performance (sauf \u00e0 avoir des liens multiples). En s\u00e9curit\u00e9 en revanche, isoler le serveur de sauvegarde sur un VLAN restreint est malin : en cas de compromission d\u2019une machine du LAN Prod (ran\u00e7ongiciel par ex), il lui sera plus difficile d\u2019atteindre le NAS de sauvegarde s\u2019il est sur un autre VLAN avec un acc\u00e8s uniquement unidirectionnel.  Recommandation : placez votre NAS/serveur de backup dans un VLAN s\u00e9par\u00e9 (par ex. VLAN 60 = 192.168.60.0/24), n\u2019autorisez que le minimum (les machines sources peuvent envoyer des sauvegardes vers lui, mais lui ne peut initier de connexion vers elles), et n\u2019autorisez pas ce VLAN vers Internet, sauf \u00e9ventuellement pour envoyer des alertes mail de backup. Ainsi, vos backups sont conserv\u00e9s dans une \u201czone\u201d distincte, r\u00e9duisant les risques en cas de malware sur le LAN principal.</p>"},{"location":"infrastructure/reseau/#vlan_6","title":"VLAN","text":""},{"location":"infrastructure/reseau/#management","title":"Management","text":""},{"location":"infrastructure/reseau/#oob-admin","title":"(OOB, admin)","text":"<p>Un VLAN souvent oubli\u00e9 dans les petits r\u00e9seaux, mais tr\u00e8s utile \u00e0 partir d\u2019un certain niveau de complexit\u00e9, est le VLAN  Administration. Id\u00e9e : regrouper toutes les  interfaces de gestion  de vos \u00e9quipements critiques (routeur, switch, NAS, hyperviseur, IPMI des serveurs\u2026) sur un r\u00e9seau \u00e0 part, accessible uniquement aux administrateurs. Par exemple VLAN  99  = 192.168.99.0/24. Vous configurez chaque \u00e9quipement pour qu\u2019il  n\u2019\u00e9coute son interface d\u2019administration web/SSH que sur l\u2019IP de ce VLAN Management. Ainsi, m\u00eame si un utilisateur malveillant se trouve sur le VLAN Prod, il ne pourra pas tenter d\u2019acc\u00e9der \u00e0 l\u2019interface du switch si celle-ci est sur VLAN 99 uniquement (et qu\u2019il n\u2019a pas acc\u00e8s \u00e0 VLAN 99)  . C\u2019est une mesure de s\u00e9curit\u00e9  suppl\u00e9mentaire : m\u00eame en environnement domestique, il est int\u00e9ressant de limiter l\u2019acc\u00e8s aux consoles d\u2019admin. Concr\u00e8tement, il faut que  vous  disposiez d\u2019un moyen d\u2019entrer dans ce VLAN management quand besoin (par ex. votre PC admin a un port physique ou un SSID Wi-Fi d\u00e9di\u00e9 \u00e0 ce VLAN, ou vous basculez un VLAN tagg\u00e9 sur votre PC quand n\u00e9cessaire). Ce n\u2019est pas toujours le plus pratique au quotidien, mais c\u2019est proche des pratiques professionnelles. Vous pouvez simplifier en combinant le VLAN Management avec votre VLAN Prod si vous \u00eates seul \u00e0 utiliser le r\u00e9seau, mais si vous \u00eates plusieurs utilisateurs non techniques chez vous, mieux vaut isoler la gestion.</p> <p>Dans la config propos\u00e9e plus haut (image du r\u00e9seau), le VLAN \u201cLAN\u201d \u00e9tait utilis\u00e9 comme r\u00e9seau de management d\u00e9di\u00e9  . On y pla\u00e7ait le switch, les AP, etc., tandis que les utilisateurs normaux \u00e9taient sur d\u2019autres VLAN par d\u00e9faut  . Cette approche se traduit par  0 service d\u2019admin  accessible depuis les VLAN utilisateurs, ce qui r\u00e9duit fortement les possibilit\u00e9s d\u2019attaque interne sur vos \u00e9quipements. En homelab, VLAN 99 Management peut ne pas \u00eatre indispensable, mais il est bon de l\u2019envisager pour \u201cfuture-proof\u201d votre design.</p>"},{"location":"infrastructure/reseau/#vlan_7","title":"VLAN","text":""},{"location":"infrastructure/reseau/#dmz","title":"DMZ","text":""},{"location":"infrastructure/reseau/#zone-demilitarisee","title":"(zone d\u00e9militaris\u00e9e)","text":"<p>La DMZ est un VLAN particulier destin\u00e9 aux  services publics/expos\u00e9s sur Internet. Si vous h\u00e9bergez, par exemple, un serveur web accessible depuis l\u2019ext\u00e9rieur, un VPN entrant, ou un reverse proxy frontal pour vos services, il est sain de le placer en DMZ. Ce VLAN DMZ (ex: VLAN 70 = 192.168.70.0/24) est isol\u00e9 du LAN : seul le routeur y acc\u00e8de. On configure des r\u00e8gles NAT/Port forwarding pour diriger le trafic entrant WAN \u2192 vers l\u2019IP du serveur en DMZ, et on autorise le minimum de ce VLAN vers l\u2019int\u00e9rieur.  Id\u00e9alement, la DMZ n\u2019initie aucune connexion vers vos LAN internes  (sauf peut-\u00eatre requ\u00eater une base de donn\u00e9es sur un VLAN sp\u00e9cifique, mais dans homelab, on \u00e9vite d\u2019exposer une base interne). Un exemple concret : vous h\u00e9bergez un  reverse proxy Nginx  pour acc\u00e9der \u00e0 vos services maison (domotic, etc.) depuis Internet. Placez ce reverse proxy en DMZ. On ouvre depuis Internet seulement le port 443 vers lui. Dans le firewall, on peut autoriser ce reverse proxy DMZ \u00e0 contacter, disons, le serveur domotique en VLAN IoT sur le port requis, et c\u2019est tout. Ainsi, si le proxy est compromis via le web, l\u2019attaquant est confin\u00e9 en DMZ. Certains adoptent m\u00eame une  double barri\u00e8re  en DMZ : le serveur DMZ est derri\u00e8re le pare-feu principal ET poss\u00e8de son propre pare-feu applicatif. Dans un homelab, ceinture et bretelles sont peut-\u00eatre excessives, mais l\u2019id\u00e9e est de ne jamais  faire transiter du trafic Internet directement dans vos VLAN sensibles. La DMZ agit comme tampon.</p> <p>Un utilisateur homelab t\u00e9moigne par exemple :  \u00abDMZ \u2013 le seul VLAN acceptant des connexions externes (443), il h\u00e9berge le reverse proxy externe et poss\u00e8de un double firewall\u00bb  . Cela illustre bien que m\u00eame en environnement perso, on peut traiter la DMZ s\u00e9rieusement. En pratique, pour configurer : cr\u00e9ez le VLAN, attribuez-le \u00e0 une interface OPNsense (ex: OPT2), donnez-lui une plage IP. Reliez-y votre serveur public. Sur OPNsense, activez les r\u00e8gles NAT voulues vers ce VLAN, et surtout  blocquez toute sortie de la DMZ vers vos LAN  par d\u00e9faut. Autorisez uniquement ce qui est n\u00e9cessaire (peut-\u00eatre la DMZ peut acc\u00e9der \u00e0 Internet pour updates, ou joindre un DNS local). Un conseil : ne r\u00e9utilisez pas vos machines de LAN en DMZ ; par exemple, \u00e9vitez qu\u2019un conteneur sur votre NAS principal soit expos\u00e9 : mieux vaut une VM d\u00e9di\u00e9e sur un h\u00f4te en DMZ. Cela \u00e9vite qu\u2019une compromission DMZ n\u2019affecte vos donn\u00e9es.</p>"},{"location":"infrastructure/reseau/#vlan_8","title":"VLAN","text":""},{"location":"infrastructure/reseau/#invites","title":"Invit\u00e9s","text":""},{"location":"infrastructure/reseau/#guest-wi-fi","title":"(Guest Wi-Fi)","text":"<p>Enfin, souvent utile dans un foyer, un VLAN  Invit\u00e9s  pour le Wi-Fi des visiteurs ou appareils temporaires. Par ex VLAN  80  = 192.168.80.0/24. Son objectif : fournir un acc\u00e8s Internet basique  sans aucun acc\u00e8s \u00e0 vos ressources internes. Ici il faut g\u00e9n\u00e9ralement activer l\u2019isolement client sur l\u2019AP Wi-Fi (pour que les invit\u00e9s ne se voient pas entre eux), et sur le pare-feu on bloque toute destination locale. En gros, c\u2019est tr\u00e8s proche du VLAN IoT en termes de r\u00e8gles, mais on peut \u00eatre encore plus restrictif (pas d\u2019acc\u00e8s sortant vers des ports sensibles, \u00e9ventuellement limiter la bande passante via QoS). Le VLAN Invit\u00e9s est un bon moyen de partager votre connexion sans compromettre le reste. Avec un portail captif ou un mot de passe distinct, vous pouvez contr\u00f4ler l\u2019utilisation. Techniquement, il suffit de cr\u00e9er ce VLAN invit\u00e9, de le lier \u00e0 un SSID d\u00e9di\u00e9 sur votre point d\u2019acc\u00e8s, et de v\u00e9rifier que les r\u00e8gles firewall interdisent tout acc\u00e8s aux autres VLAN (ce qui devrait d\u00e9j\u00e0 \u00eatre le cas si on bloque RFC1918 en sortie).</p> <p>Pour r\u00e9sumer, isoler les invit\u00e9s vous prot\u00e8ge de tout poste non ma\u00eetris\u00e9 (par exemple l\u2019ordinateur v\u00e9rol\u00e9 d\u2019un ami de passage ne pourra pas scanner/transmettre quoi que ce soit \u00e0 vos machines). C\u2019est une VLAN \u00e0 consid\u00e9rer m\u00eame si non mentionn\u00e9 initialement, puisque  anticiper les \u00e9ventualit\u00e9s  est l\u2019objectif : on ne sait jamais quand quelqu\u2019un vous demandera le Wi-Fi \u2013 autant que ce soit un r\u00e9seau distinct brid\u00e9.</p>"},{"location":"infrastructure/reseau/#conclusion-vers-un-homelab-segmente-securise-et-evolutif","title":"Conclusion : Vers un homelab segment\u00e9, s\u00e9curis\u00e9 et \u00e9volutif","text":"<p>En impl\u00e9mentant une segmentation par VLAN dans votre homelab, vous posez les bases d\u2019une architecture robuste o\u00f9 chaque cat\u00e9gorie de dispositifs \u00e9volue dans son  environnement contr\u00f4l\u00e9. La configuration peut sembler complexe au d\u00e9but (notamment la coordination entre routeur, switch et points d\u2019acc\u00e8s), mais le gain en s\u00e9curit\u00e9 et en ma\u00eetrise du r\u00e9seau est consid\u00e9rable pour un administrateur domestique. Vous avez d\u00e9sormais un  plan de r\u00e9seau d\u00e9taill\u00e9  distinguant les zones Prod, Lab, Domotique, Cam\u00e9ras, Stockage, Sauvegarde, etc., avec des  passerelles (routeur)  g\u00e9rant les communications entre ces zones de mani\u00e8re filtr\u00e9e.</p> <p>N\u2019h\u00e9sitez pas \u00e0  documenter votre topologie  (sch\u00e9mas, tableaux d\u2019adressage VLAN) et \u00e0 commenter vos r\u00e8gles firewall pour vous y retrouver. \u00c0 mesure que votre homelab grandit, cette segmentation vous facilitera l\u2019int\u00e9gration de nouveaux services sans tout remettre en question : par exemple, ajouter un serveur PBX VoIP ? Cr\u00e9ez un VLAN VoIP. Tester un cluster Kubernetes ? Peut-\u00eatre un VLAN \u201cDev\u201d s\u00e9par\u00e9. Votre r\u00e9seau est d\u00e9j\u00e0 pr\u00eat \u00e0 cloisonner ces ajouts.</p> <p>En appliquant les bonnes pratiques (principe du moindre privil\u00e8ge entre VLAN, isolation du management, utilisation d\u2019ACL avanc\u00e9es si besoin, etc.), vous rapprochez votre homelab d\u2019un  r\u00e9seau d\u2019entreprise miniature  en termes de s\u00e9rieux et de s\u00e9curit\u00e9. Enfin, v\u00e9rifiez r\u00e9guli\u00e8rement vos r\u00e8gles et appareils connect\u00e9s \u2013 la  discipline de segmentationn\u00e9cessite de s\u2019assurer qu\u2019aucun appareil ne se retrouve par erreur dans le mauvais VLAN ou avec des droits inappropri\u00e9s. Avec cette architecture VLAN bien pens\u00e9e, votre homelab pourra h\u00e9berger en toute confiance vos projets personnels, vos exercices de s\u00e9curit\u00e9 et vos gadgets connect\u00e9s, le tout  sans interf\u00e9rences ni risques excessifs  entre eux.</p>"},{"location":"infrastructure/stockage/","title":"Gestion du stockage dans un homelab s\u00e9curis\u00e9","text":""},{"location":"infrastructure/stockage/#comparatif-des-systemes-de-fichiers-zfs-vs-btrfs-vs-ext4-vs-xfs","title":"Comparatif des syst\u00e8mes de fichiers : ZFS vs Btrfs vs EXT4 vs XFS","text":"<p>Dans un homelab, le choix du syst\u00e8me de fichiers impacte directement la  fiabilit\u00e9 des donn\u00e9es  et les fonctionnalit\u00e9s disponibles (snapshots, RAID, compression\u2026). Les syst\u00e8mes de fichiers traditionnels comme  EXT4  et  XFS  offrent stabilit\u00e9 et performance de base, tandis que  Btrfs  et  ZFS  int\u00e8grent des fonctions avanc\u00e9es (copie sur \u00e9criture, somme de contr\u00f4le, etc.) pour am\u00e9liorer l\u2019int\u00e9grit\u00e9 des donn\u00e9es. Voici un comparatif d\u00e9taill\u00e9 de leurs caract\u00e9ristiques, avantages, inconv\u00e9nients et cas d\u2019usage.</p>"},{"location":"infrastructure/stockage/#ext4-le-pilier-stable-et-eprouve","title":"EXT4 \u2013 Le pilier stable et \u00e9prouv\u00e9","text":"<p>EXT4  (Fourth Extended Filesystem) est le syst\u00e8me de fichiers par d\u00e9faut de nombreuses distributions Linux depuis 2008. \u00c9volution du EXT3, il est r\u00e9put\u00e9 pour sa  stabilit\u00e9  et sa  performance \u00e9quilibr\u00e9e, avec un journal assurant une r\u00e9cup\u00e9ration rapide en cas de crash. Il fonctionne bien dans presque tous les sc\u00e9narios g\u00e9n\u00e9raux.</p> <ul> <li> <p>Avantages :  Mature et ultra-stable (plus de 10 ans d\u2019usage intensif)  . Large compatibilit\u00e9 (support\u00e9 nativement par la plupart des OS Linux et outils). Bonnes performances g\u00e9n\u00e9rales en lecture/\u00e9criture, y compris sur des disques de grande capacit\u00e9. Utilise un  journaling  qui am\u00e9liore la r\u00e9silience en cas de panne syst\u00e8me  .</p> </li> <li> <p>Inconv\u00e9nients :  Pas de fonctionnalit\u00e9s avanc\u00e9es int\u00e9gr\u00e9es \u2013 absence de snapshots, de compression transparente ou de m\u00e9canisme de RAID interne  . Protection d\u2019int\u00e9grit\u00e9 limit\u00e9e : pas de  somme de contr\u00f4le des donn\u00e9es  (seulement journal des m\u00e9tadonn\u00e9es), donc pas de d\u00e9tection automatique de corruption. \u00c9volutivit\u00e9 suffisante pour la plupart des cas, mais en th\u00e9orie moins extensible que Btrfs/ZFS.</p> </li> <li> <p>Cas d\u2019usage recommand\u00e9s :  Syst\u00e8mes Linux g\u00e9n\u00e9raux (PC, serveurs web, etc.) o\u00f9 la  simplicit\u00e9 et la fiabilit\u00e9 \u00e9prouv\u00e9e  priment  . Parfait pour les partitions syst\u00e8me ou le stockage de donn\u00e9es non critiques dans un homelab, lorsque l\u2019on n\u2019a pas besoin des fonctionnalit\u00e9s avanc\u00e9es des syst\u00e8mes modernes.</p> </li> </ul>"},{"location":"infrastructure/stockage/#xfs-le-moteur-de-performance-evolutif","title":"XFS \u2013 Le moteur de performance \u00e9volutif","text":"<p>XFS  est un syst\u00e8me de fichiers journalis\u00e9 64 bit, cr\u00e9\u00e9 \u00e0 l\u2019origine pour SGI IRIX (ann\u00e9es 90) et adopt\u00e9 dans le monde Linux (c\u2019est le choix par d\u00e9faut de Red Hat Enterprise Linux, par ex.). Il est r\u00e9put\u00e9 pour sa  haute performance en I/O(surtout sur les gros fichiers et les op\u00e9rations parall\u00e8les) et son excellente  scalabilit\u00e9  sur de tr\u00e8s grandes volum\u00e9tries.</p> <ul> <li> <p>Avantages :  Tr\u00e8s  performant en d\u00e9bit  s\u00e9quentiel et pour les fichiers de grande taille  . Supporte des syst\u00e8mes de fichiers massifs (jusqu\u2019\u00e0 8 exabytes) et g\u00e8re efficacement les charges intensives (grandes bases de donn\u00e9es, streaming vid\u00e9o, etc.). Stable et \u00e9prouv\u00e9 en production, avec des fonctionnalit\u00e9s comme la d\u00e9fragmentation \u00e0 chaud et le journaling pour prot\u00e9ger les m\u00e9tadonn\u00e9es.</p> </li> <li> <p>Inconv\u00e9nients :  Moins efficace avec d\u2019innombrables petits fichiers ou des charges tr\u00e8s m\u00e9tadonn\u00e9es (le design privil\u00e9gie les grands flux)  . N\u2019int\u00e8gre  pas  de snapshots, compression ou chiffrement natifs (il faut s\u2019appuyer sur LVM ou des solutions externes pour ces besoins)  . De plus, XFS ne permet pas de  r\u00e9duire  la taille d\u2019un syst\u00e8me de fichiers (on peut l\u2019agrandir, mais pas le shrink).</p> </li> <li> <p>Cas d\u2019usage recommand\u00e9s :  Serveurs de fichiers volumineux, stockage de m\u00e9dias et de vid\u00e9os,  workstations de montage  vid\u00e9o, environnements avec gros fichiers (images disque, backups volumineux) ou  h\u00f4tes de virtualisation  g\u00e9rant de nombreux fichiers VM de taille cons\u00e9quente  . XFS excelle d\u00e8s qu\u2019il faut un d\u00e9bit maximal et une gestion efficace de tr\u00e8s grandes capacit\u00e9s.</p> </li> </ul>"},{"location":"infrastructure/stockage/#btrfs-linnovateur-riche-en-fonctionnalites","title":"Btrfs \u2013 L\u2019innovateur riche en fonctionnalit\u00e9s","text":"<p>Btrfs  (B-Tree FS, souvent prononc\u00e9 \u201cButter FS\u201d) est un syst\u00e8me de fichiers moderne introduit en 2009, con\u00e7u pour apporter des fonctionnalit\u00e9s de niveau entreprise sur Linux (copy-on-write, snapshots, RAID logiciel\u2026). Il est par exemple le syst\u00e8me par d\u00e9faut sur Fedora, openSUSE et utilis\u00e9 par Synology sur certains NAS. Btrfs est souvent compar\u00e9 \u00e0 ZFS en termes d\u2019objectifs, tout en \u00e9tant int\u00e9gr\u00e9 au noyau Linux.</p> <ul> <li> <p>Fonctionnalit\u00e9s cl\u00e9s :  Btrfs prend en charge les  snapshots instantan\u00e9s  (copies d\u2019\u00e9tat du syst\u00e8me de fichiers \u00e0 un instant T) et les  subvolumes  (unit\u00e9s logiques s\u00e9par\u00e9es)  . Il propose un  RAID logiciel int\u00e9gr\u00e9  (niveaux 0, 1, 10 et 5/6 exp\u00e9rimentaux) sans n\u00e9cessiter d\u2019outil externe, ainsi que la  compression transparente  des donn\u00e9es (algorithmes support\u00e9s : zlib, lzo, zstd) pour \u00e9conomiser de l\u2019espace  . Surtout, Btrfs calcule des  checksums  sur les donn\u00e9es et m\u00e9tadonn\u00e9es pour d\u00e9tecter les corruptions, et peut r\u00e9aliser une auto-r\u00e9paration s\u2019il y a redondance (RAID 1/10)  . On note aussi une grande flexibilit\u00e9 avec possibilit\u00e9 d\u2019agrandir ou r\u00e9duire  un volume en ligne, et une gestion fine des quotas et de la d\u00e9duplication (via des outils externes).</p> </li> <li> <p>Avantages : Snapshots rapides  et peu co\u00fbteux en espace (on peut en prendre fr\u00e9quemment pour tester des modifications et revenir en arri\u00e8re facilement).  RAID logiciel  directement dans le syst\u00e8me de fichiers (pas besoin de mdadm), avec tol\u00e9rance aux pannes et auto-r\u00e9paration (en modes mirroring)  .  Compression  et  d\u00e9duplication(optionnelle) pour optimiser le stockage. \u00c9volutivit\u00e9 et souplesse (ajout/retrait de disques dans un volume Btrfs, redimensionnement \u00e0 la vol\u00e9e). En somme, Btrfs est un v\u00e9ritable  couteau suisse  du stockage, r\u00e9unissant de nombreuses fonctionnalit\u00e9s avanc\u00e9es.</p> </li> <li> <p>Inconv\u00e9nients :  Moins mature qu\u2019EXT4/XFS dans certaines situations critiques : toutes les distributions ne consid\u00e8rent pas Btrfs aussi \u201cproduction-ready\u201d pour les workloads intensifs (bien qu\u2019il s\u2019am\u00e9liore constamment)  . L\u2019impl\u00e9mentation des modes RAID 5/6 est encore consid\u00e9r\u00e9e  exp\u00e9rimentale  \u2013 des probl\u00e8mes de fiabilit\u00e9 n\u2019ont pas \u00e9t\u00e9 totalement r\u00e9solus \u00e0 ce jour, ce qui d\u00e9conseille leur usage en production  . De plus, Btrfs induit un l\u00e9ger  surco\u00fbt de performance  d\u00fb au copy-on-write et aux checksums (impact surtout visible sur du mat\u00e9riel plus ancien ou des charges lourdes en \u00e9criture)  . Enfin, l\u2019administration  peut sembler complexe pour les d\u00e9butants (subvolumes, \u00e9quilibre du FS, etc.), m\u00eame si des outils comme  btrfs-progs  ou Snapper facilitent la gestion.</p> </li> <li> <p>Cas d\u2019usage recommand\u00e9s :  Id\u00e9al pour les  NAS auto-h\u00e9berg\u00e9s  et serveurs domestiques qui profitent de ses fonctionnalit\u00e9s (par ex. snapshots programm\u00e9s pour les sauvegardes, ou utilisation de la compression pour stocker plus de donn\u00e9es). Recommand\u00e9 aussi pour les utilisateurs d\u00e9veloppeurs ou \u201cpower users\u201d qui appr\u00e9cient les  fonctionnalit\u00e9s avanc\u00e9es  et les options de rollback facile (ex: snapshots avant une mise \u00e0 jour syst\u00e8me). Btrfs convient bien \u00e9galement aux environnements de containers et machines de test o\u00f9 l\u2019on veut cloner rapidement des environnements (subvolumes et snapshots) tout en b\u00e9n\u00e9ficiant de la s\u00e9curit\u00e9 des checksums.</p> </li> </ul>"},{"location":"infrastructure/stockage/#zfs-le-gardien-de-lintegrite-des-donnees","title":"ZFS \u2013 Le gardien de l\u2019int\u00e9grit\u00e9 des donn\u00e9es","text":"<p>ZFS  est souvent consid\u00e9r\u00e9 comme le  Saint Graal de la fiabilit\u00e9  des syst\u00e8mes de fichiers. Con\u00e7u par Sun Microsystems et d\u00e9sormais d\u00e9velopp\u00e9 via le projet open source OpenZFS, il combine un syst\u00e8me de fichiers  et  un gestionnaire de volumes logiques. ZFS introduit des concepts r\u00e9volutionnaires de  stockage en pool  (agr\u00e9gation flexible de disques) et de  principe Copy-on-Write  g\u00e9n\u00e9ralis\u00e9 garantissant une forte coh\u00e9rence. Tr\u00e8s utilis\u00e9 dans les NAS professionnels (TrueNAS, etc.) et les infrastructures exigeant une haute int\u00e9grit\u00e9, ZFS est aussi support\u00e9 sous Linux (via module DKMS) et int\u00e9gr\u00e9 nativement \u00e0 FreeBSD.</p> <ul> <li> <p>Fonctionnalit\u00e9s cl\u00e9s :  ZFS offre un \u00e9ventail complet de fonctionnalit\u00e9s: syst\u00e8me Copy-on-Write avec  snapshots et clones  natifs (snapshots instantan\u00e9s et clones modifiables)  ,  v\u00e9rification d\u2019int\u00e9grit\u00e9  continue avec  checksums sur chaque bloc de donn\u00e9es  et  auto-r\u00e9paration  en cas de corruption gr\u00e2ce aux copies redondantes  , compression transparente (algorithme LZ4 par d\u00e9faut, ZSTD possible),  deduplication  optionnelle des donn\u00e9es, et bien s\u00fbr son propre syst\u00e8me de  RAID avanc\u00e9 (RAID-Z)  \u00e9quivalent aux RAID 5/6/7 mais sans les \u00e9cueils classiques (pas de  write hole, reconstruction plus s\u00fbre)  . ZFS g\u00e8re \u00e9galement le  chiffrement natif  (depuis OpenZFS 2.0) et la r\u00e9plication de snapshots vers d\u2019autres syst\u00e8mes ZFS. Enfin, il est notoirement  scalable  \u00e0 des \u00e9chelles \u00e9normes (pouvant adresser des p\u00e9taoctets \u00e0 l\u2019aise, bien au-del\u00e0 des besoins d\u2019un homelab).</p> </li> <li> <p>Avantages : Int\u00e9grit\u00e9 des donn\u00e9es in\u00e9gal\u00e9e  \u2013 chaque lecture est v\u00e9rifi\u00e9e par checksum, et en cas d\u2019erreur ZFS peut automatiquement corriger en lisant une copie saine (sur un miroir ou RAID-Z)  .  Stockage unifi\u00e9 en pools  : on peut agr\u00e9ger les disques en vdevs (simple, miroir, RAID-Z\u2026) au sein d\u2019un m\u00eame pool et cr\u00e9er des syst\u00e8mes de fichiers ou volumes \u00e0 la vol\u00e9e, ce qui simplifie la gestion compar\u00e9 \u00e0 LVM.  Snapshots et clones  efficaces pour les backups et tests, int\u00e9gr\u00e9s directement (on peut par exemple snapshotter une VM en un instant et la cloner pour testing).  Compression  et  dedup  \u00e9conomisent de l\u2019espace (au prix de ressources CPU/RAM suppl\u00e9mentaires)  .  \u00c9volutivit\u00e9 et performance  : ZFS peut exploiter de grandes quantit\u00e9s de RAM comme cache (ARC) pour acc\u00e9l\u00e9rer les acc\u00e8s, et il supporte le cache SSD (L2ARC) et le log s\u00e9par\u00e9 (ZIL/SLOG) pour booster les performances d\u2019\u00e9criture sync. Con\u00e7u initialement pour de l\u2019entreprise, ZFS  monte en puissance  avec le mat\u00e9riel \u2013 plus on lui donne de la RAM et des disques rapides, mieux il se comporte, du petit NAS jusqu\u2019au stockage de datacenter  .</p> </li> <li> <p>Inconv\u00e9nients : Gourmand en ressources  : il est recommand\u00e9 d\u2019avoir de la RAM en quantit\u00e9 (souvent on sugg\u00e8re ~1 Go par To de stockage, bien que cela d\u00e9pende des fonctions activ\u00e9es)  . Sur du mat\u00e9riel limit\u00e9 (petit homelab avec 2 Go de RAM par ex), ZFS peut ne pas donner la pleine mesure de ses avantages. De plus, sous Linux, ZFS n\u2019est pas int\u00e9gr\u00e9 au noyau pour des raisons de licence (CDDL incompatible GPL), il faut donc l\u2019installer s\u00e9par\u00e9ment (module DKMS ou kernel custom) \u2013 cela ajoute un peu de complexit\u00e9 aux mises \u00e0 jour syst\u00e8me  . La  complexit\u00e9  g\u00e9n\u00e9rale de ZFS peut \u00eatre d\u00e9routante pour un d\u00e9butant : de nombreux concepts (pool, vdevs, dataset, zvol, etc.) et options de r\u00e9glage. Cela peut sembler  overkill  pour de petites configurations, o\u00f9 un syst\u00e8me plus simple suffirait. Enfin, notons que l\u2019expansion d\u2019un pool ZFS  peut \u00eatre contraignante selon la configuration (on ne peut pas encore, au 21, \u00e9tendre facilement un vdev RAID-Z en ajoutant un disque, sans recr\u00e9er le vdev \u2013 bien que la fonctionnalit\u00e9 d\u2019extension RAID-Z soit en d\u00e9veloppement actif).</p> </li> <li> <p>Cas d\u2019usage recommand\u00e9s :  ZFS brille dans les sc\u00e9narios o\u00f9 la  pr\u00e9servation des donn\u00e9es  est critique. Pour un homelab s\u00e9curis\u00e9, si vous h\u00e9bergez des  machines virtuelles  ou des  conteneurs, ZFS (int\u00e9gr\u00e9 dans Proxmox VE, par exemple) permet d\u2019avoir des  snapshots coh\u00e9rents  et d\u2019\u00e9viter la corruption silencieuse des images disque gr\u00e2ce aux checksums. Id\u00e9al aussi pour un  NAS maison  o\u00f9 l\u2019on veut un maximum de fiabilit\u00e9 (par exemple un serveur de sauvegarde centralis\u00e9, un stockage pour photos/vid\u00e9os pr\u00e9cieuses) \u2013 ZFS assure que vos backups ne se d\u00e9gradent pas avec le temps (protection contre le  bitrot). En entreprise ou pour les utilisateurs avanc\u00e9s, ZFS est le choix de pr\u00e9dilection pour les  appliances de stockage  (NAS TrueNAS, serveurs de fichiers critiques, etc.) gr\u00e2ce \u00e0 son m\u00e9lange de performance et de s\u00e9curit\u00e9 des donn\u00e9es  . En r\u00e9sum\u00e9, si vos besoins requi\u00e8rent la  s\u00fbret\u00e9 maximale des donn\u00e9es  et que vous disposez du mat\u00e9riel ad\u00e9quat, ZFS est un alli\u00e9 de poids.</p> </li> </ul>"},{"location":"infrastructure/stockage/#redondance-et-tolerance-aux-pannes","title":"Redondance et tol\u00e9rance aux pannes","text":"<p>M\u00eame dans un homelab, il est essentiel de pr\u00e9voir les d\u00e9faillances mat\u00e9rielles. Disques qui tombent en panne, erreurs humaines, ransomware \u2013 une bonne strat\u00e9gie de stockage  s\u00e9curis\u00e9  repose sur plusieurs couches :  redondance en temps r\u00e9el  (RAID, mirroring\u2026),  points de restauration  (snapshots) et  sauvegardes externes. Nous allons passer en revue les options de RAID, l\u2019utilisation des snapshots et les strat\u00e9gies de sauvegarde, sp\u00e9cialement adapt\u00e9es \u00e0 un homelab.</p>"},{"location":"infrastructure/stockage/#raid-niveaux-materiel-vs-logiciel","title":"RAID : niveaux, mat\u00e9riel vs logiciel","text":"<p>L\u2019acronyme  RAID  (Redundant Array of Independent Disks) d\u00e9crit les solutions combinant plusieurs disques pour am\u00e9liorer soit la performance, soit la tol\u00e9rance de panne \u2013 souvent les deux. Il existe plusieurs  niveaux de RAIDcourants, chacun avec ses caract\u00e9ristiques :</p> <ul> <li> <p>RAID 0 (Striping) : donn\u00e9es r\u00e9parties (encha\u00een\u00e9es) sur plusieurs disques pour augmenter le d\u00e9bit. Offre des  performances maximales, id\u00e9al quand la vitesse prime, mais  sans aucune redondance  \u2013 la panne d\u2019un seul disque entra\u00eene la perte de toutes les donn\u00e9es  . \u00c0 r\u00e9server aux usages non critiques (cache, rendu vid\u00e9o temporaire, etc.).</p> </li> <li> <p>RAID 1 (Mirroring) : les donn\u00e9es sont  dupliqu\u00e9es en miroir  sur deux disques (ou plus). Fournit une  excellente tol\u00e9rance aux pannes  (on peut perdre un disque sans perte de donn\u00e9es) mais au prix d\u2019une capacit\u00e9 r\u00e9duite de moiti\u00e9 (2 To + 2 To en RAID 1 = 2 To utiles)  . Performances en lecture \u00e9lev\u00e9es (on lit sur deux disques en parall\u00e8le), \u00e9criture un peu plus lente qu\u2019un seul disque. Recommand\u00e9 pour stocker des donn\u00e9es importantes sur peu de disques (2 disques) ou comme miroir du syst\u00e8me.</p> </li> <li> <p>RAID 5 : utilise un  parity striping  distribu\u00e9 \u2013 les donn\u00e9es sont r\u00e9parties sur  n-1  disques et sur le disque restant est stock\u00e9e une information de parit\u00e9 (calcul\u00e9e) permettant de reconstruire les donn\u00e9es d\u2019un disque manquant. Ce niveau offre un  \u00e9quilibre entre performance, capacit\u00e9 et redondance  : la lecture est rapide (plusieurs disques en parall\u00e8le) et la capacit\u00e9 utilis\u00e9e est optimis\u00e9e (seulement l\u2019\u00e9quivalent d\u2019un disque est \u201csacrifi\u00e9\u201d pour la parit\u00e9)  .  Tol\u00e9rance de panne : 1 disque. Inconv\u00e9nients : performances d\u2019\u00e9criture un peu moindres (calcul de la parit\u00e9) et surtout reconstruction longue en cas de crash d\u2019un disque. Si un second disque flanche pendant la reconstruction, les donn\u00e9es sont perdues. RAID 5 convient aux espaces de stockage importants o\u00f9 on veut un compromis capacit\u00e9/s\u00e9curit\u00e9 raisonnable, mais on lui pr\u00e9f\u00e8re souvent RAID 6 aujourd\u2019hui.</p> </li> <li> <p>RAID 6 : variante de RAID 5 avec  deux blocs de parit\u00e9  r\u00e9partis, pouvant tol\u00e9rer la panne  simultan\u00e9e de 2 disques. La s\u00e9curit\u00e9 est renforc\u00e9e au prix d\u2019une capacit\u00e9 utilisable l\u00e9g\u00e8rement inf\u00e9rieure (l\u2019\u00e9quivalent de 2 disques sert de parit\u00e9). C\u2019est une solution robuste pour les baies de disques de grande capacit\u00e9, au cas o\u00f9 un second disque l\u00e2che lors de la reconstruction du premier. Les performances sont un peu en de\u00e7\u00e0 du RAID 5 en \u00e9criture (parit\u00e9 double \u00e0 calculer) mais restent acceptables en lecture et adapt\u00e9es aux environnements exigeant une haute redondance  .</p> </li> <li> <p>RAID 10 (ou 1+0) : combinaison du mirroring et du striping. On associe des paires de disques en miroir (RAID 1) puis on agr\u00e9ge ces miroirs en RAID 0 (striping entre les miroirs). On obtient ainsi  d\u2019excellentes performances(\u00e9quivalentes \u00e0 RAID 0 sur lecture/\u00e9criture)  ET une tol\u00e9rance aux pannes \u00e9lev\u00e9e  (chaque paire peut tol\u00e9rer une panne)  . Le RAID 10 n\u00e9cessite au minimum 4 disques (et un nombre pair) et n\u2019utilise que 50% de l\u2019espace total (puisque mirroring). C\u2019est une solution pris\u00e9e pour les applications critiques n\u00e9cessitant \u00e0 la fois d\u00e9bit et fiabilit\u00e9 (par ex. un serveur de base de donn\u00e9es dans un homelab). Co\u00fbt plus \u00e9lev\u00e9 en nombre de disques, mais reconstruction rapide en cas de panne (on recopie simplement un miroir).</p> </li> <li> <p>JBOD (Just a Bunch Of Disks) : techniquement pas un RAID, le JBOD permet de concat\u00e9ner des disques ind\u00e9pendants l\u2019un \u00e0 la suite de l\u2019autre, ou simplement de les pr\u00e9senter individuellement. Il n\u2019y a  pas de gain de performance ni de redondance  \u2013 c\u2019est juste un moyen d\u2019utiliser plusieurs disques comme un seul grand volume, ou comme disques s\u00e9par\u00e9s. Utile \u00e9ventuellement pour maximiser la capacit\u00e9 de stockage brute quand la tol\u00e9rance de panne n\u2019est  pas  une priorit\u00e9  .</p> </li> </ul> <p>RAID mat\u00e9riel vs RAID logiciel :  Le RAID peut \u00eatre g\u00e9r\u00e9  soit par du mat\u00e9riel d\u00e9di\u00e9 (carte contr\u00f4leur RAID), soit par le  syst\u00e8me d\u2019exploitation (RAID logiciel). En RAID  mat\u00e9riel, un contr\u00f4leur se charge de toutes les op\u00e9rations de gestion des disques de mani\u00e8re autonome (souvent avec sa propre m\u00e9moire cache, parfois prot\u00e9g\u00e9e par batterie). Cela offre typiquement de meilleures performances sur des charges lourdes et soulage le CPU principal  . Le RAID mat\u00e9riel apporte aussi souvent des options avanc\u00e9es (ex. certains niveaux RAID suppl\u00e9mentaires) et une ind\u00e9pendance vis-\u00e0-vis du syst\u00e8me (le contr\u00f4leur pr\u00e9sente un seul volume logique, utilisable par n\u2019importe quel OS)  . En contrepartie, ces cartes sont co\u00fbteuses et introduisent une d\u00e9pendance : si la carte tombe en panne, il faut id\u00e9alement la m\u00eame pour r\u00e9cup\u00e9rer l\u2019array.</p> <p>Le  RAID logiciel, lui, s\u2019appuie sur la puissance de calcul du processeur h\u00f4te pour g\u00e9rer le RAID (ex: via mdadm/Linux ou Storage Spaces sous Windows). De nos jours, avec des CPU performants, le RAID logiciel offre des performances tr\u00e8s honorables \u2013 l\u2019impact est n\u00e9gligeable pour des niveaux simples (RAID 1, 0)  , et reste raisonnable pour RAID 5/6 sur un homelab. L\u2019avantage principal est le  co\u00fbt nul  (pas de mat\u00e9riel additionnel) et une flexibilit\u00e9 accrue (migration possible d\u2019un OS \u00e0 un autre dans certains cas, ajout de disques parfois plus souple)  . Cependant, le RAID logiciel peut \u00eatre un peu  plus lent  dans certains sc\u00e9narios intensifs car il doit partager le CPU avec le reste du syst\u00e8me  . Il est aussi li\u00e9 au logiciel : par exemple, un RAID logiciel Windows ne sera pas lisible sous Linux et vice-versa, ce qui peut compliquer une migration.</p> <p>En r\u00e9sum\u00e9, pour un  homelab, un RAID logiciel (mdadm, espace de stockage ZFS/Btrfs, etc.) est souvent pr\u00e9f\u00e9rable pour \u00e9viter les frais et la complexit\u00e9 mat\u00e9rielle \u2013 les performances sont largement suffisantes dans un contexte domestique. Le RAID mat\u00e9riel se justifie surtout si vous avez d\u00e9j\u00e0 une carte (serveur de r\u00e9cup) ou pour des cas tr\u00e8s sp\u00e9cifiques (besoin d\u2019un cache prot\u00e9g\u00e9 par batterie, compatibilit\u00e9 multi-OS sur du dual-boot, etc.). Dans tous les cas,  RAID \u2260 backup  : m\u00eame avec redondance, une erreur humaine ou un ransomware peut d\u00e9truire les donn\u00e9es, d\u2019o\u00f9 l\u2019importance des snapshots et sauvegardes que nous abordons ci-dessous.</p>"},{"location":"infrastructure/stockage/#snapshots-restauration-instantanee-et-limites","title":"Snapshots : restauration instantan\u00e9e et limites","text":"<p>Les  snapshots  sont des points de restauration instantan\u00e9s d\u2019un volume ou syst\u00e8me de fichiers, parfois appel\u00e9s  \u201cphotographies\u201d  de l\u2019\u00e9tat des donn\u00e9es \u00e0 un instant  t. Beaucoup de solutions de stockage modernes (ZFS, Btrfs, LVM, VMware, etc.) les proposent. Ils offrent la capacit\u00e9 de revenir en arri\u00e8re rapidement apr\u00e8s un probl\u00e8me : par exemple, si une VM ou un dossier a \u00e9t\u00e9 modifi\u00e9 par erreur, on peut restaurer le snapshot pr\u00e9c\u00e9dent en quelques secondes. Le principal avantage d\u2019un snapshot par rapport \u00e0 une sauvegarde traditionnelle est la  rapidit\u00e9  et la fr\u00e9quence : on peut en cr\u00e9er tr\u00e8s souvent (par exemple toutes les heures) sans trop d\u2019impact, ce qui procure de nombreux points de restauration granulaires  . En cas d\u2019incident, red\u00e9marrer une VM ou restaurer un fichier \u00e0 partir d\u2019un snapshot local est quasi imm\u00e9diat, alors qu\u2019une restauration depuis une backup compl\u00e8te peut prendre beaucoup plus de temps.</p> <p>Limites des snapshots :  un snapshot n\u2019est  pas une sauvegarde ind\u00e9pendante. Contrairement \u00e0 une vraie copie de sauvegarde, un snapshot d\u00e9pend du stockage principal : il stocke g\u00e9n\u00e9ralement seulement les diff\u00e9rences (blocs modifi\u00e9s) et pointe vers les blocs inchang\u00e9s. Si le volume principal est perdu (panne hardware grave) ou corrompu, les snapshots sont perdus avec lui  . De plus, les snapshots consomment de l\u2019espace sur le stockage d\u2019origine pour conserver les anciennes versions des blocs \u2013 plus on en garde, plus on utilise d\u2019espace (ils sont souvent auto-nettoy\u00e9s au bout de X jours/heures pour \u00e9viter de saturer le stockage). Il faut donc les voir comme des  outils compl\u00e9mentaires  pour la restauration rapide, et non comme une solution de backup autonome. La  bonne pratique  est d\u2019ailleurs de combiner snapshots  et  sauvegardes  : les snapshots fournissent des points de reprise fr\u00e9quents (par ex. horaires) sur le stockage principal, et les sauvegardes externes assurent la r\u00e9cup\u00e9ration en cas de perte totale du syst\u00e8me (points de restauration quotidiens, hebdomadaires, conserv\u00e9s hors du syst\u00e8me principal)  .</p> <p>Outils de snapshots :  Pour en b\u00e9n\u00e9ficier dans un homelab, on peut s\u2019appuyer sur ZFS (commandes  zfs snapshot, ou outils comme sanoid/syncoid pour automatiser), sur Btrfs (btrfs subvolume snapshot  et l\u2019outil Snapper pour la gestion automatis\u00e9e). LVM propose aussi des snapshots de volumes logiques LVM qui peuvent servir \u00e0 prendre une image coh\u00e9rente d\u2019une partition ext4/xfs avant backup, par exemple. Sur Windows/VMware, on retrouve des fonctionnalit\u00e9s similaires (Volume Shadow Copy, snapshots VMware). Attention \u00e0 l\u2019impact performance : la m\u00e9thode de copy-on-write peut  ralentir les \u00e9critures  en pr\u00e9sence de snapshots nombreux (ce fut un probl\u00e8me avec Btrfs, et m\u00eame ZFS subit un l\u00e9ger impact au-del\u00e0 de centaines de snapshots). Il faut surveiller et purger les snapshots obsol\u00e8tes.</p> <p>En somme, les snapshots sont  formidables pour annuler une b\u00eatise  rapidement ou tester des mises \u00e0 jour, mais ils ne dispensent pas de faire de vraies sauvegardes sur un stockage s\u00e9par\u00e9. Utilisez-les comme premi\u00e8re ligne de d\u00e9fense (r\u00e9cup\u00e9ration quasi instantan\u00e9e) en compl\u00e9ment de vos backups.</p>"},{"location":"infrastructure/stockage/#sauvegardes-strategies-locales-vs-cloud-outils-open-source","title":"Sauvegardes : strat\u00e9gies locales vs cloud, outils open source","text":"<p>La sauvegarde est le pilier ultime d\u2019un homelab s\u00e9curis\u00e9. Elle garantit qu\u2019en cas de sinistre majeur (panne de plusieurs disques, vol ou incendie, erreur de manipulation irr\u00e9versible), vos donn\u00e9es pourront \u00eatre restaur\u00e9es. On conseille souvent la r\u00e8gle du  3-2-1  : 3 copies des donn\u00e9es, sur au moins 2 supports diff\u00e9rents, dont 1 copie  offsite  (hors site). Pour un homelab, cela peut se traduire par exemple par un NAS local + une sauvegarde sur disques externes + une r\u00e9plication chiffr\u00e9e vers le cloud.</p> <p>Sauvegardes locales (on-site) :  Elles offrent l\u2019avantage de la  vitesse  et du contr\u00f4le. Il peut s\u2019agir d\u2019un disque USB de backup, d\u2019un second NAS chez vous, ou m\u00eame d\u2019une autre machine sur le r\u00e9seau local qui re\u00e7oit des backups. L\u2019outil de base souvent utilis\u00e9 est  rsync  (ou son d\u00e9riv\u00e9  rsnapshot  pour g\u00e9rer des rotations). Par exemple, on peut programmer un rsync quotidien de son dossier de documents vers un disque externe. Pour des solutions plus \u00e9labor\u00e9es et efficaces en espace, on se tournera vers des logiciels de sauvegarde d\u00e9dupliqu\u00e9s comme  BorgBackup  ou  restic. Ces outils open source permettent de sauvegarder des donn\u00e9es (localement ou vers un serveur distant) en ne stockant qu\u2019une seule fois les blocs identiques (d\u00e9duplication), en compressant et en chiffrant les backups. Ils g\u00e8rent en plus un syst\u00e8me de r\u00e9tentions (ex: garder 7 daily, 4 weekly, 6 monthly, etc.). D\u2019apr\u00e8s les retours de la communaut\u00e9,  Restic  et  Borg  font partie des solutions les plus fiables actuellement (fiabilit\u00e9 primant sur la vitesse)  . Borg fonctionne en mode \u201cpush\u201d (on peut lancer la sauvegarde depuis la source vers un repo distant via SSH), Restic \u00e9galement et propose en plus un mode \u201cserveur REST\u201d. Ce sont deux excellents choix pour un homelab, avec une l\u00e9g\u00e8re pr\u00e9f\u00e9rence pour Restic si l\u2019on veut quelque chose de simple et efficace en ligne de commande (ou Borg pour ses performances en local/SSH)  .</p> <p>Pour les environnements virtualis\u00e9s, l\u2019outil  Proxmox Backup Server (PBS)  m\u00e9rite d\u2019\u00eatre mentionn\u00e9. Il s\u2019agit d\u2019une solution de sauvegarde  open source  d\u00e9di\u00e9e aux VMs/CTs Proxmox, qui stocke de fa\u00e7on  incr\u00e9mentale et d\u00e9dupliqu\u00e9e  les donn\u00e9es afin d\u2019\u00e9conomiser \u00e9norm\u00e9ment d\u2019espace  . PBS utilise en plus une compression ZSTD rapide et un chiffrement authentifi\u00e9 c\u00f4t\u00e9 client, ce qui le rend tr\u00e8s efficace pour sauvegarder des machines virtuelles enti\u00e8res en quelques minutes avec tr\u00e8s peu de donn\u00e9es transf\u00e9r\u00e9es apr\u00e8s la premi\u00e8re fois  . Dans un homelab, on peut par exemple avoir un petit serveur (ou VM) PBS qui r\u00e9ceptionne les sauvegardes de toutes les VM/CT Proxmox r\u00e9guli\u00e8rement. L\u2019interface web PBS permet la restauration facile de VMs compl\u00e8tes ou de fichiers individuels \u00e0 partir de ces backups.</p> <p>Sauvegardes distantes (cloud/off-site) :  Pour se prot\u00e9ger des risques locaux (incendie, d\u00e9g\u00e2t des eaux, vol), il est recommand\u00e9 d\u2019avoir au moins une copie des donn\u00e9es  hors de chez vous. Plusieurs approches s\u2019offrent \u00e0 un homelab : utiliser un service de cloud public (p.ex. stockage objet type Backblaze B2, AWS S3, Wasabi\u2026 ou m\u00eame un stockage chiffr\u00e9 sur Google Drive, etc.), ou bien synchroniser vers un autre site (par ex, un NAS chez un ami/famille). Les outils comme  restic  brillent ici car ils supportent nativement de nombreuses destinations cloud (Backblaze, AWS, Azure, rclone, etc.) et chiffrent tout automatiquement.  Duplicati  est une autre solution populaire avec une interface graphique web, permettant de sauvegarder chiffr\u00e9 vers divers clouds (c\u2019est un logiciel libre qui segmente les fichiers et g\u00e8re versions/chiffrement). On peut aussi citer  Rclone  qui, coupl\u00e9 \u00e0 un cryptage, permet de synchroniser dossiers et backups vers des clouds comme on le ferait avec un rsync (sans gestion de versions toutefois).</p> <p>Strat\u00e9gie recommand\u00e9e :  En homelab, on peut combiner un NAS local pour les sauvegardes rapides et un envoi cloud hebdomadaire/mensuel des donn\u00e9es critiques chiffr\u00e9es. Par exemple, backups quotidiens sur un disque local ou NAS via Borg, puis une fois par semaine, on envoie les nouvelles archives Borg sur un stockage cloud (Borg peut utiliser rclone pour cela). Ainsi on a une sauvegarde locale pour les urgences, et une copie externe pour le pire cas. Le versioning de plusieurs g\u00e9n\u00e9rations est important pour pouvoir r\u00e9cup\u00e9rer m\u00eame en cas de fichiers corrompus ou chiffr\u00e9s par un ransomware (on restaure une version plus ancienne propre). Enfin,  tester les restaurations  r\u00e9guli\u00e8rement est crucial \u2013 une sauvegarde non test\u00e9e ne peut pas \u00eatre consid\u00e9r\u00e9e comme fiable !</p> <p>En r\u00e9sum\u00e9,  snapshot, RAID et backup forment un trio compl\u00e9mentaire. Dans un homelab s\u00e9curis\u00e9, on configurera id\u00e9alement un RAID pour parer la panne d\u2019un disque, des snapshots fr\u00e9quents pour rattraper imm\u00e9diatement les erreurs/logiques, et des sauvegardes d\u00e9port\u00e9es pour se pr\u00e9munir contre les catastrophes majeures. Cela peut sembler complexe, mais de nombreux outils libres sont l\u00e0 pour automatiser ces t\u00e2ches et rendre votre stockage quasiment aussi robuste que dans un environnement pro \ud83d\ude09.</p>"},{"location":"infrastructure/stockage/#integration-dun-nas-et-stockage-centralise-avec-proxmox","title":"Int\u00e9gration d\u2019un NAS et stockage centralis\u00e9 avec Proxmox","text":"<p>Beaucoup de hobbyistes disposent d\u2019un  NAS  (Network Attached Storage) \u00e0 la maison pour centraliser les fichiers, les sauvegardes ou m\u00eame h\u00e9berger des m\u00e9dias. Int\u00e9grer ce NAS avec votre serveur de virtualisation (tel que  Proxmox VE) permet d\u2019offrir un stockage mutualis\u00e9 aux VMs/containers, voire de  booter  des machines depuis le NAS. Dans cette section, nous comparons bri\u00e8vement les solutions NAS populaires et expliquons comment les lier \u00e0 Proxmox.</p>"},{"location":"infrastructure/stockage/#truenas-vs-synology-vs-openmediavault-solutions-nas-comparees","title":"TrueNAS vs Synology vs OpenMediaVault : solutions NAS compar\u00e9es","text":"<p>TrueNAS (Core ou Scale)  \u2013 Solution logicielle NAS open-source d\u00e9riv\u00e9e de FreeNAS. TrueNAS Core est bas\u00e9 sur FreeBSD, TrueNAS Scale sur Debian Linux, mais les deux utilisent  ZFS  en syst\u00e8me de fichiers principal. TrueNAS offre une interface web riche et des fonctionnalit\u00e9s avanc\u00e9es (support natif de SMB, NFS, iSCSI, snapshots ZFS, r\u00e9plication, plugins/VMs sur la version Scale). C\u2019est une solution  puissante mais un peu complexe  \u00e0 ma\u00eetriser, orient\u00e9e utilisateurs techniques. Son point fort est d\u2019embarquer ZFS nativement, avec tout ce que cela implique (int\u00e9grit\u00e9, RAID-Z, etc.) \u2013 aucun autre FS n\u2019est propos\u00e9. TrueNAS convient \u00e0 ceux qui veulent tirer le maximum de leur NAS sur du mat\u00e9riel choisi par leurs soins.</p> <p>Synology DSM  \u2013 Syst\u00e8me propri\u00e9taire qu\u2019on retrouve pr\u00e9install\u00e9 sur les NAS Synology commerciaux. DSM est r\u00e9put\u00e9 pour sa  convivialit\u00e9  et son \u00e9cosyst\u00e8me logiciel (de nombreuses apps int\u00e9gr\u00e9es : gestion photos, vid\u00e9os, cloud sync, etc.). C\u00f4t\u00e9 stockage, les NAS Synology supportent selon les mod\u00e8les EXT4 ou Btrfs (sur les mod\u00e8les + r\u00e9cents, Btrfs apporte les snapshots, la d\u00e9tection de corruption et la compression). Synology propose des  RAID classiques et propri\u00e9taires (SHR)  pour faciliter l\u2019utilisation de disques de tailles vari\u00e9es. Les protocoles pris en charge incluent SMB/CIFS, NFS, AFP (pour Mac) et iSCSI (souvent sur les gammes Plus/enterprise). Le gros avantage de Synology est le  \u201ctout-en-un pr\u00eat \u00e0 l\u2019emploi\u201d  : on branche, on a une interface limpide, et c\u2019est parti. La contrepartie est la d\u00e9pendance \u00e0 l\u2019\u00e9cosyst\u00e8me Synology (mat\u00e9riel d\u00e9di\u00e9, OS ferm\u00e9). Pour un homelab, un NAS Synology convient si on privil\u00e9gie la simplicit\u00e9 et la fiabilit\u00e9 \u00e9prouv\u00e9e d\u2019une solution commerciale, quitte \u00e0 sacrifier un peu de souplesse. D\u2019ailleurs, pour un usage home, Synology DSM a globalement plus d\u2019atouts pr\u00eats \u00e0 l\u2019emploi (simplicit\u00e9, applis) qu\u2019une solution DIY comme TrueNAS  . Un NAS Synology cl\u00e9 en main est souvent  le meilleur choix \u201chome use\u201d  lorsque l\u2019objectif n\u2019est pas de bricoler le hardware ou d\u2019avoir absolument ZFS  . La pr\u00e9sence de Btrfs sur de nombreux mod\u00e8les Synology offre d\u00e9j\u00e0 un niveau de s\u00e9curit\u00e9 (snapshots locaux, auto-r\u00e9paration en RAID 1) suffisant pour beaucoup d\u2019usages domestiques.</p> <p>OpenMediaVault (OMV)  \u2013 Distribution NAS open-source bas\u00e9e sur Debian. OMV fournit une interface web l\u00e9g\u00e8re pour configurer des services de partage (SMB, FTP, NFS, Rsync, etc.), g\u00e9rer des utilisateurs et plugins. Contrairement \u00e0 TrueNAS, OMV n\u2019impose pas ZFS : on peut utiliser EXT4, XFS ou Btrfs sur les volumes (et on peut ajouter le plugin ZFS si on souhaite). OMV se veut  simple et extensible  via des plugins (par ex, plugin pour activer iSCSI, plugin pour docker, etc.). C\u2019est sans doute la solution qui se rapproche le plus d\u2019un \u201cNAS maison minimaliste\u201d \u2013 id\u00e9ale pour recycler un vieux PC ou un Raspberry Pi en NAS. Niveau fonctionnalit\u00e9s, de base c\u2019est plus  sobre  que TrueNAS ou Synology : pas de snapshots sans plugin (Btrfs ou ZFS), pas de gestion pouss\u00e9e de volumes hors RAID logiciel standard (mdadm). En somme,  OMV est fonctionnel mais minimal  en standard, ce qui implique parfois de mettre la main \u00e0 la p\u00e2te ou d\u2019installer des plugins/shell pour des besoins avanc\u00e9s  . Son point fort reste la  flexibilit\u00e9  (on a un Debian sous le capot, donc on peut installer tout ce qu\u2019on veut \u00e0 c\u00f4t\u00e9, y compris Portainer, etc.) et une empreinte relativement l\u00e9g\u00e8re.</p> <p>Comparatif rapide : TrueNAS et OMV sont comparables (solutions libres \u00e0 installer soi-m\u00eame), alors que Synology est une solution commerciale compl\u00e8te. TrueNAS mise sur ZFS et l\u2019approche enterprise, OMV sur la simplicit\u00e9 Debian. Synology, de son c\u00f4t\u00e9, offre une exp\u00e9rience utilisateur polie mais plus ferm\u00e9e. Si l\u2019on compare TrueNAS vs OMV : TrueNAS est plus  puissant mais requiert une courbe d\u2019apprentissage plus raide, OMV est plus simple mais avec moins de fonctionnalit\u00e9s pr\u00eates \u00e0 l\u2019emploi  . Entre TrueNAS et Synology : Synology l\u2019emporte en  ergonomie  et int\u00e9gration cl\u00e9-en-main (id\u00e9al si vous ne voulez pas \u201ctinkerer\u201d), TrueNAS l\u2019emporte en  contr\u00f4le et performances brutes(vous choisissez votre mat\u00e9riel, vous avez ZFS et pouvez tout tuner)  . D\u2019apr\u00e8s un comparatif,  \u201cDSM (Synology) a plus d\u2019avantages globalement pour un usage maison, alors que TrueNAS s\u2019adresse \u00e0 ceux qui veulent construire leur NAS eux-m\u00eames pour profiter sp\u00e9cifiquement des capacit\u00e9s de ZFS\u201d  . Enfin, toutes ces solutions supportent les  protocoles standard  de partage :  SMB/CIFS  (partages Windows),  NFS  (partage Unix), et souvent  iSCSI  (cible disque en r\u00e9seau) \u2013 sur OMV il faudra un plugin pour iSCSI, TrueNAS et Synology le g\u00e8rent nativement. On peut donc s\u2019attendre \u00e0 pouvoir monter les volumes du NAS sur \u00e0 peu pr\u00e8s n\u2019importe quel syst\u00e8me, y compris Proxmox.</p>"},{"location":"infrastructure/stockage/#integrer-un-nas-a-proxmox-ve-nfs-smb-iscsi","title":"Int\u00e9grer un NAS \u00e0 Proxmox VE (NFS, SMB, iSCSI)","text":"<p>Proxmox VE, la plateforme de virtualisation, permet d\u2019ajouter des stockages externes (dits  Storage) pour y loger soit des images de disques VM/CT, soit des ISO, templates ou backups. Un NAS est un candidat id\u00e9al pour cela, afin de  centraliser le stockage  accessible par plusieurs h\u00f4tes Proxmox \u00e9ventuellement.</p> <p>Les deux m\u00e9thodes les plus courantes pour attacher un NAS \u00e0 Proxmox sont  NFS  (partage de fichiers en r\u00e9seau) et  iSCSI(partage de bloc disque en r\u00e9seau). SMB/CIFS est parfois utilis\u00e9 aussi, mais Proxmox ne propose pas de backend SMB natif dans l\u2019interface (on peut toujours monter un CIFS via fstab ou autre, mais ce n\u2019est pas \u201cfirst-class citizen\u201d). On privil\u00e9giera donc NFS pour du partage de fichiers, ou iSCSI pour pr\u00e9senter un  disque r\u00e9seau.</p> <p>Exemple d\u2019ajout d\u2019un stockage NFS dans l\u2019interface Proxmox  VE.</p> <p>Dans l\u2019interface web Proxmox, il suffit d\u2019aller dans  Datacenter -&gt; Storage -&gt; Add -&gt; NFS  pour d\u00e9clarer un partage NFS export\u00e9 par le NAS. On renseigne l\u2019IP du NAS, le chemin export\u00e9 et on choisit le type de contenu (par ex.  VZDump backup files  pour y stocker les sauvegardes, ou  Disk image  pour y mettre des images de VM). Ce montage NFS sera ensuite visible comme un stockage dans Proxmox. L\u2019int\u00e9r\u00eat est qu\u2019un NFS \u00e9tant accessible depuis plusieurs n\u0153uds, on peut s\u2019en servir pour  partager des ISOs  ou permettre la  migration de VM  entre h\u00f4tes sans avoir \u00e0 d\u00e9placer leurs disques (si tous les Proxmox montent le m\u00eame stockage NFS centralis\u00e9). C\u00f4t\u00e9 NAS, on veillera aux permissions (autoriser l\u2019IP du serveur Proxmox). Un partage NFS est id\u00e9al pour stocker des backups ou des mod\u00e8les de VM, voire des disques de VM si la performance r\u00e9seau est suffisante.</p> <p>Pour des performances optimales sur des  disques VM  however, le  iSCSI  est souvent pr\u00e9f\u00e9r\u00e9. Le iSCSI permet de pr\u00e9senter un volume de bloc distant que Proxmox traite comme un disque physique. On peut ainsi, sur le NAS, cr\u00e9er une  LUN iSCSI  (volume logique) et la connecter \u00e0 Proxmox (Add -&gt; iSCSI  dans l\u2019interface). Proxmox verra alors un disque et pourra soit l\u2019utiliser tel quel pour une VM, soit \u2013 plus g\u00e9n\u00e9ralement \u2013 le formater en LVM pour y cr\u00e9er de multiples volumes VM. L\u2019approche classique est :  cible iSCSI  sur le NAS -&gt;  Initiateur iSCSI  c\u00f4t\u00e9 Proxmox qui se connecte -&gt; on cr\u00e9e un  Volume Group LVM  sur la LUN iSCSI -&gt; Proxmox peut y cr\u00e9er des volumes logiques pour chaque VM. Cette configuration offre des performances proches d\u2019un stockage local (surtout en multipath 10 Gb/s, etc.) et convient bien pour des VM exigeantes en IOPS. D\u2019apr\u00e8s les retours,  \u201ciSCSI est meilleur pour les IOPS, tandis que NFS se d\u00e9brouille bien en d\u00e9bit s\u00e9quentiel\u201d  sur des NAS TrueNAS  . Par exemple, pour h\u00e9berger des  VMs de base de donn\u00e9es  sur le NAS, iSCSI sera un bon choix.</p> <p>Une autre option, si votre NAS g\u00e8re ZFS (ex: TrueNAS), est d\u2019utiliser le plugin  ZFS over iSCSI  de Proxmox. Ce plugin va en fait orchestrer la cr\u00e9ation de volumes ZFS (zvol) sur le NAS via SSH, et les exposer en iSCSI. Ainsi, chaque disque de VM correspondra \u00e0 un  zvol ZFS  sur le NAS, b\u00e9n\u00e9ficiant des snapshots ZFS, etc.  . Proxmox supporte plusieurs cibles (par exemple istgt pour FreeBSD/TrueNAS Core, ou LIO pour Linux/TrueNAS Scale). \u00c0 noter toutefois, de base Proxmox ne supporte pas directement l\u2019API TrueNAS, il faut souvent configurer en mode \u201cManual + target LIO/istgt\u201d ou utiliser des scripts tiers  . L\u2019effort en vaut la chandelle si on veut combiner la  souplesse de Proxmox  (cr\u00e9er/supprimer VMs) et les  avantages ZFS  c\u00f4t\u00e9 NAS (coh\u00e9rence et sauvegardes c\u00f4t\u00e9 stockage). Veillez dans ce cas \u00e0 ce que votre NAS ZFS soit fiable et bien sauvegard\u00e9, car il devient un point central (une panne du NAS rendrait tous ces volumes indisponibles \u2013 penser \u00e0 la redondance du NAS lui-m\u00eame !).</p> <p>En r\u00e9sum\u00e9,  int\u00e9grer un NAS \u00e0 Proxmox  se fait bien via NFS ou iSCSI. Utilisez NFS pour les contenus file (sauvegardes, iso) ou m\u00eame des VM peu critiques (petits services, lab). Pour des charges plus intensives ou une int\u00e9gration fine, iSCSI est tout indiqu\u00e9, \u00e9ventuellement coupl\u00e9 \u00e0 LVM ou ZFS-over-iSCSI. Proxmox offre ainsi une grande flexibilit\u00e9 pour tirer parti d\u2019un NAS existant et centraliser le stockage de votre homelab.</p>"},{"location":"infrastructure/stockage/#grille-daide-au-choix-du-stockage","title":"Grille d\u2019aide au choix du stockage","text":"<p>Enfin, comment choisir physiquement ses supports de stockage dans un homelab s\u00e9curis\u00e9 ? Disques durs magn\u00e9tiques traditionnels (HDD) ou m\u00e9moire flash (SSD/NVMe) ? Ou un m\u00e9lange des deux ? La d\u00e9cision d\u00e9pend de  plusieurs crit\u00e8res  : le  budget par Go, les besoins de  performances  (IOPS, latence, d\u00e9bit), la  fiabilit\u00e9/long\u00e9vit\u00e9  attendue, et bien s\u00fbr le  type de donn\u00e9es  stock\u00e9es (base de donn\u00e9es VM tr\u00e8s active, archives media peu acc\u00e9d\u00e9es, etc.). Le tableau suivant r\u00e9sume les options principales avec leurs atouts et limites, ainsi que des sc\u00e9narios types o\u00f9 elles brillent.</p> Solution de stockage Co\u00fbt (\u2248 \u20ac/To) Performances (d\u00e9bit / IOPS) Long\u00e9vit\u00e9 &amp; endurance Sc\u00e9narios d\u2019usage typiques Disque dur (HDD) \ud83d\udfe2  Faible  \u2013 Le plus \u00e9conomique par To. Ex: ~15\u201320 \u20ac par To pour des disques de 8\u201314 To. \ud83d\udd34  Faibles IOPS, latence \u00e9lev\u00e9e. D\u00e9bit s\u00e9quentiel mod\u00e9r\u00e9 (~80\u2013160 Mo/s typique pour 7200 tpm)  . Adapt\u00e9 aux gros fichiers, moins aux acc\u00e8s al\u00e9atoires rapides. \ud83d\udfe0  Usure faible  (pas de limite d\u2019\u00e9criture comme les SSD, mais pi\u00e8ces m\u00e9caniques sensibles). Dur\u00e9e de vie variable (5\u201310 ans typiques), attention \u00e0 la casse m\u00e9canique. Stockage de masse \u00e9conomique :  archives, sauvegardes, m\u00e9dias  (films, photos) non critiques en latence. Ex: NAS de sauvegarde ou serveur multim\u00e9dia (Plex) stockant des vid\u00e9os -&gt; un HDD de grande capacit\u00e9 convient. SSD SATA / NVMe \ud83d\udd34  \u00c9lev\u00e9  \u2013 Plus cher par Go. Ex: ~100 \u20ac par To pour SSD SATA grand public, encore plus pour NVMe haute perf. \ud83d\udfe2  Tr\u00e8s bonnes performances. D\u00e9bit SATA 500+ Mo/s, NVMe &gt;3\u20135 Go/s  . Surtout, IOPS et latences excellents (100\u00d7 un HDD). Id\u00e9al pour acc\u00e8s concurrents, OS et bases de donn\u00e9es. \ud83d\udfe1  Endurance limit\u00e9e  : chaque cellule flash supporte un nombre fini d\u2019\u00e9critures (TBW donn\u00e9 par le fabricant). Dur\u00e9e de vie ~5 ans grand public, plus en gamme pro. Pas de pi\u00e8ces mobiles (plus robuste aux chocs). Donn\u00e9es n\u00e9cessitant  vitesse et r\u00e9activit\u00e9  :  disque syst\u00e8me  (VM/OS),  VMs et containers  actifs, bases de donn\u00e9es, cache d\u2019application. Ex: stockage principal d\u2019un  serveur de virtualisation  (Proxmox) -&gt; privil\u00e9gier un bon SSD/NVMe pour les disques VM afin d\u2019assurer des IOPS \u00e9lev\u00e9es aux machines. Hybride (SSD cache + HDD) \ud83d\udfe1  Moyen  \u2013 Combine un SSD (petite capacit\u00e9) et des HDD (grande capacit\u00e9). Co\u00fbt total interm\u00e9diaire (on ajoute le prix d\u2019un SSD cache au co\u00fbt des HDD). \ud83d\udfe0  Performances mixtes  : Le SSD sert de  cache  en lecture (et parfois en \u00e9criture) pour acc\u00e9l\u00e9rer l\u2019acc\u00e8s aux donn\u00e9es \u00ab chaudes \u00bb. Les lectures fr\u00e9quentes viennent du SSD (tr\u00e8s rapide), le reste sur HDD (lent). En \u00e9criture, selon config, le SSD peut absorber puis d\u00e9stager. Performance  h\u00e9t\u00e9rog\u00e8ne : excellente sur donn\u00e9es en cache, m\u00e9diocre sur acc\u00e8s direct disque. \ud83d\udfe1  Endurance variable  : le SSD cache encaisse beaucoup d\u2019I/O (risque d\u2019usure si utilisation intensive, pr\u00e9f\u00e9rer un SSD endurant). Les HDD derri\u00e8re subissent moins de sollicitations al\u00e9atoires (plut\u00f4t s\u00e9quentielles lors du vidage de cache). L\u2019ensemble reste tributaire des disques m\u00e9caniques pour la fiabilit\u00e9 g\u00e9n\u00e9rale. Compromis capaciti\u00e9/performance  : id\u00e9al quand on a beaucoup de donn\u00e9es peu souvent acc\u00e9d\u00e9es, et un sous-ensemble \u00ab chaud \u00bb fr\u00e9quemment utilis\u00e9. Ex: un  NAS Plex/Emby  avec SSD cache pour les index et les vid\u00e9os r\u00e9cemment lues, coupl\u00e9 \u00e0 des HDD pour stocker la vaste biblioth\u00e8que. Autre exemple : un  stockage Ceph  dans un homelab qui utilise des SSD NVMe comme acc\u00e9l\u00e9rateurs (DB/WAL) pour des OSD sur HDD. <p>Remarques finales :  Le choix peut \u00eatre  combinatoire  \u2013 par exemple un homelab bien \u00e9quip\u00e9 pourra utiliser un  SSD NVMe comme cache ou tier  pour acc\u00e9l\u00e9rer un pool principal en HDD (via L2ARC/ZIL de ZFS, cache SSD sur un NAS Synology, ou bcache sous Linux). On peut aussi adopter une approche par type de donn\u00e9es : les donn\u00e9es \u201cchaudes\u201d (VM en cours d\u2019ex\u00e9cution, base SQL) sur du SSD rapide, les donn\u00e9es \u201cfroides\u201d (backups, archives m\u00e9dias) sur du HDD \u00e0 haute capacit\u00e9. Pensez \u00e9galement \u00e0 la  consommation et au bruit  : un HDD consomme ~5\u201310 W et peut \u00eatre bruyant, contre ~1\u20132 W silencieux pour un SSD. Dans un homelab \u00e0 la maison, cela peut compter.</p> <p>Enfin, concernant la  long\u00e9vit\u00e9, les \u00e9tudes montrent que les SSD n\u2019ont plus grand-chose \u00e0 envier aux HDD en usage courant \u2013 leurs taux de panne convergent et d\u00e9passent rarement 1\u20132% par an. Les SSD actuels, s\u2019ils sont dimensionn\u00e9s correctement en capacit\u00e9 par rapport aux \u00e9critures (\u00e9viter de remplir \u00e0 100% et choisir un mod\u00e8le avec TBW suffisant), tiendront plusieurs ann\u00e9es sans souci. Les HDD, eux, doivent \u00eatre surveill\u00e9s (SMART) pour anticiper les secteurs d\u00e9fectueux et les pannes m\u00e9caniques. Dans tous les cas, une infrastructure de stockage s\u00e9curis\u00e9e doit accepter qu\u2019un support finira  forc\u00e9ment  par faillir : d\u2019o\u00f9 l\u2019importance du  RAID  pour la continuit\u00e9 de service, et des  sauvegardes  pour la r\u00e9cup\u00e9ration des donn\u00e9es. Avec ces bonnes pratiques et un choix judicieux de technologies adapt\u00e9 \u00e0 vos besoins (et votre budget), votre homelab pourra allier  performance, capacit\u00e9 et s\u00e9r\u00e9nit\u00e9  quant \u00e0 la protection de vos pr\u00e9cieuses donn\u00e9es.</p>"},{"location":"media/photos/","title":"Gestion de photos auto-h\u00e9berg\u00e9es : Immich et alternatives","text":"<p>Les solutions open-source de gestion de photos auto-h\u00e9berg\u00e9es se multiplient. Parmi les plus abouties on trouve  Immich,  PhotoPrism  et  LibrePhotos  (fork actif d\u2019OwnPhotos). Chacune offre des interfaces et des fonctionnalit\u00e9s diff\u00e9rentes. Immich vise une exp\u00e9rience proche de Google Photos\u202f: interface  timeline  chronologique, tris automatiques (\u00ab  souvenirs  \u00bb par ann\u00e9es), applications mobiles iOS/Android et outils de sauvegarde (CLI, apps)  . PhotoPrism, en revanche, est une PWA web au style plus \u00ab liste \u00bb, sans appli mobile native  . LibrePhotos propose elle aussi une vue chronologique et supporte le multi-utilisateur  .</p> <p>Fonctionnalit\u00e9s IA :  Immich int\u00e8gre reconnaissance faciale, d\u00e9tection d\u2019objets et recherche s\u00e9mantique avanc\u00e9es. Ses algorithmes (DBSCAN pour les visages) d\u00e9tectent les visages et les regroupent par \u00ab personnes \u00bb que l\u2019on peut nommer  . La recherche libre (smart search) utilise des mod\u00e8les CLIP dans Postgres, permettant de chercher par mots-cl\u00e9s sans m\u00e9tadonn\u00e9es explicites  . Un syst\u00e8me de g\u00e9ocodage inverse local (GeoNames) traduit les coordonn\u00e9es GPS EXIF en villes/\u00e9tats/pays pour les afficher et filtrer  . LibrePhotos offre aussi reconnaissance faciale, d\u00e9tection d\u2019objets/sc\u00e8nes et recherche s\u00e9mantique  . Photoprism promet des fonctions IA (\u00ab  AI-driven  \u00bb), mais en pratique la reconnaissance est jug\u00e9e m\u00e9diocre (\u201cvisages rarement reconnus, objets mal identifi\u00e9s\u201d  ).</p> <p>TABLEAU</p> <p>Les retours d\u2019exp\u00e9rience montrent qu\u2019Immich  est tr\u00e8s rapide (jobs de ML en parall\u00e8le, interface fluide) et b\u00e9n\u00e9ficie d\u2019un d\u00e9veloppement actif  . PhotoPrism, bien que mature, demande plus de ressources (GPU mat\u00e9riel acc\u00e9l\u00e8re les conversions)  et sa documentation est moins ax\u00e9e \u00ab utilisateurs d\u00e9butants \u00bb. LibrePhotos offre un bon compromis (multi-utilisateur, timeline), mais certaines fonctionnalit\u00e9s sont encore en d\u00e9veloppement. En r\u00e9sum\u00e9, Immich tend \u00e0 surpasser PhotoPrism c\u00f4t\u00e9 fonctionnalit\u00e9s et ergonomie  , tandis que LibrePhotos se rapproche de Google Photos (avec reconnaissance faciale et recherche avanc\u00e9e)  .</p>"},{"location":"media/photos/#installation-dimmich-en-homelab","title":"Installation d\u2019Immich en homelab","text":"<p>Pr\u00e9requis syst\u00e8me :  Immich s\u2019installe id\u00e9alement via Docker Compose (le plugin  docker compose  est requis  ). Recommandations mat\u00e9rielles : Linux (Ubuntu/Debian) de pr\u00e9f\u00e9rence, minimum 4\u202fGo de RAM (6\u202fGo recommand\u00e9) et 2 c\u0153urs CPU (4 conseill\u00e9s)  . La base de donn\u00e9es PostgreSQL doit r\u00e9sider sur un disque local rapide (SSD),  pas  sur un partage r\u00e9seau  . Pr\u00e9voyez ~1\u20133\u202fGo d\u2019espace disque pour le  DB_data, et assurez-vous d\u2019allouer au moins 2\u202fGo RAM \u00e0 PostgreSQL si vous limitez les ressources Docker  . Les fichiers photos/vid\u00e9os eux peuvent \u00eatre stock\u00e9s sur NAS/partage (DB_DATA_LOCATION  et  STORAGE_LOCATION  dans le  .env).</p> <p>Installation Docker Compose :  T\u00e9l\u00e9chargez les images Docker officielles (immich-server,  immich-machine-learning,  immich-...) et configurez  docker-compose.yml  avec les variables d\u2019environnement n\u00e9cessaires (source externe, ports, volumes). Exemple de proc\u00e9dure :</p> <ol> <li> <p>Cloner la template Docker Compose d\u2019Immich (disponible sur le site officiel).</p> </li> <li> <p>\u00c9diter le fichier  .env  : d\u00e9finir  DB_DATA_LOCATION  (volume local PostgreSQL),  UPLOAD_LOCATION(chemin de stockage des m\u00e9dias), et autres param\u00e8tres (ports, quotas).</p> </li> <li> <p>Lancer  docker compose up -d. Le service s\u2019expose par d\u00e9faut sur le port 2283.</p> </li> </ol> <p>Options de stockage :  On peut configurer Immich pour copier ou relier une \u00ab biblioth\u00e8que externe \u00bb via des  storage templates  (voir la doc d\u2019Immich  Storage Template). En g\u00e9n\u00e9ral, on cr\u00e9e un volume Docker pour PostgreSQL sur SSD local, et un volume pour les donn\u00e9es media (ce peut \u00eatre un partage NAS mont\u00e9 ou un disque d\u00e9di\u00e9). Pour les RAW, notez qu\u2019Immich g\u00e8re la plupart des formats (y compris RAW), mais certains (ex. CR2 Fuji) peuvent appara\u00eetre bris\u00e9s faute de conversion r\u00e9ussie  . Photoprism, en comparaison, g\u00e9n\u00e8re des sidecars RAW automatiquement (ce qui facilite la gestion des RAW)  , ce qu\u2019Immich ne fait pas (au contraire, il recommande plut\u00f4t d\u2019utiliser  External Library  pour r\u00e9f\u00e9rencer les originaux sans copier).</p> <p>Reverse proxy et s\u00e9curit\u00e9 :  En production, on place typiquement Immich derri\u00e8re un proxy (NGINX, Traefik ou Caddy) pour g\u00e9rer TLS et authentification.  Important  : le proxy doit transmettre les en-t\u00eates  Host,  X-Real-IP,  X-Forwarded-For  et  X-Forwarded-Proto  vers Immich  . L\u2019exemple NGINX suivant (\u00e0 adapter \u00e0 votre domaine) montre l\u2019id\u00e9e :</p> <pre><code>server {\n    listen 80;\n    server_name immich.example.com;\n    client_max_body_size 50G;\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    proxy_read_timeout 600s;\n    proxy_send_timeout 600s;\n    location / {\n        proxy_pass http://127.0.0.1:2283;\n    }\n    # Assurez-vous de proxyfier aussi /.well-known/immich pour l\u2019app mobile\n    location = /.well-known/immich {\n        proxy_pass http://127.0.0.1:2283;\n    }\n}\n</code></pre> <p>Cette configuration autorise les uploads volumineux (client_max_body_size  &gt; taille max) et augmente les timeouts (important pour les longues requ\u00eates)  . Un bloc similaire existe pour Traefik (il faut notamment ajouter les labels  traefik.enable,  traefik.http.routers, etc., et \u00e9tendre les d\u00e9lais d\u2019entr\u00e9e de 60s \u00e0 plusieurs minutes  ). Quel que soit le proxy, utiliser HTTPS/TLS est imp\u00e9ratif en frontal.</p> <p>C\u00f4t\u00e9 authentification, Immich int\u00e8gre nativement  OIDC  (OpenID Connect). On peut le connecter \u00e0 un fournisseur d\u2019identit\u00e9 externe (Auth0, Keycloak, Authentik, Authelia, Google\u2026) pour le login  . Par exemple, un utilisateur a configur\u00e9 Authentik et a pu d\u00e9sactiver compl\u00e8tement l\u2019authentification locale par mot de passe  . Ainsi, les profils avanc\u00e9s utiliseront l\u2019OIDC + 2FA de leur domaine, tandis que les novices peuvent rester sur l\u2019authent local simple. D\u2019autres bonnes pratiques : lancer Docker en utilisateur non-root, mettre \u00e0 jour r\u00e9guli\u00e8rement (Immich \u00e9volue tr\u00e8s vite  ) et sauvegarder la base de donn\u00e9es (Postgres).</p> <p>Configuration minimale :  Une fois le proxy en place, acc\u00e9der \u00e0  https://  permet de cr\u00e9er le premier compte (utilisateur  admin)  . Dans le panneau d\u2019administration, on pourra ensuite ajouter d\u2019autres utilisateurs, d\u00e9finir des quotas par utilisateur, r\u00e9gler les param\u00e8tres ML (nombre minimal de faces pour le clustering, etc.). Au minimum, pr\u00e9voyez 6\u20138\u202fGo de RAM allou\u00e9e \u00e0 Docker, 2\u202fCPU, et un disque SSD pour la base de donn\u00e9es. L\u2019appareil h\u00f4te doit accepter les montages Docker sur un syst\u00e8me de fichiers Unix (ext4, ZFS, APFS\u2026 pas NTFS/exFAT  )."},{"location":"media/photos/#ia-dans-immich-reconnaissance-detection-et-recherche","title":"IA dans Immich : reconnaissance, d\u00e9tection et recherche","text":"<p>Immich regroupe plusieurs fonctions IA avanc\u00e9es :</p> <ul> <li> <p>Reconnaissance faciale :  Immich d\u00e9tecte automatiquement les visages dans les photos/vid\u00e9os et les regroupe par \u00ab personnes \u00bb  . Chaque personne peut se voir attribuer un nom, et on peut rechercher une personne pour afficher tous les clich\u00e9s la contenant. L\u2019algorithme utilise la d\u00e9tection et le clustering (DBSCAN) en t\u00e2che de fond  . En pratique, la reconnaissance faciale d\u2019Immich est jug\u00e9e tr\u00e8s bonne, proche des standards Google/Apple  .</p> </li> <li> <p>D\u00e9tection d\u2019objets et recherche s\u00e9mantique :  Immich analyse chaque image avec des mod\u00e8les ML (ex. CLIP) pour g\u00e9n\u00e9rer des descriptions contextuelles  . Il en r\u00e9sulte une  recherche intelligente  (\u00ab Smart Search \u00bb) o\u00f9 l\u2019on peut saisir n\u2019importe quel mot (par ex. \u00ab plage \u00bb, \u00ab chat \u00bb) et obtenir les images correspondantes, m\u00eame sans tag manuel. Le syst\u00e8me de filtres de recherche avanc\u00e9e permet en outre de combiner : personnes, localisation, appareil photo, date, type (image/vid\u00e9o), album, etc.  . Cette recherche par  Texte libre  (CLIP) est tr\u00e8s puissante, mais consomme de la m\u00e9moire. On peut choisir des mod\u00e8les plus petits pour gagner en rapidit\u00e9 ou en m\u00e9moire aux d\u00e9pens de pr\u00e9cision  .</p> </li> <li> <p>G\u00e9olocalisation (reverse-geocoding) :  Lors de l\u2019import, si une image contient des donn\u00e9es GPS EXIF, Immich effectue un g\u00e9ocodage inverse local (base GeoNames embarqu\u00e9e) pour d\u00e9terminer la ville, l\u2019\u00e9tat et le pays  . Ces informations sont affich\u00e9es dans les d\u00e9tails de l\u2019image et utilisables pour filtrer/rechercher par lieu. L\u2019avantage est qu\u2019aucune API externe n\u2019est requise (tout est en local).</p> </li> <li> <p>Acc\u00e9l\u00e9ration mat\u00e9rielle :  Le traitement IA (d\u00e9tection des visages, objets, embeddings CLIP) est intensif. Immich peut tirer parti d\u2019un GPU pour acc\u00e9l\u00e9rer ces t\u00e2ches (CUDA pour NVIDIA, ROCm pour AMD, ARM NN, OpenVINO\u2026)  . L\u2019acc\u00e9l\u00e9ration GPU est exp\u00e9rimentale mais peut consid\u00e9rablement r\u00e9duire la charge CPU et la dur\u00e9e des jobs ML. Sur des serveurs puissants, on activera donc le support GPU dans  docker-compose  pour la machine learning. Sans GPU, les t\u00e2ches IA tourneront sur CPU, ce qui reste acceptable mais plus lent.</p> </li> </ul> <p>Chaque fonction IA consomme des ressources (RAM, CPU/GPU) lors de l\u2019indexation initiale. En usage continu, Immich cr\u00e9e des jobs asynchrones (\u00ab  worker  \u00bb) pour traiter les nouvelles images en arri\u00e8re-plan, ce qui rend l\u2019interface r\u00e9active pour l\u2019utilisateur  . En r\u00e9sum\u00e9, Immich propose reconnaissance faciale, d\u00e9tection de sc\u00e8nes/objets, recherche CLIP et g\u00e9olocalisation embarqu\u00e9e, configurables dans le panneau d\u2019administration, mais ces options peuvent rallonger le temps de traitement selon le hardware. Le tableau suivant r\u00e9capitule l\u2019impact estim\u00e9 :</p> <p>TABLEAU</p>"},{"location":"media/photos/#cas-dusage-concrets","title":"Cas d\u2019usage concrets","text":"<ul> <li> <p>Sauvegarde mobile automatis\u00e9e :  Les applications mobiles Immich (Android/iOS) supportent la synchronisation automatique des photos/vid\u00e9os d\u00e8s qu\u2019elles sont prises  . \u00c0 la cr\u00e9ation d\u2019un album  Backup  sur le t\u00e9l\u00e9phone, toutes les nouvelles images sont envoy\u00e9es en t\u00e2che de fond vers le serveur. (\u00c0 noter : PhotoPrism, quant \u00e0 lui, n\u2019a pas d\u2019app officielle \u2013 on utilisait par le pass\u00e9 des apps comme PhotoSync en WebDAV pour ses sauvegardes  .)</p> </li> <li> <p>Archivage familial :  Immich convient pour stocker la phototh\u00e8que d\u2019une famille. Chaque membre peut avoir son compte (et quota de stockage)  . On cr\u00e9e des albums partag\u00e9s (ex.  Vacances 2023), on met en favoris, on utilise le timeline pour replonger dans les archives par ann\u00e9e. Les photos de famille identifi\u00e9es par la reconnaissance faciale facilitent la recherche par personne. Immich ne supprime pas automatiquement les doublons, mais l\u2019outil CLI fournit v\u00e9rifie les  GUID  avant upload pour \u00e9viter les copies (\u00e9vite les envois r\u00e9p\u00e9t\u00e9s)  .</p> </li> <li> <p>Acc\u00e8s multi-utilisateurs et permissions :  L\u2019administrateur peut cr\u00e9er plusieurs comptes, d\u00e9finir un quota et un  storage label  par utilisateur (pour isoler leurs dossiers)  . Les utilisateurs peuvent partager des albums entre eux. Par exemple, on peut rendre un album accessible \u00e0 tous les membres de la famille. Il est aussi possible de g\u00e9n\u00e9rer un lien public sur un album/photo (fonction  public link) pour envoyer \u00e0 un ami, comme sur Google Photos  .</p> </li> <li> <p>Tri par album/date/personne :  Immich organise par date (gr\u00e2ce \u00e0 la timeline) et permet de cr\u00e9er des albums manuellement ou automatiquement (\u00ab  \u00e9v\u00e9nements  \u00bb, p. ex. \u00ab Jeudi \u00e0 Berlin \u00bb)  . La recherche par date et par personne (gr\u00e2ce aux visages nomm\u00e9s) est tr\u00e8s simple. On peut aussi filtrer par lieu (ville/pays), par appareil (mod\u00e8le d\u2019appareil), ou encore par m\u00e9dia (images vs vid\u00e9os). Les tags hi\u00e9rarchiques sont pris en charge si on veut annoter manuellement  .</p> </li> <li> <p>D\u00e9duplication :  Immich ne fusionne pas automatiquement les images similaires en autant, mais son CLI permet d\u2019\u00e9viter l\u2019import de fichiers d\u00e9j\u00e0 pr\u00e9sents (en comparant leur identifiant unique)  . Les biblioth\u00e8ques n\u2019auront donc pas de doubles stricts issus du smartphone, \u00e0 moins d\u2019avoir des transferts ind\u00e9pendants. PhotoPrism, pour sa part, g\u00e9rait les rafales RAW+JPEG en  photo stacking  automatique (inutile d\u2019avoir deux copies)  . Immich ne le fait pas, donc on veillera \u00e0 ne pas dupliquer manuellement l\u2019envoi des m\u00eames clich\u00e9s.</p> </li> </ul>"},{"location":"media/photos/#recommandations-selon-le-profil-utilisateur","title":"Recommandations selon le profil utilisateur","text":"<ul> <li> <p>D\u00e9butant :  Immich est fortement conseill\u00e9. Son installation Docker Compose est simple et sa web\u2011UI est intuitive. Les apps mobiles et la sauvegarde automatique facilitent la prise en main  . LibrePhotos est aussi convivial (vue chronologique famili\u00e8re), mais ne dispose pour l\u2019instant que d\u2019une app Android (pas encore d\u2019iOS)  . Ces deux solutions requi\u00e8rent peu de configuration initiale. Photoprism est plus complexe \u00e0 configurer et son absence d\u2019app native le r\u00e9serve \u00e0 des utilisateurs plus exp\u00e9riment\u00e9s.</p> </li> <li> <p>Interm\u00e9diaire :  Vous pouvez explorer plusieurs options selon vos besoins. Immich reste un excellent choix (IA avanc\u00e9e, OIDC int\u00e9gr\u00e9, dev actif)  . LibrePhotos offre de bonnes fonctions et gestion multi-utilisateur  . Photoprism peut \u00eatre envisag\u00e9 si l\u2019on ma\u00eetrise bien Docker (et id\u00e9alement un GPU pour l\u2019acc\u00e9l\u00e9ration), car il offre des r\u00e9glages tr\u00e8s granulaires et un solide support WebDAV  . Pensez aussi \u00e0 la s\u00e9curit\u00e9 (proxy TLS, firewall) et \u00e0 l\u2019authentification OIDC si vous avez un annuaire.</p> </li> <li> <p>Avanc\u00e9 :  Vous disposerez des ressources et comp\u00e9tences pour pousser les limites. Immich, avec l\u2019acc\u00e9l\u00e9ration GPU et ses param\u00e8tres ajustables, deviendra tr\u00e8s performant pour une grosse collection (ses jobs parall\u00e8les restent r\u00e9actifs  ). Vous pourrez d\u00e9ployer Immich en multi-conteneurs, utiliser les extensions (external libraries, backups automatis\u00e9s via CLI) et tirer profit des nouvelles versions fr\u00e9quentes  . Certains utilisateurs avanc\u00e9s font tourner Photoprism en parall\u00e8le pour comparer ou comme outil d\u2019archivage historique (Photoprism est stable mais moins \u00e9volutif, son dev est plus lent  ). Enfin, si vous \u00eates adepte de la personnalisation extr\u00eame, vous pouvez \u00e9galement int\u00e9grer Immich \u00e0 un \u00e9cosyst\u00e8me plus large (Nextcloud, Strapi, etc.), ou exp\u00e9rimenter d\u2019autres projets open source (Piwigo, Photostructure, etc.) selon vos besoins sp\u00e9cifiques.</p> </li> </ul> <p>En synth\u00e8se, pour un usage homelab,  Immich  se distingue par son \u00e9quilibre entre facilit\u00e9 d\u2019usage et fonctionnalit\u00e9s avanc\u00e9es (mobile, IA, s\u00e9curit\u00e9)  . Les profils d\u00e9butants et interm\u00e9diaires y trouveront un outil cl\u00e9 en main, tandis que les utilisateurs avanc\u00e9s appr\u00e9cieront sa capacit\u00e9 d\u2019\u00e9volution (GPU, OIDC, API)  .  LibrePhotos  est une bonne alternative \u00ab Google-like \u00bb multi\u2011utilisateur, et  PhotoPrism  reste pertinent si l\u2019on recherche une solution \u00e9prouv\u00e9e, bien que gourmande en ressources  . Chacun pourra donc choisir selon ses priorit\u00e9s : simplicit\u00e9 d\u2019interface et d\u2019installation (Immich), ou contr\u00f4le granularit\u00e9 et ind\u00e9pendance (Photoprism), ou mixte (LibrePhotos).</p>"},{"location":"media/streaming/","title":"Comparatif Plex vs Jellyfin vs Emby pour un Homelab S\u00e9curis\u00e9","text":"<p>Dans un homelab auto-h\u00e9berg\u00e9, Plex, Jellyfin et Emby sont les trois serveurs multim\u00e9dia majeurs. Chacun offre un ensemble de fonctionnalit\u00e9s similaires (gestion de collections vid\u00e9o/musique/photos, transcodage, clients multiples), mais diff\u00e8re sur des points cl\u00e9s (licence, performance, flexibilit\u00e9, co\u00fbt). Nous comparons ci-dessous ces solutions selon plusieurs crit\u00e8res :  transcodage et performances,  clients multi-appareils,  gestion multi-utilisateurs et contr\u00f4le parental,  interface utilisateur,  mod\u00e8le \u00e9conomique,  int\u00e9gration avec Overseerr/Sonarr/Radarr,  aspects l\u00e9gaux, ainsi que  installation/optimisation techniques.</p>"},{"location":"media/streaming/#transcodage-et-performances","title":"Transcodage et performances","text":"<p>Le transcodage (conversion \u00e0 la vol\u00e9e) est tr\u00e8s exigeant en ressources.  Plex  utilise principalement  Intel QuickSync(pr\u00e9sent sur les CPU Intel r\u00e9cents) pour l\u2019encodage/d\u00e9codage mat\u00e9riel  . L\u2019acc\u00e9l\u00e9ration mat\u00e9rielle dans Plex n\u00e9cessite un abonnement Plex Pass (car activ\u00e9e uniquement sur les versions r\u00e9centes du serveur)  . Plex peut th\u00e9oriquement utiliser une carte NVIDIA/AMD d\u00e9di\u00e9e, mais le support est \u00ab\u202fas is\u202f\u00bb et peu test\u00e9  .  Emby  prend en charge un large \u00e9ventail d\u2019acc\u00e9l\u00e9ration : Intel QuickSync, NVIDIA NVENC/NVDEC, AMD AMF (Windows) et VA-API (Linux)  .  Jellyfin, \u00e9tant un fork open-source d\u2019Emby, supporte aussi QuickSync, NVENC et VA-API. Sa documentation recommande fortement d\u2019utiliser un GPU (Intel Arc ou NVIDIA RTX) pour le transcodage, car le CPU seul peine (un Ryzen 9 5950X ne peut m\u00eame pas transcoder un flux 4K sans GPU)  . De fait, la qualit\u00e9 d\u2019encodage mat\u00e9riel varie selon le mat\u00e9riel : Jellyfin note  Apple \u2265 Intel \u2265 Nvidia &gt;&gt;&gt; AMD  (ex. Apple M1/2 excellent, AMD d\u00e9t\u00e9riore plus la qualit\u00e9)  . En r\u00e9sum\u00e9 :</p> <ul> <li> <p>CPU  : tous peuvent transcoder par CPU seul, mais c\u2019est tr\u00e8s lent et lourd. Jellyfin d\u00e9conseille les syst\u00e8mes  _sans_GPU (les CPUs, m\u00eame hauts de gamme, sont insuffisants)  .</p> </li> <li> <p>Intel QuickSync  : support\u00e9 par Plex (n\u00e9cessite Plex Pass)  , Emby  et Jellyfin (fortement recommand\u00e9)  .</p> </li> <li> <p>NVIDIA NVENC/NVDEC  : support\u00e9 nativement par Emby  et Jellyfin (avec quelques patchs pour lever la limite de flux) ; Plex n\u2019a pas de support officiel mature (les GPU NVIDIA sous Plex sont \u00ab\u202fpas officiellement test\u00e9s\u202f\u00bb  ).</p> </li> <li> <p>AMD (VCE/AMF)  : support partiel dans Emby (Windows)  ; Jellyfin le supporte via VA-API mais la qualit\u00e9 de l\u2019encodeur AMD est tr\u00e8s inf\u00e9rieure  . Plex ne le recommande pas.</p> </li> </ul> <p>Globalement, Plex privil\u00e9gie QuickSync et d\u00e9conseille AMD/NVIDIA, Emby est plus polyvalent (mais sans abonnement, pas de transcodage mat\u00e9riel), et Jellyfin fonctionne mieux sur Intel/NVIDIA qu\u2019AMD  . Les sorties encod\u00e9es en mat\u00e9riel peuvent \u00eatre moins nettes qu\u2019en logiciel (blocages ou flou sous faible d\u00e9bit)  . La configuration r\u00e9seau et stockage est aussi critique : Jellyfin recommande un  SSD rapide  (~100\u202fGo) pour le syst\u00e8me et le cache de transcodage et une connexion  Ethernet Gigabit  minimum (le Wi-Fi ou le 100\u202fMb/s sont insuffisants)  . Pour un acc\u00e8s distant fluide, pr\u00e9voir &gt;20\u202fMb/s d\u2019upload  . L\u2019acc\u00e9l\u00e9ration mat\u00e9rielle (Intel/NVENC) est essentielle pour du 1080p/4K multiple.</p>"},{"location":"media/streaming/#compatibilite-multi-appareils","title":"Compatibilit\u00e9 multi-appareils","text":"<p>Tous trois offrent des clients web et de nombreuses apps natives, mais leur disponibilit\u00e9 et co\u00fbt diff\u00e8rent :</p> <ul> <li> <p>Plex  dispose d\u2019applications officielles sur pratiquement toutes les plateformes grand public (web, iOS, Android, Apple TV, Roku, Amazon Fire TV, Android TV, consoles Xbox/PlayStation, Smart TV Samsung/LG, etc.). Ces apps sont globalement  gratuites, m\u00eame si certaines fonctionnalit\u00e9s avanc\u00e9es (offline, synchronisation) requi\u00e8rent Plex Pass. La compatibilit\u00e9 est tr\u00e8s \u00e9tendue et bien support\u00e9e.</p> </li> <li> <p>Emby  propose aussi des clients sur mobiles (iOS/Android), PC (Windows, macOS, Linux), TV (Roku, Android TV, Samsung Tizen, LG WebOS), consoles, etc. Beaucoup de ces apps sont gratuites \u00e0 installer, mais certaines fonctions ou la vid\u00e9o compl\u00e8te peuvent \u00eatre bloqu\u00e9es derri\u00e8re l\u2019achat de l\u2019application ou Emby Premiere (par exemple, l\u2019app mobile gratuite ne joue qu\u2019une minute de chaque vid\u00e9o sans la licence Premiere  ). Certains clients officiels Emby sur TV ou mobile co\u00fbtent un paiement unique.</p> </li> <li> <p>Jellyfin  a des clients first-party (web, Android, iOS, Windows, etc.) enti\u00e8rement gratuits, ainsi que des app tiers (Kodi, Infuse, etc.). La port\u00e9e est grande (Android, Fire TV, Apple TV via TestFlight, Roku, Samsung TV via sideload, etc.), mais certains clients officiels manquent encore ou n\u00e9cessitent un patch non officiel. En pratique, Jellyfin est \u00ab\u202flargely free\u202f\u00bb mais l\u2019installation sur certains appareils demande parfois des solutions tierces  .</p> </li> </ul> <p>D\u2019apr\u00e8s un comparatif,  Plex  est \u00ab\u202fle plus simple et convivial\u202f\u00bb, accessible \u00ab\u202fpresque partout\u202f\u00bb avec peu d\u2019applications payantes  .  Emby  offre un bon compromis (surtout si on paie l\u2019app ou Premiere), et  Jellyfin  reste gratuit mais avec parfois plus de bricolage client n\u00e9cessaire  . En r\u00e9sum\u00e9 : Plex gagne en disponibilit\u00e9 native, Emby suit de pr\u00e8s (souvent via ach\u00e8vement d\u2019app), Jellyfin couvre l\u2019essentiel mais d\u00e9pend de la communaut\u00e9 pour certains clients.</p>"},{"location":"media/streaming/#multi-utilisateurs-controle-parental-et-metadonnees","title":"Multi-utilisateurs, contr\u00f4le parental et m\u00e9tadonn\u00e9es","text":"<ul> <li> <p>Plex  : prend en charge plusieurs  profils utilisateur  via \u00ab\u202fPlex Home\u202f\u00bb. Un serveur peut partager ses biblioth\u00e8ques jusqu\u2019\u00e0 ~100 comptes utilisateurs (amis/famille)  . En revanche, pour cr\u00e9er des  comptes g\u00e9r\u00e9s  dans le Home (permettant une alternance sans re-login) et appliquer des restrictions, il faut un Plex Pass  . Plex propose des profils pr\u00e9-d\u00e9finis (Jeune/enfant, Adolescent) qui limitent l\u2019acc\u00e8s selon les classifications de contenu  . Les parents peuvent aussi d\u00e9sactiver les sources de contenus en ligne (films/s\u00e9ries Plex) pour ces comptes. Des restrictions plus fines (boutons manuels, filtres personnalis\u00e9s) demandent \u00e9galement Plex Pass.</p> </li> <li> <p>Emby  : autorise un nombre illimit\u00e9 de profils d\u2019utilisateurs. Chaque profil peut recevoir des  contr\u00f4les parentauxsophistiqu\u00e9s. On peut fixer un classement maximum de film/s\u00e9rie, bloquer ou autoriser des contenus via des  tags, et m\u00eame cr\u00e9er un planning d\u2019acc\u00e8s (ex. interdiction en dehors d\u2019un horaire)  . Ces options (classements, tags, planning) sont disponibles en gratuit, bien qu\u2019Emby Premiere active des fonctions suppl\u00e9mentaires (synchro mobile, t\u00e9l\u00e9chargements offline, etc.).</p> </li> <li> <p>Jellyfin  : g\u00e8re aussi plusieurs utilisateurs et biblioth\u00e8ques distinctes, mais ne fournit pas (encore) de syst\u00e8me de contr\u00f4le parental pr\u00e9d\u00e9fini. Pour restreindre du contenu, on utilise le tagging manuel et les  biblioth\u00e8ques s\u00e9par\u00e9es. Par exemple, on peut marquer les films \u00ab\u202fadultes\u202f\u00bb avec un tag et interdire ce tag au profil enfant, ou bien cr\u00e9er deux biblioth\u00e8ques (\u00ab\u202fFamilial\u202f\u00bb vs \u00ab\u202fAdulte\u202f\u00bb) et ne donner acc\u00e8s qu\u2019\u00e0 la biblioth\u00e8que correspondante  . C\u2019est une approche manuelle (assez puissante, mais fastidieuse \u00e0 param\u00e9trer). Notez que Jellyfin \u00e9tant open-source, il repose sur des sources de m\u00e9tadonn\u00e9es ouvertes (TheMovieDB, TheTVDB, etc.), tout comme Emby/Plex. Les trois extraient affiche, synopsis, cast, etc. automatiquement (via TMDb/IMDb), et permettent la modification manuelle des m\u00e9tadonn\u00e9es dans l\u2019interface.</p> </li> </ul> <p>Tableau \u2013 Multi-utilisateurs et contr\u00f4le parental :</p> Fonctionnalit\u00e9 Plex Emby Jellyfin Profils (utilisateurs) Jusqu\u2019\u00e0 100 comptes partag\u00e9s, 15 dans \u00ab Home \u00bb (avec Plex Pass) Illimit\u00e9 Illimit\u00e9 Comptes g\u00e9r\u00e9s (\u00ab\u202fHome\u202f\u00bb) Avec Plex Pass (admin cr\u00e9e les profils) Natif, param\u00e9trage individuel Natif (via utilisateurs s\u00e9par\u00e9s) Contr\u00f4le parental (classement) Classes pr\u00e9d\u00e9finies (Jeune, Ados\u2026)  ; avanc\u00e9 avec Plex Pass Classement par note max, tags, planning Tagging manuellement + biblioth\u00e8ques s\u00e9par\u00e9es Restrictions fines Plex Pass requis pour filtres avanc\u00e9s Sans limite (tags, horaires) Via tags/biblioth\u00e8ques (pas d\u2019interface d\u00e9di\u00e9e) M\u00e9tadonn\u00e9es &amp; organisation Puissant, ax\u00e9 Netflix/Kodi (Pinterest, critiques\u2026); \u00e9dition possible Compl\u00e8te (avec plug-ins) Compl\u00e8te (open-source, modifiable)"},{"location":"media/streaming/#interface-utilisateur-et-experience","title":"Interface utilisateur et exp\u00e9rience","text":"<p>Plex  est souvent per\u00e7u comme le plus \u00ab\u202fpolish\u00e9\u202f\u00bb et le plus simple d\u2019emploi, avec une interface \u00e9pur\u00e9e et comparable aux services de streaming commerciaux  . La navigation est intuitive (grandes images de couvertures, menus clairs) et les apps officielles offrent une exp\u00e9rience homog\u00e8ne.  Emby  propose une interface moderne (bas\u00e9e sur Bootstrap) assez claire, un bon compromis entre Plex et Jellyfin. Les possibilit\u00e9s de personnalisation GUI y sont un peu plus nombreuses (th\u00e8mes, plugins).  Jellyfin  a une interface fonctionnelle et de plus en plus compl\u00e8te (surtout en version 10+), mais certains utilisateurs trouvent l\u2019UX un peu moins intuitive (par exemple, la nouvelle navigation au scroll horizontal a surpris certains)  . En pratique, Plex s\u00e9duira ceux qui veulent une exp\u00e9rience \u00ab\u202fNetflix maison\u202f\u00bb cl\u00e9-en-main, tandis qu\u2019Emby et Jellyfin attireront les amateurs pr\u00eates \u00e0 ajuster les param\u00e8tres pour plus de flexibilit\u00e9  .</p>"},{"location":"media/streaming/#modele-economique-licences-open-source-freemium","title":"Mod\u00e8le \u00e9conomique (licences, Open Source, Freemium)","text":"<ul> <li> <p>Plex  est un logiciel  propri\u00e9taire. Le serveur de base et la plupart des apps sont gratuits, mais de nombreuses fonctions avanc\u00e9es requi\u00e8rent un abonnement  Plex Pass  (mensuel ou annuel, ~5\u20136\u202f\u20ac par mois). Le  hardware transcoding  en est un : il est d\u00e9sactiv\u00e9 sans Plex Pass  . La gestion des comptes \u00ab\u202fHome\u202f\u00bb avanc\u00e9e (profils multiples sans re-login) n\u00e9cessite aussi Plex Pass  .</p> </li> <li> <p>Emby  est en mode  freemium. Le serveur et la quasi-totalit\u00e9 des fonctionnalit\u00e9s de base sont gratuites. Emby propose une cl\u00e9 \u00ab\u202fPremiere\u202f\u00bb (\u00e0 tarif raisonnable unique) pour d\u00e9bloquer certaines fonctions : transcodage mat\u00e9riel (GPU), synchronisation mobile, extensions de plugins, etc. Sans cette cl\u00e9, le transcodage est strictement logiciel (ou inexistant sur Android TV)  . De plus, certaines apps mobiles ou de bureau ne permettent que la lecture limit\u00e9e d\u2019une minute sans Emby Premiere  .</p> </li> <li> <p>Jellyfin  est  100% libre et gratuit  (licence GNU GPL)  . Serveur et clients officiels ne co\u00fbtent rien, sans aucune restriction payante  . Il n\u2019y a ni abonnement ni frais cach\u00e9s. Tout est open-source, et l\u2019\u00e9quipe refuse la publicit\u00e9 ou la collecte de donn\u00e9es.</p> </li> </ul> <p>Tableau \u2013 Mod\u00e8le \u00e9conomique :</p> Crit\u00e8re Plex Emby Jellyfin Licence Propri\u00e9taire Propri\u00e9taire (partiellement) Open-source (GPL) H\u00e9bergement SaaS + serveur local Serveur local uniquement Serveur local uniquement Co\u00fbt de base Gratuit Gratuit Gratuit Abonnement Plex Pass  (facultatif mais requis pour HW transcoding et Home avanc\u00e9) Emby Premiere  (un paiement unique pour acc\u00e9l\u00e9ration mat\u00e9rielle, etc.) Aucun (pas d\u2019abonnement) Clients payants Non (applications gratuites sur stores) Certaines apps payantes (ex. mobile, TV) Non (clients officiels gratuits) Support Communaut\u00e9 et support Plex Communaut\u00e9 et support Emby Communaut\u00e9 open-source (forum, GitHub)"},{"location":"media/streaming/#integration-overseerr-sonarr-radarr","title":"Int\u00e9gration Overseerr, Sonarr, Radarr","text":"<p>Dans un homelab automatis\u00e9,  Sonarr  (s\u00e9ries TV) et  Radarr  (films) g\u00e8rent le t\u00e9l\u00e9chargement. Ils placent les fichiers dans les dossiers surveill\u00e9s par le serveur media, qui peut ensuite les rafra\u00eechir. Les trois serveurs se connectent nativement avec Sonarr/Radarr (via API ou SMB mounts) pour mettre \u00e0 jour la biblioth\u00e8que apr\u00e8s chaque ajout. Pour la gestion des requ\u00eates utilisateurs,  Overseerr  est tr\u00e8s populaire : c\u2019est un front-end de demandes con\u00e7u pour Plex (et Emby) qui s\u2019interface avec Sonarr/Radarr  . Une variante,  Jellyseerr  (fork d\u2019Overseerr), apporte le support  Jellyfin  (ainsi qu\u2019Emby et Plex) tout en conservant l\u2019int\u00e9gration Sonarr/Radarr  . En pratique, on d\u00e9ploie un conteneur Overseerr/Jellyseerr reli\u00e9 aux serveurs Plex/Jellyfin/Emby pour permettre aux utilisateurs de sugg\u00e9rer des films/s\u00e9ries ; les requ\u00eates sont transf\u00e9r\u00e9es vers Sonarr/Radarr pour l\u2019automatisation du t\u00e9l\u00e9chargement  .</p>"},{"location":"media/streaming/#aspects-ethiques-et-legaux","title":"Aspects \u00e9thiques et l\u00e9gaux","text":"<p>Un homelab media presuppose que l\u2019on partage  son propre contenu. Sur le plan l\u00e9gal, si le contenu est acquis l\u00e9galement (DVD originaux, fichiers achet\u00e9s), la \u00ab\u202fcopie priv\u00e9e\u202f\u00bb est souvent tol\u00e9r\u00e9e. Aux \u00c9tats-Unis, par exemple, diffuser \u00e0 ses amis un stream priv\u00e9 est consid\u00e9r\u00e9 comme analogue au partage des fichiers eux-m\u00eames  : l\u2019acte lui-m\u00eame n\u2019est pas ill\u00e9gal, c\u2019est le contenu partag\u00e9 qui doit \u00eatre l\u00e9gal. En France, la loi sur la copie priv\u00e9e (article L122-5 CPI) autorise les copies personnelles de DVD/CD poss\u00e9d\u00e9s,  sans contournement de DRM,  \u00e0 condition de ne pas les diffuser  . Autrement dit, la copie priv\u00e9e doit \u00eatre strictement individuelle (pas de pr\u00eat ni de partage). Ainsi, cr\u00e9er un flux Plex/Jellyfin pour soi ou sa famille proche rel\u00e8ve de l\u2019usage priv\u00e9 et entre dans la tol\u00e9rance du droit (bien que la loi fran\u00e7aise pr\u00e9cise que les copies ne doivent pas \u00eatre \u00ab\u202fpr\u00eat\u00e9es ou partag\u00e9es\u202f\u00bb  ). En revanche, ouvrir le serveur \u00e0 des tiers ou publier le contenu sur Internet \u00ab\u202fcomme un service de streaming\u202f\u00bb serait hors cadre priv\u00e9 et susceptible d\u2019infraction.  Conseil pratique :  limiter l\u2019acc\u00e8s (via VPN, acc\u00e8s local seulement, ou authentification stricte) et n\u2019h\u00e9berger que du contenu dont on d\u00e9tient l\u00e9galement les droits. Le simple fait d\u2019utiliser ces logiciels n\u2019est pas ill\u00e9gal, mais le respect du droit d\u2019auteur (pas de m\u00e9dias pirat\u00e9s en libre acc\u00e8s) est imp\u00e9ratif  .</p>"},{"location":"media/streaming/#installation-technique-docker-lxc-vm-reverse-proxy","title":"Installation technique : Docker, LXC, VM, reverse-proxy","text":"<p>Ces serveurs peuvent \u00eatre install\u00e9s de plusieurs mani\u00e8res. Les deux modes les plus courants en homelab sont :</p> <ul> <li> <p>Docker/Container  : tous disposent d\u2019images Docker officielles ou communautaires (p.ex.  plexinc/pms-docker,  jellyfin/jellyfin,  emby/embyserver). Un  docker-compose.yml  permet de d\u00e9clarer les volumes de donn\u00e9es (m\u00e9dias, configs, cache transcode) et ports (ex. 32400 pour Plex, 8096/8920 pour Jellyfin, 8096 pour Emby). L\u2019avantage est la portabilit\u00e9 et l\u2019isolation. Les conteneurs doivent avoir acc\u00e8s aux dossiers m\u00e9dias (via bind mounts ou un NAS) et, pour le transcodage, souvent au GPU du syst\u00e8me (via runtime NVIDIA ou habilitation QuickSync sur l\u2019h\u00f4te Linux).</p> </li> <li> <p>Machine virtuelle ou LXC  : on peut installer Plex/Jellyfin/Emby sur une VM (Debian/Ubuntu) ou un conteneur LXC (ex. Proxmox). LXC + Docker est aussi courant : on cr\u00e9e un LXC (Debian minimal), on active  iocage devicespour QuickSync, puis on lance Docker \u00e0 l\u2019int\u00e9rieur. Cela offre un peu plus de d\u00e9couplage et de s\u00e9curit\u00e9.</p> </li> </ul> <p>Reverse proxy :  en front-end, on place g\u00e9n\u00e9ralement un reverse proxy HTTP(s) (Nginx, Traefik, Caddy) pour g\u00e9rer les domaines et TLS. Par exemple,  plex.exemple.com,  jellyfin.exemple.com  pointent vers les ports internes respectifs (ex. 32400, 8096). Le proxy fournit un certificat SSL Let\u2019s Encrypt et peut exiger une authentification (HTTP Auth) ou limiter les IPs pour renforcer la s\u00e9curit\u00e9. Cela \u00e9vite d\u2019exposer directement les ports Plex/Jellyfin au WAN et permet de centraliser l\u2019acc\u00e8s web en HTTPS. En interne, on peut aussi limiter l\u2019acc\u00e8s direct (p.ex. en ne mappant pas le port 1900/32469 en UDP pour Plex, etc.), tout en autorisant la synchro via clients officiellement. Les guides d\u2019installation officielles (Jellyfin Docs, guides Plex/Emby) d\u00e9taillent ces approches. Par exemple, Jellyfin recommande un acc\u00e8s d\u00e9di\u00e9 (ports 8096/8920) et sugg\u00e8re l\u2019utilisation de Nginx/Caddy pour le SSL.</p>"},{"location":"media/streaming/#optimisation-des-performances","title":"Optimisation des performances","text":"<p>Pour un serveur r\u00e9actif :</p> <ul> <li> <p>Stockage rapide  : utilisez un SSD (ou NVMe) pour le syst\u00e8me d\u2019exploitation, le cache de transcodage et la base de donn\u00e9es de m\u00e9tadonn\u00e9es  . Jellyfin conseille 100\u202fGo de SSD pour le cache et OS, afin d\u2019\u00e9viter de saturer les disques lents  . Les m\u00e9dias (vid\u00e9os) peuvent rester sur des disques plus grands, mais si plusieurs flux 4K passent simultan\u00e9ment, un RAID SSD ou un NVMe d\u00e9di\u00e9 peut am\u00e9liorer la fluidit\u00e9.</p> </li> <li> <p>R\u00e9seau filaire  : privil\u00e9giez l\u2019Ethernet Gigabit ou sup\u00e9rieur. Jellyfin insiste qu\u2019une carte 1\u202fGbE ou plus est fortement recommand\u00e9e et d\u00e9conseille le Wi-Fi ou Powerline  . Pour l\u2019acc\u00e8s distant, pr\u00e9voyez suffisamment d\u2019upload (&gt;20\u202fMb/s est un minimum pour du 1080p  ).</p> </li> <li> <p>GPU pour transcodage  : activez l\u2019acc\u00e9l\u00e9ration mat\u00e9rielle. Par exemple, sur une machine Intel, installez les paquets pour QuickSync (Intel Media Server Studio ou sur Linux le paquet  intel-media-va-driver-non-free), puis activez QuickSync dans Jellyfin/Plex/Emby. Pour NVIDIA, installez les pilotes GPU r\u00e9cents et la runtime Docker NVIDIA, puis activez NVENC dans Jellyfin/Emby ou pointez Plex vers le GPU (ce dernier n\u2019est pas officiellement support\u00e9 sous Linux, mieux vaut utiliser un client native ou se reposer sur QuickSync). Ces acc\u00e9l\u00e9rations d\u00e9chargent le CPU, permettant plusieurs flux HD/4K \u00e0 la fois.</p> </li> <li> <p>Configuration r\u00e9seau  : limitez les connexions superflues. Par exemple, d\u00e9sactivez la recherche UPnP ou DLNA si inutile. Si vous utilisez un VPN, assurez-vous qu\u2019il g\u00e8re bien le trafic multicast (certains VPN maison bloquent le DLNA).</p> </li> <li> <p>Optimisations logicielles  : mettez \u00e0 jour les serveurs r\u00e9guli\u00e8rement (Jellyfin a souvent des correctifs optimisant FFmpeg, Emby/Plex publient des versions stables). Dans Jellyfin, assurez-vous d\u2019avoir FFmpeg 5+ via les packages officiels, et activez  Tone Mapping HDR  si vous mixez contenu HDR/SDR. Dans Emby, on peut fixer le nombre max de transcodages simultan\u00e9s. Dans tous les cas, pr\u00e9-t\u00e9l\u00e9chargez les vid\u00e9os en r\u00e9solution native compatible (direct play) autant que possible pour limiter le transcodage sur le serveur.</p> </li> </ul>"},{"location":"media/streaming/#cas-dusage-typiques-en-homelab","title":"Cas d\u2019usage typiques en Homelab","text":"<ul> <li> <p>Streaming familial  : serveur Plex/Jellyfin accessible sur le LAN (ou via VPN pour les membres autoris\u00e9s), diffusant sur smart TV, Chromecast, smartphones, etc. Les parents cr\u00e9ent un profil \u00ab\u202fEnfant\u202f\u00bb avec uniquement les dessins anim\u00e9s et films G/PG, tandis que leur profil \u00ab\u202fAdulte\u202f\u00bb d\u00e9bloque tout le contenu.</p> </li> <li> <p>Automatisation m\u00e9dia  : d\u00e8s qu\u2019un nouvel \u00e9pisode sort, Sonarr le t\u00e9l\u00e9charge et actualise Plex. Un utilisateur peut faire une requ\u00eate via Overseerr/Jellyseerr (par exemple, \u00ab\u202fJe veux la S05 de The Mandalorian\u202f\u00bb), qui lance Radarr/Sonarr et notifie le serveur.</p> </li> <li> <p>Acc\u00e8s distant s\u00e9curis\u00e9  : au lieu d\u2019exposer Plex direct sur Internet, on se connecte au homelab via VPN (WireGuard/IPv6 local) ou via un reverse proxy avec authentification forte, garantissant que seuls les utilisateurs l\u00e9gitimes peuvent streamer en mobilit\u00e9.</p> </li> <li> <p>Enregistrement TV et livres  : Emby/Jellyfin supportent la TV en direct et l\u2019enregistrement DVR (avec une carte TV ou un tuner r\u00e9seau). Ils peuvent aussi organiser une collection de musique/ebooks/photos au-del\u00e0 de la vid\u00e9o. Dans un cadre homelab, on peut ainsi centraliser  tous  les m\u00e9dias personnels (vid\u00e9os, audio, livres) dans une seule plateforme.</p> </li> <li> <p>S\u00e9curit\u00e9 avanc\u00e9e  : comme pour tout service web h\u00e9berg\u00e9, on surveille les logs, on applique des mises \u00e0 jour de s\u00e9curit\u00e9 (OS et serveurs m\u00e9dias) et on limite les acc\u00e8s (pare-feu, authentification). L\u2019option multi-utilisateur permet de cloisonner la navigation de chacun. Par exemple, Jellyfin est \u00ab\u202fprivacy-focused\u202f\u00bb et ne phone home jamais  , ce qui rassure les ing\u00e9nieurs cybers\u00e9curit\u00e9.</p> </li> </ul>"},{"location":"monitoring/grafana/","title":"Grafana : visualisation et alertes dans un homelab","text":""},{"location":"monitoring/grafana/#1-pourquoi-grafana","title":"1. Pourquoi Grafana ?","text":"<p>Grafana est devenu la r\u00e9f\u00e9rence open-source pour  l\u2019observabilit\u00e9  : m\u00e9triques, logs, traces et  alerting  unifi\u00e9s. Dans un homelab d\u2019ing\u00e9nieur cybers\u00e9curit\u00e9, il sert \u00e0 :</p> <ul> <li> <p>surveiller l\u2019\u00e9tat des hyperviseurs/VM (CPU, RAM, I/O) ;</p> </li> <li> <p>d\u00e9tecter les anomalies r\u00e9seau (pics de trafic, pertes de paquets) ;</p> </li> <li> <p>corr\u00e9ler m\u00e9triques \u2194 logs \u2194 traces (stack  Prometheus + Loki + Tempo) pour acc\u00e9l\u00e9rer l\u2019analyse d\u2019incident ;</p> </li> <li> <p>d\u00e9clencher des alertes multi-canal (mail, Telegram, webhook) quelques secondes apr\u00e8s la d\u00e9rive.</p> </li> </ul> <p>Depuis Grafana 11 (mai 2024), le moteur d\u2019alerting unifi\u00e9 est devenu l\u2019unique syst\u00e8me : l\u2019ancien \u00ab legacy alerting \u00bb est retir\u00e9 du code ; migrer avant Grafana 11 \u00e9vite toute interruption  .</p>"},{"location":"monitoring/grafana/#2-comparatif-grafana-kibana-chronograf","title":"2. Comparatif : Grafana, Kibana, Chronograf","text":"<p>TABLEAU</p> <p>Synth\u00e8se :</p> <p>Grafana  excelle d\u00e8s qu\u2019on m\u00e9lange plusieurs back-ends (Prometheus + Loki + InfluxDB) et qu\u2019on veut un seul plan de visualisation + alertes.  Kibana  reste le roi pour l\u2019analytics log plein-texte (Elastic / OpenSearch).  Chronograf  vit toujours, mais n\u2019\u00e9volue plus : bon compagnon Influx v1, moins adapt\u00e9 aux stacks modernes.</p>"},{"location":"monitoring/grafana/#3-architecture-type-grafana-observability","title":"3. Architecture type \u00ab Grafana observability \u00bb","text":"<pre><code>flowchart LR\n  subgraph Data\n    P[Prometheus&lt;br/&gt;metrics] --&gt; G\n    L[Loki&lt;br/&gt;logs] --&gt; G\n    I[InfluxDB&lt;br/&gt;IoT] --&gt; G\n  end\n  subgraph Grafana\n    G[(Grafana&amp;nbsp;11)]\n    G -- rules --&gt; A[/AlertManager/]\n    G -- dashboards --&gt; UI[Users]\n  end\n  P -. scrape .-&gt; N(Node Exporter)\n</code></pre> <ul> <li> <p>Prometheus  collecte les m\u00e9triques (node_exporter, blackbox, SNMP).</p> </li> <li> <p>Loki 3.0  agr\u00e8ge les logs via  Promtail  ; pas d\u2019index plein-texte, co\u00fbt disque r\u00e9duit  .</p> </li> <li> <p>Tempo  (optionnel) capture les traces (OpenTelemetry).</p> </li> <li> <p>Grafana  lit ces sources, affiche les dashboards et cr\u00e9e les r\u00e8gles d\u2019alertes (contact points, notification policies).</p> </li> </ul>"},{"location":"monitoring/grafana/#4-installation-rapide-docker-compose","title":"4. Installation rapide (Docker Compose)","text":"<ul> <li> <p>Prometheus  collecte les m\u00e9triques (node_exporter, blackbox, SNMP).</p> </li> <li> <p>Loki 3.0  agr\u00e8ge les logs via  Promtail  ; pas d\u2019index plein-texte, co\u00fbt disque r\u00e9duit  .</p> </li> <li> <p>Tempo  (optionnel) capture les traces (OpenTelemetry).</p> </li> <li> <p>Grafana  lit ces sources, affiche les dashboards et cr\u00e9e les r\u00e8gles d\u2019alertes (contact points, notification policies).</p> </li> </ul>"},{"location":"monitoring/grafana/#4-installation-rapide-docker-compose_1","title":"4. Installation rapide (Docker Compose)","text":"<pre><code>version: \"3.9\"\nservices:\n  grafana:\n    image: grafana/grafana-oss:11.0.0\n    user: \"472\"           # uid grafana\n    volumes:\n      - ./grafana:/var/lib/grafana\n      - ./provisioning:/etc/grafana/provisioning   # dashboards &amp; datasources\n    env_file: .env\n    ports:\n      - \"3000:3000\"\n    restart: unless-stopped\n\n  prometheus:\n    image: prom/prometheus:v2\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n    restart: unless-stopped\n\n  loki:\n    image: grafana/loki:3.0.0\n    volumes:\n      - ./loki-local-config.yaml:/etc/loki/local-config.yaml\n    restart: unless-stopped\n\n  promtail:\n    image: grafana/promtail:3.0.0\n    volumes:\n      - /var/log:/var/log\n      - ./promtail-config.yaml:/etc/promtail/promtail.yaml\n    restart: unless-stopped\n</code></pre>"},{"location":"monitoring/grafana/#5-tableaux-de-bord-bonnes-pratiques","title":"5. Tableaux de bord &amp; bonnes pratiques","text":"<p>TABLEAU</p>"},{"location":"monitoring/grafana/#6-alertes-dans-grafana-11","title":"6. Alertes dans Grafana 11","text":"<p>Le nouveau moteur  (depuis Grafana 9, seul actif en v11) introduit :</p> <ol> <li> <p>Contact Points  (mail, Slack, Discord, Telegram, PagerDuty, Webhook\u2026).</p> </li> <li> <p>Policies  : arbre de routage &gt; labels (comme Prometheus Alertmanager).</p> </li> <li> <p>Silences &amp; Mute timings  : couper les alertes pr\u00e9vues (planning de maintenance).</p> </li> </ol> <p>Exemple de  rule  Prometheus :  </p> <pre><code>apiVersion: 1\ngroups:\n  - name: homelab_cpu\n    interval: 1m\n    rules:\n      - uid: cpu_high\n        title: \"CPU &gt; 90% sur {{ $labels.instance }}\"\n        condition: \"B\"\n        data:\n          - refId: A\n            expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)\n          - refId: B\n            expr: \"A &gt; 90\"\n        annotations:\n          severity: warning\n</code></pre> <p>Puis, dans Grafana UI :</p> <p>Alerting \u2192 Contact points  \u2192 ajouter  Telegram  avec un bot ;  Notification policies  \u2192 route  severity=warning  vers Telegram de 06:00-22:00.</p> <p>Toutes les alertes sont stock\u00e9es dans la base SQLite/DB PostgreSQL de Grafana et exportables en JSON. Legacy alerting  supprim\u00e9 en Grafana 11  : assurez-vous d\u2019avoir migr\u00e9 vos anciennes r\u00e8gles  .</p>"},{"location":"monitoring/grafana/#7-scenarios-concrets-en-homelab-cyber","title":"7. Sc\u00e9narios concrets en homelab cyber","text":""},{"location":"monitoring/grafana/#71-surveillance-systeme","title":"7.1 Surveillance syst\u00e8me","text":"<ul> <li> <p>M\u00e9triques Prometheus  :  node_exporter,  smartctl_exporter,  nut_exporter  (onduleurs) \u2192 dashboard \u201cInfra-Proxmox\u201d.</p> </li> <li> <p>Alertes  : CPU &gt; 90 %, RAM &gt; 95 %, temp\u00e9rature HDD &gt; 55 \u00b0C.</p> </li> </ul>"},{"location":"monitoring/grafana/#72-logs-detection-incident","title":"7.2 Logs &amp; d\u00e9tection incident","text":"<ul> <li> <p>Loki + Promtail  : collecte des logs de : OPNsense, reverse proxy Nginx, Authentik.</p> </li> <li> <p>Explore :  {\"app\"=\"nginx\", level=\"error\"}  pour rep\u00e9rer les 500, d\u00e9clencher une alerte \u201cErreur Nginx sur auth.lab\u201d.</p> </li> </ul>"},{"location":"monitoring/grafana/#73-trafic-reseau-suspect","title":"7.3 Trafic r\u00e9seau suspect","text":"<ul> <li> <p>Grafana + Prometheus + blackbox_exporter  : ping de 20 destinations ; si latence &gt; 100 ms 3\u00d7 d\u2019affil\u00e9e \u2192 alerte Telegram.</p> </li> <li> <p>Grafana + Loki  : alert rule \u201cnombre de connexions SSH &gt; 50/min depuis IP externe\u201d (count_over_time({app=\"sshd\"}[1m]) &gt; 50).</p> </li> </ul>"},{"location":"monitoring/grafana/#74-tableau-de-bord-energie","title":"7.4 Tableau de bord \u00e9nergie","text":"<ul> <li> <p>InfluxDB  re\u00e7oit les watts via Zigbee2MQTT.</p> </li> <li> <p>Dashboard \u201cPower usage (kWh)\u201d \u2192 variable  \\$phase.</p> </li> <li> <p>Alerte \u201cconso &gt; 80 %\u201d pour d\u00e9clencher extinction de lab  non-prod  (hook Home Assistant).</p> </li> </ul>"},{"location":"monitoring/grafana/#8-securiser-grafana","title":"8. S\u00e9curiser Grafana","text":"<p>TABLEAU</p>"},{"location":"monitoring/grafana/#9-conclusion","title":"9. Conclusion","text":"<p>Grafana reste  le  tableau de bord universel du homelab :</p> <ul> <li> <p>Multi-sources (Prometheus, Loki, InfluxDB).</p> </li> <li> <p>Alerting int\u00e9gr\u00e9 (v11) avec routage avanc\u00e9.</p> </li> <li> <p>\u00c9cosyst\u00e8me tr\u00e8s actif : Loki 3.0, Tempo 3, Grafana Labs maintient l\u2019OSS (24 000 \u2b50)  .</p> </li> </ul> <p>Pour la seule visualisation de logs plein-texte, Kibana reste pertinent ; pour une stack Influx v1 minimaliste, Chronograf peut suffire. Mais pour  unifier m\u00e9triques, logs, traces et alertes \u2014 et automatiser la s\u00e9curit\u00e9  \u2014 Grafana + Prometheus + Loki est aujourd\u2019hui l\u2019option la plus robuste et p\u00e9renne dans un homelab auto-h\u00e9berg\u00e9.</p>"},{"location":"monitoring/netalert/","title":"Surveillance r\u00e9seau pour homelab : outils compar\u00e9s","text":"<p>Dans un  homelab  personnel, la surveillance r\u00e9seau n\u00e9cessite des outils capables de d\u00e9tecter de nouveaux appareils, d\u2019analyser le trafic et d\u2019alerter en cas de comportement anormal. Plusieurs solutions open\u2011source existent. Ci-dessous, nous comparons  NetAlertX  \u00e0 des alternatives majeures (ntopng, LibreNMS, Zabbix, Prometheus + Node Exporter) selon plusieurs crit\u00e8res.</p> <p>TABLEAU</p> <p>Chaque outil se d\u00e9marque ainsi :  NetAlertX  se sp\u00e9cialise dans la d\u00e9tection d\u2019intrusion locale (nouveaux appareils, changements), avec une interface claire et de nombreuses alertes pr\u00eates \u00e0 l\u2019emploi  .  ntopng  est focalis\u00e9 sur l\u2019analyse de trafic (flux/paquets) avec peu de fonctions de notification intrusives.  LibreNMS  et  Zabbix  offrent une supervision g\u00e9n\u00e9rale tr\u00e8s robuste (SNMP, m\u00e9triques, alertes avanc\u00e9es), mais requi\u00e8rent plus de ressources et de configuration.  Prometheus + Node Exporter  vise la collecte de m\u00e9triques syst\u00e8me \u00e9volutives (ex. CPU, utilisation r\u00e9seau d\u2019un serveur) avec int\u00e9gration naturelle \u00e0 Grafana, mais sans d\u00e9tection r\u00e9seau par d\u00e9faut.</p>"},{"location":"monitoring/netalert/#cas-dusage-en-homelab","title":"Cas d\u2019usage en homelab","text":"<ul> <li> <p>D\u00e9tection de nouveaux appareils  :  Surveillez quand un appareil inconnu se connecte (nouvel ordi, smartphone, IoT\u2026). NetAlertX est con\u00e7u pour cela : il \u00ab scanne votre r\u00e9seau pour rep\u00e9rer de nouveaux appareils\u2026 et vous alerte d\u00e8s qu\u2019un nouvel appareil ou une adresse IP inconnue est d\u00e9tect\u00e9 \u00bb  . LibreNMS et Zabbix peuvent d\u00e9couvrir automatiquement des \u00e9quipements via SNMP/ARP, mais \u00e9mettre une alerte requiert de configurer des triggers sp\u00e9cifiques. Un homelab typique usera souvent NetAlertX pour l\u2019\u00ab intrusion Wi-Fi/LAN \u00bb et LibreNMS/Zabbix pour le suivi continu des serveurs/routeurs.</p> </li> <li> <p>Suivi de connexions inhabituelles  :  Par exemple, d\u00e9tecter un balayage de port ou un appareil qui change fr\u00e9quemment d\u2019IP. NetAlertX surveille les changements d\u2019adresse IP des appareils et les reconnexions/d\u00e9connexions  . Pour la d\u00e9tection de scans r\u00e9seau, on compl\u00e9tera avec un IDS d\u00e9di\u00e9 (ex. Snort) ou le mode \u00ab Nmap port scan \u00bb de NetAlertX (plugin). Zabbix peut d\u00e9clencher une alerte sur un nombre anormal de paquets ou connexions avec un trigger, et LibreNMS peut signaler des flux suspects via ses graphes, mais cela reste plus artisanal. Les m\u00e9triques de trafic export\u00e9es par Node Exporter peuvent \u00eatre visualis\u00e9es dans Grafana pour rep\u00e9rer des sursauts (via alertes Prometheus), mais sans d\u00e9tection intelligente par d\u00e9faut.</p> </li> <li> <p>Alertes centralis\u00e9es (Telegram, e-mail, dashboards)  :  NetAlertX int\u00e8gre 80+ canaux de notification (dont Telegram, e-mail, Webhooks) via Apprise  . On peut ainsi recevoir une alerte sur mobile ou pousser l\u2019\u00e9v\u00e9nement dans  Home Assistant  pour automatiser (par exemple couper le Wi-Fi). LibreNMS/Zabbix notifient par e-mail ou webhook (avec Slack, PagerDuty, etc.) en fonction de conditions d\u00e9finies  . Pour un affichage unifi\u00e9, Grafana est souvent utilis\u00e9 : Zabbix et LibreNMS peuvent alimenter Grafana (via API ou exporters). NetAlertX peut lui-m\u00eame envoyer des donn\u00e9es \u00e0 Home Assistant ou \u00e0 d\u2019autres syst\u00e8mes (via Webhooks/MQTT  ), et n\u2019est pas con\u00e7u pour Grafana directement. Un sc\u00e9nario typique en homelab pourrait associer NetAlertX (alertes intrus) + Home Assistant pour l\u2019automatisation, et Prometheus/Grafana ou Zabbix pour superviser et visualiser les serveurs et \u00e9quipements principaux.</p> </li> </ul>"},{"location":"monitoring/netalert/#deploiement-de-netalertx-docker","title":"D\u00e9ploiement de NetAlertX (Docker)","text":"<p>NetAlertX est  pleinement support\u00e9 en Docker  . Voici les \u00e9tapes cl\u00e9s :</p> <ol> <li> <p>Pr\u00e9-requis &amp; volumes  : Installez Docker ou Docker Compose sur votre h\u00f4te. Cr\u00e9ez deux r\u00e9pertoires locaux pour la configuration et les donn\u00e9es, par exemple  /opt/netalertx/config  et  /opt/netalertx/db. Ces dossiers seront mont\u00e9s dans le conteneur pour persistance.</p> </li> <li> <p>Commande Docker (exemple)  : Utilisez l\u2019image officielle  ghcr.io/jokob-sk/netalertx:latest  (GitHub Container Registry). Par exemple :</p> </li> </ol> <pre><code>docker run -d --name netalertx --rm \\\n  --network host \\\n  -v /opt/netalertx/config:/app/config \\\n  -v /opt/netalertx/db:/app/db \\\n  --tmpfs /app/api \\\n  -e PUID=1000 -e PGID=1000 \\\n  -e TZ=Europe/Paris \\\n  -e PORT=20211 \\\n  --cap-add NET_RAW \\\n  ghcr.io/jokob-sk/netalertx:latest\n</code></pre> <ol> <li> <ul> <li> <p>--network host  permet au conteneur d\u2019acc\u00e9der directement au r\u00e9seau (indispensable pour scanner l\u2019ARP du LAN).</p> </li> <li> <p>Les variables  PUID/PGID  ajustent les permissions des volumes (mettez votre utilisateur UNIX).</p> </li> <li> <p>TZ  r\u00e8gle le fuseau horaire.</p> </li> <li> <p>PORT  d\u00e9finit le port web (par d\u00e9faut 20211) \u00e9cout\u00e9 en host.</p> </li> <li> <p>--cap-add NET_RAW  ou  --privileged  : donne le droit de capture (n\u00e9cessaire pour arp-scan, comme indiqu\u00e9 dans la doc)  .</p> </li> </ul> </li> <li> <p>Docker Compose (optionnel)  : Vous pouvez aussi utiliser un  docker-compose.yml  (ex. dans le repo officiel) pour d\u00e9finir ces m\u00eames param\u00e8tres de fa\u00e7on d\u00e9clarative.</p> </li> <li> <p>Premi\u00e8re configuration  : \u00c0 la premi\u00e8re ex\u00e9cution, NetAlertX initialise les fichiers de config et la base de donn\u00e9es SQLite dans les volumes mont\u00e9s. Si besoin, modifiez ensuite  /app/config/app.conf  pour ajuster les r\u00e9seaux \u00e0 surveiller (-m), la cadence des scans, etc. Un reverse-proxy (Nginx) peut \u00eatre ajout\u00e9 pour s\u00e9curiser l\u2019acc\u00e8s HTTPS.</p> </li> <li> <p>Meilleures pratiques :</p> <ul> <li> <p>Limitez l\u2019acc\u00e8s \u00e0 l\u2019interface web (authentifiez-vous et/ou placez un VPN/reverse-proxy devant) pour prot\u00e9ger l\u2019outil de surveillance.</p> </li> <li> <p>Surveillez l\u2019usage CPU/m\u00e9moire du conteneur ; ajustez le nombre de threads ou modules activ\u00e9s si la machine h\u00f4te est restreinte.</p> </li> <li> <p>Sauvegardez r\u00e9guli\u00e8rement le dossier  db  (contenant la base SQLite) pour ne pas perdre l\u2019historique.</p> </li> </ul> </li> </ol> <p>Toutes ces \u00e9tapes sont document\u00e9es dans le guide d\u2019installation officiel  et la page GitHub (Quick Start)  .</p>"},{"location":"monitoring/netalert/#securite-et-limites","title":"S\u00e9curit\u00e9 et limites","text":"<ul> <li> <p>Minimiser les faux positifs  : En d\u00e9but de d\u00e9ploiement, vous verrez beaucoup d\u2019alertes normales (\u00ab mon smartphone se d\u00e9connecte / reconnecte \u00bb). Pour r\u00e9duire le bruit : ajustez les r\u00e8gles en fonction de votre usage. Par exemple, qualifiez certains appareils de \u00ab toujours pr\u00e9sents \u00bb, ou d\u00e9finissez une plage d\u2019adresses IP fixe pour des appareils connus (puits DHCP statiques). On peut aussi utiliser des listes blanches (\u00ab whitelist \u00bb) d\u2019appareils/horaires normaux  . Comme en entreprise, un tuning progressif des r\u00e8gles (se baser sur le comportement normal) peut \u00e9liminer jusqu\u2019\u00e0 90% des faux positifs  . Dans NetAlertX, vous pouvez \u00e9tiqueter les appareils connus et ignorer certains changements mineurs. Par exemple, pour les appareils g\u00e9n\u00e9rant des MAC al\u00e9atoires (smartphones iOS/Android), une approche consiste \u00e0 fixer leur IP ou \u00e0 les exclure de la d\u00e9tection.  (exemple : ajouter leur IP dans une liste d\u2019ignore) ou \u00e0 d\u00e9sactiver la randomisation MAC sur ces appareils.</p> </li> <li> <p>S\u00e9curit\u00e9 des donn\u00e9es de logs  : Les donn\u00e9es r\u00e9seau et l\u2019historique des appareils sont sensibles. NetAlertX stocke  localement  toutes les informations par d\u00e9faut  , ce qui \u00e9vite l\u2019exfiltration non d\u00e9sir\u00e9e. Il est recommand\u00e9 de chiffrer (ou restreindre l\u2019acc\u00e8s \u00e0) ces r\u00e9pertoires. Limitez l\u2019acc\u00e8s \u00e0 la base (ex. user Linux d\u00e9di\u00e9, permissions restreintes) et chiffrez les backups. Dans un homelab, \u00e9vitez de remonter les logs sur des services cloud sans n\u00e9cessit\u00e9. De m\u00eame, s\u00e9curisez les notifications (ex. API keys Telegram ne doivent pas fuir).</p> </li> <li> <p>Visibilit\u00e9 excessive et \u00e9thique  : La surveillance r\u00e9seau permet de voir beaucoup de donn\u00e9es. Par exemple, en mode \u00ab promiscuit\u00e9 \u00bb, vous pourriez capter du trafic qui contient potentiellement des informations priv\u00e9es (adresses e-mail, noms d\u2019utilisateur, m\u00e9tadonn\u00e9es de navigation, etc.). M\u00eame sur votre propre r\u00e9seau, restez conscient de la vie priv\u00e9e des utilisateurs (famille, invit\u00e9s). N\u2019abusez pas de l\u2019extraction de payloads r\u00e9seau. Focus : NetAlertX se concentre sur les en-t\u00eates ARP/IP et la pr\u00e9sence de l\u2019appareil, pas sur le contenu des paquets. Pour le sniffing orient\u00e9 s\u00e9curit\u00e9 (IDS), rappelez-vous que certains pays ont des lois strictes sur l\u2019interception des communications (m\u00eame en entreprise/locale). En cas de doute, privil\u00e9giez la collecte de logs minimales (ex. uniquement les m\u00e9ta-donn\u00e9es, pas le contenu chiffr\u00e9) et informez les utilisateurs surveill\u00e9s.</p> </li> </ul> <p>En somme, la surveillance r\u00e9seau en homelab doit trouver l\u2019\u00e9quilibre entre visibilit\u00e9 et confidentialit\u00e9. Adoptez une configuration  responsable  : captez uniquement ce qui est n\u00e9cessaire (\u00e9vitez le \u00ab full packet capture \u00bb si vous n\u2019en avez pas besoin), prot\u00e9gez les logs, et ajustez finement vos r\u00e8gles pour distinguer comportements normaux et anomalies.</p>"},{"location":"monitoring/prometheus-influx/","title":"Collecte et stockage des m\u00e9triques : Prometheus vs InfluxDB","text":"<p>Le  homelab  d\u2019un ing\u00e9nieur en cybers\u00e9curit\u00e9 requiert une solution de monitoring fiable et performante. Prometheus et InfluxDB sont deux bases de donn\u00e9es temporelles (TSDB) populaires, chacune avec son mod\u00e8le et ses forces propres. Cette documentation compare  techniquement  Prometheus (pull-based, TSDB) et InfluxDB (push-based, TSM), leur int\u00e9gration avec les outils courants (Grafana, Home Assistant, MQTT, etc.), ainsi que des cas pratiques et une architecture type pour un homelab s\u00e9curis\u00e9. Des exemples de configurations Docker Compose, de bons usages de s\u00e9curit\u00e9 (r\u00e9verse proxy, VLAN), et un tableau comparatif final sont fournis.</p>"},{"location":"monitoring/prometheus-influx/#1-comparaison-technique-prometheus-vs-influxdb","title":"1. Comparaison technique Prometheus vs InfluxDB","text":"<ul> <li> <p>Performance et cardinalit\u00e9  : Prometheus est con\u00e7u pour des environnements  cloud-native et conteneuris\u00e9s, avec un mod\u00e8le de collecte  par pull. Il g\u00e8re efficacement les m\u00e9triques \u00e0  haute cardinalit\u00e9. InfluxDB, utilisant un mod\u00e8le  push  (via Telegraf ou API), offre souvent un  d\u00e9bit d\u2019\u00e9criture  \u00e9lev\u00e9 mais peut peiner avec des s\u00e9ries extr\u00eamement nombreuses. Autrement dit, Prometheus facilite les requ\u00eates agr\u00e9g\u00e9es sur des millions de s\u00e9ries (ex.  histogram_quantile  en PromQL), tandis qu\u2019InfluxDB peut mieux absorber un flot intensif de donn\u00e9es IoT.</p> </li> <li> <p>Stockage  : Prometheus utilise son  TSDB  interne : les donn\u00e9es sont regroup\u00e9es en  blocs de 2 heures, index\u00e9s et compress\u00e9s. Prometheus stocke en moyenne seulement  1\u20132 octets par \u00e9chantillon. Un journal d\u2019\u00e9criture (WAL) assure la durabilit\u00e9 jusqu\u2019\u00e0 la persistance dans les segments compact\u00e9s. La r\u00e9tention est g\u00e9r\u00e9e par les flags  --storage.tsdb.retention.time/size  (par d\u00e9faut 15 jours). InfluxDB, quant \u00e0 lui, utilise une architecture WAL +  TSM (Time-Structured Merge Tree). Les points sont d\u2019abord \u00e9crits dans un WAL puis flush\u00e9s en m\u00e9moire cache et finalement vers des fichiers TSM compress\u00e9s par s\u00e9ries (stockant les  deltas  des s\u00e9ries en format colonne). InfluxDB prend en charge nativement les  r\u00e9tention policies  (ex.  CREATE RETENTION POLICY \"one_year\" ON \"mydb\" DURATION 52w...) et les  continuous queries  pour downsampling automatique. Par exemple :</p> </li> </ul> <pre><code>CREATE RETENTION POLICY \"one_year\" ON \"mydb\" DURATION 52w REPLICATION 1 DEFAULT\nCREATE CONTINUOUS QUERY \"cq_30m\" ON \"mydb\"\n  RESAMPLE EVERY 30m FOR 1d\n  BEGIN\n    SELECT mean(\"value\") INTO \"downsampled\".\"cpu_load\"\n    FROM \"cpu_load\" GROUP BY time(1m), *\n  END\n</code></pre> <ul> <li> <p>Cette souplesse permet \u00e0 InfluxDB d\u2019archiver  long terme  avec agr\u00e9gation, contrairement \u00e0 Prometheus qui efface simplement les vieux blocs.</p> </li> <li> <p>Compression  : Les deux moteurs appliquent des techniques de compression par d\u00e9faut. Prometheus utilise l\u2019algorithme  Gorilla  pour les s\u00e9ries num\u00e9riques, et peut compresser le WAL avec Snappy. InfluxDB compresse chaque bloc TSM ind\u00e9pendamment : les timestamps et valeurs sont cod\u00e9s diff\u00e9remment (delta encoding, Simple8b, Snappy, XOR\u2026) selon le type (float, int, bool, string). Le stockage en colonnes par s\u00e9rie et l\u2019usage de deltas am\u00e9liorent l\u2019efficacit\u00e9 de stockage d\u2019InfluxDB pour des s\u00e9ries r\u00e9guli\u00e8res.</p> </li> <li> <p>Flexibilit\u00e9 des requ\u00eates  : Prometheus utilise  PromQL, un langage fonctionnel con\u00e7u pour les s\u00e9ries \u00e9tiquet\u00e9es (labels). Il excelle dans les requ\u00eates temps r\u00e9el, les agr\u00e9gations multi-dimensions, les joins implicites (op\u00e9rations bool\u00e9ennes sur s\u00e9quences), et les fonctions d\u2019histogrammes ou de d\u00e9riv\u00e9es. InfluxDB propose  InfluxQL  (SQL-like, historique v1) et  Flux  (langage scriptable plus r\u00e9cent). Flux permet des transformations avanc\u00e9es (joins explicites, windowing, math), mais impose souvent plus de configuration. PromQL ne supporte que des valeurs num\u00e9riques (float64) pour la plupart des op\u00e9rateurs, InfluxQL/Flux peut g\u00e9rer divers types (floats, int, bool, string).</p> </li> <li> <p>Cas d\u2019usage typiques  : En r\u00e9sum\u00e9, Prometheus est parfait pour la surveillance en temps r\u00e9el d\u2019infrastructures modernes : il int\u00e8gre la d\u00e9couverte de services (Kubernetes, Consul, etc.), l\u2019alerting natif via Alertmanager, et de nombreux  exporters  (Node Exporter, cAdvisor, Blackbox, etc.). InfluxDB brille dans les  donn\u00e9es IoT et capteurs(ex. suivi d\u2019\u00e9nergie, temp\u00e9ratures, s\u00e9ries temporelles industrielles) gr\u00e2ce \u00e0 son mod\u00e8le push et ses capacit\u00e9s d\u2019agr\u00e9gation/de dur\u00e9e. Par exemple, InfluxDB est souvent cit\u00e9 pour les d\u00e9ploiements  Smart Home  et capteurs longue dur\u00e9e, alors que Prometheus est le choix par d\u00e9faut en Cloud / containers.</p> </li> <li> <p>Alerting  : Prometheus dispose d\u2019un syst\u00e8me d\u2019alerte int\u00e9gr\u00e9 (Alertmanager) facile \u00e0 configurer pour envoyer des notifications (email, Slack, etc.) bas\u00e9es sur des r\u00e8gles PromQL. InfluxDB, historiquement (v1), s\u2019appuyait sur  Kapacitor/Chronograf  pour les alertes, ce qui peut \u00eatre plus lourd \u00e0 configurer. Aujourd\u2019hui, les utilisateurs d\u2019InfluxDB ont souvent recours \u00e0  Grafana Alerting  ou \u00e0 des solutions externes. Dans tous les cas, les deux solutions peuvent g\u00e9n\u00e9rer des alertes, mais la pile Prometheus est  native  (Prometheus \u2192 Alertmanager) tandis qu\u2019InfluxDB n\u00e9cessite en g\u00e9n\u00e9ral un composant suppl\u00e9mentaire ou l\u2019utilisation de Grafana.</p> </li> </ul>"},{"location":"monitoring/prometheus-influx/#2-integration-dans-un-homelab","title":"2. Int\u00e9gration dans un homelab","text":"<p>Un homelab de cyber-s\u00e9curit\u00e9 requiert la surveillance de multiples composants et capteurs. Voici comment Prometheus et InfluxDB se branchent sur les outils courants :</p> <ul> <li> <p>Grafana  : Indispensable pour visualiser les m\u00e9triques. Grafana supporte  nativement Prometheus et InfluxDBcomme sources de donn\u00e9es. On peut construire des dashboards graphiques complexes, utiliser des  variables de template  pour it\u00e9rer sur des h\u00f4tes ou interfaces, et d\u00e9clencher des alertes via Grafana Alerting. Par exemple, un dashboard Proxmox peut agr\u00e9ger  node_cpu_seconds_total  (Prometheus) ou  cpu_load  (Influx) au m\u00eame endroit. Grafana facilite aussi le param\u00e9trage (templating) des requ\u00eates et des alertes cross-source.</p> </li> <li> <p>Home Assistant (HA)  : HA est souvent c\u0153ur d\u2019un homelab domotique. Il offre une int\u00e9gration  Prometheus  qui expose un endpoint  /api/prometheus  pour que Prometheus scrappe les \u00e9tats des entit\u00e9s HA  . InfluxDB dispose aussi d\u2019une int\u00e9gration (ou add-on) : HA peut  pousser  ses donn\u00e9es dans InfluxDB via  influxdb:  dans  configuration.yaml. Exemple de configuration pour HA \u2192 InfluxDB :</p> </li> </ul> <pre><code>influxdb:\n  api_version: 2\n  host: 192.168.1.190\n  port: 8086\n  token: VOTRE_TOKEN\n  organization: MON_ORG\n  bucket: mesures_domotique\n  tags:\n    source: HA\n</code></pre> <ul> <li> <p>Ainsi, on exploite HA comme source de donn\u00e9es pour l\u2019un ou l\u2019autre syst\u00e8me. InfluxDB est souvent privil\u00e9gi\u00e9 pour les  graphiques longue dur\u00e9e  (\u00e9nergie, temp\u00e9rature), tandis que Prometheus peut \u00eatre utilis\u00e9 pour des alertes instantan\u00e9es (ex. batterie faible).</p> </li> <li> <p>Zigbee2MQTT et capteurs domotiques (Shelly, Zigbee)  : Ces solutions transmettent leurs mesures via MQTT. Avec InfluxDB, on peut utiliser  Telegraf  (plugin  mqtt_consumer) ou un  exporter MQTT  pour r\u00e9cup\u00e9rer les topics et \u00e9crire dans InfluxDB. Ce blog montre bien comment capter des mesures Shelly sur MQTT et les stocker en Influx 2.6 pour Grafana. Avec Prometheus, il n\u2019existe pas d\u2019endpoint Prometheus natif dans Zigbee2MQTT (sujet en discussion GitHub), on peut donc utiliser Telegraf  vers  Prometheus : le plugin  inputs.mqtt_consumer  de Telegraf lit les messages Zigbee2MQTT en JSON, puis le plugin  outputs.prometheus_client  les expose sur un endpoint  /metricspour que Prometheus les scrap. En r\u00e9sum\u00e9, capteurs Zigbee/Powerm\u00e8tre (Shelly) \u2192 MQTT \u2192 (Telegraf) \u2192 InfluxDB/Prometheus.</p> </li> <li> <p>Frigate (NVR IA)  : Frigate expose une API  /api/stats  fournissant CPU, m\u00e9moire, FPS, corail, stockage, compteurs d\u2019\u00e9v\u00e9nements, etc. Il existe un exporter Prometheus d\u00e9di\u00e9 (par ex.  bairhys/prometheus-frigate-exporter). Ce container interroge Frigate et met \u00e0 disposition ces m\u00e9triques en  /metrics. Il fournit notamment la vitesse d\u2019inf\u00e9rence, l\u2019utilisation CPU/RAM de Frigate, le FPS cam\u00e9ra, la temp\u00e9rature du Coral, etc.. On fera donc pointer Prometheus vers cet exporter pour collecter les m\u00e9triques Frigate. InfluxDB n\u2019a pas d\u2019int\u00e9gration directe, mais on peut remonter ces m\u00eames infos via Telegraf (inputs.http  ou script) ou via l\u2019API  remote write  de Influx (InfluxDB 2.0 accepte aussi le protocole Prometheus).</p> </li> <li> <p>Docker et h\u00f4tes Proxmox  : Sur chaque n\u0153ud (Proxmox ou serveur Linux), on installe  node_exporter  pour les m\u00e9triques syst\u00e8me (CPU, RAM, disques, r\u00e9seau) et  cAdvisor  (ou Docker daemon metrics) pour les conteneurs Docker. Ces exporters sont scrapp\u00e9s par Prometheus. Avec InfluxDB, Telegraf prend le relais : on peut activer  [[inputs.cpu]],  [[inputs.mem]],  [[inputs.disk]],  [[inputs.net]],  [[inputs.docker]], etc., pour r\u00e9colter les m\u00eames donn\u00e9es (voir exemple de configuration Telegraf ci-dessous). Grafana affichera en aval ces donn\u00e9es \u00e0 partir d\u2019Influx ou de Prometheus, avec les m\u00eames dashboards (il suffit de configurer la source de donn\u00e9es).</p> </li> <li> <p>Proxmox (VE)  : Proxmox n\u2019expose pas nativement de m\u00e9triques Prometheus, mais il existe plusieurs outils. Par exemple, le projet  prometheus-pve-exporter  r\u00e9cup\u00e8re via l\u2019API Proxmox l\u2019\u00e9tat des VMs/CTs, ressources, statut cluster, etc., pour Prometheus. Pour InfluxDB, Telegraf dispose d\u2019un plugin  inputs.proxmox  qui interroge l\u2019API de Proxmox et envoie les stats (CPU, m\u00e9moire, IOPS, etc.) vers Influx. Ainsi, que vous utilisiez Prometheus ou InfluxDB, il existe des solutions (exporter ou plugin) pour int\u00e9grer Proxmox dans le monitoring.</p> </li> </ul>"},{"location":"monitoring/prometheus-influx/#3-architecture-type","title":"3. Architecture type","text":"<p>En pratique, on peut d\u00e9ployer  deux stacks distinctes  ou une architecture mixte. Les concepts cl\u00e9s :</p> <ul> <li> <p>Exporters Prometheus  : Petits services HTTP exposant des m\u00e9triques au format Prometheus. Exemples :  node_exporter  (host hardware),  cadvisor  (Docker),  blackbox_exporter  (ping/HTTP),  mqtt_exporter/Telegraf Prometheus (MQTT),  zabbix_exporter, etc. Prometheus scrappe p\u00e9riodiquement ces endpoints et stocke les donn\u00e9es dans sa TSDB. L\u2019Alertmanager (optionnel) g\u00e8re les notifications.</p> </li> <li> <p>Agents Telegraf pour InfluxDB  : Telegraf est un agent \u00ab plugin-based \u00bb qui pousse les donn\u00e9es vers InfluxDB. Il lit les m\u00e9triques syst\u00e8me (inputs.cpu,  inputs.disk,  inputs.docker), IoT (inputs.mqtt_consumer,  inputs.modbus, etc.), ou m\u00eame Prometheus (inputs.prometheus  plugin) et \u00e9crit dans InfluxDB (v2). InfluxDB OSS ou Cloud stocke les s\u00e9ries, et Grafana (ou Chronograf) sert de couche graphique.</p> </li> <li> <p>Politique de r\u00e9tention  : On d\u00e9finit des r\u00e9tentions (dur\u00e9es de stockage). Prometheus purge au-del\u00e0 de  retention.time. InfluxDB g\u00e8re les politiques par base/bucket, et on peut configurer des TTLs en flux. Des downsamplings (CQ/Tasks) r\u00e9duisent la granularit\u00e9 historique.</p> </li> <li> <p>Authentification &amp; S\u00e9curit\u00e9  : En mode \u00ab homelab s\u00e9curis\u00e9 \u00bb, on met les services de monitoring sur un r\u00e9seau de gestion isol\u00e9 (VLAN d\u00e9di\u00e9). Les exporters sur les VLAN IoT (capteurs) ou Docker peuvent \u00eatre accessibles uniquement en internal. Tous les acc\u00e8s web (Grafana, InfluxUI, Prom UI, Alertmanager) passent par un reverse proxy (Nginx, Traefik) en HTTPS avec authentification forte (LDAP/htpasswd). On \u00e9vite d\u2019exposer les endpoints  :9100/metrics  (node_exporter) ou  :9103/metrics  (cadvisor) en externe, sauf \u00e9ventuellement via VPN.</p> </li> </ul> <p>Figure 1 : Exemple de sch\u00e9ma d\u2019architecture Prometheus (mod\u00e8le pull) avec exporters et Alertmanager.</p> <p>Figure : Architecture typique Prometheus \u2013 Prometheus scrappe les exporters (node_exporter, cAdvisor, etc.) et envoie les alertes \u00e0 Alertmanager, le tout visualis\u00e9 dans Grafana.</p> <p>En compl\u00e9ment, un  sch\u00e9ma ASCII  sommaire d\u2019une architecture mixte pourrait \u00eatre :</p> <pre><code>            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502  Grafana  \u2502\n            \u2514\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n                \u2502   \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502Prometheus\u2502         \u2502\n         \u2514\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2518         \u2502\n            \u2502    \u2502           \u2502\n            \u2502  \u250c\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n            \u2502  \u2502 Alertman- \u2502  \u2502\n            \u2502  \u2502  ager     \u2502  \u2502\n            \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\n\u2502 node   \u2502 cadvisor \u2502   \u2502 mqtt    \u2502\n\u2502 exporter\u2502         \u2502   \u2502 exporter\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n   (h\u00f4tes)               (IoT)       \n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \n\u2502Telegraf\u2502    \u2502   InfluxDB     \u2502 \n\u2502(Linux, \u2502    \u2502 (TSM engine)   \u2502 \n\u2502 Docker)\u2502    \u2514\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518         \u2502     \u2502\n   \u2502               \u2502     \u2502writes       \n   \u2502               \u2502     \u2502       \n   \u2502           \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u2502\n   \u2502           \u2502Cache  \u2502 \u2502\n   \u2502           \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2502\n   \u2502               \u2502     \u2502\n   \u2502           \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 WAL   \u2502 \u2502\n               \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2502\n                   \u2502     \u2502\n                   \u2502 \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\n                   \u2502 \u2502 TSM   \u2502\n                   \u2502 \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n                   \u2502     \u2502\n                   \u2502Compression\n                   \u25bc\n</code></pre> <p>Dans ce diagramme, Prometheus  scrape  r\u00e9guli\u00e8rement les exporters (node_exporter,  cadvisor,  mqtt_exporter, etc.) pour remplir sa TSDB, tandis que Telegraf  push  les donn\u00e9es vers InfluxDB qui les stocke dans le WAL puis dans des fichiers TSM compact\u00e9s. Grafana interroge ensuite Prometheus  et/ou  InfluxDB pour afficher les tableaux de bord.</p>"},{"location":"monitoring/prometheus-influx/#4-cas-dusage-pratiques","title":"4. Cas d\u2019usage pratiques","text":"<ul> <li> <p>Surveillance de l\u2019infrastructure  : On suit l\u2019\u00e9tat des VMs (Proxmox, LXC, QEMU), du r\u00e9seau, et du hardware. Exemples : CPU et m\u00e9moire des n\u0153uds (via Node Exporter ou Telegraf), trafic r\u00e9seau (via SNMP_exporter ou inputs.net), statut des VM (via proxmox-exporter ou inputs.proxmox). Grafana propose des dashboards pr\u00e9fabriqu\u00e9s pour Proxmox, Docker, etc. Des alertes communes : manque de m\u00e9moire (node_memory_availablebas), disque presque plein (node_filesystem  &gt;90%), ou container bloqu\u00e9 (perte de heartbeat).</p> </li> <li> <p>Monitoring d\u2019\u00e9nergie et domotique  : Avec des capteurs Shelly (compteurs d\u2019\u00e9nergie, interrupteurs) ou des sondes Zigbee (temp\u00e9rature, humidit\u00e9), on envoie les donn\u00e9es via MQTT. Par exemple, un Shelly EM peut publier sa consommation sur MQTT, et un agent Telegraf (plugin MQTT) \u00e9crit cette donn\u00e9e dans InfluxDB. Dans Grafana on trace l\u2019\u00e9volution de l\u2019\u00e9nergie. InfluxDB est adapt\u00e9 car on peut stocker sur des ann\u00e9es avec agr\u00e9gation. Prometheus est moins naturel ici (les donn\u00e9es \u00e9v\u00e8nementielles via MQTT demandent un pont push/pull) \u2013 souvent on utilise Telegraf \u2192 Prometheus proxy si n\u00e9cessaire.</p> </li> <li> <p>Alertes temp\u00e9rature / conso CPU  : On peut surveiller la temp\u00e9rature CPU du serveur ou la consommation \u00e9lectrique. Par exemple, installer  lm-sensors  sur un h\u00f4te Proxmox et configurer Telegraf pour lire ces capteurs, puis d\u00e9clencher une alerte si  sensors_core_temp &gt; 80\u00b0C. Prometheus peut \u00e9galement r\u00e9cup\u00e9rer la temp\u00e9rature via Node Exporter (with  sensors  enabled) et un rule PromQL (ALERT CPUHighTemp IF node_hwmon_temp_celsius &gt; 80). Pour la consommation, on peut d\u00e9clencher si la moyenne des Watts (d\u2019un Shelly) d\u00e9passe un seuil sur 5 min, avec une r\u00e8gle Alertmanager ou alert Grafana.</p> </li> </ul> <p>Chaque cas d\u2019usage met en lumi\u00e8re le choix : Prometheus pour de l\u2019alerting r\u00e9actif  et du monitoring syst\u00e8me, InfluxDB pour de la  collecte IoT/longue dur\u00e9e. Dans un homelab, on peut utiliser les deux de mani\u00e8re compl\u00e9mentaire (voir tableau ci-dessous).</p>"},{"location":"monitoring/prometheus-influx/#5-instructions-dinstallation","title":"5. Instructions d\u2019installation","text":"<p>On installe g\u00e9n\u00e9ralement ces stacks via  Docker Compose  pour simplicit\u00e9. Ci-dessous deux exemples de  docker-compose.yml  simplifi\u00e9s.</p> <p>Prometheus Stack  (Prometheus + Alertmanager + Grafana) :</p> <pre><code>version: '3.8'\nservices:\n  prometheus:\n    image: prom/prometheus:v2.46.0\n    container_name: prometheus\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n      - prometheus-data:/prometheus\n    ports:\n      - \"9090:9090\"\n    command:\n      - \"--storage.tsdb.retention.time=15d\"\n      - \"--web.enable-lifecycle\"\n  alertmanager:\n    image: prom/alertmanager:v0.25.0\n    container_name: alertmanager\n    volumes:\n      - ./alertmanager.yml:/etc/alertmanager/config.yml\n    ports:\n      - \"9093:9093\"\n  grafana:\n    image: grafana/grafana:10.0.0\n    container_name: grafana\n    environment:\n      - \"GF_SECURITY_ADMIN_PASSWORD=MotDePasseFort\"\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - grafana-data:/var/lib/grafana\nvolumes:\n  prometheus-data:\n  grafana-data:\n</code></pre> <ul> <li> <p>prometheus.yml doit lister les targets (ex. node_exporter:9100, cadvisor:8080, mqtt_exporter:9255, etc.).</p> </li> <li> <p>alertmanager.yml  configure les routes d\u2019alerte et receveurs (email/Slack).</p> </li> <li> <p>On mappe des volumes pour persister les donn\u00e9es (/prometheus,  /var/lib/grafana).</p> </li> </ul> <p>InfluxDB Stack  (InfluxDB2 + Telegraf + Grafana) :</p> <pre><code>version: '3.8'\nservices:\n  influxdb:\n    image: influxdb:2.8\n    container_name: influxdb\n    volumes:\n      - influxdb-data:/var/lib/influxdb2\n    environment:\n      - DOCKER_INFLUXDB_INIT_MODE=setup\n      - DOCKER_INFLUXDB_INIT_USERNAME=admin\n      - DOCKER_INFLUXDB_INIT_PASSWORD=MotDePasseSecurise\n      - DOCKER_INFLUXDB_INIT_ORG=my-org\n      - DOCKER_INFLUXDB_INIT_BUCKET=mybucket\n      - DOCKER_INFLUXDB_INIT_RETENTION=720h\n    ports:\n      - \"8086:8086\"\n  telegraf:\n    image: telegraf:1.40\n    container_name: telegraf\n    volumes:\n      - ./telegraf.conf:/etc/telegraf/telegraf.conf:ro\n    depends_on:\n      - influxdb\n  grafana:\n    image: grafana/grafana:10.0.0\n    container_name: grafana_influx\n    environment:\n      - \"GF_SECURITY_ADMIN_PASSWORD=AutreMotDePasse\"\n    ports:\n      - \"3001:3000\"\n    volumes:\n      - grafana2-data:/var/lib/grafana\nvolumes:\n  influxdb-data:\n  grafana2-data:\n</code></pre> <ul> <li> <p>InfluxDB 2 en mode  setup  cr\u00e9e org, bucket, utilisateur \u00e0 la premi\u00e8re ex\u00e9cution.</p> </li> <li> <p>Telegraf pousse les m\u00e9triques : le fichier  telegraf.conf  contient par exemple :</p> </li> </ul> <p><pre><code>[[outputs.influxdb_v2]]\n  urls = [\"http://influxdb:8086\"]\n  token = \"GENERE_TOKEN_INFLUX\"\n  organization = \"my-org\"\n  bucket = \"mybucket\"\n[[inputs.cpu]]\n  percpu = true\n  totalcpu = true\n[[inputs.mem]]\n[[inputs.disk]]\n[[inputs.net]]\n[[inputs.docker]]\n  endpoint = \"unix:///var/run/docker.sock\"\n[[inputs.mqtt_consumer]]\n  servers = [\"tcp://mqtt-broker:1883\"]\n  topics = [\"shellies/+/+/power\", \"zigbee2mqtt/#\"]\n  data_format = \"json\"\n</code></pre> -   Grafana (port 3001) est ici configur\u00e9 s\u00e9par\u00e9ment afin de ne pas \u00e9craser l\u2019instance Prom stack si elle existe.</p> <p>Reverse proxy et s\u00e9curit\u00e9  : En production, on place un proxy inverse (Nginx, Traefik) devant Grafana/InfluxUI/PromUI pour g\u00e9rer TLS et authentification unifi\u00e9e. Par exemple, on peut cr\u00e9er des h\u00f4tes virtuels  grafana.mondomaine.com,  prometheus.mondomaine.com, prot\u00e9g\u00e9s par basic auth ou OAuth. Il est crucial de  persister  les volumes de base de donn\u00e9es (ne pas reconstruire Influx/Prom et perdre les donn\u00e9es). On met en place des  backups r\u00e9guliers  :  influx backuppour InfluxDB, et snapshots pour Prometheus (ou copier le dossier de donn\u00e9es).</p> <p>Bonnes pratiques de r\u00e9seau  : Isoler les exportateurs dans des VLAN (ex. tous les exporters IoT/OT sur un VLAN s\u00e9par\u00e9, expos\u00e9 uniquement au broker MQTT et aux collectors). Les containers de monitoring tournent id\u00e9alement sur un segment s\u00e9curis\u00e9. On n\u2019ouvre pas les ports  9100,  9255, etc. hors du VPN interne. Grafana et Prometheus/InfluxUI doivent \u00eatre chiffr\u00e9s (HTTPS) et prot\u00e9g\u00e9s par un syst\u00e8me d\u2019authentification solide (OIDC/LDAP, ou au minimum  auth.basic).</p>"},{"location":"monitoring/prometheus-influx/#6-tableau-comparatif-recapitulatif","title":"6. Tableau comparatif r\u00e9capitulatif","text":"<p>TABLEAU</p> <p>Ce tableau synth\u00e9tise les diff\u00e9rences cl\u00e9s. En somme, Prometheus est id\u00e9al pour la surveillance  temps r\u00e9el et multi-dimensionnelle  d\u2019infrastructure dynamique, avec alerting natif. InfluxDB est un choix robuste pour du  historique volumineux  et des donn\u00e9es h\u00e9t\u00e9rog\u00e8nes, sp\u00e9cialement en contexte IoT/smart home. Chaque solution peut \u00eatre d\u00e9ploy\u00e9e isol\u00e9ment ou en compl\u00e9ment pour tirer parti de leurs points forts.</p>"},{"location":"outils/docker/","title":"Gestion de conteneurs Docker : Portainer, Dockge et interfaces auto-h\u00e9berg\u00e9es","text":"<p>Il existe aujourd\u2019hui plusieurs outils web auto-h\u00e9berg\u00e9s pour piloter des conteneurs Docker sans passer par la ligne de commande. Parmi les plus connus figurent  Portainer  et  Dockge, auxquels on peut ajouter des alternatives comme  Yacht,  CapRover,  Swarmpit, etc. Ces interfaces offrent des tableaux de bord graphiques pour d\u00e9ployer et surveiller des applications conteneuris\u00e9es. Leur choix d\u00e9pendra des besoins : nombre d\u2019h\u00f4tes \u00e0 g\u00e9rer, complexit\u00e9 des applications, niveau de contr\u00f4le et d\u2019automatisation requis, etc.</p>"},{"location":"outils/docker/#portainer-gestion-complete","title":"Portainer (gestion compl\u00e8te)","text":"<p>Portainer est un outil de gestion de conteneurs Docker tr\u00e8s populaire. Il fournit une interface graphique compl\u00e8te pour cr\u00e9er, d\u00e9ployer et superviser des conteneurs, services et stacks Docker (Compose), ainsi que des environnements Kubernetes ou Swarm  . Portainer existe en \u00e9dition  Community  (libre) et  Business  (payante)\u202f: les trois premiers n\u0153uds sont gratuits en Business Edition, ce qui permet de tester la version compl\u00e8te sans frais  . L\u2019architecture de Portainer se compose d\u2019un  serveur  et d\u2019un  agent. Le serveur h\u00e9berge l\u2019interface web, l\u2019agent (optionnel) collecte les m\u00e9triques sur d\u2019autres h\u00f4tes. Ainsi, Portainer peut g\u00e9rer plusieurs machines Docker (multi-h\u00f4tes) via son agent  . Portainer int\u00e8gre les fonctionnalit\u00e9s Docker standard (logs, console, volumes, r\u00e9seaux, registres, etc.) et simplifie le d\u00e9ploiement de stacks et de services, mais cette richesse fonctionnelle peut \u00eatre complexe pour les d\u00e9butants  . On notera que Portainer utilise par d\u00e9faut le port  9443  pour HTTPS et  8000  pour HTTP, avec un certificat auto-sign\u00e9 au premier lancement  . Il faut configurer un mot de passe administrateur \u00e0 l\u2019installation (Portainer demande de le d\u00e9finir lors du premier acc\u00e8s) et, id\u00e9alement, passer derri\u00e8re un reverse-proxy HTTPS pour la s\u00e9curit\u00e9.</p>"},{"location":"outils/docker/#dockge-gestion-legere-de-stacks-docker-compose","title":"Dockge (gestion l\u00e9g\u00e8re de stacks Docker Compose)","text":"<p>Dockge est un gestionnaire de stacks Docker Compose con\u00e7u pour la simplicit\u00e9  . D\u00e9velopp\u00e9 par l\u2019auteur de l\u2019Uptime Kuma, Dockge se concentre exclusivement sur les fichiers  docker-compose.yml  et l\u2019\u00e9dition de configurations YAML  . Contrairement \u00e0 Portainer qui expose tous les r\u00e9glages Docker individuellement, Dockge demande de pr\u00e9parer ou d\u2019importer les fichiers  docker-compose.yml  (via l\u2019interface ou en pla\u00e7ant les fichiers dans le dossier des stacks)  . Son interface est l\u00e9g\u00e8re et r\u00e9active, mais  ne g\u00e8re qu\u2019implicitement les stacks Compose  : pas de cr\u00e9ation de conteneur isol\u00e9, ni de manipulations fines du r\u00e9seau au-del\u00e0 de ce qui est d\u00e9fini dans le compose. En r\u00e9sum\u00e9, Dockge est un outil \u00ab Docker-centr\u00e9 \u00bb et limit\u00e9 : il convient si vous \u00eates \u00e0 l\u2019aise avec Docker Compose et que vous ne voulez g\u00e9rer que des stacks, mais il ne remplace pas enti\u00e8rement Portainer si vous avez besoin de fonctions avanc\u00e9es (r\u00e9seaux, conteneurs unitaires, monitoring multi-h\u00f4tes, etc.)  . Dockge fonctionne sur un seul h\u00f4te Docker (pas d\u2019agent multi-h\u00f4tes) et \u00e9coute par d\u00e9faut sur le port  5001. L\u2019installation typique consiste \u00e0 cr\u00e9er un dossier  /opt/stacks  pour vos projets, un dossier  /opt/dockge  pour Dockge, puis r\u00e9cup\u00e9rer le fichier  compose.yaml  de Dockge et lancer  docker compose up -d  . Par exemple :</p> <ul> <li> <p>mkdir -p /opt/stacks /opt/dockge &amp;&amp; cd /opt/dockge</p> </li> <li> <p>curl -fsSL https://raw.githubusercontent.com/louislam/dockge/master/compose.yaml -o compose.yaml</p> </li> <li> <p>docker compose up -d  .</p> <p>On acc\u00e8de ensuite \u00e0 Dockge sur  http://:5001."},{"location":"outils/docker/#autres-interfaces-auto-hebergees","title":"Autres interfaces auto-h\u00e9berg\u00e9es","text":"<p>Outre Portainer et Dockge, on peut citer plusieurs autres projets :</p> <ul> <li> <p>Yacht  : une interface web  open-source  ax\u00e9e sur le d\u00e9ploiement d\u2019applications via des templates. Yacht permet de d\u00e9ployer en un clic des \u201cpackages\u201d (bas\u00e9s sur Docker Compose) depuis un d\u00e9p\u00f4t externe (ex. Github)  . Son interface simple affiche d\u00e8s l\u2019accueil l\u2019utilisation CPU/M\u00e9moire des conteneurs. Contrairement \u00e0 Portainer, Yacht ne g\u00e8re qu\u2019un seul h\u00f4te (pas d\u2019agent multi-serveur)  et ne permet pas de d\u00e9ployer directement depuis le syst\u00e8me de fichiers local (il r\u00e9cup\u00e8re les stacks depuis des d\u00e9p\u00f4ts git)  . L\u2019installation est rapide : par exemple, cr\u00e9er un volume Docker  yacht  et lancer  docker run -d -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v yacht:/config selfhostedpro/yacht  . L\u2019interface est centr\u00e9e sur la gestion de templates de stack, et propose m\u00eame l\u2019import des templates Portainer. Yacht est jeune (en alpha/early access) mais tr\u00e8s actif. Par d\u00e9faut on se connecte en  admin@yacht.local  /  pass  (\u00e0 changer d\u2019urgence pour la s\u00e9curit\u00e9)  .</p> </li> <li> <p>CapRover  : plut\u00f4t qu\u2019un simple tableau de bord Docker, CapRover est une  plateforme PaaS  open-source (\u201cHeroku on Steroids\u201d). Elle automatise le d\u00e9ploiement d\u2019applications web (Node, PHP, Python, bases de donn\u00e9es, etc.) sur Docker Swarm avec Nginx et Let\u2019s Encrypt sous le capot  . CapRover fournit une interface web conviviale et un CLI pour installer/mettre \u00e0 jour des apps, configurer SSL et clusters Swarm automatiquement  . Par exemple, CapRover se lance souvent via un conteneur ou un script CLI d\u00e9di\u00e9. Ses plus : SSL gratuit automatiquement, load-balancer Nginx pr\u00e9-configur\u00e9, catalogues d\u2019apps pr\u00eats \u00e0 l\u2019emploi. C\u2019est adapt\u00e9 si vous voulez un PaaS facile pour d\u00e9ployer des sites et APIs, mais si vous cherchez juste un dashboard Docker pur, c\u2019est une solution plus lourde.</p> </li> <li> <p>Swarmpit  : une interface orient\u00e9e  Docker Swarm. Swarmpit offre la gestion de stacks (cr\u00e9ation via Compose ou g\u00e9n\u00e9ration automatique), la supervision des ressources (CPU, RAM, disque) en temps r\u00e9el, le d\u00e9ploiement de services et la recherche dans les registres Docker  . Il supporte plusieurs utilisateurs avec permissions, prend en charge les registres priv\u00e9s et peut auto-re-d\u00e9ployer un service quand une nouvelle image arrive  . C\u2019\u00e9tait une alternative pour Swarm, mais le projet semble moins actif aujourd\u2019hui.</p> </li> <li> <p>Autres  : on pourrait aussi mentionner des projets comme  Docker Compose UI  (anc\u00eatre pour gestion Compose en web, peu maintenu),  DockStation,  LazyDocker  (console TUI), voire l\u2019extension  Cockpit  pour g\u00e9rer containers (avec Podman) sur Linux. Chacun cible un besoin particulier, mais Portainer/Dockge/Yacht restent les plus utilis\u00e9s en auto-h\u00e9bergement.</p> </li> </ul>"},{"location":"outils/docker/#cas-dusage-concrets","title":"Cas d\u2019usage concrets","text":"<p>Les diff\u00e9rentes interfaces Docker servent typiquement aux cas suivants :</p> <ul> <li> <p>Gestion multi-h\u00f4tes  : si vous avez plusieurs machines Docker \u00e0 piloter, Portainer (avec son agent) ou CapRover (Swarm) sont adapt\u00e9s. Portainer peut agr\u00e9ger plusieurs environnements et afficher un tableau de bord unifi\u00e9  . Yacht et Dockge g\u00e8rent un seul h\u00f4te (pas d\u2019agent multi-serveur)  .</p> </li> <li> <p>Supervision de conteneurs critiques  : pour surveiller l\u2019\u00e9tat des conteneurs (logs, CPU, m\u00e9moire, sant\u00e9), Portainer offre des graphiques et l\u2019outil  docker stats  (accessible via l\u2019interface)  . Yacht affiche les stats CPU/M\u00e9moire directement sur le tableau de bord. Dockge est plus basique et ne fournit pas de monitorings avanc\u00e9s (on peut se contenter de Watchtower pour les mises \u00e0 jour d\u2019images). Pour une supervision pouss\u00e9e (alertes, m\u00e9triques sur le long terme), on combinera souvent ces UIs avec des outils d\u00e9di\u00e9s (Prometheus/Grafana, etc.), car ces interfaces n\u2019ont pas un syst\u00e8me d\u2019alerte int\u00e9gr\u00e9.</p> </li> <li> <p>D\u00e9ploiement d\u2019applications (stacks multi-conteneurs)  : toutes ces interfaces permettent de d\u00e9ployer des applications compos\u00e9es (via Docker Compose ou templates). Par exemple, Portainer et Yacht disposent de \u00ab\u202ftemplates\u202f\u00bb pr\u00eats \u00e0 l\u2019emploi (catalogues d\u2019apps) pour installer en 1 clic des applications populaires (WordPress, Nextcloud, etc.). Dockge, lui, s\u2019appuie sur des fichiers Docker Compose existants : on scanne un dossier  /opt/stackspour importer des stacks. CapRover propose des catalogues d\u2019apps One-Click similaires (bases de donn\u00e9es, CMS, frameworks). En r\u00e9sum\u00e9, pour \u00ab\u202fpackager\u202f\u00bb et d\u00e9ployer une application complexe, ces outils simplifient grandement le processus par rapport \u00e0 la gestion manuelle de  docker-compose up, surtout pour les d\u00e9butants.</p> </li> <li> <p>Documentation et apprentissage  : ces interfaces rendent visibles les configurations Docker (volumes, r\u00e9seaux, variables d\u2019environnement), ce qui aide \u00e0 comprendre et documenter l\u2019architecture d\u2019une application. Par exemple, Portainer permet de visualiser facilement les r\u00e9seaux utilis\u00e9s et la pile d\u2019un stack d\u00e9ploy\u00e9, ce qui est utile en d\u00e9pannage. Dockge, de son c\u00f4t\u00e9, force \u00e0 travailler en YAML, ce qui peut \u00eatre formateur pour ma\u00eetriser Docker Compose.</p> </li> </ul>"},{"location":"outils/docker/#installation-et-configuration","title":"Installation et configuration","text":"<p>Voici les \u00e9tapes cl\u00e9s pour d\u00e9ployer Docker + l\u2019interface choisie (ex. Portainer ou Dockge) :</p> <ol> <li>Installer Docker Engine. Sur une machine Linux (Debian/Ubuntu), on commence par mettre \u00e0 jour le syst\u00e8me puis ajouter le d\u00e9p\u00f4t Docker officiel  . Par exemple :</li> </ol> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg \\\n  -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n  https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" \\\n  | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\nsudo apt update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\nsudo usermod -aG docker $USER\n</code></pre> <p>Ces commandes installent Docker CE ainsi que le plugin Compose V2 et ajoutent votre utilisateur au groupe  docker. Apr\u00e8s cela, un  docker run hello-world  devrait r\u00e9ussir.</p> <ol> <li> <p>Installer dans un conteneur LXC (optionnel). Si vous utilisez Proxmox LXC, il est possible de faire tourner Docker dans un container (bien que Proxmox recommande plut\u00f4t un VM pour Docker). En conteneur LXC non-privilegi\u00e9, il faut activer le  nesting  et  keyctl. Par exemple, dans la configuration LXC ajouter : <pre><code>features: keyctl=1,nesting=1\n</code></pre> Ensuite, \u00e0 l\u2019int\u00e9rieur du LXC on r\u00e9installe Docker comme ci-dessus. Des utilisateurs rapportent que cela fonctionne avec  keyctl  et  nesting=1  .</p> </li> <li> <p>D\u00e9ployer Portainer  (par exemple). Une fois Docker en place, cr\u00e9ez un volume de donn\u00e9es et lancez Portainer : <pre><code>docker volume create portainer_data\ndocker run -d \\\n  -p 8000:8000 -p 9443:9443 \\\n  --name portainer --restart=always \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v portainer_data:/data \\\n  portainer/portainer-ce:lts\n</code></pre> Ceci d\u00e9marre Portainer Community Edition (version LTS) en mode standalone. On peut alors acc\u00e9der \u00e0 l\u2019interface web sur  https://localhost:9443  et d\u00e9finir un mot de passe admin  . Pour d\u00e9ployer Portainer BE (3 n\u0153uds gratuits), la proc\u00e9dure est similaire en rempla\u00e7ant l\u2019image par  portainer/portainer-ee:lts.</p> </li> <li> <p>D\u00e9ployer Dockge. Cr\u00e9ez d\u2019abord les dossiers requis (/opt/stacks  pour vos stacks,  /opt/dockge  pour le compose de Dockge), puis t\u00e9l\u00e9chargez le YAML de Dockge et lancez-le : <pre><code>mkdir -p /opt/stacks /opt/dockge\ncd /opt/dockge\ncurl -fsSL https://raw.githubusercontent.com/louislam/dockge/master/compose.yaml \\\n  -o compose.yaml\ndocker compose up -d\n</code></pre> Dockge sera alors disponible sur le port configur\u00e9 (5001 par d\u00e9faut)  . On y acc\u00e8de via  http://:5001. Si vous pr\u00e9f\u00e9rez utiliser  docker-compose  v1 ou Podman, remplacez simplement par  docker-compose up -d. <li> <p>D\u00e9ployer Yacht. Exemple rapide : <pre><code>docker volume create yacht\ndocker run -d \\\n  -p 8000:8000 \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v yacht:/config \\\n  selfhostedpro/yacht\n</code></pre></p> </li> <p>Apr\u00e8s lancement, Yacht \u00e9coute sur le port 8000 (\u00e0 changer si conflit avec Portainer). L\u2019interface est alors accessible sur  http://:8000  . <ol> <li>Configuration r\u00e9seau et reverse proxy. Il est fortement conseill\u00e9 de placer ces interfaces derri\u00e8re un reverse proxy HTTPS (Traefik, Nginx, Caddy, etc.) pour s\u00e9curiser l\u2019acc\u00e8s. Par exemple, on peut utiliser  nginx-proxy  (containers automatiques) et configurer  VIRTUAL_HOST=portainer.mondomaine.tld  et  VIRTUAL_PORT=9000  pour obtenir un certificat Let\u2019s Encrypt automatiquement  . Un extrait de configuration Compose type (Portainer CE) : <pre><code>services:\n  nginx-proxy:\n    image: nginxproxy/nginx-proxy\n    ports: [\"80:80\",\"443:443\"]\n    volumes:\n      - \"/var/run/docker.sock:/tmp/docker.sock:ro\"\n  portainer:\n    image: portainer/portainer-ce:lts\n    restart: always\n    environment:\n      - VIRTUAL_HOST=portainer.mondomaine.tld\n      - VIRTUAL_PORT=9000\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - portainer_data:/data\n    expose:\n      - \"9443\"\n</code></pre></li> </ol> <p>Ensuite, on pointe  portainer.mondomaine.tld  vers l\u2019IP de l\u2019h\u00f4te dans DNS. Cette m\u00e9thode assure une connexion HTTPS et peut \u00eatre \u00e9tendue \u00e0 Dockge (via Traefik labels ou environnement similaire) et Yacht.</p> <ol> <li>S\u00e9curiser l\u2019acc\u00e8s et authentification. Chaque interface a sa propre m\u00e9thode d\u2019authentification : Portainer demande un compte admin d\u00e8s l\u2019installation (et peut activer 2FA en Business Edition), Yacht a un login initial (admin@yacht.local  /  pass  \u00e0 changer imp\u00e9rativement)  , Dockge n\u2019a pas d\u2019authentification native et repose sur la protection r\u00e9seau (d\u2019o\u00f9 l\u2019int\u00e9r\u00eat du reverse proxy ou VPN). Il est imp\u00e9ratif de choisir des mots de passe forts, de tenir le logiciel \u00e0 jour, et id\u00e9alement de limiter les acc\u00e8s (par exemple via un VPN ou contr\u00f4le d\u2019acc\u00e8s du proxy).</li> </ol>"},{"location":"outils/docker/#limites-et-alternatives-kubernetes-vs-docker-compose-etc","title":"Limites et alternatives (Kubernetes vs Docker Compose, etc.)","text":"<p>Chaque solution a ses limites. Portainer, Dockge et consorts sont con\u00e7us pour des d\u00e9ploiements  Docker (et \u00e9ventuellement Swarm)  de petite \u00e0 moyenne \u00e9chelle. Si votre usage devient plus complexe (centaines de conteneurs, forte mont\u00e9e en charge, d\u00e9ploiement multi-cluster), une vraie plateforme d\u2019orchestration comme  Kubernetes  sera pr\u00e9f\u00e9rable. Kubernetes offre la scalabilit\u00e9 automatique (autoscaling), la haute disponibilit\u00e9 multi-n\u0153uds et une vaste \u00e9cosyst\u00e8me. En effet,  \u00ab Kubernetes est con\u00e7u pour g\u00e9rer des d\u00e9ploiements \u00e0 grande \u00e9chelle sur des clusters de machines, avec des fonctionnalit\u00e9s avanc\u00e9es (load balancing, autoscaling, scheduling) . Portainer est plus l\u00e9ger et reste limit\u00e9 aux petits d\u00e9ploiements\u202f\u00bb. Son apprentissage est plus difficile, mais il est plus robuste en production. \u00c0 l\u2019inverse, Docker Compose ou une interface graphique simple (Portainer/Dockge/Yacht) suffisent quand on n\u2019a qu\u2019un petit nombre de services sur un ou quelques serveurs. Par exemple, de nombreux d\u00e9veloppeurs cr\u00e9ent d\u2019abord localement avec Compose, et migrent vers Kubernetes en production pour scaler selon la charge  .</p> <p>Pour r\u00e9sumer :</p> <ul> <li> <p>Quand pr\u00e9f\u00e9rer Docker Compose pur (ligne de commande)  : pour un projet simple (un seul serveur, quelques conteneurs), l\u2019interface graphique peut \u00eatre inutile. La CLI Docker Compose reste l\u00e9g\u00e8re et suffit.</p> </li> <li> <p>Quand pr\u00e9f\u00e9rer un outil comme Portainer/Dockge/Yacht  : pour simplifier la gestion visuelle des conteneurs, faciliter les d\u00e9ploiements en \u00e9quipe ou la d\u00e9couverte de l\u2019architecture, surtout sur des environnements test/homelab ou sur un serveur unique.</p> </li> <li> <p>Quand passer \u00e0 Kubernetes  : en environnement critique d\u2019entreprise, avec besoin de redondance, de roulement transparent des mises \u00e0 jour, de besoins de ressources \u00e9lastiques. Portainer propose m\u00eame un mode K8s pour visualiser certains aspects, mais cela n\u2019\u00e9gale pas un cluster Kubernetes natif pour des usages intensifs  .</p> </li> </ul> <p>En d\u00e9finitive, Portainer et Dockge sont des outils puissants pour l\u2019auto-h\u00e9bergement Docker, chacun avec ses forces et ses limites  . Le choix d\u00e9pendra donc du contexte : nombre d\u2019h\u00f4tes \u00e0 administrer, types d\u2019applications \u00e0 d\u00e9ployer, exigences de s\u00e9curit\u00e9 et d\u2019\u00e9volutivit\u00e9. Dans tous les cas, il est important de mettre en place les bonnes pratiques (Reverse proxy SSL, gestion des utilisateurs, mises \u00e0 jour r\u00e9guli\u00e8res) pour profiter en toute s\u00e9curit\u00e9 de ces interfaces web  .</p>"},{"location":"outils/favoris/","title":"Karakeep \u2013 gestionnaire de favoris tout-en-un","text":"<p>Karakeep (anciennement  Hoarder) est un gestionnaire de favoris  open source  auto-h\u00e9berg\u00e9 (\u00ab bookmark\u2011everything app \u00bb) qui stocke non seulement des liens, mais aussi des notes, des images et des PDF  . Son interface web moderne (ci-dessus) permet d\u2019ajouter facilement du contenu et de l\u2019organiser dans des listes. Karakeep automatise la r\u00e9cup\u00e9ration des m\u00e9tadonn\u00e9es (titres, descriptions, images) de chaque lien  , propose un  moteur de recherche plein texte  sur tout le contenu stock\u00e9  , et inclut une fonction d\u2019archivage complet de pages web  (via l\u2019outil  Monolith  pour contrer la disparition des liens)  . Des  extensions navigateur  (Chrome, Firefox) et des applications mobiles (iOS, Android) sont disponibles pour capturer rapidement du contenu  . Enfin, Karakeep int\u00e8gre des fonctions bas\u00e9es sur l\u2019IA  : g\u00e9n\u00e9ration automatique de mots-cl\u00e9s (tags) et r\u00e9sum\u00e9s par ChatGPT ou mod\u00e8les locaux (via Ollama)  . Ces fonctionnalit\u00e9s (archivage de pages, recherche full-text, extensions et IA) permettent d\u2019exploiter Karakeep comme un hub personnel de veille ou de documentation  .</p>"},{"location":"outils/favoris/#comparatif-avec-dautres-solutions-open-source","title":"Comparatif avec d\u2019autres solutions open-source","text":"<p>Plusieurs autres gestionnaires de favoris auto-h\u00e9berg\u00e9s existent, chacun avec ses points forts :</p> <ul> <li> <p>Linkding  : outil l\u00e9ger et minimaliste, optimis\u00e9 pour la rapidit\u00e9  . Il r\u00e9cup\u00e8re automatiquement titre, description et ic\u00f4nes des sites  . Il offre un  archivage de pages  (sauvegarde au format HTML local ou sur Internet Archive)  , des  extensions Chrome/Firefox  pour ajouter/rechercher des liens  , et une API REST. Par contre, il n\u2019a pas d\u2019int\u00e9gration IA ni d\u2019app mobile d\u00e9di\u00e9e.</p> </li> <li> <p>Shaarli  : gestionnaire tr\u00e8s simple mono-utilisateur (pas de base de donn\u00e9es, tout est stock\u00e9 dans un fichier)  . Il sert \u00e0 \u00ab partager, commenter et sauvegarder \u00bb des liens  , et peut se transformer en blog l\u00e9ger ou wiki personnel. Shaarli inclut recherche textuelle sur les titres/descriptions  et prise en charge des  tags  , mais n\u2019offre pas d\u2019archivage de pages ni de fonctionnalit\u00e9s avanc\u00e9es (pas d\u2019extensions officielles, juste un bookmarklet  ).</p> </li> <li> <p>Omnivore  : application orient\u00e9e \u00ab read-it-later \u00bb (pour lire plus tard) et centr\u00e9e sur le texte  . Elle propose surlignage, prise de notes et partage social, ainsi que la sauvegarde de position de lecture ou de newsletters via email  . Omnivore supporte les  extensions navigateurs  (Chrome, Safari, Firefox, Edge) et le hors-ligne  . Elle permet la gestion de contenus web et PDF, mais ne g\u00e8re pas nativement d\u2019images ou de m\u00e9dias divers comme Karakeep. Omnivore inclut aussi des  tags  (\u00e9tiquettes) pour organiser les articles  .</p> </li> </ul> <p>Ainsi, Karakeep se distingue par son p\u00e9rim\u00e8tre plus large (liens + notes + images + flux RSS) et ses fonctions avanc\u00e9es (archivage complet, IA), tandis que Linkding et Shaarli visent la simplicit\u00e9, et Omnivore la lecture optimis\u00e9e de contenus textuels.</p>"},{"location":"outils/favoris/#fonctionnalites-cles-de-karakeep","title":"Fonctionnalit\u00e9s cl\u00e9s de Karakeep","text":"<ul> <li> <p>Archivage de pages web  : Karakeep peut enregistrer la page compl\u00e8te (via Monolith) et m\u00eame archiver les vid\u00e9os (YouTube-DL), garantissant la p\u00e9rennit\u00e9 du contenu  .</p> </li> <li> <p>Recherche plein-texte  : gr\u00e2ce \u00e0 Meilisearch, tous les mots du contenu sauv\u00e9 sont index\u00e9s, permettant des recherches rapides dans les articles, notes et transcriptions  .</p> </li> <li> <p>Extensions et applications  : un module  Chrome  et un  Firefox addon  permettent d\u2019ajouter un lien ou un extrait en un clic depuis le navigateur  . Les apps mobiles (Android, iOS) et le support PWA facilitent l\u2019ajout de contenu depuis un smartphone.</p> </li> <li> <p>Int\u00e9gration IA  : Karakeep attribue automatiquement des tags et g\u00e9n\u00e8re des r\u00e9sum\u00e9s de contenu via ChatGPT ou des mod\u00e8les locaux (Ollama) pour faciliter la classification et la lecture rapide  .</p> </li> <li> <p>Autres fonctionnalit\u00e9s  : OCR int\u00e9gr\u00e9 pour extraire le texte d\u2019images, capture d\u2019\u00e9crans plein-page, moteur de r\u00e8gles personnalis\u00e9es, actions group\u00e9es, support SSO, mode sombre, etc.</p> </li> </ul>"},{"location":"outils/favoris/#installation-de-karakeep","title":"Installation de Karakeep","text":""},{"location":"outils/favoris/#avec-docker-compose","title":"Avec Docker Compose","text":"<p>La m\u00e9thode recommand\u00e9e est via Docker. Apr\u00e8s avoir install\u00e9 Docker et Docker Compose, cr\u00e9ez un dossier sur votre serveur (par exemple  karakeep-app) et placez-y le fichier  docker-compose.yml  officiel  (disponible sur GitHub). Puis cr\u00e9ez un fichier  .env  o\u00f9 vous d\u00e9finissez les variables cl\u00e9s (SECRET, URL, cl\u00e9 Meili, etc)  . Par exemple :</p> <p><pre><code>KARAKEEP_VERSION=release\nNEXTAUTH_SECRET=&lt;cl\u00e9_s\u00e9cr\u00e8te&gt;\nMEILI_MASTER_KEY=&lt;cl\u00e9_meilisearch&gt;\nNEXTAUTH_URL=http://localhost:3000\n</code></pre> Apr\u00e8s avoir personnalis\u00e9 ces valeurs (changer les cl\u00e9s, indiquer votre domaine dans  NEXTAUTH_URL, etc.), lancez Karakeep avec : <pre><code>docker compose up -d\n</code></pre></p> <p>Vous devriez pouvoir acc\u00e9der \u00e0 l\u2019interface sur  http://localhost:3000  (ou votre domaine en prod)  . Le fichier Compose configure d\u00e9j\u00e0 le r\u00e9seau et les volumes n\u00e9cessaires. Pour activer l\u2019IA, ajoutez votre cl\u00e9 OpenAI dans  .env  (voir la doc)  .</p>"},{"location":"outils/favoris/#installation-bare-metal-script-debianubuntu","title":"Installation \u00ab bare-metal \u00bb (script Debian/Ubuntu)","text":"<p>Karakeep fournit un script d\u2019installation pour Debian 12/Ubuntu 24.04 (adapt\u00e9 d\u2019un module Proxmox)  . Ce script t\u00e9l\u00e9charge et installe toutes les d\u00e9pendances (Karakeep, Meilisearch pour la recherche plein texte, navigateur Chrome sans interface graphique, etc.), cr\u00e9e les services syst\u00e8me (karakeep-web,  meilisearch, etc.) et les configure pour d\u00e9marrer automatiquement  . Il s\u2019ex\u00e9cute en root (bash karakeep-linux.sh install). Cette approche convient pour installer Karakeep directement sur un serveur (ou dans un conteneur LXC Debian/Ubuntu) sans passer par Docker.</p>"},{"location":"outils/favoris/#reseau-et-reverse-proxy","title":"R\u00e9seau et Reverse Proxy","text":"<p>En production, il est conseill\u00e9 de mettre Karakeep derri\u00e8re un reverse proxy afin de g\u00e9rer le SSL et les noms de domaine. Par exemple, un conteneur  Caddy  peut automatiquement obtenir des certificats Let\u2019s Encrypt et rediriger le trafic HTTPS vers Karakeep  . Dans ce cas, on cr\u00e9e un r\u00e9seau Docker partag\u00e9 entre Karakeep et Caddy, on expose Karakeep sur un port interne (par ex.  3000), et Caddy se charge de publier Karakeep sous  https://mon-domaine.com  via  reverse_proxy karakeep_web:3000  . On peut aussi utiliser  Nginx+Certbot ou tout autre proxy inverse. L\u2019important est de faire pointer votre nom de domaine vers le serveur et de proxyfier le port 3000 de Karakeep en HTTPS s\u00e9curis\u00e9.</p>"},{"location":"outils/favoris/#cas-dusage-en-cybersecurite-homelab","title":"Cas d\u2019usage en cybers\u00e9curit\u00e9 / homelab","text":"<p>Dans un homelab de cybers\u00e9curit\u00e9, Karakeep peut servir de  plate-forme de veille et de documentation. On peut y centraliser des liens vers des CVE, des tutoriels, des articles de blog, des outils de pentest, etc. Karakeep autorise l\u2019import de flux  RSS  : en s\u2019abonnant aux blogs de s\u00e9curit\u00e9 ou alertes techniques, il \u00ab pioche \u00bb automatiquement les nouveaux articles  . La fonction de recherche plein texte facilite ensuite de retrouver une information pr\u00e9cise (ex. vuln\u00e9rabilit\u00e9, commande Linux\u2026). On peut aussi annoter les contenus ou prendre des notes internes pour les r\u00e9utiliser.</p> <p>De mani\u00e8re g\u00e9n\u00e9rale, Karakeep cr\u00e9e une  biblioth\u00e8que de ressources  partag\u00e9e. Comme le souligne l\u2019outil Reminiscence (\u00e9voqu\u00e9 sur Awesome-Homelab), un bookmark manager auto-h\u00e9berg\u00e9 est id\u00e9al pour b\u00e2tir une base de connaissances personnelle ou collaborative  . Il permet notamment de regrouper et d\u2019archiver des liens utiles \u00e0 une \u00e9quipe (ing\u00e9nieurs, pentesteurs) ou \u00e0 un projet de recherche. En somme, Karakeep transforme votre collection de favoris en un v\u00e9ritable centre de documentation et de veille sur mesure.</p>"},{"location":"outils/gestion-fichiers/","title":"Gestion de fichiers auto-h\u00e9berg\u00e9e","text":"<p>Les solutions de gestion de fichiers self-hosted permettent d\u2019acc\u00e9der et partager ses documents via une interface web en conservant ses donn\u00e9es chez soi. Parmi les plus populaires,  File Browser  (un gestionnaire de fichiers web l\u00e9ger) et  Nextcloud Files  (une suite compl\u00e8te de sync &amp; partage) se distinguent. D\u2019autres alternatives existent (Seafile, Pydio Cells, FileRun, Filestash, etc.) offrant chacune des fonctionnalit\u00e9s particuli\u00e8res. L\u2019objectif est de comparer ces solutions selon leur interface, permissions, synchronisation, acc\u00e8s distant et protocoles support\u00e9s, en tenant compte de l\u2019usage en \u00ab homelab \u00bb (stockage perso, partage local/externe, sauvegardes, multi-utilisateur) et des aspects de s\u00e9curit\u00e9 (chiffrement, audit, SSO, HTTPS, droits granulaires).</p>"},{"location":"outils/gestion-fichiers/#comparaison-technique-des-solutions","title":"Comparaison technique des solutions","text":"<ul> <li> <p>File Browser  : c\u2019est un gestionnaire de fichiers web simple et rapide  . On l\u2019installe sur un serveur en pointant un r\u00e9pertoire racine (filebrowser -r /chemin/vers/fichiers), et on acc\u00e8de aux fichiers via une interface web \u00e9pur\u00e9e. Il permet de  t\u00e9l\u00e9verser, supprimer, pr\u00e9visualiser, renommer et modifier  les fichiers, avec gestion multi-utilisateurs  (avec r\u00f4les Admin/User). Il n\u2019inclut pas de clients de synchronisation automatique : tout passe par l\u2019interface HTTP. File Browser prend en charge l\u2019\u00e9dition de fichiers en ligne et des commandes personnalis\u00e9es, mais reste limit\u00e9 \u00e0 ses propres fonctionnalit\u00e9s. Il ne propose pas de chiffrement c\u00f4t\u00e9 serveur ni d\u2019audit avanc\u00e9 (log minimal).\u202f</p> </li> <li> <p>Nextcloud Files  : c\u2019est une plateforme cloud compl\u00e8te (sync &amp; share) qui propose une  interface web moderne, des clients de synchronisation (Windows/Mac/Linux) et des applis mobiles  . Elle offre la  collaboration en temps r\u00e9el(\u00e9dition de documents, notes, etc.), la recherche unifi\u00e9e et le partage s\u00e9curis\u00e9. Nextcloud supporte de nombreux protocoles et int\u00e9grations : on peut acc\u00e9der aux fichiers via WebDAV, FTP, SMB/CIFS, NFS, SharePoint, ou en stockant les donn\u00e9es sur des stockages externes (S3, OpenStack Swift, etc.)  . En termes de permissions, Nextcloud permet des partages publics avec mot de passe/expiration, ou priv\u00e9s aux utilisateurs/groupes, avec droits (lecture/\u00e9criture/commentaire) tr\u00e8s granulaires  . C\u00f4t\u00e9 s\u00e9curit\u00e9, Nextcloud inclut des  fonctionnalit\u00e9s de cryptage puissant(chiffrement c\u00f4t\u00e9 serveur et chiffrement de bout-en-bout pour les partages sensibles)  , ainsi que des contr\u00f4les d\u2019acc\u00e8s aux fichiers bas\u00e9s sur des r\u00e8gles avanc\u00e9es et des protections anti-ransomware/brute-force  . Des apps Nextcloud permettent d\u2019ajouter SSO/SAML, LDAP/AD et MFA pour l\u2019authentification.</p> </li> <li> <p>Autres solutions  : on trouve notamment  Pydio Cells  (plateforme de partage de fichiers orient\u00e9e entreprise) et  Seafile. Pydio se veut \u00ab privacy-friendly \u00bb et permet aux \u00e9quipes de travailler ensemble sur un cloud interne  . Seafile est ax\u00e9 synchronisation et partage fiable, avec chiffrement des biblioth\u00e8ques et travail en groupe  . Ces solutions incluent g\u00e9n\u00e9ralement leurs propres clients desktop/mobiles et protocoles (par ex. WebDAV pour Pydio).  Filestash  (anciennement Nuage) est un client web multi-protocoles (FTP/SFTP/S3/WebDAV/Git, etc.) qui sert \u00e0 monter diverses sources de fichiers.  FileRun  est un gestionnaire Web (type Google Drive) avec base de donn\u00e9es, partage de liens et visionneuse int\u00e9gr\u00e9e. Chacune diff\u00e8re par la richesse fonctionnelle et l\u2019ergonomie : Nextcloud propose le plus de fonctionnalit\u00e9s (agenda, mail, chat, bureautique en ligne\u2026), File Browser offre la plus grande l\u00e9g\u00e8ret\u00e9 et simplicit\u00e9, Pydio et Seafile se positionnent sur la collaboration d\u2019\u00e9quipe. L\u2019utilisation de l\u2019une ou l\u2019autre d\u00e9pendra du besoin : simple partage de fichiers (File Browser), cloud personnel complet (Nextcloud), synchronisation de dossiers collaboratifs (Seafile) ou int\u00e9gration multi-protocoles (Filestash).</p> </li> </ul>"},{"location":"outils/gestion-fichiers/#integration-avec-differents-nas","title":"Int\u00e9gration avec diff\u00e9rents NAS","text":"<p>Dans un homelab on utilise souvent un NAS (Network Attached Storage) pour centraliser les donn\u00e9es. Les principales plateformes NAS (Synology, QNAP, TrueNAS, OpenMediaVault, Unraid, etc.) proposent des outils de gestion de fichiers et des protocoles vari\u00e9s. Par exemple,  Synology DSM  inclut  File Station, un gestionnaire centralis\u00e9 accessible par navigateur, et  Synology Drive  pour la synchronisation. Les fichiers du NAS sont expos\u00e9s via les protocoles  SMB, NFS, AFP, FTP et WebDAV  , rendant l\u2019acc\u00e8s possible depuis Windows, macOS ou mobiles. Synology permet de configurer des partages publics ou priv\u00e9s avec mots de passe, expiration, quotas et ACLs fines  . De m\u00eame,  QNAP  offre File Station avec des fonctionnalit\u00e9s proches.</p> <p>D\u2019autres OS de NAS (\u00ab\u202fDIY NAS\u202f\u00bb sur serveurs g\u00e9n\u00e9riques) supportent aussi ces logiciels : par exemple,  OpenMediaVault (OMV)  sous Linux ou  TrueNAS  (FreeBSD) permettent d\u2019installer Nextcloud ou File Browser via Docker/jails. On peut h\u00e9berger un conteneur Nextcloud sur un NAS Synology, QNAP (via Container Station) ou sur un syst\u00e8me comme OMV gr\u00e2ce au plugin Docker (\u00ab OMV-Extras \u00bb) ou via LXC sur Proxmox/TrueNAS SCALE. Les NAS libres offrent souvent des plugins ou images pour Nextcloud/OnlyOffice. Ainsi, on peut soit utiliser le gestionnaire natif du NAS, soit d\u00e9ployer l\u2019application tierce (Nextcloud, FileBrowser, etc.) sur le m\u00eame mat\u00e9riel. En r\u00e9sum\u00e9, quel que soit le type de NAS, les fichiers peuvent \u00eatre servis directement (partage SMB/NFS traditionnel) et/ou via une solution web auto-h\u00e9berg\u00e9e qui profite alors du stockage du NAS.</p>"},{"location":"outils/gestion-fichiers/#cas-dusage-en-homelab","title":"Cas d\u2019usage en homelab","text":"<ul> <li> <p>Stockage personnel et synchronisation  : Nextcloud est id\u00e9al pour une \u00ab\u202fprivate cloud\u202f\u00bb maison \u2013 chaque appareil peut synchroniser des dossiers (photos, documents) vers le serveur Nextcloud, offrant un backup et une disponibilit\u00e9 multi-appareils  . File Browser peut servir de d\u00e9p\u00f4t central simple, auquel on charge manuellement les fichiers via l\u2019interface. Dans les deux cas, on acc\u00e8de \u00e0 ses donn\u00e9es depuis le r\u00e9seau local ou Internet (avec des DNS dynamiques ou domaine personnalis\u00e9).</p> </li> <li> <p>Partage local et externe  : on peut partager des fichiers avec la famille ou des collaborateurs. Nextcloud permet de cr\u00e9er des liens publics prot\u00e9g\u00e9s (mot de passe, expiration) ou de partager directement avec d\u2019autres comptes Nextcloud, tr\u00e8s pratique pour \u00e9changer des gros fichiers ou dossiers. File Browser offre un partage plus basique (compte utilisateur d\u00e9di\u00e9, liens directs en lecture seule). Dans un r\u00e9seau local (LAN), on peut simplement mapper le stockage r\u00e9seau (SMB/NFS) ; pour l\u2019ext\u00e9rieur, on ouvrira le port HTTPS ou via un reverse-proxy (voir s\u00e9curit\u00e9)  .</p> </li> <li> <p>Sauvegardes  : on peut sauvegarder les donn\u00e9es du NAS vers Nextcloud (utiliser des t\u00e2ches cron, rclone ou l\u2019app \u00abExternal storage\u00bb de Nextcloud pour r\u00e9pliquer un partage r\u00e9seau vers Nextcloud). Nextcloud propose aussi une app de sauvegarde pair-\u00e0-pair (Backups Nextcloud) permettant de dupliquer un Nextcloud chez un ami. File Browser ne g\u00e8re pas explicitement de sauvegardes, mais on peut sauvegarder le r\u00e9pertoire de fichiers via des outils externes (rsync, BorgBackup, Snapshots ZFS).</p> </li> <li> <p>Multi-utilisateur et collaboration  : Nextcloud g\u00e8re nativement plusieurs utilisateurs et groupes avec quotas et droits diff\u00e9rents, id\u00e9al pour un homelab familial ou associatif. On peut attribuer des permissions sur dossiers partag\u00e9s, et avoir diff\u00e9rents comptes (invit\u00e9s, experts, etc.). File Browser supporte \u00e9galement plusieurs utilisateurs (un admin et des utilisateurs)  , mais sans la granularit\u00e9 de Nextcloud. D\u2019autres solutions comme Seafile ajoutent le concept de \u00ab biblioth\u00e8ques \u00bb partag\u00e9es en groupe.</p> </li> </ul>"},{"location":"outils/gestion-fichiers/#securite","title":"S\u00e9curit\u00e9","text":"<ul> <li> <p>Chiffrement  : Nextcloud propose le chiffrement c\u00f4t\u00e9 serveur (de bout en bout pour certains partages sensibles via \u00abFile Drop\u00bb). L\u2019interface web permet d\u2019activer le chiffrement des donn\u00e9es au repos (soit en stockant sur serveur chiffr\u00e9, soit en E2EE pour les fichiers partag\u00e9s)  . File Browser ne chiffre pas les fichiers, on s\u2019appuie donc sur le chiffrement au niveau du disque ou volume (ex. LUKS sur le NAS) et sur le HTTPS.</p> </li> <li> <p>Acc\u00e8s r\u00e9seau s\u00e9curis\u00e9 (HTTPS / Reverse proxy)  : Il est imp\u00e9ratif d\u2019utiliser HTTPS pour prot\u00e9ger les \u00e9changes. On place typiquement File Browser ou Nextcloud derri\u00e8re un reverse-proxy (Nginx, Traefik, Caddy\u2026) fournissant TLS/SSL (certificats Let\u2019s Encrypt). Dans la DMZ du homelab (voir diagramme r\u00e9seau), on autorise seulement le port 443 vers le serveur de fichiers et on filtre selon les VLAN. Gr\u00e2ce au proxy, on peut \u00e9galement configurer une authentification avanc\u00e9e (Auth JWT, mTLS) si n\u00e9cessaire.</p> </li> <li> <p>Contr\u00f4les d\u2019acc\u00e8s et permissions granulaires  : Nextcloud permet d\u2019affiner les droits (lecture/\u00e9criture/commentaire) \u00e0 l\u2019\u00e9chelle du fichier ou dossier partag\u00e9  . On peut mettre des ACL Windows/NFS, limiter certains utilisateurs ou groupes, d\u00e9finir des quotas. File Browser se limite aux droits d\u2019un r\u00e9pertoire global par utilisateur (pas de partage public natif, pas d\u2019ACL complexes). Les NAS eux-m\u00eames (Synology, TrueNAS\u2026) int\u00e8grent des ACLs et peuvent prot\u00e9ger les partages par mot de passe.</p> </li> <li> <p>Authentification centrale (SSO/LDAP)  : Nextcloud peut s\u2019int\u00e9grer avec des annuaires LDAP/Active Directory pour g\u00e9rer les utilisateurs, et des solutions SSO (SAML, OAuth) via apps externes  . Par exemple, on peut connecter Keycloak ou Authelia \u00e0 Nextcloud. File Browser supporte l\u2019authentification interne ou externe (OAuth ou LDAP possible via configuration). Ainsi, on peut centraliser les comptes sur un annuaire du homelab.</p> </li> <li> <p>Audit et journaux  : Nextcloud g\u00e9n\u00e8re des journaux d\u00e9taill\u00e9s (logs de connexion, de partage, etc.) pour v\u00e9rifier les acc\u00e8s et d\u00e9tecter les anomalies. File Browser journalise de mani\u00e8re plus basique (activit\u00e9s d\u2019upload/suppression). On peut compl\u00e9ter avec un SIEM local : par exemple, collecter les logs (via Filebeat/Logstash) du serveur Nextcloud ou du NAS pour les analyser (architecture ELK/Kibana). Le tout afin de d\u00e9tecter d\u2019\u00e9ventuels acc\u00e8s suspects ou compromissions.</p> </li> </ul>"},{"location":"outils/gestion-fichiers/#installation-et-integration","title":"Installation et int\u00e9gration","text":"<ul> <li> <p>Docker et conteneurs  : Pour faciliter le d\u00e9ploiement, la plupart de ces outils fournissent des images Docker officielles. Par exemple,  Nextcloud All-in-One  propose un conteneur unique (\u00ab AIO \u00bb) qui installe et configure Nextcloud ainsi que ses d\u00e9pendances  . File Browser dispose aussi d\u2019une image Docker pr\u00eate \u00e0 l\u2019emploi  . On lancera ces conteneurs dans la DMZ ou sur l\u2019h\u00f4te, en montant les volumes de donn\u00e9es ad\u00e9quats. Sous Proxmox ou TrueNAS Scale, on peut utiliser un conteneur LXC/VM ou un plugin int\u00e9gr\u00e9.</p> </li> <li> <p>LXC / VM  : Si l\u2019on utilise Proxmox ou TrueNAS, on peut h\u00e9berger Nextcloud ou File Browser dans une machine virtuelle (avec Debian/Ubuntu) ou un conteneur LXC. Par exemple, on installe Docker dans la VM ou on d\u00e9ploie Nextcloud directement depuis les paquets officiels. Les images Docker sont pratiques, mais on peut aussi compiler/r\u00e9cup\u00e9rer l\u2019ex\u00e9cutable File Browser en binaire (Linux)  .</p> </li> <li> <p>Reverse proxy et routage  : On configure un reverse proxy pour g\u00e9rer le trafic HTTPS/HTTP. Par exemple, avec Nginx on redirige  https://files.mondomaine.fr  vers l\u2019IP interne de Nextcloud, en g\u00e9rant les certificats. Un reverse proxy peut \u00e9galement fournir un pare-feu applicatif (WAF) ou limiter les taux de connexion. Dans un script d\u2019installation (comme le guide Nextcloud AIO), on voit souvent la commande  docker run \u2026 --publish 80:80 --publish 443:443 --publish 8080:8080, mais derri\u00e8re il est courant d\u2019inverser la polarit\u00e9 : le proxy frontal (port 443) redirige vers le port interne du conteneur  . Il faut configurer dans Nextcloud l\u2019URL externe correcte et \u00e9ventuellement les en-t\u00eates de proxy (trusted_proxies).</p> </li> <li> <p>Authentification et utilisateurs  : On cr\u00e9era d\u2019abord un utilisateur administrateur (Nextcloud/AIO g\u00e9n\u00e8re un mot de passe par d\u00e9faut \u00e0 r\u00e9cup\u00e9rer dans les logs  ). Ensuite, on peut importer ou synchroniser les utilisateurs depuis LDAP/AD pour un acc\u00e8s SSO unique dans le homelab. L\u2019authentification peut \u00eatre renforc\u00e9e (2FA, cl\u00e9 U2F, tokens OTP) surtout pour les acc\u00e8s web externes. Il est recommand\u00e9 d\u2019activer des mots de passe forts et de limiter les tentatives (Nextcloud g\u00e8re la protection brute-force en natif  ).</p> </li> <li> <p>Reverse proxy / Firewall (DMZ)  : Dans l\u2019architecture r\u00e9seau (voir sch\u00e9ma), on place les serveurs de fichiers dans la DMZ \u00ab\u202fServices\u202f\u00bb derri\u00e8re le firewall (OPNsense). Le firewall ouvre les ports n\u00e9cessaires (443/TCP, 80 pour redirections, 22 si besoin de SFTP) depuis l\u2019Internet vers la DMZ, en isolant les autres VLAN (LAN perso, Lab). Cette configuration \u00ab neutre \u00bb limite les risques qu\u2019un service compromis atteigne le LAN interne.</p> </li> </ul>"},{"location":"outils/gestion-mots-de-passe/","title":"Gestionnaires de mots de passe auto-h\u00e9berg\u00e9s","text":"<p>Dans un homelab, on privil\u00e9gie souvent des gestionnaires auto-h\u00e9berg\u00e9s pour garder le contr\u00f4le total des donn\u00e9es sensibles. Voici un comparatif des solutions les plus populaires :</p> <ul> <li> <p>Vaultwarden (Bitwarden RS)  : alternative l\u00e9g\u00e8re \u00e0 Bitwarden \u00e9crite en Rust, offrant les m\u00eames fonctionnalit\u00e9s (application web, extensions navigateur, apps mobiles) tout en \u00e9tant tr\u00e8s \u00e9conome en ressources  . 100\u202f% compatible avec les clients officiels Bitwarden, il permet de partager des mots de passe via des \u00ab organisations \u00bb (famille/\u00e9quipe) et propose de nombreuses fonctions premium gratuitement  . En revanche, Vaultwarden n\u2019a pas fait l\u2019objet d\u2019audits de s\u00e9curit\u00e9 officiels (seul Bitwarden officiel publie des rapports d\u2019audit)  , et d\u00e9pend du support communautaire pour les mises \u00e0 jour et la s\u00e9curit\u00e9.</p> </li> <li> <p>Passbolt  : con\u00e7u pour les \u00e9quipes et la collaboration, Passbolt permet de partager finement les secrets entre utilisateurs (permissions par mot de passe ou dossier, \u00e9quipes, etc.) et poss\u00e8de une interface web tr\u00e8s intuitive  . Sa s\u00e9curit\u00e9 est renforc\u00e9e par un chiffrement bout-en-bout bas\u00e9 sur OpenPGP : chaque mot de passe est chiffr\u00e9 avec la cl\u00e9 publique de chacun des utilisateurs autoris\u00e9s, la cl\u00e9 priv\u00e9e ne quittant jamais le client  . Passbolt est r\u00e9guli\u00e8rement audit\u00e9 par des tiers (tests d\u2019intrusion, SOC2, etc.)  , ce qui lui conf\u00e8re un haut niveau de confiance. En contrepartie, l\u2019usage quotidien repose sur l\u2019extension de navigateur (obligatoire) et certaines fonctionnalit\u00e9s avanc\u00e9es (LDAP, rapports) ne sont disponibles que dans la version Pro payante.</p> </li> <li> <p>KeePassXC + Syncthing  : KeePassXC est un gestionnaire local multiplateforme (Windows/Linux/macOS) qui stocke les mots de passe dans un fichier chiffr\u00e9 (.kdbx)  . La base peut \u00eatre synchronis\u00e9e entre appareils via Syncthing ou tout autre service (Nextcloud, Dropbox, etc.)  . On prot\u00e8ge ce fichier par un mot de passe ma\u00eetre et, en option, un fichier-cl\u00e9 ou un dispositif mat\u00e9riel (par exemple YubiKey)  . Cette solution \u00ab old-school \u00bb est tr\u00e8s s\u00fbre (AES-256, certifi\u00e9 ANSSI) et totalement hors-ligne, mais elle est plus adapt\u00e9e \u00e0 un usage individuel ou familial \u2013 le partage simultan\u00e9 d\u2019un m\u00eame fichier par plusieurs utilisateurs peut entra\u00eener des conflits et ne g\u00e8re pas les r\u00f4les utilisateurs.</p> </li> <li> <p>Autres solutions  : Par exemple, si vous utilisez Nextcloud, l\u2019application  Passwords  est un gestionnaire int\u00e9gr\u00e9 qui offre une interface web moderne et le partage de mots de passe entre utilisateurs Nextcloud  . D\u2019autres projets open source existent (Psono, Teampass, Bitwarden Server officiel en auto-h\u00e9bergement, etc.), mais Vaultwarden, Passbolt et KeePassXC couvrent d\u00e9j\u00e0 la plupart des besoins courants dans un homelab.</p> </li> </ul>"},{"location":"outils/gestion-mots-de-passe/#securite-et-chiffrement","title":"S\u00e9curit\u00e9 et chiffrement","text":"<p>Tous ces gestionnaires chiffrent vos donn\u00e9es  client-side  (z\u00e9ro connaissance). Vaultwarden/Bitwarden utilise AES-256 pour le coffre et d\u00e9rive la cl\u00e9 depuis le mot de passe ma\u00eetre (PBKDF2 ou Argon2)  . Passbolt repose sur OpenPGP (RSA 2048) pour chiffrer chaque secret avec la cl\u00e9 publique des utilisateurs concern\u00e9s, la cl\u00e9 priv\u00e9e n\u2019\u00e9tant jamais envoy\u00e9e au serveur  . KeePassXC chiffre aussi la base de donn\u00e9es par AES-256 (avec chiffrement ChaCha20 optionnel)  . Ainsi, dans tous les cas, seul l\u2019utilisateur poss\u00e9dant le mot de passe ma\u00eetre (et la cl\u00e9 priv\u00e9e dans le cas de Passbolt) peut d\u00e9chiffrer les donn\u00e9es  .</p> <p>Authentification \u00e0 deux facteurs (2FA)  : Bitwarden/Vaultwarden supporte plusieurs m\u00e9thodes 2FA \u2013 applications TOTP (Google Authenticator, Authy, etc.), cl\u00e9s mat\u00e9rielles FIDO2/WebAuthn (YubiKey, Titan, etc.) et email/Duo pour les comptes premium  . Passbolt exige d\u00e9j\u00e0 \u00e0 la base deux facteurs (la cl\u00e9 priv\u00e9e + la passphrase) et peut \u00eatre configur\u00e9 pour accepter des facteurs suppl\u00e9mentaires (YubiKey, TOTP, etc.)  . KeePassXC ne g\u00e8re pas directement le 2FA, mais on peut consid\u00e9rer un fichier-cl\u00e9 ou un p\u00e9riph\u00e9rique YubiKey comme second facteur en plus du mot de passe.</p> <p>Audit &amp; conformit\u00e9  : Bitwarden (et donc Vaultwarden par h\u00e9ritage) fait l\u2019objet d\u2019audits annuels par Cure53 et d\u2019autres laboratoires  , avec certifications (ISO27001, SOC2) et bug bounty. Vaultwarden, en tant que projet communautaire, ne publie pas d\u2019audits formels  . Passbolt a pass\u00e9 avec succ\u00e8s plusieurs audits de s\u00e9curit\u00e9 et conformit\u00e9 r\u00e9cents  , et son code est open source et 100\u202f% auditable  . KeePassXC (et KeePass) ont une longue histoire de robustesse (KeePass 2.10 a \u00e9t\u00e9 certifi\u00e9 par l\u2019ANSSI)  , m\u00eame s\u2019ils n\u2019ont pas d\u2019audit de troisi\u00e8me partie r\u00e9gulier comme les pr\u00e9c\u00e9dents.</p> <p>Stockage local vs cloud  : Tous ces gestionnaires sont con\u00e7us pour \u00eatre auto-h\u00e9berg\u00e9s, sans d\u00e9pendre d\u2019un tiers cloud. Par exemple, Passbolt peut \u00eatre install\u00e9 sur votre propre serveur (de la Raspberry Pi \u00e0 un cluster HA)  , et il fonctionne de mani\u00e8re autonome derri\u00e8re votre firewall. Vaultwarden se d\u00e9ploie aussi sur votre serveur perso ou VPS. KeePassXC garde le fichier en local et on recommande de le sauvegarder/synchroniser via un service de confiance (Syncthing, Nextcloud). L\u2019id\u00e9e commune est que  vos mots de passe restent sous votre contr\u00f4le, sur votre infrastructure priv\u00e9e  , assurant ainsi un niveau maximal de confidentialit\u00e9.</p>"},{"location":"outils/gestion-mots-de-passe/#cas-dusage-en-homelab","title":"Cas d\u2019usage en homelab","text":"<p>Un homelab regroupe souvent plusieurs utilisateurs (famille, petit bureau). Voici quelques sc\u00e9narios typiques :</p> <ul> <li> <p>Partage multi-utilisateurs  : Passbolt est taill\u00e9 pour le travail d\u2019\u00e9quipe. Il permet de cr\u00e9er des groupes, g\u00e9rer des permissions fines et partager facilement des mots de passe ou des dossiers entre plusieurs utilisateurs (avec des r\u00f4les d\u2019acc\u00e8s)  . Vaultwarden/Bitwarden offre aussi des fonctionnalit\u00e9s \u00ab organisations \u00bb pour partager des coffres communs (id\u00e9al pour une famille ou un petit groupe), mais les fonctions avanc\u00e9es (rapports, provisioning) sont r\u00e9serv\u00e9es \u00e0 la version payante. KeePassXC n\u2019a pas de fonction de partage en natif : on se contente g\u00e9n\u00e9ralement de partager le fichier  .kdbx  via Syncthing, ce qui reste manuel et sans contr\u00f4le d\u2019acc\u00e8s.</p> </li> <li> <p>Partage familial/\u00e9quipe  : Par exemple, dans une famille, on peut cr\u00e9er une organisation Vaultwarden o\u00f9 chacun a son compte personnel et on y ajoute les identifiants communs (Wi-Fi, compte Netflix familial, etc.). En milieu professionnel ou dans un bureau collaboratif, Passbolt facilite le partage organis\u00e9 de comptes (serveurs, bases de donn\u00e9es, applications) avec historique et journaux, garantissant que seuls les membres d\u2019une \u00e9quipe autoris\u00e9e y ont acc\u00e8s. L\u2019application Nextcloud Passwords (si vous utilisez Nextcloud) permet \u00e9galement le partage de mots de passe entre utilisateurs Nextcloud de mani\u00e8re transparente  .</p> </li> <li> <p>Int\u00e9gration LDAP / annuaire  : Dans un homelab ou une PME, on peut vouloir synchroniser les utilisateurs depuis un annuaire central (AD/LDAP). Passbolt Pro (version commerciale) propose un connecteur LDAP/AD qui importe automatiquement les utilisateurs et groupes de l\u2019annuaire dans Passbolt  , simplifiant la gestion des comptes. En revanche, Vaultwarden/Bitwarden et KeePassXC n\u2019int\u00e8grent pas nativement LDAP (on doit cr\u00e9er manuellement chaque compte Bitwarden). Notez qu\u2019il existe des moyens d\u00e9tourn\u00e9s (SSO ou script de provisioning) pour Bitwarden, mais rien de int\u00e9gr\u00e9 comme chez Passbolt.</p> </li> </ul>"},{"location":"outils/gestion-mots-de-passe/#installation-et-integration-docker-reverse-proxy-sauvegardes","title":"Installation et int\u00e9gration (Docker, reverse proxy, sauvegardes)","text":"<p>Ces gestionnaires se d\u00e9ploient g\u00e9n\u00e9ralement en conteneurs Docker pour la facilit\u00e9. Par exemple,  Vaultwarden  s\u2019installe en quelques commandes Docker Compose : on utilise l\u2019image  vaultwarden/server  et on monte un volume local (par ex.  ./vw-data) pour stocker la base de donn\u00e9es chiffr\u00e9e, les pi\u00e8ces jointes et les logs  . Le guide recommande d\u2019utiliser un tag de version fixe plut\u00f4t que  latest  pour garder le contr\u00f4le des mises \u00e0 jour  .  Passbolt CE  fournit \u00e9galement un fichier  docker-compose.yml  d\u2019exemple \u00e0 t\u00e9l\u00e9charger  : il faut le configurer (URL publique  APP_FULL_BASE_URL, param\u00e8tres SMTP, etc.) puis lancer  docker compose up -d. Un conteneur pour la base de donn\u00e9es (MariaDB), un autre pour PHP/Redis, etc., seront d\u00e9marr\u00e9s automatiquement  . KeePassXC est une application client (Linux, Windows, Mac) \u2013 on l\u2019installe via les paquets/flatpak habituels sur chaque poste, et on utilise Syncthing pour synchroniser le fichier  .kdbx  entre machines si n\u00e9cessaire.</p> <p>Il est recommand\u00e9 de placer ces services derri\u00e8re un  reverse proxy  s\u00e9curis\u00e9 (Caddy, Nginx, Traefik, etc.) pour g\u00e9rer HTTPS. Par exemple, on peut configurer Caddy avec un h\u00f4te  password.votredomaine.com  qui fait  reverse_proxy vaultwarden:80  vers le conteneur Vaultwarden, en ajoutant l\u2019en-t\u00eate  X-Real-IP  pour que l\u2019application voie l\u2019IP client r\u00e9elle (utile pour les logs et Fail2Ban)  . De m\u00eame, Passbolt peut \u00eatre expos\u00e9 en HTTPS sur son propre domaine, avec certificat Let\u2019s Encrypt automatique.</p> <p>Sauvegardes  : c\u2019est un point critique. Pour Vaultwarden, il faut copier r\u00e9guli\u00e8rement tout le dossier de donn\u00e9es (vw-data), car il contient la base chiffr\u00e9e, les attachements et les configurations  . Il faut aussi sauvegarder le fichier  docker-compose.yml  et la configuration du proxy (Caddyfile ou Nginx). Pour Passbolt, la proc\u00e9dure est de faire un  mysqldumpde la base de donn\u00e9es et de copier les cl\u00e9s GPG serveur (serverkey.asc  et  serverkey_private.asc) depuis le conteneur  . Ne pas oublier non plus les fichiers de configuration/d\u2019environnement (.env). Pour KeePassXC, on sauvegarde simplement le fichier  .kdbx  (et le fichier-cl\u00e9 si utilis\u00e9). Ces sauvegardes doivent \u00eatre stock\u00e9es hors-site (NAS, autre cloud priv\u00e9) et test\u00e9es r\u00e9guli\u00e8rement  .</p> <p>En r\u00e9sum\u00e9, un d\u00e9ploiement s\u00e9curis\u00e9 comprend un conteneur pour chaque composant (moteur de base de donn\u00e9es, application, proxy), la configuration HTTPS/2FA, et un plan de sauvegarde rigoureux. En suivant ces bonnes pratiques (chiffrement fort, double authentification, isolation r\u00e9seau, audits, etc.), vous obtiendrez un gestionnaire de mots de passe auto-h\u00e9berg\u00e9 fiable et adapt\u00e9 \u00e0 votre homelab  .</p>"},{"location":"reseau/dashboard/","title":"Comparatif des dashboards auto-h\u00e9berg\u00e9s (Glance, Homarr, Heimdall &amp; co.)","text":"<p>Les  dashboards auto-h\u00e9berg\u00e9s  sont des pages d\u2019accueil personnalis\u00e9es permettant de regrouper et d\u2019acc\u00e9der d\u2019un coup d\u2019\u0153il \u00e0 tous vos services self-hosted (auto-h\u00e9berg\u00e9s). Ils servent de  portail centralis\u00e9  pour votre homelab, facilitant le lancement d\u2019applications web, la surveillance de certaines m\u00e9triques, ou l\u2019affichage de contenus (flux RSS, m\u00e9t\u00e9o, etc.). Ce comparatif passe en revue les solutions g\u00e9n\u00e9ralistes les plus populaires \u2013 notamment  Glance,  Homarr  et  Heimdall  \u2013 en les comparant sur des crit\u00e8res techniques cl\u00e9s (performance,  personnalisation,  int\u00e9grations, etc.), et mentionne \u00e9galement d\u2019autres alternatives int\u00e9ressantes. Enfin, nous proposerons quelques recommandations selon les besoins (meilleur choix pour d\u00e9butant, pour les utilisateurs avanc\u00e9s, etc.).</p>"},{"location":"reseau/dashboard/#apercu-des-principaux-dashboards-generalistes","title":"Aper\u00e7u des principaux dashboards g\u00e9n\u00e9ralistes","text":""},{"location":"reseau/dashboard/#glance","title":"Glance","text":"<p>Glance  est un dashboard r\u00e9cent qui se distingue par son approche type  \u00ab journal \u00bb, agr\u00e9geant de nombreux  widgets dynamiques  sur une page. Plut\u00f4t qu\u2019une simple liste d\u2019ic\u00f4nes, Glance peut afficher en temps r\u00e9el des contenus vari\u00e9s : flux RSS, posts Reddit, m\u00e9t\u00e9o, vid\u00e9os YouTube r\u00e9centes, cours de march\u00e9s boursiers, statut de conteneurs Docker, statistiques syst\u00e8me du serveur, etc.  . Il supporte de  nombreuses pages et onglets  et offre une  vaste customisation  du tableau de bord (choix de dispositions en colonnes, th\u00e8mes, styles, CSS personnalis\u00e9)  . \u00c9crit en Go, Glance est r\u00e9put\u00e9  l\u00e9ger et performant : le binaire Docker fait moins de 20 Mo et la page se charge en ~1 seconde (selon le nombre de widgets)  . En contrepartie, sa configuration se fait via des fichiers YAML, ce qui conviendra surtout aux utilisateurs \u00e0 l\u2019aise avec l\u2019\u00e9dition de fichiers de config (il n\u2019y a pas d\u2019interface graphique pour ajouter des widgets). Glance est id\u00e9al si vous souhaitez un tableau de bord riche en informations  \u00ab \u00e0 consulter d\u2019un coup d\u2019\u0153il \u00bb  plut\u00f4t qu\u2019un simple lanceur de liens.</p>"},{"location":"reseau/dashboard/#homarr","title":"Homarr","text":"<p>Homarr  est un dashboard  moderne et intuitif, privil\u00e9giant la configuration via une interface web soign\u00e9e plut\u00f4t que par fichiers. Une fois Homarr d\u00e9ploy\u00e9, on peut organiser ses tuiles d\u2019application en  glisser-d\u00e9poser  tr\u00e8s facilement  . L\u2019ajout de nouveaux services se fait dans le navigateur : Homarr propose une liste de mod\u00e8les (ic\u00f4nes pr\u00e9d\u00e9finies) et peut m\u00eame  r\u00e9cup\u00e9rer automatiquement le logo  d\u2019une application d\u00e8s qu\u2019on tape son nom (par ex. \u201cPlex\u201d)  . On configure l\u2019URL cible, le comportement du clic (nouvel onglet ou non), et \u00e9ventuellement un  ping de surveillance  ou une  int\u00e9gration APIsi le service est compatible  . Homarr int\u00e8gre quelques  widgets  utiles comme la m\u00e9t\u00e9o, un bloc-notes Markdown, un calendrier ou des iframes  . Il offre aussi des  int\u00e9grations natives  pour certaines applications populaires (ex : Plex, Sonarr, Radarr, Pi-hole, etc.) afin d\u2019afficher des informations directement sur le dashboard  . C\u00f4t\u00e9 personnalisation visuelle, Homarr permet de modifier le th\u00e8me, les couleurs et la disposition (nombre de colonnes selon la taille d\u2019\u00e9cran) tr\u00e8s simplement via le menu des param\u00e8tres  . En somme, Homarr vise un bon \u00e9quilibre entre simplicit\u00e9 et fonctionnalit\u00e9s. Apr\u00e8s une p\u00e9riode b\u00eata active fin 2024, il a gagn\u00e9 en fluidit\u00e9 et stabilit\u00e9.  Attention  toutefois, Homarr n\u2019est pas encore pleinement optimis\u00e9 pour mobile (l\u2019interface n\u2019est pas tr\u00e8s r\u00e9active sur petit \u00e9cran)  . Il convient particuli\u00e8rement \u00e0 ceux qui veulent un tableau de bord \u00e9l\u00e9gant, configurable sans toucher de fichiers, et couvrant l\u2019essentiel (liens, quelques widgets et int\u00e9grations basiques).</p>"},{"location":"reseau/dashboard/#heimdall","title":"Heimdall","text":"<p>Heimdall  est un des tableaux de bord auto-h\u00e9berg\u00e9s les plus connus, souvent recommand\u00e9 pour sa  simplicit\u00e9  et sa robustesse. C\u2019est un  dashboard \u201cno-frills\u201d  \u2013 comprenez par l\u00e0 qu\u2019il se concentre sur l\u2019essentiel : fournir une page d\u2019accueil avec des tuiles menant \u00e0 vos applications web, sans s\u2019encombrer de fonctionnalit\u00e9s avanc\u00e9es  . L\u2019interface est \u00e9pur\u00e9e, avec de gros boutons/ic\u00f4nes pour chaque service. La configuration se fait int\u00e9gralement via l\u2019UI : un bouton \u201cAdd Application\u201d permet d\u2019ajouter un lien en choisissant parmi une  longue liste de mod\u00e8les pr\u00e9-d\u00e9finis  (avec ic\u00f4ne et nom du service)  . Chaque tuile peut \u00eatre personnalis\u00e9e (URL, libell\u00e9, couleur, ic\u00f4ne\u2026) et, pour certaines applications prises en charge en mode  \u00ab Enhanced Apps \u00bb, Heimdall peut afficher une petite information dynamique (par ex. la vitesse de download actuelle d\u2019un Speedtest, le statut d\u2019un torrent, etc.) en configurant l\u2019API ou un identifiant utilisateur  . Heimdall int\u00e8gre \u00e9galement un  champ de recherche  optionnel sur la page d\u2019accueil (Google, Bing ou DuckDuckGo) pour servir de page de d\u00e9marrage navigateur  . Techniquement, Heimdall est tr\u00e8s l\u00e9ger en ressources (application PHP/MySQL ou en image Docker Linuxserver) et fonctionne imm\u00e9diatement apr\u00e8s installation. Il offre quelques options de personnalisation (fond d\u2019\u00e9cran, th\u00e8mes sombres/clair) mais reste  moins flexible  que d\u2019autres \u2013 par exemple, pas de widgets multiples ni de modifications pouss\u00e9es du layout  . C\u2019est un choix recommand\u00e9 pour les  d\u00e9butants  ou ceux qui recherchent une  solution simple et fonctionnelle  pour centraliser leurs liens d\u2019applications auto-h\u00e9berg\u00e9es, sans config complexe ni maintenance.</p>"},{"location":"reseau/dashboard/#dashy","title":"Dashy","text":"<p>Dashy  se pr\u00e9sente comme un  dashboard tr\u00e8s complet et personnalisable. \u00c9crit en Node/React, il propose une interface moderne avec de nombreuses  fonctionnalit\u00e9s avanc\u00e9es  : v\u00e9rification de statut des services,  widgets vari\u00e9s  (m\u00e9t\u00e9o, horloge, cours des crypto, scores sportifs, etc.), th\u00e8mes et pack d\u2019ic\u00f4nes multiples, \u00e9diteur visuel int\u00e9gr\u00e9, etc.  . Sa grande force est la  flexibilit\u00e9 de configuration  : on peut configurer Dashy via un fichier YAML (m\u00e9thode la plus fiable), ou utiliser l\u2019\u00e9diteur JSON int\u00e9gr\u00e9, voire un \u00e9diteur visuel glisser-d\u00e9poser directement dans le navigateur  . Cette richesse a toutefois un co\u00fbt en termes de  performance. En effet, Dashy g\u00e9n\u00e8re un build statique \u00e0 chaque modification majeure, ce qui fait que le conteneur peut prendre du temps \u00e0 (re)d\u00e9marrer et consommer pas mal de RAM  . Des utilisateurs rapportent des lenteurs lors du chargement initial ou de l\u2019enregistrement de modifications (plusieurs secondes, voire n\u00e9cessit\u00e9 de recharger la page)  . En environnement limit\u00e9 (Raspberry Pi, petite VM), Dashy peut donc sembler  plus lourdque des alternatives plus simples. En contrepartie, une fois configur\u00e9, il offre parmi les  tableaux de bord les plus complets  : il supporte par exemple les flux RSS  , peut s\u2019int\u00e9grer \u00e0 l\u2019outil de monitoring  Glances  pour afficher des m\u00e9triques syst\u00e8me d\u00e9taill\u00e9es  , et dispose d\u2019une  communaut\u00e9 active  qui cr\u00e9e des th\u00e8mes et widgets suppl\u00e9mentaires. Dashy convient bien aux  utilisateurs avanc\u00e9s  et  power users  qui veulent un maximum de fonctionnalit\u00e9s et de la  customisation  pouss\u00e9e (quitte \u00e0 sacrifier un peu de l\u00e9g\u00e8ret\u00e9). Pour un usage optimal, il est recommand\u00e9 de l\u2019ex\u00e9cuter sur une machine aux ressources suffisantes et d\u2019y consacrer du temps de configuration.</p>"},{"location":"reseau/dashboard/#homepage-ben-phelps","title":"Homepage (Ben Phelps)","text":"<p>Homepage  (par Ben Phelps) est un  tableau de bord tr\u00e8s en vogue  depuis 2022  , appr\u00e9ci\u00e9 pour son  \u00e9quilibre entre simplicit\u00e9 et puissance. Visuellement, il offre un look soign\u00e9 et minimaliste proche de Heimdall/Homer, mais sous le capot il propose une  panoplie d\u2019int\u00e9grations via API  qui le rapprochent d\u2019un Dashy ou Homarr. On d\u00e9ploie Homepage via Docker, puis on le configure en \u00e9ditant quelques fichiers YAML (pas d\u2019UI de configuration)  . Cette approche  \u201cInfrastructure as code\u201d  peut rebuter les d\u00e9butants, mais elle s\u2019av\u00e8re efficace pour les utilisateurs techniques et bien document\u00e9e sur le site officiel. Homepage est hautement  personnalisable  : on peut d\u00e9finir ses sections de liens (signets statiques), ses services (applications avec ic\u00f4ne, description, ping automatique, etc.), et surtout ajouter de nombreux  Widgets d\u2019information  en haut de page (par exemple la m\u00e9t\u00e9o, l\u2019\u00e9tat d\u2019un contr\u00f4leur Unifi, l\u2019utilisation d\u2019une instance Docker ou Kubernetes, etc.)  . Il int\u00e8gre \u00e9galement des  Service Widgets  sp\u00e9cifiques \u00e0 des logiciels (Plex, Sonarr, Pi-hole, etc.) permettant d\u2019afficher directement des statistiques pertinentes via leurs API  . La liste des services compatibles est tr\u00e8s large et sans cesse enrichie  . C\u00f4t\u00e9 personnalisation visuelle, tout se fait aussi en YAML (choix de th\u00e8mes, images de fond, couleurs\u2026). Par exemple on peut ajuster les couleurs et fonds d\u2019\u00e9cran globalement ou par utilisateur  . Malgr\u00e9 l\u2019absence de GUI, la majorit\u00e9 des utilisateurs trouvent Homepage relativement  simple \u00e0 configurer  et  agr\u00e9able \u00e0 utiliser  au quotidien \u2013 y compris en mobilit\u00e9, o\u00f9 son rendu responsive est bien g\u00e9r\u00e9 (certains retours soulignent que d\u2019autres dashboards ont un affichage mobile moins consistant)  . En r\u00e9sum\u00e9, Homepage est un excellent choix  interm\u00e9diaire : plus  l\u00e9ger  que Dashy (pas de rebuild lourd \u00e0 chaque modification) tout en offrant une  grande richesse fonctionnelle, \u00e0 condition d\u2019\u00eatre \u00e0 l\u2019aise avec la configuration via fichiers.</p>"},{"location":"reseau/dashboard/#homer","title":"Homer","text":"<p>Homer  est un autre dashboard populaire, connu pour \u00eatre  simple, statique et rapide. Il s\u2019agit d\u2019une  single-page app  en HTML/JS enti\u00e8rement statique \u2013 ce qui signifie qu\u2019une fois g\u00e9n\u00e9r\u00e9, le dashboard peut \u00eatre servi par n\u2019importe quel serveur web sans backend lourd. La configuration se fait dans un fichier  config.yml  o\u00f9 l\u2019on d\u00e9finit ses cat\u00e9gories et liens  . Homer permet d\u2019organiser les applications en  groupes  (cat\u00e9gories) avec un nom et une ic\u00f4ne pour chaque groupe  , et \u00e0 l\u2019int\u00e9rieur chaque entr\u00e9e peut avoir un logo personnalis\u00e9, un sous-titre, des mots-cl\u00e9s pour la recherche, etc.  . Il est \u00e9galement possible d\u2019ajouter des tags de couleur sur les tuiles pour indiquer le type (ex:  app,  outil, etc.)  . Visuellement, Homer propose une esth\u00e9tique un peu  \u00ab cartoon \u00bb  par d\u00e9faut (ic\u00f4nes plates et vives)  , mais celle-ci est  hautement personnalisable  : on peut modifier le th\u00e8me (couleurs HEX), le fond d\u2019\u00e9cran, et surtout choisir n\u2019importe quelles ic\u00f4nes/images pour repr\u00e9senter ses services  . D\u2019ailleurs, la communaut\u00e9 fournit de nombreux packs d\u2019ic\u00f4nes pr\u00eats \u00e0 l\u2019emploi pour Homer. Quelques  widgets simples  existent (par exemple un widget d\u2019heure, une vignette pour afficher le statut d\u2019un service via URL/ping, etc.), mais Homer ne va pas aussi loin que Homepage ou Dashy en mati\u00e8re d\u2019int\u00e9grations d\u2019API \u2013 il reste avant tout un  lanceur de services  \u00e9l\u00e9gant. Gr\u00e2ce \u00e0 sa nature statique, Homer est  ultra-l\u00e9ger  et tourne tr\u00e8s bien sur de petits mat\u00e9riels (il consomme \u00e0 peine quelques m\u00e9gaoctets de RAM). Il convient \u00e0 ceux qui veulent un dashboard sobre, rapide, et qui n\u2019ont pas peur d\u2019\u00e9diter manuellement un fichier de config pour le mettre \u00e0 jour.</p>"},{"location":"reseau/dashboard/#flame","title":"Flame","text":"<p>Flame  est un dashboard open-source qui a \u00e9t\u00e9  fortement inspir\u00e9 de SUI  (Startpage minimaliste, voir plus bas) mais en y ajoutant une interface de configuration int\u00e9gr\u00e9e  . L\u2019objectif de Flame est d\u2019\u00eatre  le plus simple possible \u00e0 installer et configurer  : on lance le conteneur Docker et tout se g\u00e8re via le front-end web. Aucune \u00e9dition de fichier n\u2019est requise, tout passe par des formulaires conviviaux. En pratique, Flame permet d\u2019ajouter des applications (liens) et des signets via un  \u00e9diteur graphique  tr\u00e8s facile d\u2019approche  . On peut t\u00e9l\u00e9charger ou choisir des ic\u00f4nes, organiser les liens en cat\u00e9gories, et m\u00eame ajouter un  widget m\u00e9t\u00e9o  ou un  moteur de recherche  sur la page  . L\u2019interface est \u00e9pur\u00e9e, avec un style proche de SUI/Homer (ic\u00f4nes Material Design pour les services) et une mise en page tr\u00e8s sobre \u2013 ce qui le rend  clair et lisible. Gr\u00e2ce \u00e0 sa philosophie minimaliste, Flame est \u00e9galement  l\u00e9ger  et tourne sans effort sur un NAS ou Raspberry Pi. En contrepartie, il ne propose pas d\u2019int\u00e9grations complexes ni de widgets avanc\u00e9s (hormis la m\u00e9t\u00e9o et l\u2019heure). Flame est souvent cit\u00e9 comme un des meilleurs choix  pour les d\u00e9butants  ou ceux qui veulent un  tableau de bord fonctionnel en 5 minutes  sans sacrifier l\u2019esth\u00e9tique. Si vos besoins se limitent \u00e0 un joli  homepage  pour vos liens, Flame fait parfaitement l\u2019affaire  . \u00c0 noter que Flame et SUI partagent un sch\u00e9ma d\u2019ic\u00f4nes (Material Design Icons), ce qui facilite la migration de l\u2019un \u00e0 l\u2019autre  .</p>"},{"location":"reseau/dashboard/#sui","title":"SUI","text":"<p>SUI  (pour  Server User Interface) est un  dashboard minimaliste  qui a servi de base \u00e0 Flame. C\u2019est essentiellement une  landing page statique  avec une liste d\u2019applications et de signets, configurable via de simples fichiers JSON. Aucune base de donn\u00e9es ou backend n\u2019est requis, il suffit de cloner le d\u00e9p\u00f4t et d\u2019\u00e9diter  apps.json  et  links.json  pour d\u00e9finir vos applications et vos favoris  . En termes de fonctionnalit\u00e9s, SUI se limite au strict n\u00e9cessaire : des ic\u00f4nes cliquables pour lancer vos services, la possibilit\u00e9 de changer rapidement le th\u00e8me (mode clair/sombre et quelques couleurs pr\u00e9d\u00e9finies)  , et c\u2019est tout. Il  ne supporte pas les widgets  ni les int\u00e9grations externes (pas de m\u00e9t\u00e9o, pas de stats syst\u00e8mes, etc.)  . L\u2019int\u00e9r\u00eat de SUI r\u00e9side dans sa  simplicit\u00e9 extr\u00eame  et son c\u00f4t\u00e9  \u201cfichier statique\u201d  : aucune configuration serveur complexe, tr\u00e8s peu de ressources consomm\u00e9es, et une vitesse de chargement imbattable. En revanche, d\u00e8s que l\u2019on souhaite le moindre dynamisme ou une configuration \u00e0 la vol\u00e9e, on sera limit\u00e9 \u2013 c\u2019est pourquoi Flame a \u00e9merg\u00e9 pour offrir une exp\u00e9rience similaire mais administrable depuis le navigateur. On recommande SUI uniquement si vous cherchez le minimalisme absolu  et  que l\u2019\u00e9dition manuelle de JSON ne vous fait pas peur. Pour la plupart des utilisateurs d\u00e9butants, Flame sera pr\u00e9f\u00e9r\u00e9 car plus accessible.</p>"},{"location":"reseau/dashboard/#fenrus","title":"Fenrus","text":"<p>Fenrus  est un dashboard moins connu que les pr\u00e9c\u00e9dents, mais qui m\u00e9rite l\u2019attention pour ses fonctionnalit\u00e9s avanc\u00e9es. D\u00e9velopp\u00e9 initialement en Node puis r\u00e9\u00e9crit en .NET (Blazor Server)  , Fenrus vise \u00e0 \u00eatre un  portail tout-en-un  pour votre homelab. Il prend en charge la  gestion multi-utilisateurs : d\u00e8s la premi\u00e8re connexion, vous cr\u00e9ez un compte admin, et pouvez ensuite d\u00e9sactiver les inscriptions ouvertes ou cr\u00e9er d\u2019autres comptes si vous voulez un dashboard par utilisateur  . Chaque utilisateur peut avoir son propre tableau de bord personnalis\u00e9, ce qui est un gros avantage pour un usage familial ou partag\u00e9. Fenrus propose une configuration via  interface web compl\u00e8te : apr\u00e8s login, l\u2019ajout de liens se fait via une UI intuitive, avec l\u00e0 aussi une liste de  presets d\u2019apps int\u00e9gr\u00e9s (avec ic\u00f4nes)  pour acc\u00e9l\u00e9rer la configuration  . Il supporte \u00e9galement la notion de  \u201csmart apps\u201d : ce sont des applications pour lesquelles Fenrus va aller r\u00e9cup\u00e9rer des informations suppl\u00e9mentaires \u00e0 afficher (par exemple, le statut d\u2019un service, des m\u00e9triques de Pi-hole comme le nombre de pubs bloqu\u00e9es, etc.)  . Cela rappelle les  Enhanced Apps  de Heimdall mais en plus pouss\u00e9. Fenrus permet m\u00eame d\u2019imbriquer des dashboards entre eux  (on peut cr\u00e9er des tuiles renvoyant vers d\u2019autres pages de dashboard, pratique pour organiser par th\u00e8mes ou sites)  . En termes de design, Fenrus offre un look moderne avec fonds anim\u00e9s (d\u00e9sactivables)  et widgets repositionnables. Il est aussi possible de lancer des  terminaux Docker/SSH  depuis Fenrus et de surveiller la disponibilit\u00e9 de services (uptime) \u2013 des fonctions relativement uniques dans ce domaine  . C\u00f4t\u00e9 ressources, l\u2019image Docker p\u00e8se autour de 100 Mo (car inclut .NET runtime)  et la consommation en m\u00e9moire reste mod\u00e9r\u00e9e pour un usage standard. Fenrus s\u2019adresse aux utilisateurs voulant un  hub unifi\u00e9 puissant, avec contr\u00f4le d\u2019acc\u00e8s par utilisateurs, int\u00e9grations et administration 100% via interface. Il peut \u00eatre un peu plus complexe \u00e0 auto-h\u00e9berger (technologie .NET) et son interface est en anglais, mais il apporte des atouts pr\u00e9cieux pour qui a des besoins multi-user ou de  dashboard  \u00e9volu\u00e9.</p>"},{"location":"reseau/dashboard/#organizr","title":"Organizr","text":"<p>Organizr  est une solution plus ancienne et diff\u00e9rente dans son approche, souvent utilis\u00e9e par les  communaut\u00e9s de partage de serveurs media. Plus qu\u2019un simple tableau de bord de liens, Organizr est un  portail web complet  avec syst\u00e8me d\u2019authentification utilisateur, gestion de  groupes et permissions, et une interface en  onglets. Il permet par exemple de cr\u00e9er des comptes (ou de lier l\u2019authentification aux comptes Plex des utilisateurs) puis de pr\u00e9senter des onglets accessibles selon les droits de chacun (exemple : onglet  Media  pour Plex/Sonarr/Radarr visible par la famille, onglet  Admin  visible seulement par l\u2019administrateur)  . Organizr excelle dans l\u2019int\u00e9gration d\u2019applications via des  iframes : au lieu d\u2019ouvrir un nouveau navigateur, on peut afficher l\u2019interface de Sonarr, Radarr, etc., directement \u00e0 l\u2019int\u00e9rieur d\u2019un onglet Organizr  . Cela donne vraiment l\u2019impression d\u2019une  application unifi\u00e9e  plut\u00f4t qu\u2019une collection de liens. Organizr propose de nombreuses  options de personnalisation dans son interface  (th\u00e8mes, disposition) et prend en charge divers  plugins  et int\u00e9grations (notifications, monitoring basique, etc.)  . En revanche, il est plus lourd \u00e0 faire tourner (stack PHP/SQL avec plusieurs fonctionnalit\u00e9s) et sa configuration initiale peut \u00eatre fastidieuse compar\u00e9e aux autres dashboards. Il reste toutefois tr\u00e8s  personnalisable via l\u2019UI  (pas de fichiers manuels \u00e0 \u00e9diter, tout se fait dans le panneau d\u2019admin)  . Si votre objectif est de fournir \u00e0 plusieurs utilisateurs un  point d\u2019acc\u00e8s centralis\u00e9 et s\u00e9curis\u00e9  \u00e0 tout un \u00e9cosyst\u00e8me d\u2019apps (type serveur multim\u00e9dia partag\u00e9), Organizr est une excellente solution. Mais pour un usage homelab purement personnel, sa complexit\u00e9 n\u2019est souvent pas n\u00e9cessaire face \u00e0 des outils plus simples.</p>"},{"location":"reseau/dashboard/#yal-yet-another-landing-page","title":"Yal (Yet Another Landing page)","text":"<p>Yal  est un petit nouveau dans la cat\u00e9gorie des homepages minimalistes. Comme son nom l\u2019indique, c\u2019est \u00ab encore une page de d\u00e9marrage \u00bb, focalis\u00e9e sur la  pr\u00e9sentation de liens  de mani\u00e8re \u00e9l\u00e9gante. Yal se d\u00e9marque par sa  simplicit\u00e9  et son souci de  s\u00e9curit\u00e9 : il tourne avec les privil\u00e8ges minimum et sert essentiellement de  hub de liens avec fonction de recherche int\u00e9gr\u00e9e  . L\u2019interface est basique mais on peut la  personnaliser visuellement  assez facilement (ajout du logo/branding, choix de couleurs). En revanche, Yal n\u2019offre pas de widget, pas d\u2019int\u00e9gration d\u2019API \u2013 c\u2019est vraiment pour avoir une page d\u2019accueil jolie et rapide regroupant vos favoris et services, avec une barre de recherche. Par sa l\u00e9g\u00e8ret\u00e9 extr\u00eame, Yal peut convenir aux contextes tr\u00e8s contraints ou \u00e0 ceux qui veulent un projet simple \u00e0 auditer (son code \u00e9tant r\u00e9duit au minimum).</p> <p>(D\u2019autres projets existent encore \u2013 par ex. des forks ou variantes comme Dashy Lite, HomerCE, etc. \u2013 mais la liste ci-dessus couvre les options les plus discut\u00e9es et \u00e9prouv\u00e9es \u00e0 ce jour.)</p>"},{"location":"reseau/dashboard/#dashboards-specialises-domotique-supervision-etc","title":"Dashboards sp\u00e9cialis\u00e9s (domotique, supervision, etc.)","text":"<p>Outre les portails g\u00e9n\u00e9ralistes ci-dessus, il existe des  tableaux de bord d\u00e9di\u00e9s \u00e0 des usages sp\u00e9cifiques  \u2013 qui peuvent \u00eatre auto-h\u00e9berg\u00e9s \u00e9galement. Quelques exemples notables :</p> <ul> <li> <p>Dashboards domotique (smart home) : le plus connu est sans doute l\u2019interface  Lovelace  de Home Assistant. Home Assistant est une solution compl\u00e8te de domotique auto-h\u00e9berg\u00e9e, et inclut un tableau de bord hautement personnalisable pour contr\u00f4ler les appareils de la maison connect\u00e9e. On peut y afficher des tuiles pour les lumi\u00e8res, thermostats, cam\u00e9ras, etc., avec des retours d\u2019\u00e9tat en temps r\u00e9el. C\u2019est excellent pour piloter son foyer, mais d\u00e9tourn\u00e9 en tant que homepage g\u00e9n\u00e9raliste cela demanderait du travail (quoique certains l\u2019ont fait via des cartes Markdown et boutons Home Assistant)  . D\u2019autres exemples de dashboards domotique :  Domoticz  (interface web incluse pour la maison intelligente),  Jeedom, etc. Ces outils ne sont \u00e0 consid\u00e9rer que si votre objectif principal est la domotique ; pour un usage portail d\u2019applications web classiques, mieux vaut s\u2019orienter vers les solutions g\u00e9n\u00e9ralistes pr\u00e9c\u00e9dentes.</p> </li> <li> <p>Dashboards de supervision syst\u00e8me : pour la surveillance de serveurs, syst\u00e8mes et conteneurs, on retrouve des outils sp\u00e9cialis\u00e9s comme  Grafana,  Glances,  Netdata,  Zabbix, etc. Par exemple,  Glances  est un utilitaire \u00e9crit en Python qui fournit un tableau de bord en console ou web affichant en temps r\u00e9el l\u2019utilisation CPU, RAM, E/S disque, r\u00e9seau et divers composants du syst\u00e8me  . On peut l\u2019exposer via une interface web et m\u00eame l\u2019int\u00e9grer \u00e0 un dashboard comme Dashy pour remonter ces infos.  Grafana, quant \u00e0 lui, excelle dans l\u2019affichage de tableaux de bord de m\u00e9triques sous forme de graphiques (CPU, trafic, temp\u00e9ratures\u2026) en se branchant sur des bases de donn\u00e9es de s\u00e9ries temporelles (Prometheus, InfluxDB, etc.). C\u2019est l\u2019outil de choix pour qui veut de jolis graphes et alertes, mais il n\u00e9cessite plus de configuration.  Netdata  offre un tableau de bord temps-r\u00e9el pour une machine donn\u00e9e, avec \u00e9norm\u00e9ment de d\u00e9tails (jusqu\u2019au monitoring des processus, E/S, etc.) sans configuration pr\u00e9alable.  Zabbix  est une solution d\u2019entreprise plus lourde pour superviser un parc entier de machines et services. En r\u00e9sum\u00e9, ces dashboards de monitoring sont parfaits pour suivre la  sant\u00e9 technique  de vos serveurs et applications. Vous pouvez soit les consulter s\u00e9par\u00e9ment, soit parfois les  int\u00e9grer dans votre dashboard principal  via des iframes ou des widgets/API (exemple : int\u00e9grer un graph Grafana dans Homepage, ou un widget \u201chealth\u201d qui interroge l\u2019API de Pi-hole, etc.).</p> </li> </ul> <p>En r\u00e8gle g\u00e9n\u00e9rale,  les dashboards sp\u00e9cialis\u00e9s sont compl\u00e9mentaires  des dashboards g\u00e9n\u00e9ralistes. Il est courant d\u2019utiliser par exemple Heimdall ou Homarr pour lancer les applications, puis Grafana/Glances pour surveiller les ressources, ou d\u2019avoir Home Assistant pour la domotique et un autre dashboard pour les autres services. Veillez simplement \u00e0 ce que tout soit bien  s\u00e9curis\u00e9  (ces interfaces exposent beaucoup d\u2019infos, mettez de l\u2019authentification ou limitez l\u2019acc\u00e8s au r\u00e9seau local).</p>"},{"location":"reseau/dashboard/#comparaison-technique-performance-personnalisation-integrations","title":"Comparaison technique (performance, personnalisation, int\u00e9grations\u2026)","text":"<p>Pour mieux guider le choix, examinons quelques  crit\u00e8res de comparaison cl\u00e9s  et voyons comment se positionnent ces diff\u00e9rents dashboards auto-h\u00e9berg\u00e9s :</p> <ul> <li> <p>Performance et l\u00e9g\u00e8ret\u00e9 : Les solutions purement statiques ou minimales comme  Homer,  SUI,  Yal  ou  Heimdallsont les plus l\u00e9g\u00e8res \u2013 elles consomment tr\u00e8s peu de RAM/CPU et chargent instantan\u00e9ment (id\u00e9al pour Raspberry Pi, NAS peu puissant, etc.).  Glance  malgr\u00e9 ses widgets reste tr\u00e8s optimis\u00e9 (Go lang) et affiche aussi des temps de chargement ~1 seconde seulement  .  Flame  et  Homarr  ont une empreinte raisonnable (quelques centaines de Mo de RAM au plus) gr\u00e2ce \u00e0 une conception l\u00e9g\u00e8re ou \u00e0 l\u2019optimisation r\u00e9cente du code Homarr.  Homepage  (Ben Phelps) utilise Node/React mais sans recompilation fr\u00e9quente, il demeure relativement fluide en runtime. \u00c0 l\u2019inverse,  Dashy  est connu pour \u00eatre plus lourd : son conteneur fait un rendu React et doit reconstruire le site en cas de modification, ce qui se traduit par un  temps de d\u00e9marrage plus long  et une consommation m\u00e9moire notable  . Sur un petit serveur, plusieurs utilisateurs ont observ\u00e9 des  ralentissements avec Dashy  (chargements initiaux lents, interface saccad\u00e9e) l\u00e0 o\u00f9 Homepage ou Homarr restaient fluides  .  Fenrus  embarquant .NET se situe entre deux : un peu plus lourd qu\u2019un Heimdall, mais il a \u00e9t\u00e9 optimis\u00e9 lors de la r\u00e9\u00e9criture (le rendu serveur Blazor est plus rapide que l\u2019ancienne version Node)  .  Organizr  est aussi relativement lourd (application PHP compl\u00e8te avec base de donn\u00e9es) et peut charger plus lentement qu\u2019un simple Homer, mais cela peut \u00eatre acceptable en multi-usages. En somme, si votre priorit\u00e9 est la  l\u00e9g\u00e8ret\u00e9  absolue, orientez-vous vers Homer/SUI/Heimdall (voire Homepage qui reste assez light) et \u00e9vitez Dashy \u00e0 moins d\u2019avoir des ressources confortables.</p> </li> <li> <p>Facilit\u00e9 d\u2019installation et de configuration : Sur ce crit\u00e8re, les dashboards offrant une  configuration via interface graphique  l\u2019emportent clairement pour les d\u00e9butants.  Heimdall  se distingue par sa simplicit\u00e9 \u201cplug-and-play\u201d : on l\u2019installe et on ajoute les liens via le web sans lire de documentation.  Flame  et  Homarr  \u00e9galement brillent par leur  simplicit\u00e9 de configuration  : tout se fait via de jolis formulaires int\u00e9gr\u00e9s, ce qui permet de construire son dashboard sans jamais \u00e9diter de fichiers  .  Fenrus  propose aussi une config 100% Web (avec en plus la gestion des comptes utilisateurs) \u2013 malgr\u00e9 sa richesse, son interface reste intuitive selon les retours  .  Organizr  a une interface d\u2019admin compl\u00e8te, mais l\u2019ampleur des r\u00e9glages possibles peut d\u00e9router un nouveau venu. Du c\u00f4t\u00e9 des outils \u00e0 configuration  fichier  (YAML/JSON), on retrouve  Homer,  Homepage,  SUI,  Glance,  Dashy  (optionnellement) et consorts. Ceux-ci demandent de lire la documentation et de manipuler des fichiers de config, ce qui peut \u00eatre un frein initial. Toutefois, parmi eux,  Homepage  est souvent cit\u00e9 pour sa  bonne documentation et sa relative facilit\u00e9m\u00eame en YAML, compar\u00e9 par exemple \u00e0 un Dashy dont la config YAML est plus complexe et fragment\u00e9e  . Dashy essaie de compenser avec ses \u00e9diteurs int\u00e9gr\u00e9s, mais ceux-ci peuvent parfois \u00eatre instables ou moins pratiques que pr\u00e9vu  .  Homer  et  SUI  ont l\u2019avantage d\u2019une structure de fichier simple et d\u2019exemples par d\u00e9faut qu\u2019il suffit d\u2019adapter. En r\u00e9sum\u00e9 : pour un  d\u00e9butant complet, Heimdall ou Flame/Homarr sont conseill\u00e9s. Pour un  utilisateur interm\u00e9diaire  ne craignant pas de mettre les mains dans YAML, Homepage ou Homer restent simples. Pour un  expert  qui veut tout peaufiner, Dashy ou Glance offrent de grandes possibilit\u00e9s mais demandent plus d\u2019effort initial.</p> </li> <li> <p>Personnalisation de l\u2019interface : Tous ces dashboards permettent, \u00e0 des degr\u00e9s divers, de  personnaliser l\u2019apparence  et l\u2019organisation. Les plus  limit\u00e9s  de ce point de vue sont Heimdall et SUI \u2013 ils offrent seulement quelques th\u00e8mes ou fonds d\u2019\u00e9cran, sans pouvoir vraiment changer la disposition des \u00e9l\u00e9ments (grid fixe) ni les styles au-del\u00e0 de l\u2019essentiel. \u00c0 l\u2019oppos\u00e9,  Dashy,  Glance  et  Homepage  sont extr\u00eamement  personnalisables  : choix de mise en page (colonnes, sections pliables\u2026), multitude de  th\u00e8mes disponibles  ou personnalisables, possibilit\u00e9 d\u2019ajouter du CSS personnalis\u00e9  , etc.  Homarr  et  Flame  offrent un bon compromis : on peut changer les couleurs, le fond, le nombre de colonnes, classer par cat\u00e9gories, mais on reste sur un design global pr\u00e9\u00e9tabli (par exemple Homarr occupe toute la largeur avec des cat\u00e9gories empil\u00e9es verticalement qu\u2019on ne peut pas redimensionner librement)  .  Homer  permet de personnaliser chaque ic\u00f4ne/service individuellement (logos, sous-titres, couleurs de tag) et de modifier enti\u00e8rement la palette de couleurs de l\u2019UI, ce qui permet d\u2019obtenir un rendu tr\u00e8s personnalis\u00e9 malgr\u00e9 une structure fig\u00e9e  .  Fenrus  et  Organizr  proposent aussi pas mal d\u2019options visuelles (Organizr a des th\u00e8mes CSS, Fenrus a un fond anim\u00e9 par d\u00e9faut, etc.), tout en guidant l\u2019utilisateur avec un style pr\u00e9d\u00e9fini. Si votre objectif est d\u2019avoir un  design vraiment unique, Dashy est probablement le plus modulable (on peut m\u00eame changer la mise en page en horizontal, vertical, tableau, etc., et cr\u00e9er des vues tr\u00e8s originales). Glance offre un style unique type \u201cjournal\u201d qui change des grilles classiques. En revanche, si vous aimez les  interfaces sobres fa\u00e7on mat\u00e9riel design, Flame/SUI/Homer/Homepage vous donneront satisfaction d\u00e8s l\u2019installation, avec seulement des retouches mineures pour adapter \u00e0 votre th\u00e8me pr\u00e9f\u00e9r\u00e9.</p> </li> <li> <p>Fonctionnalit\u00e9s et int\u00e9grations : C\u2019est sans doute le crit\u00e8re qui diff\u00e9rencie le plus ces solutions. Du c\u00f4t\u00e9 des fonctionnalit\u00e9s  basiques communes : tous savent afficher des liens d\u2019applications avec ic\u00f4ne, \u00e9ventuellement des signets (liens externes), et parfois un champ de recherche.  Heimdall, Flame, SUI, Yal  restent globalement sur ce niveau de base (Heimdall ajoutant une search bar et quelques tuiles \u201cam\u00e9lior\u00e9es\u201d pour deux ou trois services).  Homer  ajoute la recherche par mots-cl\u00e9s et quelques  badges, mais pas de contenu dynamique. Pour des  widgets dynamiques  (ex : m\u00e9t\u00e9o, RSS, t\u00e2ches, notes, etc.), il faut se tourner vers  Homarr, Homepage, Dashy, Glance. Par exemple, Homarr inclut un petit module m\u00e9t\u00e9o et un bloc-notes  , Homepage permet d\u2019afficher des infos Docker, r\u00e9seau, m\u00e9t\u00e9o, etc., tout en haut de la page  , Dashy propose une biblioth\u00e8que de widgets tr\u00e8s \u00e9tendue (y compris des int\u00e9grations tierces comme afficher les scores sportifs, les cours boursiers, etc.)  .  Glance  est con\u00e7u nativement pour agr\u00e9ger des contenus externes sur votre page (actus RSS, Reddit, vid\u00e9os YouTube\u2026)  . Du c\u00f4t\u00e9 des  int\u00e9grations d\u2019applications :  Homepage  et  Homarr  offrent des int\u00e9grations API avec beaucoup de services homelab (Plex, Sonarr/Radarr, Jellyfin, Ombi, Pi-hole, Traefik, etc.), ce qui permet d\u2019avoir par exemple le nombre de torrents actifs, l\u2019\u00e9tat d\u2019un t\u00e9l\u00e9chargement, le nombre de pubs bloqu\u00e9es ou le prochain \u00e9pisode \u00e0 diffuser, directement sur la tuile du service.  Heimdall  propose aussi une liste limit\u00e9e d\u2019Enhanced Apps  avec des champs de configuration API pour quelques services courants  .  Fenrus  pousse encore plus loin avec ses  \u201csmart apps\u201d  qui enrichissent les tuiles avec des informations contextuelles automatiquement  .  Organizr  permet des choses diff\u00e9rentes (ex : int\u00e9grer un lecteur de musique ou de vid\u00e9o via plugins, ou utiliser Organizr comme source d\u2019authentification unique pour vos applications gr\u00e2ce au support SSO)  . Il est important de cerner vos besoins : si vous souhaitez juste un  lanceur d\u2019apps simple, beaucoup de fonctionnalit\u00e9s ne vous seront pas utiles \u2013 un Heimdall ou Flame suffiront. Si au contraire vous voulez exploiter \u00e0 fond les  APIs de vos services  pour tout visualiser au m\u00eame endroit, optez pour Homepage, Homarr, Fenrus ou Dashy qui sont con\u00e7us pour cela. Notons que  certaines int\u00e9grations peuvent dupliquer ce que font d\u2019autres outils  : par ex., afficher les graphes de CPU dans Dashy est possible, mais un outil d\u00e9di\u00e9 comme Grafana le fera mieux ; avoir un widget m\u00e9t\u00e9o est sympa, mais votre t\u00e9l\u00e9phone le fait aussi, etc. L\u2019essentiel est de trouver le juste milieu qui vous convient entre  simplicit\u00e9  et  \u201ctout dans un seul \u00e9cran\u201d.</p> </li> <li> <p>Support multi-utilisateurs : La plupart des dashboards list\u00e9s sont pens\u00e9s pour un usage personnel, et  ne g\u00e8rent pas nativement plusieurs utilisateurs avec des sessions s\u00e9par\u00e9es. Par d\u00e9faut, Homarr, Homer, Heimdall, Dashy, etc., n\u2019ont pas de concept de comptes utilisateurs (on peut \u00e9ventuellement mettre un login unique via un proxy ou partager le lien du dashboard en lecture seule, mais pas de pages distinctes par user). Si vous avez besoin de  tableaux de bord distincts ou d\u2019acc\u00e8s restreints par utilisateur, deux solutions se d\u00e9marquent :  Fenrus  (multi-user int\u00e9gr\u00e9, chaque compte ayant son dashboard isol\u00e9)  , et  Organizr  (multi-user avec r\u00f4les et acc\u00e8s diff\u00e9renci\u00e9s aux onglets)  . Organizr permet m\u00eame de synchroniser les comptes avec Plex, ce qui est pratique dans un contexte de serveur m\u00e9dia partag\u00e9  . Une autre approche consiste \u00e0 d\u00e9ployer plusieurs instances de dashboards diff\u00e9rents \u2013 par exemple, un Homepage pour la famille (avec les services grand public) et un autre pour l\u2019admin \u2013 c\u2019est ce que font certains utilisateurs  . Mais cela reste du bricolage. Donc si le besoin multi-user est  critique, privil\u00e9giez Fenrus ou Organizr. Sinon, consid\u00e9rez tous ces outils comme des  \u00ab pages d\u2019accueil personnelles \u00bb  (quitte \u00e0 les s\u00e9curiser par un mot de passe global si vous le souhaitez).</p> </li> <li> <p>Compatibilit\u00e9 et maintenance dans le temps : Un dernier point \u00e0 comparer est la  sant\u00e9 des projets open-sourcecorrespondants. Tous ceux mentionn\u00e9s ici sont open-source et disponibles sur GitHub (souvent maintenus par des passionn\u00e9s). Certains sont tr\u00e8s actifs avec des mises \u00e0 jour fr\u00e9quentes (par ex.  Homepage  a une forte communaut\u00e9 depuis 2022,  Homarr  a eu une refonte majeure en 2024,  Dashy  est activement d\u00e9velopp\u00e9 avec de nombreuses releases,  Homer  et  Heimdall  sont stables depuis des ann\u00e9es). D\u2019autres sont plus ou moins fig\u00e9s (SUI n\u2019a plus beaucoup de maj depuis que Flame a pris le relais).  Fenrus  est d\u00e9velopp\u00e9 par un seul auteur, avec des updates ponctuelles.  Organizr  est \u00e9galement stable mais son rythme de d\u00e9veloppement a ralenti. Avant de s\u2019engager sur un dashboard, il peut \u00eatre utile de jeter un \u0153il au repo GitHub (nombre de contributeurs, fr\u00e9quence des commits) et \u00e0 la communaut\u00e9 (Discord, Reddit) pour estimer la  p\u00e9rennit\u00e9. Ceci dit, m\u00eame un projet non mis \u00e0 jour reste utilisable s\u2019il r\u00e9pond \u00e0 vos besoins actuels \u2013 ce sont des applications assez simples en termes de d\u00e9pendances.</p> </li> </ul>"},{"location":"reseau/dashboard/#quel-dashboard-choisir-recommandations-finales","title":"Quel dashboard choisir ? (Recommandations finales)","text":"<p>Pour conclure, voici quelques  suggestions de choix  en fonction de profils ou crit\u00e8res sp\u00e9cifiques :</p> <ul> <li> <p>Meilleur choix pour un d\u00e9butant (installation \u201cen un clic\u201d)  :  Heimdall  est recommand\u00e9 pour sa mise en route instantan\u00e9e et son usage ultra-simple  . Si vous voulez un peu plus de personnalisation visuelle tout en restant novice,  Flame  est une excellente alternative gr\u00e2ce \u00e0 son interface utilisateur conviviale  . Ces deux solutions permettent d\u2019obtenir un r\u00e9sultat propre sans \u00e9crire une seule ligne de config.</p> </li> <li> <p>Le plus l\u00e9ger pour un petit serveur  :  Homer  ou  SUI  seront imbattables en termes de l\u00e9g\u00e8ret\u00e9 \u2013 ils ne consomment quasiment rien et restent tr\u00e8s rapides.  Heimdall  et  Yal  sont \u00e9galement tr\u00e8s peu gourmands. \u00c9vitez  Dashy  sur de trop faibles machines, car son empreinte est sup\u00e9rieure  .</p> </li> <li> <p>Le plus personnalisable et riche en fonctionnalit\u00e9s  :  Dashy  remporte la palme de la flexibilit\u00e9 (widgets, th\u00e8mes, agencement libre) et  Homepage  n\u2019est pas loin derri\u00e8re avec ses int\u00e9grations et widgets extensibles  .  Homarr  offre aussi un bon panel de personnalisations (couleurs, tuiles redimensionnables, widgets de base) via l\u2019UI, tandis que  Glance  propose un style unique tr\u00e8s informatif. Si vous adorez bricoler et ajouter toujours plus de donn\u00e9es sur votre dashboard, Dashy ou Homepage vous combleront.</p> </li> <li> <p>Meilleures int\u00e9grations d\u2019applications  :  Homepage  et  Homarr  supportent nativement de nombreuses int\u00e9grations (APIs Plex, Sonarr, Radarr, etc.) pour enrichir vos tuiles de service  .  Heimdall  en fournit quelques-unes en \u201cEnhanced Apps\u201d.  Fenrus  permet \u00e9galement d\u2019int\u00e9grer des infos (par ex. Pi-hole, uptime, etc.) via ses  smart apps  . Si l\u2019objectif est d\u2019avoir un  aper\u00e7u d\u2019\u00e9tat  de vos services (ex : torrent en cours, nombre de fichiers \u00e0 t\u00e9l\u00e9charger, etc.), Homarr ou Homepage seront d\u2019excellents choix.</p> </li> <li> <p>Pour une utilisation mobile (smartphone/tablette)  :  Homepage  est signal\u00e9 pour bien fonctionner sur mobile (responsive design soign\u00e9)  .  Heimdall  et  Homer  s\u2019en sortent correctement vu leur simplicit\u00e9.  Dashy  et  Homarr  ont parfois quelques soucis d\u2019affichage responsive (tuiles qui d\u00e9passent, etc., m\u00eame si Homarr s\u2019am\u00e9liore). Si l\u2019acc\u00e8s mobile est important, testez le rendu de la d\u00e9mo de chaque dashboard sur votre t\u00e9l\u00e9phone. De plus, pr\u00e9f\u00e9rez une interface \u00e9pur\u00e9e (moins de colonnes, pas trop de widgets lourds) pour un usage mobile fluide.</p> </li> <li> <p>Usage multi-comptes ou partag\u00e9  :  Fenrus  ou  Organizr  sont tout indiqu\u00e9s si vous avez besoin de comptes s\u00e9par\u00e9s et de pages d\u00e9di\u00e9es par utilisateur  . Par exemple, pour un serveur familial ou un petit intranet d\u2019entreprise, Organizr pourra g\u00e9rer les connexions et droits, et Fenrus fournir un dashboard perso \u00e0 chacun. En l\u2019absence de ces besoins, restez sur les solutions classiques mono-user, vous \u00e9viterez une complexit\u00e9 inutile.</p> </li> <li> <p>Look &amp; Feel sp\u00e9cifique  : Ce crit\u00e8re est subjectif, mais pour donner des tendances :  Heimdall  a un look tr\u00e8s sobre \u201cclassique\u201d,  Homer  un style color\u00e9 retro-cartoon,  Flame/SUI  un design minimaliste moderne,  Homarr  une esth\u00e9tique \u201cmaterial design\u201d \u00e9l\u00e9gante,  Dashy  une pr\u00e9sentation plus originale avec sections \u00e0 la carte,  Glance_ressemble \u00e0 une page de magazine remplie de contenus,  _Organizr  reprend l\u2019aspect d\u2019un portail avec menu lat\u00e9ral,  Fenrus  a un style par d\u00e9faut plut\u00f4t futuriste. N\u2019h\u00e9sitez pas \u00e0 consulter des  captures d\u2019\u00e9cran/demo  de chacun pour voir lequel vous pla\u00eet le plus \u2013 tous offrent des options de th\u00e8mes pour ajuster ensuite, mais l\u2019agencement de base diff\u00e8re. Le meilleur dashboard est aussi celui qu\u2019on prend plaisir \u00e0 regarder et utiliser au quotidien.</p> </li> </ul> <p>En d\u00e9finitive,  le choix du dashboard d\u00e9pendra de vos priorit\u00e9s personnelles. Ce comparatif a montr\u00e9 qu\u2019aucune solution n\u2019est \u201cparfaite\u201d sur tous les plans : par exemple, le plus simple (Heimdall) est aussi le moins extensible, le plus complet (Dashy) est plus lourd, etc. Prenez en compte la puissance de votre machine, le temps que vous \u00eates pr\u00eat \u00e0 investir dans la configuration, et les fonctionnalit\u00e9s indispensables \u00e0 vos yeux. L\u2019avantage, c\u2019est que tous ces projets \u00e9tant gratuits et open-source, vous pouvez en tester plusieurs relativement facilement (beaucoup proposent des conteneurs Docker mono-fichier pour un essai rapide). Pourquoi ne pas commencer simple avec un Heimdall ou un Flame pour apprivoiser le concept, puis \u00e9voluer vers un Homarr ou Homepage si vous en ressentez les limites ?  Quel que soit votre choix, avoir un dashboard auto-h\u00e9berg\u00e9 transformera votre exp\u00e9rience homelab  en centralisant vos outils et en donnant \u00e0 votre serveur une v\u00e9ritable page d\u2019accueil sur mesure.</p>"},{"location":"reseau/ddns/","title":"DNS Dynamique et DNS Local : Comparatif et Guide Technique","text":""},{"location":"reseau/ddns/#introduction-au-dns-dynamique-ddns","title":"Introduction au DNS dynamique (DDNS)","text":"<p>Sch\u00e9ma \u2013 Fonctionnement d\u2019un service de DNS dynamique.  Un routeur partage son IP actuelle avec le serveur DynDNS, qui associe cette IP au nom d\u2019h\u00f4te (ici  homexyz). Le routeur devient alors joignable via une URL fixe (homexyz.dyndns.org), malgr\u00e9 la variabilit\u00e9 de son adresse IP  . Le DNS dynamique (DDNS) est un m\u00e9canisme qui  met \u00e0 jour automatiquement un enregistrement DNS  lorsque l\u2019adresse IP publique d\u2019un client change  . Cela permet d\u2019acc\u00e9der \u00e0 une machine ou un service chez soi via un nom de domaine stable, m\u00eame si l\u2019IP fournie par le FAI est dynamique et change r\u00e9guli\u00e8rement. En pratique, un petit programme (client DDNS) s\u2019ex\u00e9cute sur votre routeur ou serveur local, surveille les changements d\u2019IP et informe le fournisseur de DDNS lorsque n\u00e9cessaire. Ce dernier met \u00e0 jour l\u2019enregistrement DNS (g\u00e9n\u00e9ralement de type A pour IPv4 et AAAA pour IPv6) pointant vers la nouvelle IP. Ainsi, les  clients peuvent toujours utiliser le m\u00eame nom de domaine  pour atteindre votre r\u00e9seau domestique, sans se soucier des changements d\u2019adresse  .</p>"},{"location":"reseau/ddns/#comparaison-technique-des-services-ddns-cloudflare-duckdns-no-ip-etc","title":"Comparaison technique des services DDNS (Cloudflare, DuckDNS, No-IP, etc.)","text":"<p>Plusieurs services de DNS dynamique coexistent, chacun avec ses atouts, limitations et modalit\u00e9s. Nous pr\u00e9sentons ci-dessous un comparatif technique des solutions populaires, notamment  Cloudflare DDNS,  DuckDNS,  No-IP, ainsi que quelques alternatives, en examinant leurs caract\u00e9ristiques principales.</p>"},{"location":"reseau/ddns/#cloudflare-dns-dynamique-via-api-sur-son-propre-domaine","title":"Cloudflare (DNS dynamique via API sur son propre domaine)","text":"<p>Cloudflare  n\u2019est pas \u00e0 proprement parler un service DDNS traditionnel, mais la popularit\u00e9 de son offre DNS gratuite fait qu\u2019on peut l\u2019utiliser pour du DNS dynamique en mettant \u00e0 jour ses enregistrements via l\u2019API. Il faut  d\u00e9tenir son propre nom de domaine  et le configurer sur Cloudflare (plan gratuit). Ensuite, on utilise l\u2019API de Cloudflare pour mettre \u00e0 jour l\u2019enregistrement DNS pointant vers l\u2019IP dynamique. Cloudflare recommande d\u2019ailleurs cette approche : un script local peut surveiller les changements d\u2019IP et pousser les mises \u00e0 jour via l\u2019API Cloudflare  . Alternativement, on peut utiliser un client existant comme  ddclient  (un utilitaire compatible avec de nombreux fournisseurs DNS) qui supporte Cloudflare nativement  .</p> <ul> <li> <p>Co\u00fbt : Cloudflare ne facture pas ce service \u2013 le plan gratuit Cloudflare DNS suffit, hormis l\u2019achat du nom de domaine aupr\u00e8s d\u2019un registrar.</p> </li> <li> <p>M\u00e9canisme : la mise \u00e0 jour se fait via des requ\u00eates HTTPS \u00e0 l\u2019API REST de Cloudflare, en fournissant un  token API  ou une cl\u00e9 API globale pour authentification. Il est  recommand\u00e9 d\u2019utiliser un token API restreint  aux droits DNS sur la zone concern\u00e9e, par mesure de s\u00e9curit\u00e9  . Dans l\u2019interface Cloudflare, on cr\u00e9e un jeton avec permissions \u00ab Zone : DNS : Edit \u00bb sur le domaine cible. Ce token pourra \u00eatre utilis\u00e9 par ddclient ou un script maison. Par exemple, sur OPNsense on configurera  Username  = \u201ctoken\u201d et  Password  = le token API Cloudflare  .</p> </li> <li> <p>Domaine et h\u00f4tes : Cloudflare permet d\u2019utiliser  son propre domaine  (ex.  monserveur.maison.com). On peut mettre \u00e0 jour un ou plusieurs enregistrements (sous-domaines) de ce domaine. Il n\u2019y a pas de limite stricte sur le nombre d\u2019h\u00f4tes g\u00e9r\u00e9s dynamiquement (en pratique, on peut avoir de multiples sous-domaines). On peut aussi tirer parti de plusieurs domaines si on en poss\u00e8de, le tout via le m\u00eame compte Cloudflare.</p> </li> <li> <p>Propagation &amp; TTL : Les enregistrements DNS chez Cloudflare peuvent avoir un TTL tr\u00e8s bas (jusqu\u2019\u00e0  60 secondes  sur les enregistrements non-proxy  ). Cela signifie qu\u2019en cas de changement d\u2019IP, la nouvelle IP se propage rapidement.  Note:  Si l\u2019enregistrement est pass\u00e9 en mode proxy (CDN Cloudflare activ\u00e9, \u00ab orange cloud \u00bb), le TTL est g\u00e9r\u00e9 diff\u00e9remment car les clients voient l\u2019IP du proxy Cloudflare.</p> </li> <li> <p>Avantages : mise \u00e0 jour rapide, usage de son propre nom de domaine (plus professionnel), aucun besoin de confirmer p\u00e9riodiquement l\u2019activit\u00e9 (pas d\u2019expiration tant que le domaine est valide), int\u00e9gration possible avec d\u2019autres fonctionnalit\u00e9s Cloudflare (proxy web, pare-feu applicatif, certificats SSL gratuits, DNSSEC, etc.). De plus, Cloudflare \u00e9tant un DNS anycast mondial, la  fiabilit\u00e9 et rapidit\u00e9 de r\u00e9solution  sont excellentes.</p> </li> <li> <p>Inconv\u00e9nients : n\u00e9cessite de g\u00e9rer un nom de domaine (co\u00fbt annuel du domaine, configuration des serveurs NS vers Cloudflare). L\u2019int\u00e9gration n\u2019est pas \u00ab plug-and-play \u00bb sur tous les \u00e9quipements : peu de routeurs grand public proposent Cloudflare en option DDNS, il faudra souvent recourir \u00e0 un script ou \u00e0 la fonction \u00ab Custom DDNS \u00bb. La s\u00e9curit\u00e9 doit \u00eatre bien configur\u00e9e (utilisation d\u2019un token limit\u00e9) car une compromission du token pourrait permettre de d\u00e9tourner votre DNS. Enfin, Cloudflare n\u2019offre pas d\u2019option simple de sous-domaine gratuit g\u00e9n\u00e9rique (contrairement \u00e0 DuckDNS, No-IP\u2026), il faut utiliser un domaine \u00e0 soi.</p> </li> </ul>"},{"location":"reseau/ddns/#duckdns-service-ddns-gratuit","title":"DuckDNS (service DDNS gratuit)","text":"<p>DuckDNS  est un service de DNS dynamique enti\u00e8rement gratuit, op\u00e9r\u00e9 de mani\u00e8re communautaire (soutenu par des dons), tr\u00e8s appr\u00e9ci\u00e9 pour sa simplicit\u00e9. Il fournit des sous-domaines sous la forme  *.duckdns.org. Quelques points cl\u00e9s :</p> <ul> <li> <p>Co\u00fbt et limites : DuckDNS est 100\u202f% gratuit, sans offre payante. Chaque compte peut cr\u00e9er  jusqu\u2019\u00e0 5 sous-domaines  DuckDNS (on peut en obtenir davantage sur demande dans certains cas)  . Cette limite de 5 est g\u00e9n\u00e9ralement suffisante pour un usage personnel (ex.  maison.duckdns.org,  cloud.duckdns.org, etc.).</p> </li> <li> <p>Mise \u00e0 jour : L\u2019API DuckDNS est extr\u00eamement simple : la mise \u00e0 jour se fait via une requ\u00eate HTTP (ou HTTPS) contenant un  token d\u2019authentification unique  et le nom de domaine. Par exemple :  https://www.duckdns.org/update?domains=monhote&amp;token=abcdef123456&amp;ip=1.2.3.4. De nombreux scripts tout pr\u00eats existent. DuckDNS fournit d\u2019ailleurs des instructions pour divers OS (Windows, Linux, macOS) et peut \u00eatre int\u00e9gr\u00e9 dans des scripts shell, cron, containers Docker, etc. Par exemple, pour Docker, on trouve des images l\u00e9g\u00e8res qui appellent p\u00e9riodiquement l\u2019URL DuckDNS. Sur Home Assistant, une extension DuckDNS facilite l\u2019int\u00e9gration (y compris l\u2019obtention d\u2019un certificat SSL via Let\u2019s Encrypt).</p> </li> <li> <p>Avantages : extr\u00eame simplicit\u00e9 et l\u00e9g\u00e8ret\u00e9. Pas de cr\u00e9ation de compte complexe : on s\u2019authentifie via un compte GitHub, Google ou autre provider OAuth pour obtenir son token.  Aucune confirmation mensuelle  n\u2019est requise : une fois configur\u00e9, le sous-domaine reste actif tant qu\u2019il est r\u00e9guli\u00e8rement mis \u00e0 jour. Le service supporte IPv6 \u00e9galement. DuckDNS n\u2019impose pas de fr\u00e9quence minimale ou maximale de mise \u00e0 jour, mais typiquement un cron toutes les 5 minutes ou \u00e0 chaque changement d\u2019IP suffit. La communaut\u00e9 Homelab/auto-h\u00e9bergement le recommande souvent pour sa fiabilit\u00e9 globale et son  int\u00e9gration facile \u00e0 des projets DIY  (automatisation, scripts).</p> </li> <li> <p>Inconv\u00e9nients : d\u00e9pendance \u00e0 un service gratuit g\u00e9r\u00e9 par une petite \u00e9quipe (disponibilit\u00e9 g\u00e9n\u00e9ralement bonne mais il y a eu de rares interruptions rapport\u00e9es  ). Le choix du domaine est limit\u00e9 \u00e0  duckdns.org  (pas d\u2019autres suffixes), ce qui peut faire moins \u00ab professionnel \u00bb ou \u00eatre plus facile \u00e0 deviner. DuckDNS n\u2019offre pas de fonctionnalit\u00e9s annexes (pas de gestion de DNS complexes, pas de support client d\u00e9di\u00e9 \u2013 juste une FAQ et forum). N\u00e9anmoins, pour un usage personnel, ces limites sont tr\u00e8s acceptables.</p> </li> </ul>"},{"location":"reseau/ddns/#no-ip-service-freemium-historique","title":"No-IP (service freemium, historique)","text":"<p>No-IP  est l\u2019un des plus anciens services de DNS dynamique (concurrent de DynDNS \u00e0 l\u2019\u00e9poque). Il fonctionne sur un mod\u00e8le freemium : il existe un niveau gratuit limit\u00e9, et des offres payantes avec plus de fonctionnalit\u00e9s. Caract\u00e9ristiques :</p> <ul> <li> <p>Offre gratuite : Permet aujourd\u2019hui  1 hostname actif  (sous-domaine) sur un compte gratuit  . Historiquement, No-IP offrait 3 h\u00f4tes gratuits, mais les conditions ont chang\u00e9 ces derni\u00e8res ann\u00e9es. Le sous-domaine peut \u00eatre choisi parmi une  trentaine de noms de domaine propos\u00e9s  par No-IP (ex.  ddns.net,  hopto.org,  zapto.org, etc.). Cela donne un peu de diversit\u00e9 (si par exemple  monserveur.hopto.org  est pris, on peut essayer  monserveur.ddns.net, etc.).</p> </li> <li> <p>Expiration/confirmation : La contrainte majeure de l\u2019offre gratuite est la n\u00e9cessit\u00e9 de  confirmer p\u00e9riodiquementque le hostname est toujours utilis\u00e9. Concr\u00e8tement,  tous les 30 jours  No-IP envoie un email de confirmation \u00e0 l\u2019utilisateur, qui doit cliquer un lien pour \u00e9viter la d\u00e9sactivation de son DNS  . Si on ne confirme pas, l\u2019h\u00f4te passe en \u00e9tat \u00ab Expired \u00bb puis \u00ab Redemption \u00bb et finit par \u00eatre supprim\u00e9  . Cette politique vise \u00e0 lib\u00e9rer les noms non utilis\u00e9s, mais c\u2019est une contrainte \u00e0 ne pas n\u00e9gliger (ou bien il faut passer en offre payante pour s\u2019en affranchir).</p> </li> <li> <p>Offre Enhanced/Premium : No-IP propose des abonnements payants relativement abordables supprimant la confirmation mensuelle et autorisant plus d\u2019h\u00f4tes (par ex. l\u2019offre Enhanced ~5$/mois pour 5 hostnames, l\u2019offre  Plusou  Professional  pour davantage d\u2019h\u00f4tes et son propre domaine, etc.  ). Les offres payantes permettent aussi d\u2019utiliser des enregistrements DNS avanc\u00e9s (MX, TXT), un support client, etc.</p> </li> <li> <p>Clients et int\u00e9gration : No-IP \u00e9tant ancien et r\u00e9pandu,  de nombreux routeurs et NAS int\u00e8grent nativement un client No-IP. Il suffit souvent d\u2019entrer son username, mot de passe et nom d\u2019h\u00f4te dans l\u2019interface du routeur pour que celui-ci mette \u00e0 jour l\u2019IP automatiquement. No-IP fournit aussi son application de mise \u00e0 jour (DUC \u2013 Dynamic Update Client) sur Windows/Linux, ainsi qu\u2019un client en ligne de commande. L\u2019API simple (protocole proche de DynDNS v2) permet d\u2019utiliser des clients g\u00e9n\u00e9riques (ddclient, inadyn, etc.).</p> </li> <li> <p>Avantages : Fiabilit\u00e9 d\u2019une soci\u00e9t\u00e9 \u00e9tablie (No-IP revendique 100% de disponibilit\u00e9 DNS).  Large choix de domaines  gratuits qui peuvent \u00eatre plus m\u00e9morables que les concurrents. Int\u00e9gration plug-and-play sur beaucoup d\u2019\u00e9quipements. Possibilit\u00e9 d\u2019\u00e9volution vers des offres avanc\u00e9es (par exemple, utiliser votre propre nom de domaine avec No-IP comme gestionnaire DNS dynamique : leur offre Plus g\u00e8re jusqu\u2019\u00e0 50 h\u00f4tes sur votre domaine personnalis\u00e9  ).</p> </li> <li> <p>Inconv\u00e9nients : La confirmation mensuelle est souvent vue comme une corv\u00e9e (il ne faut pas oublier de cliquer sous peine de coupure). Un seul h\u00f4te gratuit limite l\u2019utilisation multi-services (mais on peut contourner partiellement avec un wildcard, voir plus bas). Le service gratuit comporte de la publicit\u00e9 (emails de rappel, et auparavant les redirections web affichaient des banni\u00e8res, bien que ce soit moins un probl\u00e8me pour un simple enregistrement A). Enfin, No-IP a pu \u00eatre cibl\u00e9 par certains blocages ou abus dans le pass\u00e9 (des malware utilisaient des h\u00f4tes No-IP, entra\u00eenant parfois des blocages temporaires de certains domaines No-IP par des FAI ou entreprises). Ce n\u2019est pas commun, mais \u00e0 savoir.</p> </li> </ul>"},{"location":"reseau/ddns/#autres-alternatives-notables","title":"Autres alternatives notables","text":"<p>En dehors de Cloudflare, DuckDNS et No-IP, il existe d\u2019autres services DynDNS, chacun avec ses particularit\u00e9s :</p> <ul> <li> <p>FreeDNS (Afraid.org) : Service gratuit ancien et fiable, qui offre jusqu\u2019\u00e0  5 sous-domaines gratuits  . Son point fort est le grand choix de domaines publics partag\u00e9s (plus de 50) parmi lesquels choisir son sous-domaine. Par exemple  .mooo.com  (tr\u00e8s utilis\u00e9),  .afraid.org, etc. L\u2019interface est un peu rustique, mais c\u2019est efficace. FreeDNS propose aussi une formule payante augmentant le nombre de sous-domaines (50 \u00e0 500) et offrant des options comme les wildcards et un branding sans r\u00e9f\u00e9rence \u00e0 Afraid.org  .</p> </li> <li> <p>Dynu : Un fournisseur moderne qui offre un service gratuit de DNS dynamique  sans expiration. D\u2019apr\u00e8s certaines ressources, la version gratuite de Dynu permettrait plusieurs hostnames (jusqu\u2019\u00e0 30) mais avec certaines limitations  . Cependant, il semble qu\u2019il faille cr\u00e9er un compte et que les fonctionnalit\u00e9s compl\u00e8tes (DNSSEC, plus de domaines, etc.) n\u00e9cessitent un abonnement modique. \u00c0 v\u00e9rifier, car le comparatif IONOS mentionne une p\u00e9riode d\u2019essai de 7 jours pour la version gratuite  \u2013 ce point peut pr\u00eater \u00e0 confusion. N\u00e9anmoins, Dynu est souvent cit\u00e9 comme alternative, avec client d\u00e9di\u00e9 et API.</p> </li> <li> <p>Securepoint DynDNS : Service gratuit propos\u00e9 par une entreprise allemande, limit\u00e9 \u00e0  5 h\u00f4tes  mais offrant un  choix de 100 domaines  diff\u00e9rents  . N\u00e9cessite une inscription. Supporte IPv6 et fournit un \u201ctoken\u201d de mise \u00e0 jour unique pour usage dans les clients. Plut\u00f4t destin\u00e9 aux utilisateurs europ\u00e9ens (site en allemand/anglais).</p> </li> <li> <p>YDNS : Service gratuit (g\u00e9r\u00e9 par une association allemande) offrant des domaines sous  ydns.eu  ou la possibilit\u00e9 d\u2019utiliser son propre domaine. Avantage :  supporte DNSSEC  pour les domaines personnalis\u00e9s. Nombre d\u2019h\u00f4tes illimit\u00e9 annonc\u00e9  . Interface minimaliste, API possible.</p> </li> <li> <p>deSEC (dedyn.io) : Solution  non-profit bas\u00e9e en Allemagne, orient\u00e9e s\u00e9curit\u00e9. deSEC offre gratuitement de g\u00e9rer vos domaines avec DNSSEC et API, ainsi que des sous-domaines sous  dedyn.io. On peut y voir un  v\u00e9ritable gestionnaire de DNS dynamique moderne. Limite : ~15 domaines par compte (mais extensible sur demande)  . Pas de pub, pas d\u2019offre payante, tout est financ\u00e9 par dons/recherche. Compatible directement avec les clients ACME (Let\u2019s Encrypt) pour la validation DNS. C\u2019est une alternative robuste et ouverte \u00e0 DuckDNS/no-ip, pour utilisateurs avanc\u00e9s  .</p> </li> <li> <p>Dyn.com (Oracle DynDNS) : Historiquement  LE  service DynDNS, tr\u00e8s connu il y a 15 ans, mais il n\u2019est plus disponible gratuitement depuis longtemps. Oracle (qui a rachet\u00e9 Dyn) a m\u00eame annonc\u00e9 l\u2019arr\u00eat complet du service grand public en 2022. Il n\u2019est donc plus \u00e0 consid\u00e9rer pour un nouvel usage.</p> </li> <li> <p>Autres : citons encore  Google Domains  qui offrait un DDNS pour les domaines enregistr\u00e9s chez eux (mais Google Domains est en cours de reprise par Squarespace en 2023-2024),  OVH DynHost  (pour les domaines chez OVH),  Namecheap Dynamic DNS  (pour domaines chez Namecheap) \u2013 ces services attach\u00e9s aux registrars peuvent \u00eatre utiles si vous avez achet\u00e9 le domaine chez eux. Enfin, il existe la possibilit\u00e9 d\u2019auto-h\u00e9berger son propre service DDNS  (par exemple via un script PHP ou un petit serveur DNS avec mise \u00e0 jour par requ\u00eate HTTP), mais ceci d\u00e9passe le cadre de la comparaison \u2013 c\u2019est faisable pour les makers cherchant un contr\u00f4le total.</p> </li> </ul> <p>Wildcards et cas multi-sous-domaines : Une question fr\u00e9quente est la prise en charge des  wildcards DNS  (par exemple  .maison.ddns.net). La plupart des services gratuits  n\u2019autorisent pas de wildcard sur un domaine gratuit, ou seulement avec une offre payante (No-IP le permet en payant). Cloudflare permet des wildcards sur votre domaine, mais Let\u2019s Encrypt par exemple n\u00e9cessite un d\u00e9fi DNS pour obtenir un certificat wildcard. En pratique, si on veut exposer plusieurs services derri\u00e8re une IP dynamique, deux approches : 1) mettre \u00e0 jour  plusieurs enregistrements A  (ex:  service1.mondomaine.com,  service2.mondomaine.com  \u2013 Cloudflare API ou le client peut g\u00e9rer plusieurs hostnames), ou 2) utiliser un nom d\u2019h\u00f4te dynamique principal et faire des  CNAME*  pour les autres. Par exemple, avec DuckDNS on a  maison.duckdns.org  mis \u00e0 jour; on peut pointer  nextcloud.mondomaineperso.com CNAME maison.duckdns.org  \u2013 ainsi ce CNAME suivra l\u2019IP dynamique indirectement. Cette m\u00e9thode mixte est utile si on tient \u00e0 utiliser un nom de domaine personnalis\u00e9 sans g\u00e9rer l\u2019API soi-m\u00eame.</p>"},{"location":"reseau/ddns/#scenarios-dusage-types-avec-le-dns-dynamique","title":"Sc\u00e9narios d\u2019usage types avec le DNS dynamique","text":"<p>Dans quel contexte a-t-on besoin de DNS dynamique ? Voici trois sc\u00e9narios courants de la vie d\u2019un homelab ou r\u00e9seau domestique, illustrant l\u2019usage du DDNS et les consid\u00e9rations associ\u00e9es.</p>"},{"location":"reseau/ddns/#1-homelab-derriere-une-ip-dynamique-acces-distant-a-un-reseau-domestique","title":"1. Homelab derri\u00e8re une IP dynamique (acc\u00e8s distant \u00e0 un r\u00e9seau domestique)","text":"<p>Imaginons une personne qui h\u00e9berge chez elle un  serveur NAS  ou des services web (site personnel, cloud priv\u00e9 type Nextcloud, cam\u00e9ra de surveillance, etc.). Son FAI lui attribue une IP publique dynamique qui change r\u00e9guli\u00e8rement (par exemple \u00e0 chaque red\u00e9marrage de box, ou tous les X jours). Sans DNS dynamique, il faudrait conna\u00eetre l\u2019IP \u00e0 jour et la communiquer \u00e0 chaque fois \u2013 impraticable. Le DDNS r\u00e9sout ce probl\u00e8me : on configure un nom de domaine (par ex.  mynas.duckdns.org) et un client DDNS sur la box ou le NAS. D\u00e9sormais, l\u2019utilisateur peut acc\u00e9der \u00e0 son NAS en utilisant ce  nom de domaine fixe, que ce soit pour se connecter en SSH, en HTTP, ou pour toute autre application (ex: configurer un client de sauvegarde vers  mynas.duckdns.org). Le service DDNS garantit que ce nom pointe vers la bonne IP m\u00eame apr\u00e8s un changement.</p> <p>Dans ce sc\u00e9nario, on  configure le routeur pour rediriger les ports n\u00e9cessaires  vers le serveur interne. Par exemple, on peut ouvrir le port 443 vers le NAS pour acc\u00e9der \u00e0 l\u2019interface web.  C\u00f4t\u00e9 s\u00e9curit\u00e9, il est recommand\u00e9 d\u2019utiliser des certificats SSL (ex: via Let\u2019s Encrypt, qui accepte les noms de domaine DuckDNS ou autres) pour chiffrer les connexions externes. Le nom de domaine dynamique permet justement d\u2019obtenir et renouveler ces certificats automatiquement.</p> <p>Si l\u2019on souhaite un acc\u00e8s plus s\u00e9curis\u00e9, on pourrait n\u2019exposer aucun port et passer par un VPN ou un tunnel. Par exemple, Tailscale (VPN maill\u00e9) ou Cloudflare Tunnel (agent qui sortant qui enregistre le service chez Cloudflare) sont des alternatives pour \u00e9viter des ouvertures de ports. Ces solutions utilisent aussi DNS (Cloudflare Tunnel fournit un nom en  tunnels.dev, Tailscale peut g\u00e9rer des MagicDNS internes), mais elles sortent du cadre du DDNS classique. Retenons qu\u2019un homelab accessible via DDNS doit \u00eatre  prot\u00e9g\u00e9 comme un serveur en ligne : mises \u00e0 jour, pare-feu, mots de passe forts, etc., car il devient joignable depuis Internet par son nom.</p>"},{"location":"reseau/ddns/#2-integration-avec-un-reverse-proxy-pour-multi-services","title":"2. Int\u00e9gration avec un reverse proxy pour multi-services","text":"<p>Beaucoup d\u2019auto-h\u00e9bergeurs d\u00e9ploient plusieurs services web sur la m\u00eame IP (ex: serveur web, interface domotique, cam\u00e9ra IP, etc.). Gr\u00e2ce au DNS dynamique, on peut utiliser  plusieurs sous-domaines  qui pointent tous vers la m\u00eame IP publique. Ensuite, un  reverse proxy  local (Nginx, Traefik, Caddy\u2026) se charge de distribuer le trafic entrant vers le bon service en fonction du nom de domaine requis.</p> <p>Concr\u00e8tement, on peut avoir par exemple un nom de domaine dynamique principal  ma-maison.fr  (g\u00e9r\u00e9 via Cloudflare ou autre). On cr\u00e9e des enregistrements pour  nextcloud.ma-maison.fr,  camera.ma-maison.fr,  homeassistant.ma-maison.fr  \u2013 tous pointent \u00e0 l\u2019adresse IP de la box. Sur le routeur, on a une redirection du port 443 vers la machine h\u00e9bergeant le reverse proxy (ex: un Raspberry Pi). Ce reverse proxy voit la requ\u00eate arriv\u00e9e et, gr\u00e2ce au SNI du TLS ou \u00e0 l\u2019Host HTTP, fait suivre aux bons serveurs internes.</p> <p>Exemple illustratif :  \u00ab Supposons que vous ayez le domaine dandreyd.com__. Vous pouvez cr\u00e9er des sous-domaines : service1.dandreyd.com__, service2.dandreyd.com__, etc., qui pointent tous vers l\u2019IP publique (1.2.3.4) de votre serveur. Votre reverse proxy \u00e9coute sur cette IP et, lorsqu\u2019une connexion arrive sur service1.dandreyd.com__, il la route vers le service interne correspondant (par ex. 192.168.2.19) \u00bb  . De cette fa\u00e7on,  un seul point d\u2019entr\u00e9e  (IP + port 443) peut desservir de multiples applications. Le DNS dynamique s\u2019assure que  *.dandreyd.com  est toujours \u00e0 jour vers l\u2019IP du jour.</p> <p>Avec Cloudflare DNS par exemple, on peut m\u00eame activer le  proxy Cloudflare (orange cloud)  sur certains sous-domaines, ce qui ajoute une couche de cache/WAF (utile pour un site web public) et masque l\u2019IP originelle. Cependant, pour des services personnels non web (Nextcloud priv\u00e9, etc.), on utilise g\u00e9n\u00e9ralement le DNS de Cloudflare en mode DNS seulement (pas de proxy) pour \u00e9viter des complexit\u00e9s sur les flux non-HTTP.</p> <p>Certificats SSL : Dans un tel setup, on obtient des certificats multi-domaines (ou wildcard) pour couvrir tous les sous-domaines. Let\u2019s Encrypt via un challenge DNS (facile si on a Cloudflare) ou via challenge HTTP (possible en exposant temporairement chaque service ou via le proxy) peut automatiser cela. Par exemple, l\u2019add-on DuckDNS de Home Assistant automatise la cr\u00e9ation d\u2019un certificat pour le nom DuckDNS + un acc\u00e8s s\u00e9curis\u00e9.</p> <p>En termes de s\u00e9curit\u00e9, ce sc\u00e9nario profite du fait que  chaque service n\u2019est pas expos\u00e9 sur un port distinct  (on n\u2019ouvre que 443, et \u00e9ventuellement 80 pour les challenges, bien que avec le DNS challenge ce ne soit pas n\u00e9cessaire). Le reverse proxy peut g\u00e9rer l\u2019authentification, forcer HTTPS, et appliquer des r\u00e8gles (rate limiting, firewall d\u2019app, int\u00e9gration fail2ban, etc.). On conseille de  d\u00e9sactiver l\u2019acc\u00e8s HTTP  (redirection vers HTTPS) et de n\u2019autoriser que TLS moderne sur le proxy.</p>"},{"location":"reseau/ddns/#3-considerations-de-securite-et-bonnes-pratiques","title":"3. Consid\u00e9rations de s\u00e9curit\u00e9 et bonnes pratiques","text":"<p>Exposer son r\u00e9seau domestique via un nom de domaine public n\u00e9cessite quelques pr\u00e9cautions :</p> <ul> <li> <p>Mises \u00e0 jour DNS s\u00e9curis\u00e9es : Toujours utiliser le  chiffrement  pour les requ\u00eates de mise \u00e0 jour DDNS. La plupart des services imposent HTTPS, mais si ce n\u2019est pas le cas, pr\u00e9f\u00e9rez un client qui le supporte ou un tunnel. Par exemple, ddclient en mode Cloudflare utilise HTTPS par d\u00e9faut  . Ceci \u00e9vite qu\u2019un attaquant sur le m\u00eame r\u00e9seau puisse intercepter votre token.</p> </li> <li> <p>Protection des identifiants : Les services comme Cloudflare utilisent des API tokens \u2013 stockez-les en lieu s\u00fbr (fichier de config en permissions restreintes, etc.). De m\u00eame pour les logins/mots de passe No-IP ou autres. Ne les mettez pas en dur dans un script public.</p> </li> <li> <p>Ports expos\u00e9s minimalement : N\u2019exposez que le n\u00e9cessaire. Par exemple, inutile d\u2019ouvrir Telnet ou SSH au monde entier. Privil\u00e9giez un VPN pour l\u2019administration distante. Si un service n\u2019a pas vocation \u00e0 \u00eatre acc\u00e9d\u00e9 publiquement, ne le mappez pas sur le reverse proxy.</p> </li> <li> <p>Utilisez HTTPS : Gr\u00e2ce au DNS dynamique, vous avez un nom de domaine \u2013 profitez-en pour d\u00e9ployer du HTTPS via Let\u2019s Encrypt ou un autre CA. De nombreux tutos existent pour coupler Let\u2019s Encrypt avec DuckDNS (le DNS-01 challenge via DuckDNS est une possibilit\u00e9, ou plus simplement le HTTP-01 si le service est accessible). Un navigateur ou une API appellera ainsi  https://monservice.maison:443  en toute confiance.</p> </li> <li> <p>Cloudflare en proxy : Si vous utilisez Cloudflare DNS, \u00e9valuer l\u2019option proxy (mode \u201corange\u201d). Pour un blog personnel ou un petit site, cela peut apporter une couche de protection (Cloudflare filtre les attaques DDoS, offre un pare-feu applicatif de base). Par contre, pour acc\u00e9der \u00e0 un service non-HTTP (SSH, MQTT\u2026), le proxy Cloudflare ne convient pas, on restera en connexion directe (ou on utilisera Cloudflare Tunnel sp\u00e9cifiquement pour certaines applications web).</p> </li> <li> <p>Mises \u00e0 jour et monitoring : Tenez \u00e0 jour vos services expos\u00e9s (un Nextcloud obsol\u00e8te ou une cam\u00e9ra IP non patch\u00e9e peuvent \u00eatre compromis). Surveillez les logs, et \u00e9ventuellement utilisez des outils comme Fail2Ban pour bannir les IP en cas de brute-force. Le DNS dynamique ne rend pas l\u2019attaque plus facile en soi, mais il rend votre service plus  visible sur Internet  via un nom de domaine. D\u2019ailleurs, attention, certains robots scannent les domaines *.duckdns.org ou  .no-ip.  connus \u2013 vous pourriez voir du trafic malveillant g\u00e9n\u00e9rique. D\u2019o\u00f9 l\u2019importance des pr\u00e9cautions classiques.</p> </li> </ul> <p>En r\u00e9sum\u00e9, un usage typique du DNS dynamique dans un cadre homelab implique une configuration combinant  DDNS + redirections NAT + (optionnellement) reverse proxy + certificats SSL. Cette combinaison permet de reproduire \u00e0 l\u2019\u00e9chelle domestique ce qu\u2019un h\u00e9bergeur professionnel ferait, tout en contournant la limitation d\u2019IP non fixe.</p>"},{"location":"reseau/ddns/#serveurs-dns-locaux-unbound-dnsmasq-et-leur-role-en-reseau-domestique","title":"Serveurs DNS locaux (Unbound, Dnsmasq) et leur r\u00f4le en r\u00e9seau domestique","text":"<p>Abordons maintenant la question des  DNS locaux : au sein de votre r\u00e9seau local, vous pouvez d\u00e9ployer un serveur DNS maison (par exemple avec  Unbound  ou  Dnsmasq). Quel est l\u2019int\u00e9r\u00eat, et comment cela s\u2019articule-t-il avec le DNS dynamique vu plus haut ?</p>"},{"location":"reseau/ddns/#role-dun-dns-local-dans-une-architecture-domestique","title":"R\u00f4le d\u2019un DNS local dans une architecture domestique","text":"<p>Dans un r\u00e9seau domestique typique, vos PC, smartphones et objets utilisent le DNS de l\u2019op\u00e9rateur ou un DNS public (Google, Cloudflare\u2026) pour r\u00e9soudre les noms de domaine externes. Installer un serveur DNS local (sur le routeur ou un Raspberry Pi) peut apporter plusieurs b\u00e9n\u00e9fices :</p> <ul> <li> <p>Cache DNS partag\u00e9 : Le serveur DNS local sert de  cache  pour toutes les requ\u00eates des appareils. Les r\u00e9solutions r\u00e9p\u00e9t\u00e9es (par ex.  www.google.com) seront acc\u00e9l\u00e9r\u00e9es car la r\u00e9ponse sera servie localement sans requ\u00eater \u00e0 chaque fois un DNS externe. Cela  am\u00e9liore la latence  per\u00e7ue et r\u00e9duit un peu la consommation de bande passante  .</p> </li> <li> <p>R\u00e9solution des noms locaux : Un DNS local peut conna\u00eetre les noms de vos machines internes (par exemple  monpc.lan  qui pointe vers 192.168.1.10). Sans DNS local, on se rabat sur des solutions comme mDNS (.local) ou WINS, pas toujours fiables ou universelles. Avec Dnsmasq ou Unbound configur\u00e9, on peut automatiquement enregistrer les baux DHCP dans le DNS : ainsi, toute machine du LAN peut pinguer  monpc.lan  et \u00e7a r\u00e9sout. Unbound sur OPNsense/pfSense, par exemple, a une option  Register DHCP leases  qui ajoute les machines DHCP au DNS  . Cela  simplifie grandement l\u2019administration : plus besoin d\u2019\u00e9diter les fichiers hosts de chaque PC.</p> </li> <li> <p>Override / Split-horizon DNS : On peut d\u00e9finir des entr\u00e9es DNS sp\u00e9cifiques pour certains noms. Tr\u00e8s utile dans le cas du  DNS dynamique  justement. Supposons que depuis l\u2019ext\u00e9rieur on acc\u00e8de \u00e0  monnas.duckdns.org  (r\u00e9solu vers l\u2019IP publique). Depuis l\u2019int\u00e9rieur du LAN, si on utilise ce m\u00eame nom, on va sortir vers Internet pour revenir vers la box (hairpin NAT). Cela peut \u00eatre inefficace, voire bloqu\u00e9 par certains routeurs. Avec un DNS local, on peut configurer une r\u00e8gle override disant :  \u201cmonnas.duckdns.org = 192.168.1.50\u201d  (IP locale du NAS). Ainsi les clients internes acc\u00e8dent directement, sans passer par la boucle externe. Unbound et Dnsmasq permettent ces  overrides locaux  facilement (sur OPNsense GUI, via \u201cHost Overrides\u201d ou \u201cDomain Overrides\u201d)  . On parle de DNS \u00ab split-horizon \u00bb lorsque l\u2019interne et l\u2019externe renvoient des IP diff\u00e9rentes pour un m\u00eame nom, optimisant l\u2019acc\u00e8s selon la provenance.</p> </li> <li> <p>Filtrage et s\u00e9curit\u00e9 : Un DNS local peut incorporer des  listes de blocage  (pour bloquer des domaines publicitaires, malveillants, etc.). Par exemple, Pi-hole (tr\u00e8s populaire sur Raspberry Pi) utilise en interne Dnsmasq (ou son fork FTL) pour filtrer des domaines. Unbound peut aussi faire du filtrage via des zones nulles. Cela procure un  bloqueur de pub/malware r\u00e9seau  centralis\u00e9. De plus, un serveur DNS local bien configur\u00e9 peut activer  DNSSEC  pour v\u00e9rifier l\u2019authenticit\u00e9 des r\u00e9ponses DNS externes, et m\u00eame chiffrer les requ\u00eates sortantes via  DNS over TLS (DoT)si on le configure en forwarder TLS. Unbound supporte nativement DNSSEC et DoT  , ce qui permet d\u2019\u00e9viter les attaques de cache poisoning et d\u2019am\u00e9liorer la confidentialit\u00e9 des requ\u00eates (en emp\u00eachant un espion local ou FAI de voir toutes les requ\u00eates en clair).</p> </li> <li> <p>Haute disponibilit\u00e9 locale : Si votre acc\u00e8s Internet tombe, un DNS local garde en cache un certain nombre de domaines r\u00e9cemment r\u00e9solus, permettant aux machines de continuer \u00e0 se r\u00e9soudre localement et parfois d\u2019acc\u00e9der \u00e0 des ressources en cache (si par exemple un serveur local sert du contenu, etc.). Bon, \u00e7a reste un cas limit\u00e9, mais disons que l\u2019infrastructure locale ne d\u00e9pend plus enti\u00e8rement des DNS ext\u00e9rieurs.</p> </li> </ul>"},{"location":"reseau/ddns/#unbound-vs-dnsmasq-differences-et-complementarite","title":"Unbound vs. Dnsmasq : diff\u00e9rences et compl\u00e9mentarit\u00e9","text":"<p>Dnsmasq  et  Unbound  sont deux solutions courantes pour le DNS local, souvent utilis\u00e9es dans les firmwares routeurs et homelabs. Leurs r\u00f4les se recoupent partiellement, mais ils ont des philosophies diff\u00e9rentes  :</p> <ul> <li> <p>Dnsmasq  est un  DNS forwarder/cache l\u00e9ger  qui fait aussi serveur DHCP. Il ne r\u00e9sout pas les requ\u00eates r\u00e9cursives lui-m\u00eame : il  transmet les requ\u00eates \u00e0 un ou plusieurs DNS upstream  (par exemple les DNS de l\u2019op\u00e9rateur ou de Cloudflare)  . Il se veut tr\u00e8s l\u00e9ger en m\u00e9moire et con\u00e7u pour les routeurs/embarqu\u00e9s. Il excelle \u00e0 distribuer les baux DHCP et \u00e0 enregistrer automatiquement ces h\u00f4tes en DNS. En revanche, il ne valide pas DNSSEC tout seul, et ne chiffre pas les requ\u00eates (il peut n\u00e9anmoins \u00eatre point\u00e9 vers un r\u00e9solveur tiers qui fait DNSSEC). Son empreinte est minimale, ce qui le rend id\u00e9al pour de petits environnements ou \u00e9quipements modestes.</p> </li> <li> <p>Unbound  est un  r\u00e9solveur DNS r\u00e9cursif complet  (comme BIND dans sa fonction r\u00e9cursive) qui peut interroger directement les serveurs racine, domaines de premier niveau, etc. Il  n\u2019a pas besoin de serveur DNS upstream(sauf si on le configure en mode forwarder). Unbound fait de la  validation DNSSEC  en local et supporte les protocoles modernes (DNS over TLS, DNS64 pour IPv6, etc.)  . Il maintient un cache efficace et robuste. Depuis quelques ann\u00e9es, il a \u00e9t\u00e9 adopt\u00e9 par d\u00e9faut sur OPNsense/pfSense car jug\u00e9 plus s\u00e9curis\u00e9 et respectueux de la vie priv\u00e9e (plus besoin de faire confiance \u00e0 un DNS tiers)  . Unbound ne fait pas DHCP, mais il peut parfaitement r\u00e9cup\u00e9rer les infos du serveur DHCP du syst\u00e8me (voir plus haut) pour la r\u00e9solution locale.</p> </li> </ul> <p>En termes de  performances : un r\u00e9solveur complet comme Unbound peut \u00eatre tr\u00e8s rapide apr\u00e8s le premier remplissage de cache, et \u00e9vite des d\u00e9pendances. Cependant, la premi\u00e8re requ\u00eate \u00e0 un domaine peut \u00eatre un peu plus longue (le temps de contacter les racines et autorit\u00e9s). Sur un r\u00e9seau domestique, la diff\u00e9rence est n\u00e9gligeable, d\u2019autant qu\u2019Unbound optimise et pipeline les requ\u00eates. Dnsmasq, lui, d\u00e9pend totalement de la latence vers le DNS amont (par ex. 20ms vers 1.1.1.1). Donc apr\u00e8s cache, ils se valent, mais Unbound offre plus de contr\u00f4le et potentiellement une r\u00e9solution plus directe  .</p> <p>S\u00e9curit\u00e9 et fiabilit\u00e9 : Comme mentionn\u00e9, Dnsmasq fait confiance aux r\u00e9ponses de l\u2019upstream \u2013 si votre FAI vous redirige certaines requ\u00eates (portails captifs, censures, etc.), Dnsmasq s\u2019y pliera. Unbound, en r\u00e9solvant lui-m\u00eame et en validant DNSSEC, garantit d\u2019avoir les  donn\u00e9es officielles de la zone DNS  . Il peut d\u00e9tecter une alt\u00e9ration (via DNSSEC) ou \u00e9viter certaines censures (sauf si l\u2019acc\u00e8s \u00e0 certains serveurs DNS est bloqu\u00e9, auquel cas on peut configurer Unbound pour passer par un tunnel ou DoT).</p> <p>Utilisation conjointe : Il est possible d\u2019utiliser  les deux de concert. Par exemple, Pi-hole v5 combine Dnsmasq (FTL) pour le filtrage + Unbound en arri\u00e8re-plan comme r\u00e9solveur, configur\u00e9 de sorte que Dnsmasq forward tout \u00e0 Unbound localement. Cependant, dans la plupart des d\u00e9ploiements routeur, on choisit l\u2019un ou l\u2019autre. pfSense/OPNsense proposent soit Unbound (DNS Resolver) soit Dnsmasq (DNS Forwarder) \u2013 mais pas les deux en m\u00eame temps pour le m\u00eame port. \u00c9tant donn\u00e9 les avantages,  Unbound est g\u00e9n\u00e9ralement recommand\u00e9 par d\u00e9faut  pour les r\u00e9seaux modernes, sauf cas d\u2019usage sp\u00e9cifique  . Dnsmasq reste utile si on a tr\u00e8s peu de ressources ou si on veut une config ultra-simple.</p> <p>En r\u00e9sum\u00e9  :</p> <p>Unbound : r\u00e9solveur r\u00e9cursif complet, rapide (direct, cache efficace), supporte DNSSEC/DoT, gestion avanc\u00e9e des overrides et blocages, id\u00e9al pour s\u00e9curit\u00e9 et performance.</p> <p>Dnsmasq : forwarder DNS + DHCP, tr\u00e8s l\u00e9ger, configuration simple, convient aux petits \u00e9quipements ou si on veut simplement relayer vers un DNS public.</p>"},{"location":"reseau/ddns/#mise-en-place-dans-un-reseau-domestique","title":"Mise en place dans un r\u00e9seau domestique","text":"<p>Dans la pratique, de nombreuses  distributions routeur  embarquent d\u00e9j\u00e0 ces services. Par exemple :</p> <ul> <li> <p>OPNsense/pfSense : utilisent Unbound par d\u00e9faut comme DNS Resolver local (avec possibilit\u00e9 de switcher vers Dnsmasq si d\u00e9sir\u00e9). L\u2019interface permet de d\u00e9finir des  Host Overrides  pour les noms locaux, activer l\u2019enregistrement des baux DHCP  , etc. Si vous utilisez l\u2019un de ces firewalls, vos clients DHCP re\u00e7oivent l\u2019adresse du firewall comme DNS, profitant ainsi du cache local et des r\u00e9solutions internes. Ces syst\u00e8mes facilitent aussi la configuration de DNS over TLS (ex: forwarder vers Cloudflare chiffr\u00e9) ou l\u2019ajout de listes de blocage via des plugins.</p> </li> <li> <p>Routeurs grand public/firmware open-source : Un routeur sous  OpenWrt  utilise Dnsmasq par d\u00e9faut pour DNS+DHCP. L\u00e0 aussi, les machines du LAN utilisent le routeur comme DNS. On peut configurer des noms locaux via /etc/hosts ou le DHCP statique. OpenWrt permet aussi d\u2019ajouter Unbound en compl\u00e9ment pour avoir DNSSEC (via le package  unbound-host). D\u2019autres firmware comme ASUSWRT int\u00e8grent souvent une option DNSSEC ou DoT en forwarder, parfois en gardant dnsmasq pour le cache.</p> </li> <li> <p>Raspberry Pi / Pi-hole : Installer Pi-hole donne un DNS local filtrant (bas\u00e9 sur Dnsmasq). Il suffit de pointer les DNS des postes vers l\u2019IP du Pi-hole (ou configurer le DHCP pour qu\u2019il annonce le Pi comme DNS). Ajoutez Unbound sur le Pi et vous avez un r\u00e9solveur local complet sans d\u00e9pendance externe, am\u00e9liorant la confidentialit\u00e9 (c\u2019est une configuration tr\u00e8s pris\u00e9e des bidouilleurs pour bloquer pubs et trackers sur tout le r\u00e9seau).</p> </li> <li> <p>NAS Synology/QNAP : Certains NAS offrent un package \u201cDNS Server\u201d (ex: Synology DNS Server) qui est souvent bas\u00e9 sur BIND ou dnsmasq, permettant de cr\u00e9er votre zone locale maison (par ex.  maison.lan  avec vos enregistrements) et de faire forward des requ\u00eates externes. C\u2019est une option pour centraliser le DNS si le routeur ne le fait pas bien.</p> </li> </ul> <p>Il est important de veiller \u00e0  \u00e9viter les conflits : ne pas avoir deux serveurs DNS sur le r\u00e9seau pr\u00e9tendant g\u00e9rer la m\u00eame chose pour les clients. G\u00e9n\u00e9ralement on en choisit un comme primaire (souvent le routeur). On peut en avoir un second en secours (par ex. un Pi-hole en secondaire), auquel cas il faut bien configurer pour qu\u2019ils aient des vues coh\u00e9rentes (surtout pour les noms locaux).</p> <p>Enfin,  DNS local et DNS dynamique  peuvent se compl\u00e9ter : On a vu l\u2019exemple du split-horizon pour le nom dynamique. On pourrait par exemple automatiser l\u2019ajout dans Unbound de l\u2019enregistrement correspondant au DDNS. Sur pfSense, ceci peut \u00eatre fait via un script ou en utilisant l\u2019option RFC 2136 (mise \u00e0 jour DNS vers un serveur DNS interne). Cependant, le plus simple est souvent de configurer manuellement un override statique si l\u2019IP locale est fixe. Autre int\u00e9gration : si votre DNS local est configur\u00e9 pour forwarder vers un DNS public, vous pouvez param\u00e9trer un forward conditionnel pour votre domaine dynamique vers un serveur sp\u00e9cifique. Mais cela devient complexe inutilement pour un usage maison. Dans la plupart des cas, une entr\u00e9e statique locale suffira pour que  monserveur.domaine.com  r\u00e9solve diff\u00e9remment en LAN et en WAN.</p>"},{"location":"reseau/ddns/#guide-de-configuration-clients-ddns-et-integration-routeur","title":"Guide de configuration : clients DDNS et int\u00e9gration routeur","text":"<p>Pour terminer, voici quelques conseils et options pour  mettre en \u0153uvre concr\u00e8tement le DNS dynamique  et les DNS locaux dans votre r\u00e9seau.</p>"},{"location":"reseau/ddns/#clients-et-scripts-pour-le-dns-dynamique","title":"Clients et scripts pour le DNS dynamique","text":"<ul> <li> <p>Via le routeur/Firewall : Si vous poss\u00e9dez un routeur type  pfSense, OPNsense, OpenWrt, utilisez sa fonctionnalit\u00e9 DDNS int\u00e9gr\u00e9e. Sur pfSense, rendez-vous dans  Services &gt; Dynamic DNS  et ajoutez une entr\u00e9e en choisissant votre fournisseur (Cloudflare, DuckDNS, No-IP, etc. sont propos\u00e9s). Entrez les identifiants requis (par ex. pour Cloudflare,  Email  +  Global API Key  ou  Token  selon versions). Le routeur se chargera de d\u00e9tecter les changements d\u2019IP (via l\u2019interface WAN ou un service web) et de mettre \u00e0 jour le DNS  . Sur OPNsense, apr\u00e8s avoir install\u00e9 le plugin os-ddclient, la configuration est similaire : vous pouvez d\u00e9finir l\u2019intervalle de v\u00e9rification (par ex. toutes les 5 minutes) et le service (Cloudflare, DuckDNS\u2026). Par exemple, pour DuckDNS, vous s\u00e9lectionnez  DuckDNS, en  Hostname  mettez  monhote.duckdns.org, et en mot de passe le token fourni par DuckDNS (le champ  Username  pouvant rester vide si non requis). Le routeur \u00e9tant toujours allum\u00e9 et conscient de son IP WAN, c\u2019est souvent la solution la plus robuste.</p> </li> <li> <p>Via un NAS ou serveur Linux : Si vous avez une machine toujours allum\u00e9e, installer un client comme  ddclient  est recommand\u00e9. ddclient est un d\u00e9mon Perl tr\u00e8s flexible qui supporte la plupart des fournisseurs (No-IP, Cloudflare, DuckDNS, Dyn, etc.)  . On le configure via  /etc/ddclient.conf. Par exemple, pour Cloudflare : pr\u00e9ciser le protocol=cloudflare, le token API en password, le nom de zone et le record \u00e0 mettre \u00e0 jour  . Une fois configur\u00e9, ddclient tourne en t\u00e2che de fond et fait les updates. Sur Docker, on peut utiliser l\u2019image  linuxserver/ddclient  qui simplifie le d\u00e9ploiement  . Pour DuckDNS, un script shell simple lanc\u00e9 par cron fait tr\u00e8s bien l\u2019affaire (appel wget/curl de l\u2019URL duckdns toutes les 5 minutes).</p> </li> <li> <p>Clients propri\u00e9taires : No-IP propose son utilitaire  No-IP DUC. Il suffit de l\u2019ex\u00e9cuter et de fournir ses identifiants No-IP \u2013 il va tourner en background. D\u2019autres services ont des clients d\u00e9di\u00e9s (Dyn avait  inadyn, etc.). \u00c0 noter : inadyn existe toujours en open-source et peut servir de client universel, mais ddclient est plus r\u00e9pandu d\u00e9sormais.</p> </li> <li> <p>Automatisation logicielle : Certains logiciels embarquent des fonctions DDNS. Par exemple,  Home Assistant  a un add-on DuckDNS qui non seulement met \u00e0 jour l\u2019IP mais configure aussi le certificat Let\u2019s Encrypt \u2013 pratique pour un acc\u00e8s \u00e0 l\u2019interface HA depuis l\u2019ext\u00e9rieur.  Ubiquiti Unifi  routeurs/UDM ont une section DDNS (ils supportent No-IP, DuckDNS, DynDNS, etc.). M\u00eame Windows Server a un client DynDNS int\u00e9gr\u00e9 si besoin. Pensez \u00e0 v\u00e9rifier si l\u2019un de vos \u00e9quipements actuels ne pourrait pas faire le job avant d\u2019ajouter un \u00e9ni\u00e8me script.</p> </li> </ul>"},{"location":"reseau/ddns/#exemples-de-configuration-rapides","title":"Exemples de configuration rapides","text":"<ul> <li>DuckDNS + script shell (Linux) : cr\u00e9ez un script  /usr/local/bin/duckdns.sh  contenant par ex.:</li> </ul> <p><pre><code>TOKEN=\"Votre-Token-DuckDNS\"\nDOMAINS=\"monhote\"\nIP=$(curl -s https://api.ipify.org)  \ncurl \"https://www.duckdns.org/update?domains=$DOMAINS&amp;token=$TOKEN&amp;ip=$IP\"\n</code></pre> -   Ajoutez une t\u00e2che cron (*/5 * * * * /usr/local/bin/duckdns.sh &gt;/dev/null 2&gt;&amp;1). Ceci va mettre \u00e0 jour toutes les 5 min. (DuckDNS renvoie \u201cOK\u201d ou \u201cKO\u201d selon succ\u00e8s).</p> <ul> <li>Cloudflare + curl : une commande curl pour mettre \u00e0 jour Cloudflare (via API v4) ressemble \u00e0 :</li> </ul> <pre><code>curl -X PUT \"https://api.cloudflare.com/client/v4/zones/&lt;ZONE_ID&gt;/dns_records/&lt;RECORD_ID&gt;\" \\\n     -H \"Authorization: Bearer &lt;API_TOKEN&gt;\" \\\n     -H \"Content-Type: application/json\" \\\n     --data '{\"type\":\"A\",\"name\":\"sub.mondomaine.com\",\"content\":\"&lt;new_ip&gt;\",\"ttl\":120}'\n</code></pre> <ul> <li> <p>O\u00f9    et    sont des identifiants que vous obtenez via l\u2019API ou l\u2019interface (une fois pour config). C\u2019est un peu lourd \u00e0 trouver manuellement, d\u2019o\u00f9 l\u2019int\u00e9r\u00eat d\u2019outils comme ddclient qui le font automatiquement \u00e0 partir du nom de domaine. <li> <p>OPNsense + Cloudflare (exemple) : Installer le plugin os-ddclient. Dans  Services &gt; Dynamic DNS, ajouter une entr\u00e9e : Service = Cloudflare. Remplir  Zone  =  mondomaine.com  (domaine g\u00e9r\u00e9),  Hostname(s)  = le(s) sous-domaine(s) \u00e0 mettre \u00e0 jour (ex:  maison,minecraft  pour  maison.mondomaine.com  et  minecraft.mondomaine.com),  Username  =  token,  Password  = le token API Cloudflare. Choisir  Check IP Method  = \u201cInterface\u201d (ou un service web) et l\u2019interface WAN. Sauvegarder, activer. Le log permettra de v\u00e9rifier la bonne mise \u00e0 jour  .</p> </li> <li> <p>pfSense + DuckDNS (exemple) : Dans  Services &gt; Dynamic DNS, ajouter : Service = Custom (car pfSense peut ne pas avoir DuckDNS nativement selon version). Fournir l\u2019URL de mise \u00e0 jour DuckDNS contenant  %IP%  et les param\u00e8tres. Heureusement, des tutoriels existent et pfSense 2.5+ int\u00e8gre DuckDNS dans la liste d\u00e9roulante (ce qui simplifie : on entre juste le domaine et le token en guise de mot de passe). On valide et on observe le statut.</p> </li>"},{"location":"reseau/ddns/#mise-en-place-dun-dns-local","title":"Mise en place d\u2019un DNS local","text":"<ul> <li> <p>OPNsense/pfSense : Le DNS Resolver (Unbound) est probablement d\u00e9j\u00e0 actif. V\u00e9rifiez dans  Services &gt; Unbound DNS &gt; General  que  Enable  est coch\u00e9. Activez  DHCP Registration  si vous voulez que les clients DHCP soient r\u00e9solus  . Vous pouvez aussi d\u00e9finir un  Domain Override  si, par exemple, vous avez un domaine local sp\u00e9cifique ou si vous voulez que les requ\u00eates vers  .local  ou autre aillent vers un autre serveur. Dans  Access Lists, assurez-vous que le r\u00e9seau LAN est autoris\u00e9 (par d\u00e9faut oui). R\u00e9sultat : toutes les machines qui utilisent l\u2019IP du routeur comme DNS profiteront du cache et des noms locaux.</p> <p>Pour tester, faites un  nslookup monpc.lan 192.168.1.1  (si 192.168.1.1 est pfSense) \u2013 cela doit renvoyer l\u2019IP de monpc si ce dernier a communiqu\u00e9 son nom via DHCP.</p> </li> <li> <p>Configurer DNSSEC/DoT : Sur Unbound (OPNsense), DNSSEC est activ\u00e9 d\u2019un clic  . Pour DNS over TLS, soit on utilise Unbound en mode resolver pur (pas besoin, il interroge les racines en clair mais on a DNSSEC), soit en mode forwarder chiffr\u00e9 : dans  Query Forwarding, on peut activer Forwarding et sp\u00e9cifier des serveurs TLS comme 1.1.1.1@853 avec validation. Cela chiffre les requ\u00eates vers l\u2019ext\u00e9rieur, au prix de repasser par un resolver tiers. C\u2019est un choix. Pour Dnsmasq, on ne peut pas faire DoT nativement, il faudrait passer par un stub comme  stubby  ou utiliser le DNS over HTTPS du routeur (certains firmwares ASUS le font).</p> </li> <li> <p>Int\u00e9gration Pi-hole + Unbound : Installer Pi-hole (qui remplace votre DNS du routeur aupr\u00e8s des clients) puis suivre la doc pour ajouter Unbound. En gros, Unbound \u00e9coute sur 127.0.0.1:5335 et Pi-hole forwarde tout vers lui. On obtient un DNS local, filtrant et totalement r\u00e9cursif. C\u2019est excellent pour la vie priv\u00e9e et le confort (plus de pubs, etc.).</p> </li> <li> <p>Acc\u00e8s aux services locaux par nom : Si vous n\u2019avez pas de DNS local mais que vous le souhaitez sans trop d\u2019effort, vous pouvez par exemple  utiliser Dnsmasq sur votre PC  (utile si vous voulez juste quelques noms sans configurer tout le r\u00e9seau). Mais le mieux reste de faire g\u00e9rer cela par le routeur ou un petit serveur central comme d\u00e9crit ci-dessus.</p> </li> </ul> <p>En conclusion, un  serveur DNS local  bien configur\u00e9 compl\u00e8te id\u00e9alement l\u2019utilisation d\u2019un  DNS dynamique. Le DDNS vous donne une porte d\u2019entr\u00e9e fixe depuis Internet, tandis que le DNS local vous offre un contr\u00f4le et un confort \u00e0 l\u2019int\u00e9rieur du r\u00e9seau. En combinant les deux, vous pouvez par exemple taper  cloud.maison.local  depuis chez vous et  cloud.mondynamique.net  depuis l\u2019ext\u00e9rieur, et atterrir sur le m\u00eame service, de mani\u00e8re optimale dans chaque contexte.</p>"},{"location":"reseau/ddns/#conclusion","title":"Conclusion","text":"<p>Le DNS dynamique est une brique essentielle pour toute personne h\u00e9bergeant des services sur une connexion \u00e0 IP variable. Des services comme Cloudflare, DuckDNS ou No-IP offrent des solutions vari\u00e9es \u2013 du  DIY sur son propre domaine avec API  \u00e0 la  solution pr\u00eate \u00e0 l\u2019emploi totalement gratuite  \u2013 chacun ayant ses avantages. Il est important de choisir en fonction de ses besoins : Cloudflare conviendra \u00e0 ceux qui ont un domaine et veulent une int\u00e9gration pouss\u00e9e (par exemple coupler avec un CDN ou d\u2019autres r\u00e8gles DNS), DuckDNS s\u00e9duira par sa simplicit\u00e9 sans tracas, No-IP par son int\u00e9gration universelle, etc. Les alternatives non-propri\u00e9taires comme deSEC, FreeDNS, YDNS montrent qu\u2019il existe un \u00e9cosyst\u00e8me ouvert pour le DDNS, ce qui est rassurant en termes de p\u00e9rennit\u00e9.</p> <p>En parall\u00e8le, soigner son  infrastructure DNS locale  apporte une meilleure exp\u00e9rience utilisateur et plus de ma\u00eetrise du r\u00e9seau. Un  DNS resolver local (Unbound)  apportera s\u00e9curit\u00e9 (DNSSEC, pas de tracking FAI) et ind\u00e9pendance, l\u00e0 o\u00f9 un  DNS forwarder (Dnsmasq)  apportera flexibilit\u00e9 et l\u00e9g\u00e8ret\u00e9. Souvent, les deux ne sont pas en opposition stricte mais r\u00e9pondent \u00e0 des usages l\u00e9g\u00e8rement diff\u00e9rents \u2013 \u00e0 vous de voir ce qui s\u2019int\u00e8gre le mieux dans votre architecture.</p> <p>Enfin, n\u2019oublions pas que ces outils ne sont efficaces qu\u2019accompagn\u00e9s des bonnes pratiques de r\u00e9seau : tenir ses services \u00e0 jour, utiliser le chiffrement, segmenter les acc\u00e8s si n\u00e9cessaire (un service critique n\u2019a peut-\u00eatre pas besoin d\u2019\u00eatre joignable par tout le monde), et surveiller son syst\u00e8me. Avec un DDNS bien configur\u00e9, un reverse proxy, et un DNS local, votre homelab se comportera presque comme une infra professionnelle \u2013 en miniature \u2013 et vous donnera le contr\u00f4le total sur vos services,  \u00e0 la maison comme \u00e0 distance.</p>"},{"location":"reseau/dns/","title":"Pi-hole, AdGuard Home et Technitium DNS : comparatif et configurations en homelab","text":""},{"location":"reseau/dns/#comparatif-technique-detaille","title":"Comparatif technique d\u00e9taill\u00e9","text":"<p>Pr\u00e9sentation g\u00e9n\u00e9rale :  Pi-hole, AdGuard Home et Technitium DNS Server sont trois solutions populaires de DNS filtrant pour bloquer les publicit\u00e9s et prot\u00e9ger un r\u00e9seau domestique. Toutes trois fonctionnent comme des serveurs DNS locaux capables de  bloquer les domaines ind\u00e9sirables  (publicit\u00e9, trackers, malwares, sites adultes) \u00e0 l\u2019aide de listes noires. Elles disposent \u00e9galement de fonctionnalit\u00e9s communes telles que la journalisation des requ\u00eates DNS et une interface d\u2019administration web  . Cependant, elles diff\u00e8rent sur leur  architecture technique et fonctionnalit\u00e9s avanc\u00e9es. Le tableau ci-dessous r\u00e9sume certaines capacit\u00e9s :</p> <ul> <li> <p>Blocage de domaines ind\u00e9sirables : Pi-hole,  AdGuard Home  et  Technitium DNS  assurent tous un DNS sinkhole efficace. Ils peuvent charger des listes de domaines \u00e0 bloquer (ads, malwares, etc.), appliquer le Safe Search et utiliser des listes personnalis\u00e9es  . Le blocage par expressions r\u00e9guli\u00e8res est aussi support\u00e9 par Pi-hole et AdGuard.  En pratique, l\u2019efficacit\u00e9 de filtrage par d\u00e9faut est similaire  \u2013 tous deux utilisent des listes de blocage comparables et bloquent un nombre proche de publicit\u00e9s d\u00e8s l\u2019installation, m\u00eame s\u2019il est conseill\u00e9 d\u2019ajouter d\u2019autres listes pour am\u00e9liorer la couverture  . Technitium int\u00e8gre \u00e9galement ces fonctionnalit\u00e9s de base de blocage DNS.</p> </li> <li> <p>Performance et ressources :  Les diff\u00e9rences de performance entre Pi-hole et AdGuard Home sont  minimes. Des tests montrent que les temps de r\u00e9ponse DNS sont \u00e9quivalents (18ms pour Pi-hole vs 21ms pour AdGuard dans un exemple, \u00e9cart n\u00e9gligeable)  . C\u00f4t\u00e9 empreinte syst\u00e8me, AdGuard Home est \u00e9crit en Go tandis que Pi-hole s\u2019appuie sur dnsmasq et une interface PHP, ce qui fait souvent dire que Pi-hole consomme un peu plus de RAM. En r\u00e9alit\u00e9, avec une configuration de base, Pi-hole utilise environ  30\u202fMo de RAM de plus  qu\u2019AdGuard Home, diff\u00e9rence imperceptible sur du mat\u00e9riel moderne  .  Avec de tr\u00e8s grandes listes de blocage, Pi-hole a \u00e9t\u00e9 mesur\u00e9 autour de ~100\u202fMo de RAM contre ~250\u202fMo pour AdGuard dans un test sur Portainer  \u2013 mais d\u2019autres retours signalent l\u2019inverse ou un \u00e9cart moindre, selon l\u2019environnement.  Globalement, les trois solutions restent l\u00e9g\u00e8res  et tournent sans probl\u00e8me sur un Raspberry Pi ou un petit NAS  . Le  CPU  n\u2019est g\u00e9n\u00e9ralement pas un facteur limitant (quelques % d\u2019utilisation au plus). Les trois chargent les listes de blocage en m\u00e9moire pour une r\u00e9solution rapide, il faut donc pr\u00e9voir suffisamment de RAM si vous importez des listes massives  .</p> </li> <li> <ul> <li>M\u00e9canisme DNS :  Pi-hole et AdGuard Home agissent principalement comme  serveurs DNS cache/forward  : ils re\u00e7oivent les requ\u00eates des clients, bloquent celles correspondant aux domaines filtr\u00e9s, et transf\u00e8rent les autres \u00e0 un serveur DNS amont (par exemple Cloudflare, Quad9, ou un r\u00e9solveur local). Pi-hole n\u2019embarque pas de r\u00e9solveur r\u00e9cursif complet par d\u00e9faut, mais il est courant de l\u2019associer \u00e0  Unbound  pour r\u00e9soudre directement depuis la racine. AdGuard Home, lui, peut \u00e9galement fonctionner en mode r\u00e9cursif (il dispose d\u2019une option pour activer un r\u00e9solveur DNS complet en interne) ou en mode  forwarder  vers des serveurs chiffr\u00e9s (DoH/DoT) gr\u00e2ce \u00e0 sa prise en charge native de DNS-over-HTTPS, DNS-over-TLS et m\u00eame DNS-over-QUIC  .  Technitium DNS  se distingue ici car c\u2019est un  serveur DNS complet (r\u00e9cursif et faisant autorit\u00e9)  : il int\u00e8gre nativement la r\u00e9solution r\u00e9cursive  et  peut h\u00e9berger des zones DNS locales autoritaires  . En clair, Technitium offre d\u2019embl\u00e9e ce que Pi-hole/AdGuard font plus un r\u00e9solveur interne (plus besoin d\u2019installer Unbound) et un serveur faisant autorit\u00e9 sur vos domaines locaux. Il supporte aussi directement DoH/DoT en sortie  et en entr\u00e9e, ce qui permet de servir vos clients via DNS chiffr\u00e9 si souhait\u00e9 (AdGuard Home peut aussi servir en DoH/DoQ en configurant les fonctionnalit\u00e9s avanc\u00e9es).</li> </ul> </li> <li> <p>Interface et gestion : Pi-hole  offre une interface web simple et \u00e9pur\u00e9e pour configurer les listes noires/blanches, voir les journaux de requ\u00eates et quelques r\u00e9glages r\u00e9seau de base. Son interface, bien que moins \u00ab moderne \u00bb, reste fonctionnelle et soutenue par une  forte communaut\u00e9  (nombreux tutoriels, support, etc.)  .  AdGuard Home  dispose d\u2019une interface plus moderne et conviviale, avec des tableaux de bord color\u00e9s et des menus bien organis\u00e9s. La configuration initiale est facilit\u00e9e (tout en un seul binaire), et de nombreuses options (DNS chiffr\u00e9, contr\u00f4le parental, filtres personnalis\u00e9s) sont activables en quelques clics  . En revanche, certains r\u00e9glages avanc\u00e9s de DNS local sur AdGuard sont un peu cach\u00e9s (il faut ajouter des enregistrements DNS locaux via les  _\u201cCustom Rules\u201d_manuellement)  , alors que Pi-hole propose une section d\u00e9di\u00e9e \u201cDNS Local\u201d plus intuitive pour ajouter des noms locaux  .  Technitium DNS, malgr\u00e9 son ampleur fonctionnelle, fournit \u00e9galement une interface web compl\u00e8te. Les retours d\u2019exp\u00e9rience notent qu\u2019elle est  tr\u00e8s riche en options tout en restant user-friendly, similaire \u00e0 Pi-hole/AdGuard voire plus intuitive sur certains points  . On peut tout configurer depuis le GUI ou via une API HTTP, sans devoir \u00e9diter manuellement des fichiers de configuration  . L\u2019interface de Technitium permet par exemple de cr\u00e9er des zones DNS, des r\u00e8gles de transfert conditionnel, de multiples port\u00e9es DHCP, etc., directement via le web.</p> </li> <li> <p>Int\u00e9gration r\u00e9seau et fonctionnalit\u00e9s :  Les trois solutions peuvent fonctionner sur la plupart des plateformes (Linux, Docker, Raspberry Pi, etc.)  .  Chacune peut servir de serveur DHCP  pour votre LAN, rempla\u00e7ant le DHCP de votre box/routeur si n\u00e9cessaire  . Pi-hole et AdGuard Home g\u00e8rent un seul domaine DHCP/local \u00e0 la fois, tandis que  Technitium DNS peut d\u00e9finir plusieurs plages DHCP  pour couvrir plusieurs VLAN/r\u00e9seaux isol\u00e9s depuis une seule instance  . C\u2019est un atout dans un homelab segment\u00e9 en multiples sous-r\u00e9seaux : Technitium permet de  servir plusieurs VLAN  en DHCP/DNS distincts via une configuration centralis\u00e9e. C\u00f4t\u00e9 DNS local, Pi-hole et AdGuard autorisent l\u2019ajout de quelques enregistrements locaux ou la redirection conditionnelle (ex. transf\u00e9rer les requ\u00eates d\u2019un suffixe local vers un autre DNS) \u2013 fonctionnalit\u00e9 dite  conditional forwarding  pour r\u00e9soudre les noms de votre LAN via le DNS de votre routeur.  Technitium  pousse plus loin en permettant de  cr\u00e9er des zones locales compl\u00e8tes  (par exemple une zone \u201clab.home.arpa\u201d avec tous vos enregistrements) et d\u2019activer des  serveurs secondaires  pour ces zones (transfert de zone possible)  . Il supporte aussi la notion de  Conditional Forwarder  plus avanc\u00e9e : pour un domaine donn\u00e9, vous pouvez sp\u00e9cifier un serveur DNS diff\u00e9rent, tout en pouvant  surcharger certains enregistrements  de ce domaine localement  . Enfin, en termes d\u2019int\u00e9gration, Pi-hole et AdGuard sont souvent utilis\u00e9s en  compl\u00e9ment du routeur/pare-feu  : il faut configurer votre DHCP (sur la box ou OPNsense par exemple) pour distribuer l\u2019adresse IP du Pi-hole/AdGuard comme DNS aux clients du r\u00e9seau. Technitium pourrait tout \u00e0 fait \u00eatre utilis\u00e9 de la m\u00eame mani\u00e8re, ou m\u00eame install\u00e9 directement sur la machine faisant routeur si on le souhaite (il remplace alors avantageusement le DNS de base du routeur). Notons qu\u2019AdGuard Home existe aussi en  package sur certaines appliances  (par ex. sur OPNsense/pfSense via des plugins tiers), ce qui peut simplifier son d\u00e9ploiement dans un firewall existant.</p> </li> <li> <p>Contr\u00f4le granulaire et profils :  Depuis la version 5,  Pi-hole  offre une gestion par groupes de clients : on peut assigner des appareils \u00e0 des groupes et appliquer \u00e0 chaque groupe des listes de blocage diff\u00e9rentes (par exemple, ne pas bloquer les m\u00eames sites pour les enfants et les adultes). AdGuard Home permet \u00e9galement de cr\u00e9er des  r\u00e8gles par client  (bas\u00e9es sur l\u2019IP ou le nom du client) et de filtrer diff\u00e9remment selon l\u2019appareil  . La flexibilit\u00e9 de Technitium \u00e0 ce sujet est encore en d\u00e9veloppement : il supporte bien les listes noires et blanches globales et la cr\u00e9ation de profils, mais  les r\u00e8gles fines par client/groupe sont plus limit\u00e9es  pour l\u2019instant  . En revanche, Technitium offre des fonctionnalit\u00e9s uniques comme la possibilit\u00e9 d\u2019h\u00e9berger un  cache DNS partag\u00e9 entre r\u00e9seaux  ou d\u2019op\u00e9rer un  serveur racine local  (il peut t\u00e9l\u00e9charger la zone racine ICANN et agir en r\u00e9solveur totalement autonome hors-ligne si on le souhaite)  .</p> </li> </ul> <p>En r\u00e9sum\u00e9, Pi-hole et AdGuard Home couvrent l\u2019essentiel des besoins d\u2019un homelab en blocage DNS, avec un avantage pour AdGuard sur les fonctionnalit\u00e9s int\u00e9gr\u00e9es (chiffrement DNS, contr\u00f4le parental) et pour Pi-hole sur la simplicit\u00e9 et la communaut\u00e9. Technitium DNS va plus loin en combinant les fonctions de Pi-hole/AdGuard avec celles d\u2019un serveur DNS professionnel (zones locales, r\u00e9solveur int\u00e9gr\u00e9, etc.)  . Ce surplus de fonctionnalit\u00e9s peut sembler  \u201coverkill\u201d  pour un petit r\u00e9seau, mais offre une  grande flexibilit\u00e9 pour un ing\u00e9nieur s\u00e9curit\u00e9  souhaitant un laboratoire \u00e9volutif. Le tableau de comparaison suivant (d\u2019apr\u00e8s Supernetworks) illustre que Technitium couvre la plupart des cases de Pi-hole/AdGuard, et apporte des plus comme le DNS r\u00e9cursif et la gestion multi-r\u00e9seaux  . Le choix d\u00e9pendra donc de vos  priorit\u00e9s  : l\u00e9g\u00e8ret\u00e9 et support communautaire (Pi-hole), interface moderne et tout-en-un (AdGuard Home), ou puissance DNS maximale (Technitium).</p>"},{"location":"reseau/dns/#exemples-de-configurations-types","title":"Exemples de configurations types","text":"<p>Pour exploiter ces outils DNS dans un homelab, voici quelques  architectures types  et configurations recommand\u00e9es :</p>"},{"location":"reseau/dns/#configuration-dns-primairesecondaire-pour-resilience","title":"Configuration \u201cDNS primaire/secondaire\u201d pour r\u00e9silience","text":"<p>Il est judicieux d\u2019avoir  deux instances DNS filtrantes  pour \u00e9viter un point unique de d\u00e9faillance. Par exemple, d\u00e9ployer  deux Pi-hole  (ou AdGuard) sur deux machines distinctes : l\u2019un sera DNS primaire, le second en DNS secondaire. Via le DHCP, on distribue les deux adresses DNS aux clients. En fonctionnement normal, les clients interrogeront surtout le primaire, le secondaire prenant le relais si le premier est injoignable (timeout). Cette redondance assure que m\u00eame pendant la maintenance ou la panne d\u2019un serveur DNS, le r\u00e9seau continue \u00e0 r\u00e9soudre les noms  . Il est possible d\u2019utiliser  des solutions mixtes : par ex. un Pi-hole comme serveur principal et un AdGuard Home en secondaire, ce dernier configur\u00e9 avec les m\u00eames listes de blocage pour un r\u00e9sultat similaire. Certains homelabs combinent aussi  Technitium et Pi-hole  : Technitium servant de r\u00e9solveur DNS rapide en interne, et Pi-hole agissant en filtrage en amont pour certains clients sp\u00e9cifiques  . L\u2019important est de conserver une coh\u00e9rence (m\u00eames listes) ou de d\u00e9cider que le secondaire ne filtre pas (selon que l\u2019on pr\u00e9f\u00e8re la  disponibilit\u00e9  ou le  filtrage strict). Dans tous les cas, r\u00e9glez des  timeouts raisonnables  sur le primaire afin que le client bascule vite sur le secondaire en cas de souci (les OS utilisent g\u00e9n\u00e9ralement ~5 secondes par d\u00e9faut).</p> <p>En environnement virtualis\u00e9, on peut \u00e9galement mettre en place un m\u00e9canisme de  failover  plus pouss\u00e9 : par exemple ex\u00e9cuter deux conteneurs Pi-hole en parall\u00e8le et utiliser keepalived pour partager une IP virtuelle flottante entre eux. Si le Pi-hole principal tombe, le secondaire annonce l\u2019IP virtuelle et prend imm\u00e9diatement le relais, \u00e9vitant m\u00eame le d\u00e9lai de bascule c\u00f4t\u00e9 clients. Ce type de HA est plus complexe, mais peut se justifier dans un lab critique.</p>"},{"location":"reseau/dns/#dns-avec-chiffrement-dohdot-en-amont-et-en-interne","title":"DNS avec chiffrement (DoH/DoT) en amont et en interne","text":"<p>Chiffrer les requ\u00eates DNS  peut \u00eatre int\u00e9ressant pour la confidentialit\u00e9. Les trois solutions supportent le chiffrement DNS en  amont  (vers les serveurs publics) : Pi-hole peut \u00eatre coupl\u00e9 \u00e0 un client DoH/DoT (ex: Cloudflared, Stubby) ou \u00e0 Unbound pour chiffrer entre Unbound et les serveurs racine. AdGuard Home et Technitium int\u00e8grent nativement le support des  DNS-over-HTTPS (DoH)  et  DNS-over-TLS (DoT)  pour les requ\u00eates sortantes  . Il suffit de configurer dans l\u2019UI l\u2019adresse du resolver DoH de votre choix (ex :  https://dns.quad9.net/dns-query  pour Quad9).</p> <p>En  interne, AdGuard Home peut aussi se comporter en  serveur DoH/DoT  pour vos clients : on peut le configurer pour \u00e9couter en TLS (port 853) ou HTTPS (port 443/API DNS) afin que les postes clients puissent chiffrer leurs requ\u00eates jusqu\u2019au serveur DNS local  . Technitium \u00e9galement permet cette configuration (il peut \u00e9couter en DoH/DoT sur votre r\u00e9seau local si vous activez HTTPS avec un certificat valide). Pi-hole n\u2019a pas cette fonctionnalit\u00e9 int\u00e9gr\u00e9e, mais on peut la reproduire en pla\u00e7ant un  proxy DoH  devant Pi-hole (par exemple, un conteneur  cloudflared  configur\u00e9 en mode serveur DoH local). Ainsi, les PC/ smartphones du r\u00e9seau peuvent \u00eatre configur\u00e9s pour utiliser l\u2019URL DoH locale (ou le port TLS local) au lieu du port 53 classique, ajoutant une couche de chiffrement sur le segment local pour \u00e9viter qu\u2019un intrus sur le WiFi ne voie les requ\u00eates en clair.</p> <p>Pour un  homelab de s\u00e9cu, cette configuration DoH interne peut \u00eatre utile pour tester le comportement de machines dans un contexte o\u00f9 le DNS est chiffr\u00e9 de bout en bout. Cependant, notez que si vos clients utilisent DoH vers l\u2019ext\u00e9rieur (par exemple navigateur configur\u00e9 en DoH vers Cloudflare), cela  contourne  votre serveur DNS filtrant local. Une solution est justement d\u2019h\u00e9berger un serveur DoH local (avec AdGuard/Technitium) et de forcer via les politiques du navigateur ou de l\u2019OS l\u2019utilisation de celui-ci, afin de garder le contr\u00f4le sur les requ\u00eates.</p>"},{"location":"reseau/dns/#mode-proxy-dns-vs-mode-resolveur-local","title":"Mode \u00ab proxy DNS \u00bb vs mode r\u00e9solveur local","text":"<p>On parle ici du  fonctionnement interne  du serveur DNS filtrant. En  mode proxy/forwarder, le serveur relaie la requ\u00eate vers un ou plusieurs serveurs DNS externes (par ex. les DNS de FAI, Cloudflare, etc.) apr\u00e8s avoir filtr\u00e9. Ce mode est le plus simple :  Pi-hole  et  AdGuard Home  l\u2019utilisent par d\u00e9faut (on configure une liste de serveurs DNS en amont, et le logiciel fait du caching + filtrage).  Technitium DNS  peut aussi op\u00e9rer ainsi, mais offre en plus le  mode r\u00e9solveur r\u00e9cursif  complet : dans ce mode, il va interroger directement la racine internet, puis chaque TLD, etc., sans d\u00e9pendre d\u2019un serveur tiers.  Pi-hole  peut \u00eatre converti en r\u00e9solveur local en l\u2019associant \u00e0  Unbound  (Unbound fait la r\u00e9cursion, Pi-hole filtre le r\u00e9sultat)  .  AdGuard Home  a une option exp\u00e9rimentale pour la r\u00e9cursion, mais elle n\u2019est pas aussi aboutie qu\u2019Unbound ou Technitium en termes de fonctionnalit\u00e9s DNSSEC par exemple.</p> <p>Quel mode choisir ?  En homelab, le mode forwarder sur DNS publics (Cloudflare/Quad9) avec DoH/DoT est souvent suffisant et facile \u00e0 mettre en place. Le  mode r\u00e9solveur local  apporte une ind\u00e9pendance totale vis-\u00e0-vis des DNS tiers et \u00e9vite de partager vos requ\u00eates \u00e0 un service externe, au prix d\u2019un l\u00e9ger surcro\u00eet de trafic (il doit revalider toutes les DNSSEC signatures lui-m\u00eame, etc.). Un ing\u00e9nieur cybers\u00e9curit\u00e9 appr\u00e9ciera le r\u00e9solveur local pour supprimer une d\u00e9pendance externe et contr\u00f4ler enti\u00e8rement la cha\u00eene (ex: pas de risque d\u2019une r\u00e9ponse alt\u00e9r\u00e9e par un FAI malveillant). Technitium \u00e9tant  \u201ctout-en-un\u201d, il est id\u00e9al pour tester ce sc\u00e9nario : vous pouvez d\u00e9sactiver toutes les forwarders et le laisser g\u00e9rer la r\u00e9solution r\u00e9cursive  en interne  facilement. Pi-hole + Unbound offre le m\u00eame b\u00e9n\u00e9fice avec un peu plus de configuration manuelle  . Dans tous les cas, v\u00e9rifiez que DNSSEC est bien activ\u00e9 sur votre r\u00e9solveur (toutes ces solutions le supportent soit nativement soit via leur upstream) pour garantir l\u2019authenticit\u00e9 des r\u00e9ponses DNS.</p>"},{"location":"reseau/dns/#serveur-dns-par-vlan-segmentation-du-dns","title":"Serveur DNS par VLAN / segmentation du DNS","text":"<p>Dans un homelab segment\u00e9 en  plusieurs VLAN ou sous-r\u00e9seaux, il faut d\u00e9cider comment d\u00e9ployer le DNS filtrant :  centralis\u00e9  (une instance dessert tous les r\u00e9seaux) ou  distribu\u00e9  (une instance par segment).</p> <ul> <li> <p>Option centralis\u00e9e :  Vous pouvez faire tourner une seule instance (ex: un Pi-hole sur le LAN principal) et permettre aux autres VLAN d\u2019y acc\u00e9der. Cela n\u00e9cessite que les requ\u00eates DNS des autres r\u00e9seaux soient rout\u00e9es vers le Pi-hole (r\u00e8gles firewall autorisant l\u2019UDP/TCP 53 depuis les VLAN IoT/Guest vers l\u2019IP du Pi-hole). Sur OPNsense/pfSense, on peut par exemple ouvrir le DNS du Pi-hole \u00e0 ces r\u00e9seaux sp\u00e9cifiques. L\u2019avantage : une seule config \u00e0 g\u00e9rer (toutes les listes au m\u00eame endroit) et une vue globale de l\u2019activit\u00e9 DNS. Inconv\u00e9nient : moins d\u2019isolement (les VLAN d\u00e9pendent d\u2019un service commun) et complexit\u00e9 de routage. Il faut aussi que le  DHCP de chaque VLAN pointe vers le Pi-hole central  comme DNS.</p> </li> <li> <p>Option distribu\u00e9e :  Installer une instance par VLAN. Par ex, un Pi-hole dans le VLAN Perso, un AdGuard Home dans le VLAN IoT. Chaque r\u00e9seau utilise son serveur local (fourni via DHCP). Cela renforce l\u2019isolation (pas de travers\u00e9e inter-VLAN pour le DNS) et permet de  personnaliser les filtres par r\u00e9seau  (ex: VLAN enfants avec filtrage strict via AdGuard Home + SafeSearch activ\u00e9  , VLAN lab sans filtrage ou avec des r\u00e9glages diff\u00e9rents). Technitium facilite aussi une approche interm\u00e9diaire :  une seule instance multi-VLAN. En effet il supporte plusieurs adresses d\u2019\u00e9coute et plusieurs scopes DHCP, on peut donc d\u00e9ployer Technitium sur un serveur ayant acc\u00e8s \u00e0 tous les VLAN (ex: une VM multi-hommes ou directement sur OPNsense) et configurer un  scope DHCP par VLAN  ainsi que des r\u00e8gles de filtrage par groupe d\u2019adresses IP. C\u2019est une architecture puissante mais attention \u00e0 la haute dispo : si cette unique instance tombe, tous les VLAN perdent le DNS. On revient alors \u00e0 l\u2019option primaire/secondaire pour chaque VLAN ou \u00e0 un serveur redondant central.</p> </li> </ul> <p>En pratique, une approche hybride convient souvent : par exemple un Pi-hole principal sur le LAN Perso, accessible aussi par le VLAN invit\u00e9 mais avec une r\u00e8gle firewall qui redirige toute requ\u00eate DNS \u00e9mise depuis le VLAN invit\u00e9 vers le Pi-hole (on peut m\u00eame forcer via une redirection NAT DNS). En parall\u00e8le, on peut d\u00e9ployer un second DNS (AdGuard) d\u00e9di\u00e9 aux VLAN sensibles (IoT, etc.) pour bien cloisonner.  Le choix d\u00e9pend de la taille du lab et des exigences de s\u00e9curit\u00e9  : plus on centralise, plus c\u2019est facile \u00e0 administrer mais plus impactant en cas de panne ; plus on distribue, plus on segmente les risques mais plus il y a d\u2019instances \u00e0 maintenir.</p>"},{"location":"reseau/dns/#scenarios-specifiques-dusage-en-homelab","title":"Sc\u00e9narios sp\u00e9cifiques d\u2019usage en homelab","text":"<p>Apr\u00e8s la technique, voici quelques  cas d\u2019usage concrets  de ces solutions DNS dans un homelab orient\u00e9 cybers\u00e9curit\u00e9 :</p>"},{"location":"reseau/dns/#blocage-des-publicites-et-du-tracking-internet","title":"Blocage des publicit\u00e9s et du tracking internet","text":"<p>Le cas d\u2019usage num\u00e9ro un de Pi-hole/AdGuard est le  blocage des pubs et trackers  au niveau r\u00e9seau. En configurant l\u2019un de ces serveurs comme DNS principal du r\u00e9seau,  toutes  les requ\u00eates vers des domaines publicitaires connus sont r\u00e9solues vers une adresse inexistante (0.0.0.0) ou simplement non r\u00e9solues, ce qui emp\u00eache l\u2019affichage des pubs sur les appareils (TV connect\u00e9es, smartphones, etc.) sans avoir \u00e0 configurer chaque appareil individuellement  . Dans un homelab, cela permet non seulement d\u2019acc\u00e9l\u00e9rer la navigation (moins de contenu charg\u00e9) mais aussi de r\u00e9duire les vecteurs de suivi invisibles.  AdGuard Home  et  Pi-hole  disposent tous deux de listes de filtres maintenues par la communaut\u00e9 pour bloquer pub, trackers de t\u00e9l\u00e9m\u00e9trie Windows, banni\u00e8res cookies, etc. Par d\u00e9faut, leurs listes basiques bloquent une bonne partie des pubs courantes, mais on peut les enrichir (EasyList, listes sp\u00e9cifiques locales, etc.)  .  Technitium  utilisera les m\u00eames listes (format hosts, DOM blocklist) \u2013 il suffit d\u2019importer les URLs des listes dans son interface. Un avantage du DNS centralis\u00e9 : on peut bloquer la pub  m\u00eame sur les appareils qui n\u2019acceptent pas d\u2019extensions  (TV, consoles, IoT).</p> <p>Pour un lab de s\u00e9cu, on peut aussi se servir de ces blocages DNS comme premi\u00e8re barri\u00e8re contre certaines menaces : par exemple, en chargeant des listes de domaines de malware connus (EmergingThreats, etc.), on emp\u00eache des malwares  \u00e9ventuellement ex\u00e9cut\u00e9s dans le lab  de contacter leur serveur de commande via DNS. Bien s\u00fbr, ce n\u2019est pas infaillible (un malware peut contacter directement une IP), mais cela couvre les  C&amp;C bas\u00e9s sur domaine  et le tracking de certaines applications indiscr\u00e8tes  . On peut pousser plus loin le principe en activant sur AdGuard des listes de type  \u201cSafe Browsing\u201d  ou contr\u00f4le parental (bloquer les domaines adultes, jeux d\u2019argent, etc.)  \u2013 utile si le homelab sert de r\u00e9seau familial \u00e9galement.</p> <p>Un sc\u00e9nario fr\u00e9quent en homelab est de  mesurer l\u2019efficacit\u00e9 de ces listes  : Pi-hole et AdGuard fournissent des statistiques (pourcentage de requ\u00eates bloqu\u00e9es, domaines les plus bloqu\u00e9s, etc.)  . Cela permet \u00e0 un passionn\u00e9 de cybers\u00e9curit\u00e9 d\u2019analyser quel trafic sort de son r\u00e9seau. Par exemple, on peut d\u00e9couvrir qu\u2019une Smart TV tente de contacter  dozens  de domaines de tracking diff\u00e9rents \u2013 et ajuster les r\u00e8gles en cons\u00e9quence. On pourra aussi tester diff\u00e9rentes approches : par exemple comparer  Pi-hole vs NextDNS  (service cloud) sur le blocage de pubs, ou combiner Pi-hole avec un  bloqueur de contenu local  sur le navigateur et voir la diff\u00e9rence. Ce type d\u2019exp\u00e9rimentation est courant en homelab pour \u00e9valuer la meilleure protection multicouche.</p>"},{"location":"reseau/dns/#isolation-reseau-par-le-dns-iot-et-environnements-sensibles","title":"Isolation r\u00e9seau par le DNS (IoT et environnements sensibles)","text":"<p>Dans une architecture de s\u00e9curit\u00e9, le DNS peut servir \u00e0  isoler ou contr\u00f4ler les communications  d\u2019un segment donn\u00e9. Prenons le VLAN IoT : on souhaite qu\u2019il n\u2019ait acc\u00e8s qu\u2019\u00e0 Internet de mani\u00e8re tr\u00e8s limit\u00e9e, pour \u00e9viter qu\u2019un objet compromis n\u2019attaque d\u2019autres machines. En plus des r\u00e8gles firewall restreignant les destinations IP, on peut utiliser un serveur DNS filtrant d\u00e9di\u00e9 \u00e0 ce VLAN avec une politique tr\u00e8s stricte. Par exemple, d\u00e9ployer AdGuard Home pour le VLAN IoT avec  uniquement  une whitelist de domaines autoris\u00e9s (les serveurs officiels des appareils connus) et bloquer  tout le reste. AdGuard Home permet de cr\u00e9er des r\u00e8gles globales ou par client, donc on pourrait dire \u201cautoriser seulement ces domaines pour les IP des cam\u00e9ras, etc.\u201d. Technitium, via des zones de transfert conditionnel et surcharges, peut m\u00eame renvoyer un nom de domaine vers une IP locale factice pour pi\u00e9ger l\u2019appareil ou emp\u00eacher la r\u00e9solution.</p> <p>Un autre sc\u00e9nario d\u2019isolation DNS est d\u2019emp\u00eacher qu\u2019un service en  zone DMZ compromise ne puisse appeler l\u2019int\u00e9rieur  : on pourrait configurer le DNS de la DMZ pour qu\u2019il  ne r\u00e9solve pas  les noms internes du LAN. Par exemple, Technitium h\u00e9bergeant la zone \u201clab.internal\u201d pour le LAN, mais n\u2019autorisant pas les requ\u00eates venant de la DMZ \u00e0 y acc\u00e9der (via un contr\u00f4le d\u2019acc\u00e8s sur la zone ou en n\u2019exposant pas ce serveur DNS \u00e0 la DMZ). Ou plus simplement, avoir des DNS s\u00e9par\u00e9s physiquement : le DNS du LAN conna\u00eet les noms du LAN, celui de la DMZ non. Ainsi, si un serveur DMZ est compromis, il ne pourra pas facilement d\u00e9couvrir ni contacter par nom les machines internes. On parle parfois de  DNS split-horizon  pour la s\u00e9curit\u00e9 : pr\u00e9senter une vue DNS diff\u00e9rente selon l\u2019origine de la requ\u00eate. Technitium DNS peut g\u00e9rer ce genre de choses en cr\u00e9ant des  zones avec port\u00e9e  (views) ou en combinant des zones locales et des forwarders conditionnels. Pi-hole et AdGuard ne g\u00e8rent pas des \u201cviews\u201d multiples, mais on peut en d\u00e9ployer un par zone de s\u00e9curit\u00e9 pour obtenir un effet similaire.</p> <p>Enfin,  isoler par DNS  peut signifier  bloquer toute r\u00e9solution externe non autoris\u00e9e  : un principe de base est de forcer les clients \u00e0 n\u2019utiliser  que le DNS filtrant. Sur OPNsense/pfSense, on impl\u00e9mente une r\u00e8gle NAT qui intercepte toute requ\u00eate DNS UDP/53 sortante et la redirige vers le serveur DNS local (Pi-hole) \u2013 on s\u2019assure ainsi qu\u2019aucun appareil ne tente de bypasser le filtre en utilisant 8.8.8.8. Cette technique combin\u00e9e avec un Pi-hole/AdGuard renforce \u00e9norm\u00e9ment le contr\u00f4le : m\u00eame un appareil malveillant configur\u00e9 avec un DNS dur en dur sera oblig\u00e9 de passer par le filtre.  Attentiontoutefois aux DNS over HTTPS des applications : ceux-ci ne passant pas par le port 53, il faut les bloquer au firewall (ex: bloquer les requ\u00eates vers les domaines connus de DoH publics) ou mettre en place votre propre DoH interceptant comme \u00e9voqu\u00e9 plus haut.</p>"},{"location":"reseau/dns/#dns-split-pour-lab-interne-dns-interne-vs-externe","title":"DNS \u00ab split \u00bb pour lab interne (DNS interne vs externe)","text":"<p>Le concept de  split-horizon DNS  s\u2019applique particuli\u00e8rement dans un homelab o\u00f9 l\u2019on peut avoir des services accessibles \u00e0 la fois depuis l\u2019int\u00e9rieur et l\u2019ext\u00e9rieur. Supposons que vous h\u00e9bergez un site web  monlab.fr  qui a une IP publique (pour y acc\u00e9der depuis Internet) et une IP priv\u00e9e (acc\u00e8s depuis le LAN sans sortir). Vous souhaitez que les machines internes utilisent l\u2019IP priv\u00e9e quand elles r\u00e9solvent  monlab.fr, tandis que le public doit voir l\u2019IP publique. Ceci peut \u00eatre r\u00e9alis\u00e9 avec nos serveurs DNS :</p> <ul> <li> <p>Avec  Pi-hole/AdGuard, la m\u00e9thode courante est d\u2019ajouter une entr\u00e9e DNS locale pour  monlab.fr  pointant vers l\u2019IP priv\u00e9e. Pi-hole offre l\u2019ajout d\u2019un enregistrement A manuel dans \u201cDNS Local\u201d et AdGuard via les  custom rules  . Ainsi, quand un client du LAN demande  monlab.fr, le serveur DNS local lui donne directement l\u2019IP priv\u00e9e. Pour les clients externes (qui n\u2019interrogent pas votre DNS local), ils continueront d\u2019aller vers le DNS public et recevront l\u2019IP publique \u2013 s\u00e9paration de vue accomplie.</p> </li> <li> <p>Avec  Technitium, on peut aller plus loin en d\u00e9finissant  monlab.fr  comme zone locale faisant autorit\u00e9 dans le DNS interne. Vous cr\u00e9ez la zone  monlab.fr  dans Technitium avec vos enregistrements priv\u00e9s. Ensuite, pour que les requ\u00eates externes continuent de fonctionner, Technitium peut soit ne pas \u00eatre expos\u00e9 \u00e0 l\u2019ext\u00e9rieur, soit \u00eatre configur\u00e9 pour forwarder ce domaine vers le DNS public comme  forwarder conditionnel,  tout en ayant des overrides  : par exemple, vous pouvez d\u00e9finir dans la zone locale un enregistrement sp\u00e9cifique qui outrepasse la r\u00e9ponse publique (comme pointer  monlab.fr  vers priv\u00e9) et laisser le reste passer. Technitium excelle dans ce r\u00f4le de DNS split-horizon gr\u00e2ce \u00e0 sa capacit\u00e9 de g\u00e9rer \u00e0 la fois de l\u2019autoritatif et du r\u00e9cursif dans une seule instance  .</p> </li> </ul> <p>Ce  DNS split  est tr\u00e8s utile en homelab pour les VPN aussi : quand vous \u00eates connect\u00e9 en VPN dans votre r\u00e9seau, vous voulez peut-\u00eatre que  wiki.lan  se r\u00e9solve, mais pas quand vous \u00eates \u00e0 l\u2019ext\u00e9rieur. En configurant votre Pi-hole/AdGuard interne pour r\u00e9soudre .lan ou .home.arpa, et en le combinant avec une configuration du client VPN pour utiliser ce DNS, vous obtenez une r\u00e9solution locale des noms \u00e0 travers le VPN. Technitium pourrait lui \u00eatre le serveur central qui r\u00e9pond diff\u00e9remment selon l\u2019IP source (par exemple, si requ\u00eate vient d\u2019une IP du VPN, autoriser certains noms).</p> <p>En r\u00e9sum\u00e9, ces sc\u00e9narios montrent que  un serveur DNS homelab ne sert pas qu\u2019\u00e0 bloquer des pubs, mais peut \u00eatre un \u00e9l\u00e9ment central de la s\u00e9curit\u00e9 r\u00e9seau : il contribue \u00e0 la  d\u00e9tection  (en journalisant quelles adresses sont requ\u00eat\u00e9es), \u00e0 la  protection  (en bloquant ou redirigeant certaines requ\u00eates) et \u00e0 la  flexibilit\u00e9  (en offrant des vues DNS diff\u00e9rentes selon le contexte). Cela permet de  simuler des environnements pro  (DNS d\u2019entreprise avec domaines internes, zones externes, etc.) \u00e0 la maison.</p>"},{"location":"reseau/dns/#securite-mises-a-jour-et-resilience-du-service-dns","title":"S\u00e9curit\u00e9, mises \u00e0 jour et r\u00e9silience du service DNS","text":""},{"location":"reseau/dns/#securite-de-linstance-dns","title":"S\u00e9curit\u00e9 de l\u2019instance DNS","text":"<p>Du point de vue s\u00e9curitaire, il faut consid\u00e9rer  la s\u00e9curit\u00e9 du logiciel DNS lui-m\u00eame  et son  int\u00e9gration s\u00fbre dans le r\u00e9seau. Pi-hole et AdGuard Home sont \u00e9crits dans des langages robustes (C/PHP pour l\u2019un, Go pour l\u2019autre) et b\u00e9n\u00e9ficient de mises \u00e0 jour r\u00e9guli\u00e8res en cas de vuln\u00e9rabilit\u00e9. Jusqu\u2019ici, aucune faille majeure publique n\u2019a compromis ces outils de fa\u00e7on catastrophique, mais il est arriv\u00e9 que Pi-hole corrige des bugs de corruption de m\u00e9moire ou XSS dans l\u2019interface. Technitium DNS est relativement r\u00e9cent mais \u00e9crit en .NET (langage m\u00e9moire-safe)  , ce qui limite certaines cat\u00e9gories de vuln\u00e9rabilit\u00e9s.  Le principal risque  est l\u2019exposition involontaire  de l\u2019interface web d\u2019administration. Il est imp\u00e9ratif de  la prot\u00e9ger  : par d\u00e9faut Pi-hole n\u2019a pas d\u2019HTTPS sur son UI (on peut le mettre derri\u00e8re un proxy HTTPS si besoin)  , AdGuard Home et Technitium peuvent activer HTTPS sur l\u2019interface plus facilement (certificat \u00e0 installer)  . Dans tous les cas, il faut restreindre l\u2019acc\u00e8s de l\u2019UI aux seules IP autoris\u00e9es (via firewall ou en \u00e9coutant seulement sur l\u2019IP locale). \u00c9vitez d\u2019exposer l\u2019interface de gestion sur Internet. Si vous devez acc\u00e9der \u00e0 distance, faites-le via VPN dans votre homelab ou SSH tunnel.</p> <p>Concernant la  s\u00e9paration des r\u00f4les, veillez \u00e0 ce que le serveur DNS n\u2019ait pas plus de privil\u00e8ges que n\u00e9cessaire sur le syst\u00e8me. Par exemple, en Docker il tourne g\u00e9n\u00e9ralement en utilisateur non-root. Sur une machine d\u00e9di\u00e9e, ne pas l\u2019ex\u00e9cuter en root (Pi-hole installe un utilisateur  pihole  pour FTL, etc.). Gardez \u00e9galement votre syst\u00e8me \u00e0 jour \u2013 surtout si c\u2019est un Linux minimal type Raspberry Pi OS, pour b\u00e9n\u00e9ficier des patchs de s\u00e9curit\u00e9 du kernel, etc.</p> <p>Mises \u00e0 jour automatiques :  Par design, Pi-hole  n\u2019auto-met pas \u00e0 jour son core  tout seul (on utilise la commande  pihole -up  manuellement ou on met \u00e0 jour le conteneur Docker). Idem pour Technitium et AdGuard \u2013 ces services ne se mettent pas \u00e0 jour automatiquement comme pourraient le faire des applications cloud. Il faut donc un processus pour les maintenir (veillez aux annonces de nouvelles versions). En revanche,  les listes de blocage, elles, sont souvent  mises \u00e0 jour automatiquement. Pi-hole programme un rafra\u00eechissement hebdomadaire de Gravity (les listes) par d\u00e9faut via cron. AdGuard Home, de son c\u00f4t\u00e9, v\u00e9rifie et met \u00e0 jour les filtres abonn\u00e9s r\u00e9guli\u00e8rement (p\u00e9riodicit\u00e9 configurable, souvent quotidienne) \u2013 il a un avantage l\u00e0-dessus en offrant une interface pour g\u00e9rer la fr\u00e9quence  . Technitium peut \u00eatre configur\u00e9 pour fetcher les listes \u00e0 intervalle \u00e9galement (sinon on peut scripter un cron avec son API). Il est crucial de garder les listes \u00e0 jour pour b\u00e9n\u00e9ficier des nouveaux domaines malveillants \u00e0 bloquer. Pour le core, je vous conseille d\u2019int\u00e9grer la v\u00e9rification des updates de ces services dans votre routine (par exemple, check mensuel, ou s\u2019abonner aux flux GitHub des projets). Sur la s\u00e9curit\u00e9 du code lui-m\u00eame, Pi-hole a l\u2019avantage d\u2019une  tr\u00e8s large communaut\u00e9  qui audite et contribue, AdGuard Home a une \u00e9quipe d\u00e9di\u00e9e (soci\u00e9t\u00e9 AdGuard) et Technitium est principalement maintenu par une petite \u00e9quipe mais tr\u00e8s r\u00e9active  .</p>"},{"location":"reseau/dns/#journalisation-et-respect-de-la-vie-privee","title":"Journalisation et respect de la vie priv\u00e9e","text":"<p>Un serveur DNS filtrant va naturellement  journaliser  beaucoup d\u2019informations : chaque requ\u00eate client, l\u2019adresse qui l\u2019a faite, la r\u00e9ponse retourn\u00e9e, etc. Cela peut poser question dans un contexte personnel (respect de la vie priv\u00e9e des usagers du r\u00e9seau, par exemple votre famille) ou tout simplement encombrer le stockage \u00e0 long terme.</p> <p>Par d\u00e9faut, Pi-hole et AdGuard loggent toutes les requ\u00eates dans une base (FTL DB pour Pi-hole, fichiers log/DB pour AdGuard). On peut voir l\u2019historique via l\u2019interface (requ\u00eates des derni\u00e8res 24h, 7j, etc.).  Pi-hole propose un mode de confidentialit\u00e9 r\u00e9glable  : du log complet \u00e0  aucune journalisation, en passant par des niveaux interm\u00e9diaires o\u00f9 il anonymise partiellement (par ex. ne pas stocker l\u2019adresse IP du client, ou ne pas stocker les domaines consult\u00e9s)  . Cela permet si on le souhaite de r\u00e9duire la granularit\u00e9 des logs \u2013 utile si vous h\u00e9bergez Pi-hole pour un tiers et que vous ne voulez pas conserver ses requ\u00eates. AdGuard Home a \u00e9galement une option \u201cMode furtif\u201d (stealth mode) qui peut limiter ce qui est consign\u00e9 et m\u00eame bloquer les requ\u00eates aux domaines typiques de t\u00e9l\u00e9m\u00e9trie. On peut aussi purger automatiquement les journaux au bout d\u2019un certain temps dans AdGuard. Technitium DNS, au moins dans sa version actuelle, a une interface de log un peu moins d\u00e9velopp\u00e9e  , mais les donn\u00e9es sont bien l\u00e0 (fichiers logs et/ou base SQL). Rien ne vous emp\u00eache d\u2019envoyer les logs DNS vers un SIEM local (Splunk, Elastic) pour analyser le trafic \u2013 c\u2019est m\u00eame un excellent exercice en homelab Blue Team. Cependant, faites attention :  ne pas logguer trop longtemps  sur SD card (si vous utilisez un Pi) pour \u00e9viter son usure, et filtrer ce qui est pertinent.</p> <p>Un aspect \u201cvie priv\u00e9e\u201d important :  aucune de ces solutions n\u2019envoie vos donn\u00e9es DNS \u00e0 l\u2019\u00e9diteur  (tout est self-hosted, local)  .  Seul AdGuard Home utilisait par d\u00e9faut les serveurs DNS d\u2019AdGuard  en upstream lors de l\u2019installation (modifiable bien s\u00fbr)  . Donc par transparence, sachez qu\u2019apr\u00e8s installation, il vaut mieux configurer explicitement vos serveurs DNS pr\u00e9f\u00e9r\u00e9s plut\u00f4t que de laisser ceux par d\u00e9faut (si on veut \u00e9viter que AdGuard (la compagnie) connaisse vos requ\u00eates). Pi-hole et Technitium n\u2019ont pas ce genre de particularit\u00e9 : ils utilisent ce que vous leur indiquez (ou rien, dans le cas d\u2019un r\u00e9solveur pur).</p>"},{"location":"reseau/dns/#resilience-du-service-dns-et-optimisation","title":"R\u00e9silience du service DNS et optimisation","text":"<p>La  r\u00e9silience  englobe la haute disponibilit\u00e9 (disponibilit\u00e9 du service) et la robustesse face aux lenteurs. Comme \u00e9voqu\u00e9 dans la section config, disposer de plusieurs DNS redondants est la meilleure parade contre une panne franche. Mais on peut aussi am\u00e9liorer la  tol\u00e9rance aux \u00e9checs  dans la configuration m\u00eame d\u2019une instance. Par exemple, dans Pi-hole/AdGuard, configurer  plusieurs serveurs DNS upstream  (DNS de secours) permet qu\u2019en cas de silence d\u2019un des serveurs (ex: Cloudflare ne r\u00e9pond plus), l\u2019autre soit essay\u00e9. AdGuard Home offre m\u00eame des strat\u00e9gies (parall\u00e8le, priorit\u00e9, etc.) pour interroger plusieurs upstreams en m\u00eame temps et prendre le plus rapide ou \u00e9liminer celui qui ne r\u00e9pond pas.  Technitium DNS  \u00e9tant un r\u00e9solveur complet, il va g\u00e9rer la redondance au niveau du protocole DNS lui-m\u00eame (plusieurs serveurs racine, etc.), mais si vous configurez des forwarders manuels, pensez aussi \u00e0 en mettre plusieurs.</p> <p>Le  timeout DNS  par d\u00e9faut est de quelques secondes, mais vous pouvez l\u2019ajuster si vous constatez des retards. Toutefois, attention \u00e0 ne pas le rendre trop court et d\u00e9clarer en \u00e9chec trop vite des domaines pouvant n\u00e9cessiter un peu plus de temps (DNSSEC validation par exemple).</p> <p>Un point de r\u00e9silience est la  caching  : heureusement, tous les trois poss\u00e8dent un cache local des r\u00e9ponses DNS. Ainsi, si votre lien Internet tombe temporairement, les noms r\u00e9cemment r\u00e9solus restent dans le cache pour la dur\u00e9e du TTL, permettant aux appareils de continuer \u00e0 fonctionner pour les domaines d\u00e9j\u00e0 connus. Vous pouvez augmenter la taille du cache si vous avez beaucoup de clients, mais g\u00e9n\u00e9ralement les valeurs par d\u00e9faut suffisent (Pi-hole FTL et AdGuard g\u00e8rent \u00e7a automatiquement). Technitium vous laissera ajuster certains param\u00e8tres DNS avanc\u00e9s (taille cache, etc.) si besoin.</p> <p>Enfin, du point de vue  cybers\u00e9curit\u00e9, on peut parler de la  r\u00e9silience face aux attaques DNS  : un homelab pourrait \u00eatre la cible d\u2019une attaque DNS (ex: un malware interne fait des millions de requ\u00eates pour saturer Pi-hole). Pi-hole et AdGuard ont des m\u00e9canismes basiques de rate-limiting pour \u00e9viter qu\u2019un client unique spame trop de requ\u00eates et ne submerge le service. Par exemple Pi-hole limite \u00e0 1000 requ\u00eates par minute par client par d\u00e9faut (configurable) \u2013 cela \u00e9vite qu\u2019un IoT bavard ne rende le DNS indisponible pour tout le monde. Sur Technitium, je ne suis pas s\u00fbr du taux par d\u00e9faut, mais \u00e9tant un serveur plus sophistiqu\u00e9, il doit pouvoir encaisser pas mal de charges (voire on peut utiliser les fonctionnalit\u00e9s de Windows/.NET if it runs on Windows to mitigate abuse). Dans tous les cas, surveillez vos tableaux de bord : si vous voyez qu\u2019un appareil fait 10 000 requ\u00eates/jour, il y a un souci (boucle DNS, etc.) qu\u2019il faut corriger pour ne pas impacter la qualit\u00e9 de service DNS.</p> <p>En r\u00e9sum\u00e9, la mise en place d\u2019un DNS filtrant dans un homelab de s\u00e9curit\u00e9 apporte non seulement un confort (moins de pubs) mais fait partie int\u00e9grante de la  d\u00e9fense en profondeur  du r\u00e9seau domestique. Avec Pi-hole, AdGuard Home ou Technitium DNS, on dispose d\u2019outils modulables qu\u2019il faut configurer selon les besoins : n\u2019h\u00e9sitez pas \u00e0 exp\u00e9rimenter diff\u00e9rentes topologies et r\u00e9glages pour trouver l\u2019\u00e9quilibre optimal entre  s\u00e9curit\u00e9,  performance  et  simplicit\u00e9 de gestion  . Chaque solution a ses points forts, mais toutes visent le m\u00eame objectif : donner \u00e0 l\u2019utilisateur le contr\u00f4le sur ses r\u00e9solutions DNS afin de s\u00e9curiser le r\u00e9seau contre une partie des menaces et nuisances en ligne. Les retours d\u2019exp\u00e9rience conseillent m\u00eame d\u2019tester plusieurs solutions en parall\u00e8le  et d\u2019adopter celle qui vous convient le mieux en termes d\u2019interface et de fonctionnalit\u00e9s  .</p>"},{"location":"reseau/reverse-proxy/","title":"Solutions de Reverse Proxy pour un Homelab de Cybers\u00e9curit\u00e9","text":"<p>Dans un homelab orient\u00e9 cybers\u00e9curit\u00e9, les reverse proxies jouent un r\u00f4le crucial pour exposer en toute s\u00e9curit\u00e9 des services internes vers l\u2019ext\u00e9rieur. Ils permettent de centraliser la gestion des acc\u00e8s, d\u2019appliquer des r\u00e8gles de s\u00e9curit\u00e9 (authentification, filtrage) et de segmenter le r\u00e9seau. Nous allons comparer techniquement  Nginx Proxy Manager,  Traefik  et  Authelia, et examiner des exemples de configuration typiques ainsi que des cas d\u2019usage et fonctionnalit\u00e9s de s\u00e9curit\u00e9 avanc\u00e9es adapt\u00e9s \u00e0 un homelab.</p>"},{"location":"reseau/reverse-proxy/#comparaison-technique-nginx-proxy-manager-traefik-et-authelia","title":"Comparaison technique : Nginx Proxy Manager, Traefik et Authelia","text":"<p>Nginx Proxy Manager (NPM)  est une interface web conviviale permettant de piloter un serveur Nginx (bas\u00e9 sur OpenResty) en arri\u00e8re-plan. Il offre une gestion simplifi\u00e9e des h\u00f4tes proxy avec une GUI intuitive : on peut facilement ajouter un  h\u00f4te proxy  (domaine, adresse cible et port) via une interface web, g\u00e9rer les certificats SSL Let\u2019s Encrypt en un clic, d\u00e9finir des acc\u00e8s restreints, etc. Par d\u00e9faut, NPM prend en charge les fonctionnalit\u00e9s de base communes \u00e0 Traefik, comme la gestion automatique des certificats SSL/TLS (via Let\u2019s Encrypt et divers fournisseurs DNS) et le proxying de multiples protocoles (HTTP, HTTPS, mais aussi TCP/UDP via les streams Nginx)  . Son atout principal est la simplicit\u00e9 : tout se fait via l\u2019UI, sans n\u00e9cessiter d\u2019\u00e9diter des fichiers de configuration. NPM g\u00e8re les utilisateurs multiples avec r\u00f4les et journalisation des modifications (audit logs) int\u00e9gr\u00e9s, ce qui permet une administration partag\u00e9e et trac\u00e9e \u2013 une fonctionnalit\u00e9 que Traefik n\u2019a pas nativement  . Techniquement, NPM stocke sa configuration (h\u00f4tes, utilisateurs, certificats\u2026) dans une base de donn\u00e9es (SQLite ou MariaDB/MySQL)  . Cela signifie que la configuration persiste et peut \u00eatre sauvegard\u00e9e, mais introduit aussi un point d\u2019\u00e9chec potentiel (corruption de DB). NPM \u00e9tant un frontal \u00e0 Nginx, il b\u00e9n\u00e9ficie des performances reconnues de Nginx (\u00e9crites en C, tr\u00e8s optimis\u00e9es) \u2013 on observe en effet que Traefik est  un peu moins rapide  que Nginx/OpenResty en proxy HTTP, m\u00eame si l\u2019\u00e9cart est mineur dans le contexte d\u2019un homelab  . En contrepartie, NPM est moins flexible sur certains points avanc\u00e9s : par exemple, l\u2019interface ne permet de d\u00e9finir qu\u2019un seul serveur de destination par host (pas de load-balancing multiple en GUI)  , et une erreur de configuration peut rendre Nginx indisponible (toute la configuration Nginx \u00e9choue si un host est mal d\u00e9fini), interrompant  tous  les sites jusqu\u2019\u00e0 correction  . NPM convient bien aux d\u00e9butants ou \u00e0 ceux qui privil\u00e9gient la rapidit\u00e9 de mise en place via une interface graphique  .</p> <p>Traefik  est un reverse proxy moderne, pens\u00e9 pour les environnements dynamiques (Docker, Kubernetes). Contrairement \u00e0 NPM, Traefik privil\u00e9gie la configuration  \u201cas code\u201d  : pas de v\u00e9ritable GUI d\u2019administration (son tableau de bord web est  en lecture seule, servant \u00e0 visualiser la config active)  . La configuration s\u2019effectue via des fichiers YAML statiques/dynamiques ou via des  labels Docker  attach\u00e9s aux conteneurs \u2013 ce qui permet une  d\u00e9couverte automatique  des services. En effet, Traefik peut surveiller l\u2019API Docker ou Kubernetes et cr\u00e9er les routes proxy correspondantes \u00e0 la vol\u00e9e en fonction des labels, sans red\u00e9marrage du conteneur Traefik  . Cette capacit\u00e9 d\u2019auto-discovery  est un avantage dans un homelab tr\u00e8s containeris\u00e9 : d\u00e9ployer un nouveau service Docker avec les bons labels suffit pour l\u2019exposer sur le domaine voulu, Traefik configurant automatiquement le routage  . Traefik int\u00e8gre nativement le support de Let\u2019s Encrypt (ACME) : il peut g\u00e9n\u00e9rer et renouveler automatiquement les certificats SSL, y compris via des challenges DNS (il suffit de fournir les tokens API des DNS providers dans la configuration)  . Il supporte pleinement le  load balancing  entre plusieurs instances d\u2019un service (round-robin, etc.) et des  middlewares  puissants pour modifier ou filtrer les requ\u00eates (r\u00e9\u00e9critures d\u2019URL, redirections, rate limiting, IP whitelisting, authentification basique, injection de headers de s\u00e9curit\u00e9, etc.)  . Traefik ne n\u00e9cessite pas de base de donn\u00e9es \u2013 sa configuration vit en m\u00e9moire et se met \u00e0 jour dynamiquement \u2013 ce qui le rend moins sujet \u00e0 des corruptions et permet des changements \u00e0 chaud sans interruption  . En cas de configuration invalide, seul l\u2019\u00e9l\u00e9ment concern\u00e9 \u00e9chouera tandis que le reste du proxy continue de fonctionner, ce qui am\u00e9liore la  robustesse  de l\u2019ensemble par rapport \u00e0 Nginx (o\u00f9 une erreur peut bloquer tout le service)  . C\u00f4t\u00e9 performances, Traefik (\u00e9crit en Go) est l\u00e9g\u00e8rement moins performant que Nginx en termes de latence pure ou de d\u00e9bit, mais pour un usage homelab les diff\u00e9rences sont g\u00e9n\u00e9ralement n\u00e9gligeables  . Traefik s\u2019adresse plut\u00f4t aux utilisateurs avanc\u00e9s ou aux environnements n\u00e9cessitant une forte automatisation et int\u00e9gration CI/CD, au prix d\u2019une  courbe d\u2019apprentissage  plus \u00e9lev\u00e9e (compr\u00e9hension des routers, services, middlewares, labels)  . En r\u00e9sum\u00e9,  Traefik excelle en environnement containeris\u00e9 dynamique, tandis que  Nginx Proxy Manager brille par sa simplicit\u00e9 et son interface utilisateur.</p> <p>Authelia, quant \u00e0 lui, n\u2019est pas un reverse proxy mais un service  d\u2019authentification et d\u2019autorisation  open-source con\u00e7u pour se  coupler aux reverse proxies  existants (Nginx, Traefik, Caddy, HAProxy, etc.)  . Authelia agit comme un  portail d\u2019authentification  \u00e0 facteurs multiples (MFA) fournissant du  Single Sign-On (SSO)  pour vos applications web auto-h\u00e9berg\u00e9es  . En pratique, il s\u2019int\u00e8gre via le m\u00e9canisme de  \u201cforward authentication\u201d  : le reverse proxy est configur\u00e9 pour interroger Authelia \u00e0 chaque requ\u00eate entrante non authentifi\u00e9e. Authelia valide si l\u2019utilisateur a une session active (cookie SSO) ou demande \u00e0 ce qu\u2019il se connecte via son  portail web s\u00e9curis\u00e9. Une fois l\u2019authentification effectu\u00e9e (avec mot de passe + second facteur possible), Authelia informe le proxy que la requ\u00eate peut passer, et l\u2019utilisateur acc\u00e8de alors au service cible  . Authelia dispose d\u2019une interface web pour le login des utilisateurs (portal web) mais pas d\u2019une interface \u201cadmin\u201d \u00e9quivalente \u00e0 NPM/Traefik \u2013 sa configuration se fait via un fichier YAML. Il supporte en backend les utilisateurs d\u00e9finis dans un fichier YAML ou dans un annuaire  LDAP/Active Directory, ainsi que la possibilit\u00e9 d\u2019\u00eatre  fournisseur OpenID Connect (OIDC)  . Ce dernier point signifie qu\u2019Authelia peut s\u2019int\u00e9grer dans un \u00e9cosyst\u00e8me OAuth2/OIDC : par exemple, des applications supportant OIDC peuvent d\u00e9leguer l\u2019authentification \u00e0 Authelia, ou Authelia peut utiliser des  en-t\u00eates \u201ctrusted\u201d  pour propager l\u2019identit\u00e9 de l\u2019utilisateur aux applications web  . Authelia se d\u00e9ploie facilement en Docker (image &lt;20\u202fMo) et consomme peu de ressources (quelques dizaines de Mo de RAM)  \u2013 int\u00e9ressant pour un homelab o\u00f9 on cherche \u00e0 minimiser l\u2019empreinte. Il n\u00e9cessite g\u00e9n\u00e9ralement un  stockage  pour les donn\u00e9es de session (Redis par exemple pour la haute dispo, sinon en m\u00e9moire ou SQLite) et peut utiliser une base (SQLite, MySQL\u2026) pour stocker son \u00e9tat (sessions, pr\u00e9f\u00e9rences) si on le souhaite  . Authelia compl\u00e8te donc Traefik ou Nginx Proxy en ajoutant une couche d\u2019authentification forte centralis\u00e9e.  \u00c0 noter  : Nginx Proxy Manager ne propose pas nativement l\u2019int\u00e9gration d\u2019Authelia dans son interface, contrairement \u00e0 Traefik o\u00f9 la documentation officielle fournit des exemples de configuration pour Authelia  . Il est tout de m\u00eame possible d\u2019utiliser Authelia avec Nginx Proxy Manager en ajoutant des directives personnalis\u00e9es dans la configuration Nginx (voir plus loin).</p>"},{"location":"reseau/reverse-proxy/#principales-differences-nginx-proxy-manager-vs-traefik","title":"Principales diff\u00e9rences Nginx Proxy Manager vs Traefik","text":"<p>Pour synth\u00e9tiser la comparaison NPM vs Traefik dans un contexte homelab :</p> <ul> <li> <p>Interface &amp; configuration : NPM offre une  interface web compl\u00e8te  pour tout configurer (domaine, upstream, certificat, authentification\u2026), conviviale pour les d\u00e9butants. Traefik propose seulement un  tableau de bord  de visualisation, la configuration se fait par  fichiers  ou  labels  dans une approche Infrastructure-as-Code  . Modifier une config Traefik exige donc de conna\u00eetre sa syntaxe (YAML/labels) mais permet une automatisation et une mise en version du code, l\u00e0 o\u00f9 NPM privil\u00e9gie la simplicit\u00e9 point&amp;click.</p> </li> <li> <p>Gestion des utilisateurs et des droits : NPM g\u00e8re nativement des comptes multiples avec r\u00f4les (admin, viewer) et garde un  journal d\u2019audit  des changements  . Traefik n\u2019a pas d\u2019utilisateurs multiples ni d\u2019authentification sur son dashboard par d\u00e9faut (il faut ajouter une auth basique manuellement si on veut prot\u00e9ger l\u2019acc\u00e8s \u00e0 l\u2019UI)  . Dans un homelab \u00e0 plusieurs administrateurs ou pour tracer les modifications, NPM marque donc un point.</p> </li> <li> <p>Persistance de la configuration : NPM stocke sa configuration dans une base de donn\u00e9es (fichiers SQLite ou serveur MariaDB)  , ce qui assure une persistance m\u00eame apr\u00e8s red\u00e9marrage du conteneur. Traefik n\u2019a pas de DB \u2013 les configs statiques/dynamiques sont recharg\u00e9es en m\u00e9moire \u00e0 chaque d\u00e9marrage et peuvent \u00eatre mises \u00e0 jour \u00e0 chaud. Moins de risque de corruption mais il faut penser \u00e0 sauvegarder manuellement les fichiers de configuration Traefik/les commandes de d\u00e9ploiement Docker-Compose (alors que NPM n\u00e9cessite de sauvegarder son volume ou dump SQL).</p> </li> <li> <p>Routing et d\u00e9couvertes de services : Traefik est con\u00e7u pour la  d\u00e9couverte automatique  des services dans Docker/K8s \u2013 tout conteneur lanc\u00e9 avec les bons labels est automatiquement pris en charge (sous r\u00e9serve qu\u2019il soit dans le r\u00e9seau Docker de Traefik)  . NPM ne d\u00e9couvre rien automatiquement : il faut d\u00e9clarer chaque host via l\u2019UI (bien qu\u2019il soit possible de scripter l\u2019API ou d\u2019utiliser Nginx Proxy  Companion  pour du Docker g\u00e9n\u00e9rique, ce n\u2019est pas int\u00e9gr\u00e9 dans NPM). Pour un homelab tr\u00e8s dynamique (services \u00e9ph\u00e9m\u00e8res, scaling), Traefik se montre plus pratique.</p> </li> <li> <p>Flexibilit\u00e9 des fonctionnalit\u00e9s : Traefik embarque des  middlewares modulaires  activables facilement (ex :  traefik.http.middlewares.rateLimit,  ...redirectscheme,  ...auth  etc.), ainsi qu\u2019un \u00e9cosyst\u00e8me de  plugins  officiel pour \u00e9tendre ses capacit\u00e9s (ex : plugin Fail2Ban,  CrowdSec, ModSecurity WAF, etc.)  . Nginx (et donc NPM) est tr\u00e8s puissant aussi, mais ajouter par exemple un WAF ModSecurity ou un syst\u00e8me de ban IP n\u00e9cessite de modifier la configuration avanc\u00e9e ou d\u2019utiliser des conteneurs compl\u00e9mentaires \u2013 ce n\u2019est pas \u201cplug and play\u201d via l\u2019interface. En contrepartie, Nginx permet un  contr\u00f4le tr\u00e8s fin  de chaque d\u00e9tail (directives SSL/TLS, tuning performance, modules tiers) en \u00e9ditant la config, tandis que Traefik fait plus de choses automatiquement mais offre moins de contr\u00f4le granulaire que du pur Nginx  .</p> </li> <li> <p>Performances : Nginx/OpenResty offre en g\u00e9n\u00e9ral un meilleur throughput et une latence un peu plus faible que Traefik dans les m\u00eames conditions  . Pour un homelab avec quelques services, cette diff\u00e9rence est  peu perceptible  . Nginx excelle sous forte charge ou pour servir du contenu static/cache, tandis que Traefik consomme un peu plus de CPU/RAM pour son moteur Go mais reste tout \u00e0 fait adapt\u00e9 \u00e0 des charges modestes. On pourra retenir que si l\u2019on cherche \u00e0 optimiser chaque pourcent de performance, Nginx a l\u2019avantage, mais Traefik apporte d\u2019autres b\u00e9n\u00e9fices (auto-config) qui peuvent primer en homelab.</p> </li> </ul> <p>En r\u00e9sum\u00e9,  NPM  est id\u00e9al pour d\u00e9marrer rapidement et administrer simplement un reverse proxy multi-sites via une interface graphique, avec la robustesse \u00e9prouv\u00e9e de Nginx.  Traefik  convient aux setups plus automatis\u00e9s ou complexes, particuli\u00e8rement si tout tourne en conteneurs, en offrant une int\u00e9gration native avec Docker/K8s et des fonctionnalit\u00e9s avanc\u00e9es (middlewares, load balancing) au prix d\u2019une configuration par code. Dans bien des cas, le choix d\u00e9pendra donc de votre aisance technique et des besoins sp\u00e9cifiques du lab (simplicit\u00e9 vs. flexibilit\u00e9)  . Notons qu\u2019Authelia  n\u2019est pas en concurrence directe avec ces proxies mais vient plut\u00f4t les compl\u00e9ter pour la couche authentification/SSO multi-facteurs.</p>"},{"location":"reseau/reverse-proxy/#exemples-de-configurations-typiques","title":"Exemples de configurations typiques","text":"<p>Passons en revue quelques configurations typiques qu\u2019on peut mettre en place avec ces outils, dans un homelab, pour renforcer la s\u00e9curit\u00e9 et le confort d\u2019utilisation.</p>"},{"location":"reseau/reverse-proxy/#reverse-proxy-avec-authentification-des-acces","title":"Reverse proxy avec authentification des acc\u00e8s","text":"<p>Un usage courant en homelab est de  prot\u00e9ger l\u2019acc\u00e8s aux services internes par une authentification. Plusieurs approches existent :</p> <ul> <li> <p>Authentification basique (Basic Auth)  : C\u2019est la m\u00e9thode la plus simple, int\u00e9gr\u00e9e nativement.  Nginx Proxy Manager  permet de cr\u00e9er des  Access Lists  contenant des utilisateurs (login/mot de passe HTTP Basic) et de les associer \u00e0 un host. Par exemple, on peut d\u00e9finir une liste \u201cAdmin seulement\u201d avec utilisateur  admin  et mot de passe, puis la lier \u00e0 l\u2019h\u00f4te proxy d\u2019une application sensible \u2013 NPM forcera alors la saisie de ce login/mot de passe pour acc\u00e9der au service.  Traefik  offre un middleware de basic auth \u00e9quivalent : on peut d\u00e9finir dans les labels Docker  traefik.http.middlewares.monauth.basicauth.users=utilisateur:motdepasse_hash\u00e9  et attacher ce middleware \u00e0 un router  . Dans le fichier Compose pr\u00e9sent\u00e9 plus haut, on voit un exemple prot\u00e9geant le dashboard Traefik par basic auth (utilisateur  admin, mot de passe  password) via ces labels  . Cette m\u00e9thode a l\u2019avantage d\u2019\u00eatre simple mais n\u2019offre pas de SSO (chaque service a ses propres identifiants) ni de second facteur.</p> </li> <li> <p>Authentification avanc\u00e9e avec Authelia (SSO)  : Pour un homelab cybers\u00e9curit\u00e9, mettre en place Authelia apporte une couche  SSO \u00e0 double facteur  pour tous les services web. La configuration consiste \u00e0 d\u00e9ployer le service Authelia (Docker) et \u00e0 le  d\u00e9clarer dans le reverse proxy  en tant que provider d\u2019authentification. Concr\u00e8tement, avec  Nginx (Proxy Manager)  cela se fait en ajoutant des directives custom Nginx dans l\u2019onglet \u201cAdvanced\u201d de chaque host \u00e0 prot\u00e9ger. Par exemple, on ins\u00e9rera dans la config du host :</p> </li> </ul> <pre><code>auth_request /authelia;\nauth_request_set  $target_url  $scheme://$http_host$request_uri;\nerror_page  401  =302  https://auth.mondomaine.com/?rd=$target_url;\n</code></pre> <ul> <li> <p>(ainsi que d\u2019autres directives pour passer les en-t\u00eates d\u2019utilisateur)  . Ces instructions signifient : \u201cpour chaque requ\u00eate sur ce host, interroger l\u2019URL  /authelia  (endpoint interne qui pointe vers Authelia) \u2013 si Authelia renvoie 401 non autoris\u00e9, alors rediriger (302) le client vers la page de login Authelia  auth.mondomaine.com  en lui passant l\u2019URL cible dans  rd  (redirect)\u201d. Authelia, une fois l\u2019utilisateur authentifi\u00e9, redirigera celui-ci vers l\u2019URL initiale, qui cette fois sera accept\u00e9e (car munie du cookie de session). Ce m\u00e9canisme utilise le  directive auth_request de Nginxpour interroger un serveur d\u2019auth externe  .</p> <p>Du c\u00f4t\u00e9  Traefik, l\u2019int\u00e9gration est tout aussi simple via un  middleware de type ForwardAuth. On peut d\u00e9clarer, par exemple dans un fichier dynamique ou via labels, un middleware pointant vers Authelia :</p> </li> </ul> <p><pre><code>traefik.http.middlewares.authelia.forwardAuth.address: \"http://authelia:9091/api/authz/forward-auth\"\ntraefik.http.middlewares.authelia.forwardAuth.trustForwardHeader: \"true\"\ntraefik.http.middlewares.authelia.forwardAuth.authResponseHeaders: \"Remote-User,Remote-Groups,Remote-Email\"\n</code></pre> -   Ensuite, pour chaque service \u00e0 prot\u00e9ger, on attache ce middleware  authelia  au router Traefik concern\u00e9 (par ex. label  traefik.http.routers.monservice.middlewares=authelia@docker)  . Ainsi, toute requ\u00eate passera par Authelia qui d\u00e9cidera de la laisser passer ou non. Authelia fournit en plus des en-t\u00eates (Remote-User, Remote-Groups, etc.) que le proxy peut forwarder \u00e0 l\u2019application cible si besoin  (utile si l\u2019application veut conna\u00eetre l\u2019utilisateur logg\u00e9).</p> <pre><code>_Dans la pratique_, une configuration compl\u00e8te implique aussi : la d\u00e9finition des r\u00e8gles d\u2019acc\u00e8s dans Authelia (fichier YAML  _access_control_: quels domaines exigent 2FA, lesquels sont en acc\u00e8s libre ou 1FA)  , la cr\u00e9ation des utilisateurs (fichier ou connexion \u00e0 un LDAP), et la s\u00e9curisation du portail Authelia lui-m\u00eame via HTTPS. Une fois en place, ce setup offre une  **authentification unifi\u00e9e**  : l\u2019utilisateur se connecte une fois sur Authelia et acc\u00e8de ensuite \u00e0 plusieurs services sans se reconnecter (SSO) tant que sa session est valide  . On b\u00e9n\u00e9ficie aussi de fonctionnalit\u00e9s de s\u00e9curit\u00e9 comme le deuxi\u00e8me facteur (TOTP, Webauthn\u2026) et la protection anti-brute-force fournie par Authelia (voir section S\u00e9curit\u00e9).\n</code></pre> <ul> <li>Restriction par adresse IP (IP whitelisting)  : Une m\u00e9thode plus simple, qui peut compl\u00e9ter les pr\u00e9c\u00e9dentes, est de  limiter l\u2019acc\u00e8s \u00e0 certains services par IP source  (par exemple, accessibles uniquement depuis le LAN du homelab ou via VPN). Nginx Proxy Manager permet de d\u00e9finir dans les Access Lists des plages IP autoris\u00e9es ou refus\u00e9es. Traefik propose un middleware  IPWhiteList  o\u00f9 l\u2019on sp\u00e9cifie des subnets autoris\u00e9s. Dans l\u2019extrait de configuration Traefik pr\u00e9c\u00e9dent, on voit par exemple un middleware  local-ipwhitelist@file  pouvant \u00eatre appliqu\u00e9 \u00e0 un router pour  n\u2019accepter que les IP priv\u00e9es  . Ce type de filtrage est tr\u00e8s utile pour, par exemple, exposer l\u2019interface d\u2019administration d\u2019un NAS ou d\u2019une VM uniquement aux IP locales, tout en ayant d\u2019autres services du proxy accessibles depuis Internet. Cela segmente l\u2019acc\u00e8s sans n\u00e9cessiter d\u2019authentification pour les services purement internes.</li> </ul> <p>En combinant ces m\u00e9thodes, on peut obtenir un niveau de s\u00e9curit\u00e9 granulaire adapt\u00e9 \u00e0 chaque service du homelab. Par exemple, un wiki personnel pourrait \u00eatre accessible uniquement depuis le LAN (filtrage IP), tandis qu\u2019une application plus critique (ex: interface domotique) serait expos\u00e9e sur Internet mais prot\u00e9g\u00e9e par Authelia (login + 2FA), et un service moins sensible pourrait se contenter d\u2019une auth basique.</p>"},{"location":"reseau/reverse-proxy/#acces-securise-aux-services-internes-depuis-lexterieur","title":"Acc\u00e8s s\u00e9curis\u00e9 aux services internes depuis l\u2019ext\u00e9rieur","text":"<p>L\u2019un des buts du reverse proxy dans un homelab est de  rendre accessibles depuis l\u2019ext\u00e9rieur  (Internet) certaines applications internes, de mani\u00e8re s\u00e9curis\u00e9e. Voici les bonnes pratiques de configuration pour cet usage :</p> <ul> <li> <p>Placer le proxy en \u201cfrontale\u201d s\u00e9curis\u00e9e  : Le reverse proxy sert de  point d\u2019entr\u00e9e unique. On configure le routeur/pare-feu de la box internet pour ne forward que les ports 80/443 vers la machine h\u00e9bergeant le proxy (id\u00e9alement uniquement 443, voir HTTPS ci-dessous). Ainsi,  aucun service interne n\u2019est expos\u00e9 en direct  \u2013 ils sont tous sur des IP priv\u00e9es non routables, seul le proxy (dans une DMZ ou VLAN d\u00e9di\u00e9 de pr\u00e9f\u00e9rence) est joignable depuis Internet. Cette configuration limite la surface d\u2019attaque : un attaquant ne peut cibler que le proxy lui-m\u00eame, et non chaque service individuellement.</p> </li> <li> <p>Noms de domaine et DNS  : On utilise un (sous-)domaine pour chaque service, g\u00e9r\u00e9 via un DNS public (par ex. un domaine personnalis\u00e9, ou des sous-domaines d\u2019un DDNS). Par exemple,  nextcloud.monlab.fr,  wiki.monlab.fr, etc. Le reverse proxy est configur\u00e9 pour \u00e9couter sur ces noms et acheminer vers le bon service interne. Cela permet de virtualiser sur une seule IP publique plusieurs services web. Nginx Proxy Manager et Traefik g\u00e8rent tr\u00e8s bien le routage par nom de host, et Traefik peut m\u00eame d\u00e9finir une r\u00e8gle par wildcard ou par motif d\u2019URL si n\u00e9cessaire. Veillez \u00e0 configurer des  entr\u00e9es DNS  pointant vers votre IP publique (et \u00e0 mettre \u00e0 jour si IP dynamique, via un service DDNS ou l\u2019API du registrar).</p> </li> <li> <p>HTTPS obligatoire  :  Chiffrer les communications  est indispensable. Le proxy doit pr\u00e9senter des certificats SSL valides pour vos domaines. Heureusement, NPM comme Traefik automatisent Let\u2019s Encrypt : il suffit d\u2019activer l\u2019option (et d\u2019avoir son domaine correctement point\u00e9 DNS). Dans NPM, on coche \u201cRequest a new SSL Certificate\u201d et \u201cForce SSL\u201d. Dans Traefik, on configure un resolver ACME (email, m\u00e9thode http-01 ou dns-01) \u2013 par exemple via la section  certificatesResolvers  du fichier Traefik  . Une fois les certificats en place, on doit  rediriger tout le trafic HTTP vers HTTPS  pour \u00e9viter toute fuite en clair. NPM propose le bouton  Force SSL  qui fait ajouter une r\u00e8gle de redirection 301 automatique. Avec Traefik, on d\u00e9finit soit un middleware  redirectScheme  global, soit on utilise la directive d\u2019entryPoint : par exemple le fichier de config peut contenir:</p> </li> </ul> <pre><code>entryPoints:\n  http:\n    address: \":80\"\n    http:\n      redirections:\n        entryPoint:\n          to: https\n          scheme: https\n  https:\n    address: \":443\"\n    # ...\n</code></pre> <ul> <li> <p>qui signifie qu\u2019on redirige toute connexion HTTP vers l\u2019entr\u00e9e HTTPS correspondante  . Apr\u00e8s ce r\u00e9glage, toute tentative en  http://  sera automatiquement renvoy\u00e9e en  https://, garantissant que m\u00eame les utilisateurs ou liens non s\u00e9curis\u00e9s finissent chiffr\u00e9s.</p> </li> <li> <p>Authentification et autorisation  : Comme discut\u00e9 plus haut, il est fortement recommand\u00e9 de prot\u00e9ger par un m\u00e9canisme d\u2019authentification tout service ouvert sur Internet (\u00e0 moins que le service ait d\u00e9j\u00e0 sa propre auth robuste). Ainsi, on \u00e9vite qu\u2019une application vuln\u00e9rable soit accessible publiquement sans contr\u00f4le. Typiquement, on utilisera Authelia ou au moins une authentification basique pour les applications sensibles. Authelia permet en plus de d\u00e9finir des  r\u00e8gles d\u2019autorisation  fines (par groupe d\u2019utilisateurs, par adresse IP source, etc.)  , ce qui peut servir \u00e0 n\u2019autoriser que certains utilisateurs \u00e0 acc\u00e9der \u00e0 une ressource donn\u00e9e.</p> </li> <li> <p>Durcissement et filtres  : Le proxy peut \u00e9galement servir de  premi\u00e8re ligne de d\u00e9fense applicative. On peut activer des  headers de s\u00e9curit\u00e9  globaux (HSTS, XSS-Protection, Content-Security-Policy, etc.) sur le proxy. Par exemple, Nginx Proxy Manager permet d\u2019ajouter des custom headers, et Traefik propose un middleware  headers(souvent un preset de \u201cSecure Headers\u201d) qu\u2019on peut appliquer sur toutes les routes  . De m\u00eame, on peut filtrer ou bloquer certains patterns de requ\u00eates connus comme malveillants (Block Common Exploits  est une option de NPM qui ajoute quelques r\u00e8gles Nginx de base). Pour aller plus loin, on pourrait int\u00e9grer un WAF (pare-feu applicatif) : Traefik, via un plugin comme  Traefik Pilot  (ou en le cha\u00eenant avec un conteneur ModSecurity), et Nginx via le module ModSecurity ou en pla\u00e7ant Cloudflare en proxy en amont par exemple. Dans un homelab, une approche populaire est d\u2019utiliser  CrowdSec  coupl\u00e9 au reverse proxy : CrowdSec analyse les logs (par ex. les acc\u00e8s Nginx ou Traefik) et bannit automatiquement les IP malveillantes (scans, brute-force) via un bouncer. Traefik poss\u00e8de un middleware CrowdSec natif en plugin, ce qui facilite l\u2019int\u00e9gration  .</p> </li> </ul> <p>En somme, exposer un service interne via un reverse proxy n\u00e9cessite de  tout ramener \u00e0 un point d\u2019entr\u00e9e s\u00e9curis\u00e9 unique  (le proxy), d\u2019y appliquer  chiffrement et authentification, et de segmenter ce qui est accessible de ce qui ne l\u2019est pas. Un homelab de cybers\u00e9curit\u00e9 tirera profit de cette configuration pour simuler une architecture proche d\u2019une DMZ d\u2019entreprise, o\u00f9 l\u2019on peut pratiquer la gestion des acc\u00e8s externes de mani\u00e8re s\u00e9curis\u00e9e.</p>"},{"location":"reseau/reverse-proxy/#separation-des-zones-reseau-segmentation","title":"S\u00e9paration des zones r\u00e9seau (segmentation)","text":"<p>Dans un contexte cybers\u00e9curit\u00e9, il est judicieux de  segmenter le r\u00e9seau du homelab  en zones de confiance (par exemple : r\u00e9seau  DMZ  pour les services expos\u00e9s, r\u00e9seau  interne  pour les donn\u00e9es sensibles, r\u00e9seau  management  pour l\u2019administration, etc.). Le reverse proxy peut jouer un r\u00f4le central dans cette s\u00e9paration :</p> <ul> <li> <p>On peut placer le serveur qui h\u00e9berge Traefik/Nginx Proxy Manager dans une  zone DMZ  (r\u00e9seau isol\u00e9 ne contenant que les machines \u201cfrontales\u201d). Ce proxy DMZ a des acc\u00e8s filtr\u00e9s vers la zone interne pour joindre les services, tandis que le trafic entrant depuis Internet est limit\u00e9 \u00e0 aller vers le proxy uniquement. Ainsi, si un service interne est compromis, l\u2019attaquant doit encore traverser le proxy pour en sortir. Et si le proxy lui-m\u00eame est compromis, il est dans une DMZ qui limite les d\u00e9g\u00e2ts sur le reste du r\u00e9seau.</p> </li> <li> <p>Gr\u00e2ce au reverse proxy, on peut garder  ferm\u00e9s tous les ports  des services internes (ils \u00e9coutent seulement en local ou sur le LAN interne). Par exemple, une appli web sur un serveur interne n\u2019\u00e9coute que sur son port 8080 en interne ; seul le proxy y acc\u00e8de pour relayer les requ\u00eates externes. Cela r\u00e9duit la surface d\u2019attaque r\u00e9seau. On autorisera dans le firewall interne uniquement l\u2019IP du proxy DMZ \u00e0 contacter l\u2019IP du service sur le port requis.</p> </li> <li> <p>Le proxy peut \u00e9galement faire office de  passerelle entre VLAN  : s\u2019il a des interfaces (ou VLAN) sur plusieurs r\u00e9seaux, il peut accepter des requ\u00eates d\u2019un r\u00e9seau A et aller chercher la ressource sur un r\u00e9seau B. Cependant, il faut \u00eatre prudent : le proxy ne doit pas devenir une porte d\u00e9rob\u00e9e entre r\u00e9seaux segment\u00e9s. Il convient de n\u2019autoriser que les flux n\u00e9cessaires (typiquement HTTP/HTTPS du proxy DMZ vers le backend interne sur le port du service web).</p> </li> <li> <p>Authelia, dans une optique Zero Trust, peut renforcer la s\u00e9paration : on peut exiger une authentification forte m\u00eame pour acc\u00e9der \u00e0 certains services depuis la zone  interne. Par exemple, si le homelab a un r\u00e9seau WiFi \u201cIoT\u201d moins s\u00fbr, on peut exiger que les utilisateurs de ce r\u00e9seau s\u2019authentifient via Authelia pour acc\u00e9der \u00e0 l\u2019interface d\u2019administration d\u2019un serveur, m\u00eame si c\u2019est techniquement en interne.</p> </li> </ul> <p>En termes de configuration, la s\u00e9paration des zones se fait hors du reverse proxy (c\u2019est une architecture r\u00e9seau), mais le proxy doit \u00eatre configur\u00e9 en cons\u00e9quence : bonnes adresses IP, r\u00e8gles firewall appropri\u00e9es, etc. Traefik ou Nginx peuvent \u00e9couter sur plusieurs interfaces si n\u00e9cessaire, ou on peut d\u00e9ployer deux instances de proxy (un dans la DMZ externe, un interne) cascade si on veut complexifier l\u2019architecture. Pour un homelab n\u00e9anmoins, une instance dans la zone expos\u00e9e suffit g\u00e9n\u00e9ralement, parlant aux services en interne.</p>"},{"location":"reseau/reverse-proxy/#filtrage-et-supervision-des-requetes","title":"Filtrage et supervision des requ\u00eates","text":"<p>Un homelab de cybers\u00e9curit\u00e9 sert souvent \u00e0 exp\u00e9rimenter avec des outils de d\u00e9tection et de protection. Le reverse proxy est un endroit strat\u00e9gique pour impl\u00e9menter du  filtrage de requ\u00eates  et de la  supervision  :</p> <ul> <li> <p>Journaux d\u2019acc\u00e8s centralis\u00e9s  : Le proxy enregistre toutes les requ\u00eates entrantes (domaines, URL, IP source, r\u00e9ponse\u2026). Ceci offre une visibilit\u00e9 globale sur qui acc\u00e8de \u00e0 quoi. On peut connecter ces logs \u00e0 des outils SIEM ou de monitoring (par ex. Grafana/Loki pour Traefik, ou un ELK/Graylog) afin de d\u00e9tecter des anomalies. Traefik fournit un log d\u2019acc\u00e8s d\u00e9taill\u00e9 (format JSON possible) configurable dans traefik.yml  . Nginx Proxy Manager logge via Nginx (format combin\u00e9 classique) et on peut ajuster la verbosit\u00e9.  Analyser ces logs  permet de rep\u00e9rer des scans, des tentatives d\u2019exploitation (URL \u00e9tranges), etc.</p> </li> <li> <p>Blocage automatique d\u2019IP malveillantes  : Coupl\u00e9 aux logs, on peut int\u00e9grer des solutions comme  Fail2Ban  ou  CrowdSec. Fail2Ban peut surveiller les logs Nginx pour des motifs (codes 401 r\u00e9p\u00e9titifs, 404 suspectes) et ins\u00e9rer des r\u00e8gles firewall pour bannir l\u2019IP temporairement. CrowdSec, plus \u00e9volu\u00e9, utilise des  scenarios  pour d\u00e9tecter comportements malveillants (brute-force, scan, etc.) et peut agir au niveau du proxy (bouncer Traefik) ou du firewall syst\u00e8me. Traefik, gr\u00e2ce \u00e0 son plugin CrowdSec ou fail2ban, facilite cette automatisation  . Pour NPM, on peut d\u00e9ployer CrowdSec sur la machine et le configurer pour parser les logs Nginx.</p> </li> <li> <p>Web Application Firewall (WAF)  : L\u2019ajout d\u2019un WAF permet de filtrer des requ\u00eates en fonction de leur contenu (payload) pour bloquer des attaques web connues (injections SQL, XSS, etc.). Nginx peut int\u00e9grer ModSecurity v3 en tant que module (certaines images Docker custom de NPM existent incluant ModSec). Traefik, lui, n\u2019int\u00e8gre pas nativement de WAF complet, mais on peut mettre Traefik derri\u00e8re un conteneur SWAG/NGINX+ModSecurity, ou utiliser le plugin  OHWF  (Open Hybrid WAF) exp\u00e9rimental. Une alternative courante en homelab est d\u2019utiliser Cloudflare en proxy inverse en amont du homelab : Cloudflare fournit un WAF g\u00e9r\u00e9 qui stoppe d\u00e9j\u00e0 beaucoup d\u2019attaques avant m\u00eame qu\u2019elles n\u2019atteignent votre reverse proxy. Cependant, cela signifie confier le trafic \u00e0 un tiers, ce qui sort un peu du cadre purement auto-h\u00e9berg\u00e9.</p> </li> <li> <p>Headers et CSP  : Outre bloquer ce qui est mauvais, on peut ajouter ce qui est bon. Par exemple, ajouter des  headers de s\u00e9curit\u00e9  comme HSTS (Strict-Transport-Security), X-Content-Type-Options, X-Frame-Options, Content-Security-Policy, etc., pour r\u00e9duire la surface aux attaques client. Traefik a un middleware  secureHeaders(configurable via fichier dynamique) qui fournit un ensemble de ces headers recommand\u00e9s  . Nginx permet de les ajouter via  add_header. Dans un homelab, c\u2019est un bon exercice de configurer ces en-t\u00eates correctement pour apprendre le hardening web.</p> </li> </ul> <p>En combinant ces mesures de filtrage et de supervision, le homelab peut simuler un environnement  sous surveillance, comme en entreprise, o\u00f9 chaque requ\u00eate est logg\u00e9e, analys\u00e9e, et potentiellement bloqu\u00e9e si suspecte. Cela permet de tester des sc\u00e9narios d\u2019attaque en conditions r\u00e9alistes et de valider l\u2019efficacit\u00e9 des contre-mesures (par exemple, lancer un scan depuis l\u2019ext\u00e9rieur et voir CrowdSec bannir l\u2019IP dans Traefik, etc.).</p>"},{"location":"reseau/reverse-proxy/#fonctionnalites-de-securite-avancees-ldap-oauth2-sso-2fa","title":"Fonctionnalit\u00e9s de s\u00e9curit\u00e9 avanc\u00e9es (LDAP, OAuth2, SSO, 2FA)","text":"<p>Au-del\u00e0 des configurations de base, un homelab de s\u00e9curit\u00e9 peut tirer profit de fonctionnalit\u00e9s avanc\u00e9es offertes par nos outils :</p>"},{"location":"reseau/reverse-proxy/#integration-ldapoauth2-pour-lauthentification-centralisee","title":"Int\u00e9gration LDAP/OAuth2 pour l\u2019authentification centralis\u00e9e","text":"<p>Dans un contexte professionnel, l\u2019authentification des utilisateurs se fait souvent via un  annuaire central  (LDAP/Active Directory) ou un  f\u00e9d\u00e9ration d\u2019identit\u00e9  (SSO OAuth2/OIDC, SAML\u2026). Il est int\u00e9ressant de reproduire cela en homelab. Ni Nginx Proxy Manager ni Traefik n\u2019int\u00e8grent \u00e0 eux seuls un serveur LDAP ou OAuth2, mais  Authelia  peut servir d\u2019interface :</p> <ul> <li> <p>Authelia + LDAP  : Authelia peut \u00eatre configur\u00e9 pour utiliser un  backend LDAP/AD  comme source des utilisateurs et groupes. Par exemple, on peut d\u00e9ployer une petite instance OpenLDAP ou FreeIPA dans le homelab, y g\u00e9rer quelques comptes, et configurer Authelia en  authentication_backend: ldap  (plut\u00f4t que  file). Ainsi, lorsqu\u2019un utilisateur se connecte via Authelia, ses identifiants sont v\u00e9rifi\u00e9s aupr\u00e8s de l\u2019annuaire LDAP. Cela permet de centraliser l\u2019authentification de tout le homelab sur un r\u00e9f\u00e9rentiel unique (comme ce serait le cas avec un Active Directory en entreprise). Authelia supporte les op\u00e9rations LDAP usuelles et m\u00eame la r\u00e9initialisation de mot de passe LDAP via un lien mail  . De plus, en se basant sur les  groups  LDAP, on peut d\u00e9finir des politiques d\u2019acc\u00e8s dans Authelia (par exemple, seul le groupe \u201cadmins\u201d a acc\u00e8s \u00e0 l\u2019interface de gestion proxmox). Cette int\u00e9gration est un excellent exercice pour un homelab car elle touche aux notions d\u2019annuaire, de sch\u00e9ma utilisateur et de synchronisation.</p> </li> <li> <p>SSO OAuth2/OIDC  : Authelia se positionne comme un  fournisseur OpenID Connect 1.0 certifi\u00e9  . Cela signifie qu\u2019il parle le protocole moderne d\u2019authentification (OIDC est une surcouche d\u2019OAuth2) utilis\u00e9 par de nombreuses applications web. On peut donc, d\u2019une part, int\u00e9grer des applications tierces qui supportent l\u2019OIDC pour d\u00e9l\u00e9guer leur login \u00e0 Authelia. D\u2019autre part, Authelia peut lui-m\u00eame consommer des identit\u00e9s d\u2019un fournisseur externe OAuth2 ? \u2013 Ce cas d\u2019usage est moins courant car Authelia est plut\u00f4t fait pour \u00eatre  le  fournisseur. Si l\u2019on souhaitait \u201cLogin with Google\u201d par exemple sur nos services, on utiliserait plut\u00f4t un outil comme  OAuth2 Proxy  ou  Authentik  qui ferait office d\u2019interm\u00e9diaire avec Google. Nginx et Traefik peuvent s\u2019int\u00e9grer avec OAuth2 Proxy de fa\u00e7on semblable \u00e0 Authelia (via  auth_request  ou forwardAuth).  Authentik  et  Keycloak  sont deux alternatives populaires \u00e0 Authelia pour le SSO avanc\u00e9 : Authentik est open-source (Django) et offre plus de connecteurs (par ex. login Google, SAML, etc.), Keycloak est une solution robuste utilis\u00e9e en entreprise. Cependant, leur mise en \u0153uvre est plus lourde. Dans un homelab cyber, mettre en place Authentik ou Keycloak pour comparer avec Authelia peut \u00eatre instructif, mais Authelia a l\u2019avantage de la l\u00e9g\u00e8ret\u00e9 et de la simplicit\u00e9 pour d\u00e9buter le SSO.</p> </li> <li> <p>OAuth2 access control  : Traefik Enterprise (version payante) int\u00e8gre nativement l\u2019OIDC/OAuth2 et le SSO d\u2019entreprise (avec support JWT, etc.), mais avec Traefik open-source on s\u2019appuie sur les solutions externes cit\u00e9es. Nginx (open-source) peut utiliser des modules Lua ou des modules tiers pour valider des JWT ou interroger un IdP OAuth2, mais cela sort du scope standard de NPM.</p> </li> </ul> <p>En r\u00e9sum\u00e9, l\u2019int\u00e9gration LDAP/OAuth2 dans le homelab se fait via un composant d\u00e9di\u00e9 (Authelia, Keycloak, etc.) coupl\u00e9 au reverse proxy. Cela permet de reproduire une  authentification centralis\u00e9e  comme on en trouve en milieu professionnel, et d\u2019exp\u00e9rimenter avec des protocoles standards (LDAP, OAuth2/OIDC). Pour un ing\u00e9nieur s\u00e9cu, c\u2019est l\u2019occasion de se familiariser avec la gestion des identit\u00e9s, la d\u00e9l\u00e9gation d\u2019authentification, et de comprendre les d\u00e9fis de l\u2019int\u00e9gration SSO.</p>"},{"location":"reseau/reverse-proxy/#protection-contre-les-attaques-par-force-brute","title":"Protection contre les attaques par force brute","text":"<p>Les attaques par  brute-force  (essais r\u00e9p\u00e9t\u00e9s de mots de passe) sont une menace classique d\u00e8s qu\u2019un service est accessible sur Internet. Dans un homelab expos\u00e9, on veillera \u00e0 mettre en place des m\u00e9canismes de protection :</p> <ul> <li> <p>Authelia \u2013 Regulation  : Authelia int\u00e8gre nativement un module de limitation des tentatives de login. On peut configurer des param\u00e8tres comme  max_retries  (nombre de tentatives avant blocage),  find_time  (intervalle de temps de comptabilisation) et  ban_time  (dur\u00e9e du bannissement)  . Par exemple, on pourrait autoriser 5 essais en 2 minutes avant de bloquer l\u2019utilisateur pendant 10 minutes. Ce m\u00e9canisme de  Login Regulation  emp\u00eache un attaquant d\u2019essayer une infinit\u00e9 de mots de passe sur un compte  . Le bannissement est g\u00e9n\u00e9ralement appliqu\u00e9 par identifiant (et potentiellement par IP). Authelia journalise ces \u00e9v\u00e9nements, ce qui permet de d\u00e9tecter une attaque en cours.</p> </li> <li> <p>Fail2Ban  : Pour les services non prot\u00e9g\u00e9s par Authelia (ou m\u00eame en compl\u00e9ment), Fail2Ban reste un alli\u00e9 pr\u00e9cieux. En homelab, on peut configurer Fail2Ban pour surveiller les logs Nginx Proxy Manager. Par exemple, rep\u00e9rer 401 Unauthorized r\u00e9p\u00e9t\u00e9s sur une URL d\u2019auth -&gt; ban de l\u2019IP au niveau iptables. Sur Traefik, on peut envisager de le faire aussi via les logs d\u2019acc\u00e8s (moins trivial car Traefik n\u2019a pas de log \u201cerreur 401\u201d distinct, mais c\u2019est faisable). L\u2019avantage de Fail2Ban est sa simplicit\u00e9 et son efficacit\u00e9 pour bannir au niveau r\u00e9seau, emp\u00eachant l\u2019attaquant d\u2019envoyer la suite des requ\u00eates.</p> </li> <li> <p>Traefik plugins  : Comme mentionn\u00e9 pr\u00e9c\u00e9demment, Traefik dispose d\u2019un plugin  Fail2Ban  officiel qui reproduit ce comportement directement dans le proxy. Il peut suivre les 401 sur un middleware d\u2019authentification par exemple et couper l\u2019acc\u00e8s. Aussi, l\u2019utilisation de  CrowdSec  apporte une dimension communautaire : si une IP est connue pour attaquer d\u2019autres membres de la communaut\u00e9, elle peut \u00eatre pr\u00e9-bannie (syst\u00e8me de blocklist collaborative). On peut configurer le bouncer CrowdSec pour qu\u2019il renvoie directement une page de blocage depuis le proxy si l\u2019IP est bannie, avant m\u00eame d\u2019arriver aux services.</p> </li> <li> <p>Complexit\u00e9 des mots de passe &amp; 2FA  : La meilleure d\u00e9fense anti brute-force reste d\u2019exiger des  mots de passe forts  et id\u00e9alement un  second facteur. Authelia impose par exemple une politique de mot de passe (param\u00e9trable via l\u2019option zxcvbn pour exiger une certaine robustesse du mot de passe)  . Et bien s\u00fbr, avec le 2FA activ\u00e9, un mot de passe compromis ne suffit plus, ce qui d\u00e9courage fortement le brute-force. Dans un homelab, on peut tester diff\u00e9rentes m\u00e9thodes de second facteur : TOTP (Google Authenticator, etc.),  WebAuthn  (cl\u00e9 U2F type YubiKey), ou  Duo push  . Authelia supporte ces m\u00e9thodes multiples \u2013 par exemple WebAuthn permet d\u2019apprendre \u00e0 int\u00e9grer l\u2019authentification par cl\u00e9 physique ou empreinte digitale, ce qui est tr\u00e8s int\u00e9ressant en cybers\u00e9curit\u00e9 moderne.</p> </li> </ul> <p>En conclusion sur la brute-force, combiner un  verrou logiciel  (Authelia ou Fail2Ban qui bloque apr\u00e8s X essais) avec une  authentification forte  (mots de passe solides + second facteur) offre une d\u00e9fense efficace. Un homelab bien configur\u00e9 doit ainsi r\u00e9sister aux bots qui tentent des attaques automatis\u00e9es sur les pages de login. N\u2019oublions pas la surveillance : il est formateur de constater dans les logs ces tentatives et de v\u00e9rifier que les contre-mesures r\u00e9agissent (ex: voir l\u2019IP passer en bannie apr\u00e8s trop d\u2019\u00e9checs).</p>"},{"location":"reseau/reverse-proxy/#authentification-unifiee-et-multi-facteurs-sso-mfa","title":"Authentification unifi\u00e9e et multi-facteurs (SSO &amp; MFA)","text":"<p>Nous avons d\u00e9j\u00e0 \u00e9voqu\u00e9 plusieurs fois le SSO et le MFA, que propose notamment Authelia. Regroupons ici ces notions pour bien comprendre leur apport dans le homelab :</p> <ul> <li> <p>Single Sign-On (SSO)  : Le SSO vise \u00e0 permettre \u00e0 un utilisateur de s\u2019authentifier  une seule fois  pour acc\u00e9der \u00e0 plusieurs applications diff\u00e9rentes, sans avoir \u00e0 re-saisir ses identifiants pour chaque service. Dans notre stack, Authelia r\u00e9alise cela en \u00e9mettant un  cookie de session  apr\u00e8s login, valable pour l\u2019ensemble des sous-domaines prot\u00e9g\u00e9s (on d\u00e9finit un domaine racine commun, par ex.  *.monlab.fr)  . Ainsi, l\u2019utilisateur qui se connecte sur  service1.monlab.fr  via Authelia obtient un cookie de session (sur  .monlab.fr), et lorsqu\u2019il ira sur  service2.monlab.fr, le reverse proxy pr\u00e9sentera ce cookie \u00e0 Authelia qui verra que la session est valide et laissera passer automatiquement  . L\u2019exp\u00e9rience est transparente : une seule page de login, puis navigation fluide entre services. C\u2019est tr\u00e8s confortable pour l\u2019utilisateur et plus s\u00e9curis\u00e9 (on \u00e9vite d\u2019avoir des mots de passe multiples circulant). Pour le mettre en \u0153uvre en homelab, on s\u2019assure que  session.domain  est bien r\u00e9gl\u00e9 dans Authelia (par ex.  monlab.fr) et on prot\u00e8ge tous les services via Authelia. On peut tester le SSO en ouvrant diff\u00e9rents navigateurs ou en invalidant le cookie pour voir comment la session se propage.</p> </li> <li> <p>Multi-Factor Authentication (MFA)  : C\u2019est un pilier de la s\u00e9curit\u00e9 moderne. Authelia permet d\u2019activer le  2FA  (ou m\u00eame 3FA) pour les domaines qu\u2019on veut. Dans la config  access_control, on peut d\u00e9finir  policy: two_factor  pour certaines ressources sensibles  . Au login, apr\u00e8s le mot de passe, Authelia va alors demander le code TOTP (ou une validation via l\u2019appli Duo, ou une authentification WebAuthn/Passkey) avant de valider la session. L\u2019int\u00e9gration de MFA dans un homelab est un excellent moyen de se familiariser avec ces technologies. Par exemple, on peut enregistrer une cl\u00e9 U2F sur Authelia et ainsi utiliser une cl\u00e9 physique pour se logguer \u2013 ce qui ajoute une couche \u201cquelque chose que l\u2019on poss\u00e8de\u201d en plus du mot de passe. Authelia supporte \u00e9galement les  Passkeys  (technologie plus r\u00e9cente visant \u00e0 remplacer les mots de passe)  , ce qui permet d\u2019exp\u00e9rimenter les futures tendances de l\u2019authentification passwordless.</p> </li> <li> <p>Granularit\u00e9 et exceptions  : On peut vouloir SSO + MFA pour la plupart des services, mais peut-\u00eatre pas pour tous. Authelia offre une granularit\u00e9 par r\u00e8gle : on peut mettre certaines applications en  one_factor  (juste mot de passe) et d\u2019autres en  two_factor  . On peut m\u00eame combiner avec des conditions r\u00e9seau \u2013 par exemple, exiger 2FA seulement quand on est en dehors du LAN, mais en one_factor sur le LAN (via la directive  networks  dans les r\u00e8gles). Cela permet de reproduire une politique de confiance conditionnelle (un peu comme du MFA contextuel en entreprise). C\u2019est \u00e0 l\u2019appr\u00e9ciation de chacun en homelab ; du point de vue s\u00e9curit\u00e9 pure, il est recommand\u00e9 d\u2019activer le MFA pour les acc\u00e8s externes au minimum.</p> </li> </ul> <p>En mettant en place le SSO et MFA dans le homelab, on se rapproche des standards d\u2019infrastructure s\u00e9curis\u00e9e d\u2019une entreprise. C\u2019est tr\u00e8s formateur pour un ing\u00e9nieur s\u00e9curit\u00e9 de comprendre les m\u00e9canismes sous-jacents : cookies de session, jetons JWT \u00e9ventuellement (Authelia peut \u00e9mettre des JWT OIDC), protocole WebAuthn, algorithme TOTP, etc. De plus, cela am\u00e9liore nettement la  s\u00e9curit\u00e9  de votre homelab r\u00e9el, ce qui n\u2019est pas n\u00e9gligeable si vous exposez des services personnels.</p>"},{"location":"reseau/reverse-proxy/#conclusion","title":"Conclusion","text":"<p>Mettre en \u0153uvre un reverse proxy dans un homelab est quasiment un passage oblig\u00e9 pour qui veut exposer des services de mani\u00e8re ma\u00eetris\u00e9e.  Nginx Proxy Manager  et  Traefik  sont deux excellentes options qui r\u00e9pondent \u00e0 des profils diff\u00e9rents : NPM offre la simplicit\u00e9 d\u2019une interface graphique et la robustesse de Nginx \u2013 id\u00e9ale pour d\u00e9buter ou pour un lab \u00e0 configuration ponctuelle \u2013, tandis que Traefik apporte l\u2019automatisation et la souplesse pour un lab tr\u00e8s containeris\u00e9 ou \u00e9volutif, avec des fonctionnalit\u00e9s avanc\u00e9es int\u00e9gr\u00e9es (d\u00e9couverte, middlewares). Dans un contexte de cybers\u00e9curit\u00e9, Traefik se montre tr\u00e8s adapt\u00e9 gr\u00e2ce \u00e0 ses plugins de s\u00e9curit\u00e9 et son int\u00e9gration document\u00e9e avec des outils comme Authelia  , mais NPM peut tout \u00e0 fait \u00eatre utilis\u00e9 de mani\u00e8re s\u00e9curis\u00e9e \u00e9galement (en y ajoutant manuellement les m\u00eames composants).</p> <p>L\u2019outil  Authelia, en particulier, s\u2019av\u00e8re un compl\u00e9ment pr\u00e9cieux pour un homelab s\u00e9curis\u00e9. En d\u00e9ployant Authelia aux c\u00f4t\u00e9s du reverse proxy, on dote son lab d\u2019un v\u00e9ritable  syst\u00e8me d\u2019authentification unifi\u00e9e \u00e0 double facteur, comparable \u00e0 ce qu\u2019on trouve en production dans les entreprises, le tout avec des solutions open-source. Ceci transforme le homelab en terrain d\u2019entra\u00eenement pour impl\u00e9menter et tester des politiques de s\u00e9curit\u00e9 (SSO, MFA, restrictions granulaires) sur ses propres services auto-h\u00e9berg\u00e9s.</p> <p>En fin de compte, le choix pr\u00e9cis de la stack (Nginx vs Traefik, avec ou sans Authelia) d\u00e9pendra de vos objectifs d\u2019apprentissage et de vos contraintes. Un  ing\u00e9nieur en cybers\u00e9curit\u00e9  apprendra beaucoup en exp\u00e9rimentant les deux approches : commencer par Nginx Proxy Manager pour appr\u00e9hender les concepts de base (reverse proxy, certificats, DNS, redirections), puis monter en puissance avec Traefik pour l\u2019aspect \u201cInfra as Code\u201d et int\u00e9gration continue, tout en ajoutant Authelia pour la couche IAM (Identity and Access Management). Le homelab ainsi constitu\u00e9 permettra de simuler bon nombre de sc\u00e9narios de s\u00e9curit\u00e9 (attaques web, tests d\u2019intrusion depuis l\u2019ext\u00e9rieur, mise en place de d\u00e9fenses actives) dans un environnement contr\u00f4l\u00e9 et modulable.</p> <p>En somme, Nginx Proxy Manager, Traefik et Authelia forment un trio compl\u00e9mentaire pour construire un homelab \u00e0 la fois  fonctionnel  (multi-services expos\u00e9s proprement) et  s\u00e9curis\u00e9  (contr\u00f4le fin des acc\u00e8s, surveillance, r\u00e9silience). \u00c0 vous de jouer pour les configurer selon vos besoins, et n\u2019oubliez pas : la documentation officielle et la communaut\u00e9 sont d\u2019une grande aide pour approfondir chaque composant et r\u00e9soudre les \u00e9ventuels \u00e9cueils techniques rencontr\u00e9s en chemin.</p>"},{"location":"reseau/torrent-vpn/","title":"VPN et Torrent : AirVPN vs Gluetun, Int\u00e9gration &amp; Isolement r\u00e9seau","text":""},{"location":"reseau/torrent-vpn/#contexte-et-enjeux-de-la-protection-vpn-pour-le-torrent","title":"Contexte et enjeux de la protection VPN pour le torrent","text":"<p>T\u00e9l\u00e9charger via BitTorrent sur un homelab  self-hosted  pr\u00e9sente des risques en termes de confidentialit\u00e9 et de s\u00e9curit\u00e9. Un VPN de qualit\u00e9 permet de chiffrer le trafic P2P et de masquer l\u2019adresse IP publique r\u00e9elle, \u00e9vitant ainsi d\u2019exposer son identit\u00e9 aux pairs du torrent et aux tiers malveillants. De plus, un bon VPN aide \u00e0 contourner d\u2019\u00e9ventuelles restrictions de FAI sur le trafic P2P. Cependant, tous les services VPN ne se valent pas pour cet usage : il faut examiner la  performance(vitesse, stabilit\u00e9), la  s\u00e9curit\u00e9  (chiffrement, politique de logs), la  compatibilit\u00e9 P2P  (autorisation du torrent, support du port forwarding) et les moyens d\u2019int\u00e9gration technique (clients, conteneurs, etc.)  . Nous comparons ci-dessous AirVPN, Gluetun et d\u2019autres services similaires, puis abordons l\u2019int\u00e9gration avec des clients BitTorrent et les bonnes pratiques d\u2019isolement r\u00e9seau (VLAN, pare-feu), sans oublier la pr\u00e9vention des fuites DNS, l\u2019usage d\u2019un  kill switch  et la question des logs.</p>"},{"location":"reseau/torrent-vpn/#comparatif-airvpn-vs-gluetun-et-autres-vpn-adaptes-au-torrent","title":"Comparatif : AirVPN vs Gluetun et autres VPN adapt\u00e9s au torrent","text":"<p>AirVPN  est un fournisseur VPN r\u00e9put\u00e9 dans la communaut\u00e9 pour son s\u00e9rieux technique et son respect de la vie priv\u00e9e. Bas\u00e9 en Italie, AirVPN applique une politique stricte de  no-log, ne conservant  aucune donn\u00e9e  permettant de relier une IP et un horaire \u00e0 un utilisateur  . Il autorise  BitTorrent sur tous ses serveurs  sans discrimination et fournit un service de  port forwarding (transmission de port entrant)  indispensable aux utilisateurs torrent  . En pratique, AirVPN permet \u00e0 chaque client d\u2019ouvrir plusieurs ports via son interface (par exemple pour am\u00e9liorer le  seeding). C\u00f4t\u00e9 s\u00e9curit\u00e9, son application  Eddie  (libre et multiplateforme) inclut la fonctionnalit\u00e9  Network Lock, un  kill switch  qui bloque tout trafic hors VPN en cas de d\u00e9connexion et pr\u00e9vient les fuites IPv6/DNS ou WebRTC  . AirVPN supporte OpenVPN (chiffrements AES-256-GCM et CHACHA20-POLY1305) et WireGuard pour un meilleur d\u00e9bit  . En termes de  performance, AirVPN offre des d\u00e9bits corrects mais son r\u00e9seau, plus restreint que certains concurrents, peut \u00eatre l\u00e9g\u00e8rement moins rapide que les poids lourds du march\u00e9 sur des tests globaux. Cependant, avec WireGuard et un serveur bien choisi, de nombreux utilisateurs parviennent \u00e0 saturer leur bande passante sans probl\u00e8me dans un usage torrent normal. AirVPN se distingue enfin par un support de la communaut\u00e9 actif (forums techniques) et l\u2019acceptation de nombreux moyens de paiement anonymes (cryptomonnaies comme Monero, etc.)  .</p> <p>Gluetun  n\u2019est pas un fournisseur VPN \u00e0 proprement parler, mais un  client VPN l\u00e9ger en conteneur Docker  qui sert de passerelle pour d\u2019autres applications. Il supporte de nombreux fournisseurs VPN en OpenVPN ou WireGuard (AirVPN, Mullvad, ProtonVPN, PIA, etc. sont pris en charge)  . L\u2019id\u00e9e est qu\u2019au lieu d\u2019utiliser l\u2019application native du VPN, on utilise Gluetun comme point d\u2019acc\u00e8s VPN dans un environnement auto-h\u00e9berg\u00e9.  Performance  : Gluetun ajoute tr\u00e8s peu de surco\u00fbt, car il se base sur OpenVPN/WireGuard en arri\u00e8re-plan. Avec WireGuard (support\u00e9 pour la plupart des grands VPN dans Gluetun), on obtient g\u00e9n\u00e9ralement de meilleurs d\u00e9bits et une utilisation CPU r\u00e9duite par rapport \u00e0 OpenVPN, ce qui est id\u00e9al sur des mat\u00e9riels modestes (NAS, mini-PC)  .  S\u00e9curit\u00e9  : Gluetun int\u00e8gre d\u2019office un  pare-feu interne (kill switch)  ne laissant passer que le trafic n\u00e9cessaire vers les serveurs VPN et \u00e9ventuellement le LAN autoris\u00e9  . Ainsi, en cas de chute du VPN, les conteneurs connect\u00e9s \u00e0 Gluetun n\u2019ont pas d\u2019acc\u00e8s Internet direct, \u00e9vitant les fuites. Gluetun configure \u00e9galement le  DNS sur TLS  (DNS chiffr\u00e9) pour les conteneurs connect\u00e9s, emp\u00eachant les fuites DNS en for\u00e7ant les requ\u00eates DNS \u00e0 passer par le VPN  .  Compatibilit\u00e9 torrent  : Gluetun \u00e9tant compatible avec AirVPN et consorts, on b\u00e9n\u00e9ficie des m\u00eames avantages (ex: port forwarding) selon le fournisseur choisi. Par exemple, si on utilise AirVPN via Gluetun, il suffit de renseigner les ports attribu\u00e9s par AirVPN dans la configuration (variable d\u2019environnement  FIREWALL_VPN_INPUT_PORTS  de Gluetun et configuration du port dans le client torrent) afin d\u2019accepter les connexions entrantes  . Gluetun facilite aussi le  partage de la connexion VPN  entre plusieurs applications : un seul conteneur Gluetun peut prot\u00e9ger plusieurs clients BitTorrent ou autres services (Sonarr, Radarr, etc.) en les joignant au r\u00e9seau Docker de Gluetun  . En somme, Gluetun offre une solution  flexible  et  open source  pour int\u00e9grer un VPN dans un homelab, avec un contr\u00f4le fin (logs locaux minimalistes, param\u00e8tres modulables) \u2013 \u00e0 condition bien s\u00fbr de disposer d\u2019un compte chez un bon fournisseur VPN sous-jacent.</p> <p>Autres services VPN \u00e0 consid\u00e9rer  : plusieurs fournisseurs concurrents d\u2019AirVPN sont appr\u00e9ci\u00e9s des utilisateurs P2P, chacun avec ses atouts et limites. Parmi les plus recommand\u00e9s figurent :</p> <ul> <li> <p>Mullvad  (Su\u00e8de) \u2013 \u00c9norme r\u00e9putation de confidentialit\u00e9 (audits publics, incident o\u00f9 aucun log n\u2019a pu \u00eatre saisi lors d\u2019un mandat  ). Forfait simple \u00e0 5 \u20ac/mois, anonymat possible (compte num\u00e9ro, paiement en liquide envoy\u00e9 par courrier).  Inconv\u00e9nient  en 2023 : Mullvad a supprim\u00e9 le port forwarding  . Cela limite la connectivit\u00e9 entrante pour le torrent (pas id\u00e9al pour le  seeding  intensif ou des usages type serveur). Mullvad reste excellent en s\u00e9curit\u00e9 et a de bons d\u00e9bits en WireGuard, mais sans ouverture de ports, un torrent sera en mode passif (connectivit\u00e9 un peu r\u00e9duite). \u00c0 prendre en compte selon vos besoins.</p> </li> <li> <p>ProtonVPN  (Suisse) \u2013 Service moderne orient\u00e9 confidentialit\u00e9 (code client open source, audits), b\u00e9n\u00e9ficiant d\u2019une infrastructure performante. ProtonVPN  autorise le P2P  sur des serveurs d\u00e9di\u00e9s et propose du  port forwarding  (sur les offres payantes  Plus/Visionary)  . Leurs vitesses sont tr\u00e8s \u00e9lev\u00e9es sur les serveurs r\u00e9cents (10 Gbit)  , souvent sup\u00e9rieures \u00e0 Mullvad  . En contrepartie, ProtonVPN est un peu plus cher et son interface est moins technique qu\u2019AirVPN. C\u2019est un bon choix si la vitesse est prioritaire et que l\u2019on veut un \u00e9cosyst\u00e8me (ils offrent aussi mail s\u00e9curis\u00e9, etc.), tout en ayant les ports ouverts pour le torrent.</p> </li> <li> <p>Private Internet Access (PIA)  \u2013 Fournisseur historique (d\u00e9sormais bas\u00e9 aux \u00c9tats-Unis, propri\u00e9t\u00e9 du groupe Kape). PIA propose des tarifs attractifs, un large r\u00e9seau de serveurs et  supporte le port forwarding  sur certains serveurs  . Ses clients int\u00e8grent un kill switch et sont open source. PIA a prouv\u00e9 \u00e0 plusieurs reprises en justice sa politique  no-log. Cependant, son appartenance \u00e0 une entreprise ayant rachet\u00e9 de nombreux VPN (et anciennement associ\u00e9e \u00e0 des adwares) fait que certains utilisateurs  privacy  restent m\u00e9fiants. Niveau torrent, PIA fonctionne bien et autorise P2P sur tous les serveurs ne se trouvant pas dans des pays restrictifs. C\u2019est une option \u00ab grand public \u00bb performante si l\u2019on est \u00e0 l\u2019aise avec l\u2019id\u00e9e de faire confiance \u00e0 sa politique de confidentialit\u00e9.</p> </li> <li> <p>IVPN  (Gibraltar) \u2013 VPN tr\u00e8s \u00e9thique et transparent (membre de l\u2019initiative Privacy Guides), ax\u00e9 sur la minimisation des donn\u00e9es. Toutefois, IVPN est en train d\u2019abandonner le port forwarding  \u00e9galement (d\u00e9cision similaire \u00e0 Mullvad)  . Sans ports ouverts, IVPN est parfait pour la navigation anonyme, mais moins optimis\u00e9 pour torrent (sauf usage purement en t\u00e9l\u00e9chargement sans seeding public). \u00c0 noter qu\u2019IVPN offre une fonctionnalit\u00e9  Multi-hop  et des clients minimalistes orient\u00e9s confidentialit\u00e9 maximale.</p> </li> <li> <p>Windscribe  (Canada) \u2013 Service au positionnement un peu diff\u00e9rent : il propose une version gratuite limit\u00e9e et une version Pro flexible. Windscribe  peut fournir du port forwarding  mais seulement via l\u2019achat d\u2019une IP d\u00e9di\u00e9e (Static IP  dans leurs options) ou l\u2019utilisation de serveurs dits  legacy. L\u2019avantage est qu\u2019il int\u00e8gre un pare-feu/kill switch permanent appel\u00e9  Firewall  c\u00f4t\u00e9 client. Windscribe a une approche un peu moins formelle, mais la communaut\u00e9 tech le consid\u00e8re comme relativement fiable (pas de preuve de no-log publi\u00e9e n\u00e9anmoins). Utile pour ceux qui voudraient un plan tr\u00e8s modulable ou des fonctions comme le proxy int\u00e9gr\u00e9.</p> </li> </ul> <p>(Bien s\u00fbr, d\u2019autres VPN existent \u2013 par exemple NordVPN ou Surfshark offrent de tr\u00e8s bons d\u00e9bits \u2013 mais ils n\u2019autorisent pas le port forwarding et sont donc moins int\u00e9ressants pour le torrent. Des services sp\u00e9cialis\u00e9s comme TorGuard ou Hide.me proposent aussi le port forwarding et ciblent les power users, mais ils sont moins grand public. Dans ce comparatif, on se concentre sur les solutions \u00e9prouv\u00e9es par la communaut\u00e9 auto-h\u00e9bergement et confidentialit\u00e9.)</p>"},{"location":"reseau/torrent-vpn/#integration-des-clients-bittorrent-avec-gluetun","title":"Int\u00e9gration des clients BitTorrent avec Gluetun","text":"<p>Une des forces de Gluetun est de simplifier l\u2019int\u00e9gration des applications de t\u00e9l\u00e9chargement en conteneur avec le VPN. Le principe est de faire tourner le client BitTorrent (par ex.  qBittorrent,  Transmission  ou autres) dans un conteneur Docker s\u00e9par\u00e9, mais  connect\u00e9 au r\u00e9seau de Gluetun  plut\u00f4t qu\u2019au r\u00e9seau par d\u00e9faut. Gr\u00e2ce \u00e0 Docker Compose, on peut d\u00e9finir que le service qBittorrent utilise  network_mode: \"service:gluetun\"  afin que  tout son trafic passe par le conteneur VPN  . Dans ce sc\u00e9nario, qBittorrent n\u2019a  aucune connectivit\u00e9 directe  hors VPN : il obtient une IP locale virtuelle du conteneur Gluetun et sort uniquement \u00e0 travers le tunnel chiffr\u00e9. C\u2019est id\u00e9al pour garantir qu\u2019aucun t\u00e9l\u00e9chargement ne fuite hors VPN.</p> <p>Concr\u00e8tement, il faut d\u2019abord lancer Gluetun avec les bonnes variables (identifiants VPN, choix du serveur, activation \u00e9ventuelle du WireGuard, etc. comme vu pr\u00e9c\u00e9demment). Ensuite, on lance le conteneur du client torrent en d\u00e9pendance de Gluetun. Par exemple, voici un extrait de configuration Docker Compose typique :</p> <pre><code>services:\n  gluetun:\n    image: qmcgaw/gluetun\n    cap_add:\n      - NET_ADMIN\n    devices:\n      - /dev/net/tun:/dev/net/tun\n    environment:\n      - VPN_SERVICE_PROVIDER=AIRVPN\n      - VPN_TYPE=wireguard\n      - WG_PRIVATE_KEY=&lt;cl\u00e9 priv\u00e9e WireGuard&gt;\n      - SERVER_COUNTRIES=FR # ex: choisir un pays/serveur\n      - FIREWALL_VPN_INPUT_PORTS=51820 # ex: port entrant attribu\u00e9 par le VPN\n      - FIREWALL_OUTBOUND_SUBNETS=192.168.0.0/24 # acc\u00e8s LAN (\u00e0 adapter ou vider pour isoler)\n    # ... autres variables (PUID, PGID, TZ, etc.) ...\n    restart: unless-stopped\n\n  qbittorrent:\n    image: linuxserver/qbittorrent\n    network_mode: \"service:gluetun\"  # utilise le r\u00e9seau du VPN\n    depends_on:\n      - gluetun\n    ports:\n      - \"8080:8080\"  # port web UI, expos\u00e9 via VPN\n    environment:\n      - WEBUI_PORT=8080\n      # ... PUID/PGID ...\n    volumes:\n      - /data/torrents:/downloads  # stockage des torrents\n    restart: unless-stopped\n</code></pre> <p>Dans cet exemple, qBittorrent utilisera l\u2019interface r\u00e9seau de Gluetun (tun0) et son adresse IP VPN. On peut acc\u00e9der \u00e0 son interface Web via le port 8080 redirig\u00e9, et ce trafic passera par le VPN. Si le VPN tombe, le port ne r\u00e9pondra plus (kill switch de Gluetun actif).  Int\u00e9gration avec port forwarding  : si votre VPN (ex: AirVPN, PIA, ProtonVPN) vous fournit un port entrant, il faut le configurer c\u00f4t\u00e9 VPN/routeur  et  dans le client torrent. Avec Gluetun, on utilise  FIREWALL_VPN_INPUT_PORTS  pour ouvrir le port dans son pare-feu interne  , puis dans qBittorrent on fixe ce m\u00eame port comme port d\u2019\u00e9coute. Ainsi, le trafic entrant depuis le serveur VPN sera transmis au client torrent  . Plusieurs guides et scripts existent pour automatiser cette synchronisation (par ex. mise \u00e0 jour du port de qBittorrent via l\u2019API de Gluetun sur Unraid  ), mais manuellement cela fonctionne bien une fois le port configur\u00e9.</p> <p>Clients torrent compatibles  : qBittorrent est tr\u00e8s r\u00e9pandu et se marie bien avec Gluetun. Transmission fonctionne \u00e9galement en conteneur, de m\u00eame que Deluge ou d\u2019autres \u2013 il suffit de les mettre sur le m\u00eame  service network  que Gluetun. \u00c0 noter que certains conteneurs \u201ctout-en-un\u201d existent (ex: l\u2019image Docker  haugene/transmission-openvpn  qui combine un client torrent et un client OpenVPN). Cependant, l\u2019approche modulaire avec Gluetun + qBittorrent est plus flexible : on peut y ajouter d\u2019autres applications (Jackett, Sonarr, Radarr\u2026) en les faisant passer par le m\u00eame VPN. Il suffit de connecter ces conteneurs au r\u00e9seau de Gluetun (option  network_mode: service:gluetun  ou via un r\u00e9seau Docker partag\u00e9)  . Cela mutualise la connexion VPN de fa\u00e7on propre.</p> <p>Enfin, pour une s\u00e9curit\u00e9 renforc\u00e9e, il est possible de  lier le client BitTorrent \u00e0 l\u2019interface VPN  m\u00eame en dehors de Docker. Par exemple, si l\u2019on ex\u00e9cute qBittorrent sur l\u2019h\u00f4te directement, on peut sp\u00e9cifier dans ses options avanc\u00e9es de n\u2019\u00e9couter que sur l\u2019interface  tun0. Ainsi, s\u2019il n\u2019y a pas de VPN actif, qBittorrent ne pourra pas se connecter du tout. Cette pr\u00e9caution s\u2019ajoute au kill switch du VPN pour \u00e9viter toute fuite accidentelle si un jour le client VPN \u00e9tait d\u00e9sactiv\u00e9 involontairement.</p>"},{"location":"reseau/torrent-vpn/#schema-disolement-reseau-vlan-et-regles-de-pare-feu","title":"Sch\u00e9ma d\u2019isolement r\u00e9seau : VLAN et r\u00e8gles de pare-feu","text":"<p>Pour un ing\u00e9nieur en s\u00e9curit\u00e9, il est conseill\u00e9 d\u2019isoler le trafic torrent du reste du r\u00e9seau local. L\u2019id\u00e9e g\u00e9n\u00e9rale est de cr\u00e9er un sous-r\u00e9seau d\u00e9di\u00e9 (par exemple un VLAN distinct) pour la machine ou le conteneur qui t\u00e9l\u00e9charge, et d\u2019appliquer des r\u00e8gles de pare-feu strictes entre ce VLAN et le LAN principal.</p> <ul> <li> <p>VLAN d\u00e9di\u00e9 aux t\u00e9l\u00e9chargements  : On peut configurer un VLAN (par exemple VLAN 20) sur le routeur/commutateur, auquel sera connect\u00e9 le serveur ou la VM/conteneur du client torrent. Ce VLAN n\u2019aura acc\u00e8s qu\u2019\u00e0 Internet (de pr\u00e9f\u00e9rence, uniquement via le VPN). Les autres appareils du LAN r\u00e9sident sur VLAN 1 (par exemple) et n\u2019ont pas de route vers VLAN 20. Ainsi, m\u00eame si le client torrent est compromis, il ne pourra pas scanner ou atteindre les partages sensibles du LAN  .</p> </li> <li> <p>R\u00e8gles de pare-feu inter-VLAN  : Sur le routeur ou firewall, on met en place une r\u00e8gle bloquant  toute connexion initi\u00e9e depuis le VLAN torrent vers le LAN principal. Seules les connexions n\u00e9cessaires vers Internet sont autoris\u00e9es. Par exemple, on autorisera VLAN20 -&gt; Internet  UNIQUEMENT  vers les adresses/IP des serveurs VPN et en passant par les ports du protocole VPN (UDP 1194/443 si OpenVPN, UDP 51820 si WireGuard, etc.). On peut \u00e9galement autoriser le trafic DNS du VLAN torrent, soit vers le r\u00e9solveur VPN de Gluetun (DNS sur TLS), soit vers un DNS local selon le cas, mais g\u00e9n\u00e9ralement il vaut mieux que ces requ\u00eates passent dans le tunnel chiffr\u00e9. Toutes les autres tentatives (VLAN torrent vers 192.168.0.0/24, etc.) doivent \u00eatre bloqu\u00e9es par d\u00e9faut  . Inversement, on peut \u00e9ventuellement autoriser depuis le LAN principal  l\u2019acc\u00e8s entrant  \u00e0 l\u2019interface web du client torrent ou au partage de fichiers du serveur de t\u00e9l\u00e9chargement, si l\u2019admin souhaite y acc\u00e9der depuis son PC. Ces acc\u00e8s sp\u00e9cifiques doivent \u00eatre finement filtr\u00e9s (par exemple, autoriser seulement l\u2019IP de l\u2019admin du LAN vers l\u2019IP du torrent box sur le port 8080).</p> </li> <li> <p>Exemple d\u2019architecture  : imaginez un NAS ou un mini-PC faisant office de  seedbox  sur VLAN 20. Il se connecte au VPN (via Gluetun) et t\u00e9l\u00e9charge des torrents. Le routeur/pfSense ne laisse passer que le trafic chiffr\u00e9 VPN entre ce NAS et le WAN, tout autre trafic est bloqu\u00e9. Le reste du r\u00e9seau (VLAN 1) ignore compl\u00e8tement VLAN 20 (pas de communication possible). D\u00e8s lors, les t\u00e9l\u00e9chargements ne peuvent pas r\u00e9v\u00e9ler l\u2019adresse IP du foyer (ils montrent l\u2019IP VPN) et le NAS torrent ne peut pas joindre les appareils sensibles. Ce  compartimentage  renforce la s\u00e9curit\u00e9 globale du homelab.</p> </li> </ul> <p>(\u00c0 d\u00e9faut de VLAN, on peut obtenir un r\u00e9sultat similaire en pla\u00e7ant le client torrent sur un sous-r\u00e9seau diff\u00e9rent avec une interface s\u00e9par\u00e9e ou en le connectant directement derri\u00e8re un second routeur. L\u2019important est la segmentation : r\u00e9duire au minimum les passerelles entre l\u2019environnement torrent et le LAN principal. M\u00eame en conteneur local, pensez \u00e0 d\u00e9sactiver l\u2019acc\u00e8s au r\u00e9seau local dans Gluetun en ne renseignant pas FIREWALL_OUTBOUND_SUBNETS (ou en le limitant strictement) .)</p>"},{"location":"reseau/torrent-vpn/#prevention-des-fuites-dns-kill-switch-et-gestion-des-logs-pour-lanonymat","title":"Pr\u00e9vention des fuites DNS, kill switch et gestion des logs pour l\u2019anonymat","text":"<p>Un bon VPN pour le torrent doit absolument emp\u00eacher les  fuites DNS  et inclure un  kill switch. Avec AirVPN, l\u2019option  Network Lock  veille \u00e0 ce qu\u2019aucune donn\u00e9e (y compris les requ\u00eates DNS) ne sorte hors du tunnel en cas de coupure  . De m\u00eame, Gluetun assure ces fonctions automatiquement : son pare-feu int\u00e9gr\u00e9 bloque tout trafic non VPN et utilise par d\u00e9faut un DNS chiffr\u00e9 (modifiable) pour r\u00e9soudre les noms de domaine  . Il est recommand\u00e9 de  d\u00e9sactiver IPv6  sur l\u2019interface torrent ou dans le VPN si votre configuration ne l\u2019utilise pas, afin d\u2019\u00e9viter d\u2019\u00e9ventuelles fuites IPv6 si le fournisseur VPN ne g\u00e8re pas bien le dual-stack. La plupart des bons VPN (AirVPN, Mullvad, ProtonVPN\u2026) supportent IPv6 et traitent ce cas proprement (AirVPN fournit m\u00eame de l\u2019IPv6 aux clients pour \u00e9viter tout leak  ). V\u00e9rifiez apr\u00e8s mise en place en utilisant des outils comme ipleak.net ou doileak.com pour confirmer qu\u2019aucune requ\u00eate DNS ne part vers votre FAI et que l\u2019IP visible correspond bien au VPN.</p> <p>Concernant les  journaux (logs) et l\u2019anonymat  : id\u00e9alement, votre fournisseur VPN ne doit pas conserver de logs d\u2019activit\u00e9. AirVPN, par exemple, n\u2019enregistre aucune donn\u00e9e de connexion hormis un compteur anonyme de sessions simultan\u00e9es  . Mullvad et ProtonVPN ont \u00e9galement des politiques strictes (Mullvad a d\u00e9montr\u00e9 qu\u2019aucune info exploitable n\u2019\u00e9tait stock\u00e9e suite \u00e0 une perquisition  ). Pour l\u2019utilisateur, il est aussi judicieux de  minimiser les traces  : \u00e9vitez de cr\u00e9er un compte VPN avec votre email personnel; pr\u00e9f\u00e9rez des emails alias ou anonymes. Payez avec des m\u00e9thodes discr\u00e8tes (cryptomonnaie, esp\u00e8ces, bons cadeaux) si vous voulez pousser l\u2019anonymat \u00e0 fond, afin que votre identit\u00e9 civile ne soit pas li\u00e9e au compte VPN.</p> <p>Du c\u00f4t\u00e9 du client BitTorrent, sachez que les torrents publics peuvent exposer l\u2019IP VPN dans les  swarm. Cela n\u2019est pas probl\u00e9matique (c\u2019est le but, et elle n\u2019est pas directement reli\u00e9e \u00e0 vous),  mais ne t\u00e9l\u00e9chargez pas sans VPN  m\u00eame bri\u00e8vement, sinon votre IP r\u00e9elle pourrait se retrouver dans la liste des pairs partag\u00e9e. On veillera par ailleurs \u00e0 configurer le client torrent pour qu\u2019il ne divulgue pas d\u2019infos inutiles : par exemple, d\u00e9sactiver le  tracking  DHT/PEX si cela n\u2019est pas n\u00e9cessaire, \u00e9viter d\u2019utiliser son vrai nom d\u2019utilisateur Windows dans les \u00e9changes SMB vers le NAS, etc. Ces aspects restent mineurs compar\u00e9s aux protections du VPN, mais font partie d\u2019une hygi\u00e8ne globale.</p> <p>Enfin, on peut se demander si conserver des  logs en local  pose probl\u00e8me. Les journaux de Gluetun ou du client torrent (par ex. historique des t\u00e9l\u00e9chargements) sont stock\u00e9s sur votre serveur. En cas de compromission du serveur ou de saisie physique, ces donn\u00e9es pourraient r\u00e9v\u00e9ler ce que vous avez t\u00e9l\u00e9charg\u00e9. Si c\u2019est une pr\u00e9occupation, vous pouvez configurer le client torrent pour qu\u2019il n\u2019enregistre pas l\u2019historique des t\u00e2ches une fois termin\u00e9es, ou monter le dossier de config en  RAM  pour qu\u2019il s\u2019efface \u00e0 chaque red\u00e9marrage. Certains vont jusqu\u2019\u00e0 faire tourner le client dans une VM chiffr\u00e9e ou sur un disque chiffr\u00e9, mais pour un usage homelab classique, ce niveau est souvent excessif. L\u2019essentiel est surtout  c\u00f4t\u00e9 VPN: assurez-vous de choisir un fournisseur de confiance qui ne logge rien d\u2019identifiant et qui offre les fonctions de s\u00e9curit\u00e9 (kill switch, DNS s\u00e9curis\u00e9, ports) adapt\u00e9es au torrent  . Avec AirVPN via Gluetun, par exemple, vous cumulez les avantages : pas de logs c\u00f4t\u00e9 VPN, trafic cloisonn\u00e9 et chiffr\u00e9, fuites bloqu\u00e9es, et ports configurables pour rester efficace en P2P.</p> <p>En r\u00e9sum\u00e9, AirVPN et Gluetun forment une combinaison puissante pour du torrenting anonyme et performant dans un homelab. AirVPN apporte un r\u00e9seau robuste et respectueux de la vie priv\u00e9e, tandis que Gluetun facilite son utilisation dans un environnement Docker, avec isolation et contr\u00f4les pr\u00e9cis. D\u2019autres VPN comme ProtonVPN ou Mullvad peuvent \u00eatre utilis\u00e9s via Gluetun selon vos priorit\u00e9s (vitesse, port forwarding, tarif), mais il faudra tenir compte des r\u00e9cents changements (abandon du port forwarding chez certains). Quelle que soit la solution retenue, n\u2019oubliez pas de segmenter votre r\u00e9seau pour contenir les risques, et de tester votre configuration (adresse IP visible, \u00e9tanch\u00e9it\u00e9 DNS/IP) avant de lancer vos t\u00e9l\u00e9chargements. De cette fa\u00e7on, vous profiterez du contenu via BitTorrent en toute tranquillit\u00e9, sans mettre en danger votre r\u00e9seau personnel ni votre anonymat en ligne</p>"},{"location":"reseau/vpn-remote-access/","title":"Comparatif : Twingate vs WireGuard vs ZeroTier pour l\u2019acc\u00e8s VPN distant","text":""},{"location":"reseau/vpn-remote-access/#presentation-generale","title":"Pr\u00e9sentation g\u00e9n\u00e9rale","text":"<p>Twingate :  Twingate est une solution d\u2019acc\u00e8s r\u00e9seau \u201cZero Trust\u201d visant \u00e0 remplacer les VPN traditionnels. Au lieu d\u2019ouvrir un acc\u00e8s complet \u00e0 un r\u00e9seau, Twingate segmente l\u2019acc\u00e8s au niveau des  services  individuels. Par conception, tout est  ferm\u00e9 par d\u00e9faut  et l\u2019utilisateur n\u2019obtient que les acc\u00e8s sp\u00e9cifiques qui lui sont accord\u00e9s (principe du moindre privil\u00e8ge)  . La plateforme Twingate est g\u00e9r\u00e9e via le cloud : on d\u00e9ploie des  Connecteurs  dans le r\u00e9seau priv\u00e9 (par ex. sur un serveur ou NAS) et les utilisateurs installent un client Twingate sur leurs appareils. L\u2019authentification s\u2019int\u00e8gre g\u00e9n\u00e9ralement avec un fournisseur d\u2019identit\u00e9 (SSO/LDAP, etc.), et chaque tentative d\u2019acc\u00e8s est v\u00e9rifi\u00e9e (authentification  etautorisation) avant d\u2019\u00eatre autoris\u00e9e  . L\u2019architecture est con\u00e7ue de sorte qu\u2019aucun composant unique ne puisse \u00e0 lui seul autoriser du trafic : il faut toujours au moins deux validations (par ex. le contr\u00f4leur cloud + le connecteur) pour qu\u2019un flux passe, ajoutant ainsi une couche de s\u00e9curit\u00e9  . Twingate \u00e9tablit des tunnels chiffr\u00e9s (via TLS 1.2) entre le client de l\u2019utilisateur et le connecteur, en empruntant des connexions  sortantes  (aucun port entrant n\u2019est ouvert sur le r\u00e9seau priv\u00e9). Il en r\u00e9sulte un acc\u00e8s distant tr\u00e8s discret (invisible aux scans externes) et ma\u00eetris\u00e9, ne donnant acc\u00e8s qu\u2019aux ressources d\u00e9finies (applications web, bases de donn\u00e9es, SSH, etc.) plut\u00f4t qu\u2019\u00e0 tout le LAN. En r\u00e9sum\u00e9, Twingate est un  service cloud  (non self-hosted) qui offre une exp\u00e9rience utilisateur simple (client \u201ctoujours actif\u201d s\u2019authentifiant via SSO) et une administration centralis\u00e9e (console web pour d\u00e9finir les ressources, droits, politiques MFA, etc.).</p> <p>WireGuard :  WireGuard est un protocole VPN moderne, open-source, con\u00e7u pour \u00eatre  simple, rapide et s\u00e9curis\u00e9. Il s\u2019agit d\u2019un logiciel que l\u2019on peut auto-h\u00e9berger sur un serveur (Linux, Windows, routeur, etc.) afin de cr\u00e9er un tunnel VPN chiffr\u00e9 de niveau IP entre le client et le serveur. Son code source extr\u00eamement minimaliste (seulement quelques milliers de lignes) r\u00e9duit la surface d\u2019attaque et facilite l\u2019audit de s\u00e9curit\u00e9  . WireGuard utilise des algorithmes cryptographiques de pointe (Curve25519, ChaCha20, Poly1305\u2026) garantissant la confidentialit\u00e9 et l\u2019int\u00e9grit\u00e9 des donn\u00e9es  . Il est support\u00e9 nativement par de nombreux OS (int\u00e9gr\u00e9 au noyau Linux, disponible sur Windows, macOS, Android, iOS, etc.) ce qui lui conf\u00e8re une excellente  performance  et compatibilit\u00e9 multiplateforme  . En pratique, WireGuard fonctionne en attribuant \u00e0 chaque pair une cl\u00e9 publique et une adresse IP virtuelle ; les pairs autoris\u00e9s sont configur\u00e9s statiquement (\u00e9change de cl\u00e9s pr\u00e9-partag\u00e9es) et le serveur \u00e9coute sur un port UDP fixe. Compar\u00e9 aux solutions classiques (OpenVPN, IPsec), WireGuard est r\u00e9put\u00e9 bien plus simple \u00e0 configurer et administrer. Cependant, il ne g\u00e8re pas nativement les notions d\u2019utilisateurs ou d\u2019annuaires : l\u2019authentification se fait uniquement par les cl\u00e9s. Une fois connect\u00e9, le client a g\u00e9n\u00e9ralement acc\u00e8s \u00e0 tout le r\u00e9seau priv\u00e9 rout\u00e9 par le serveur (sauf \u00e0 segmenter manuellement via des r\u00e8gles firewall ou en d\u00e9ployant plusieurs serveurs). WireGuard excelle par sa l\u00e9g\u00e8ret\u00e9 et son efficacit\u00e9, mais n\u00e9cessite de  l\u2019auto-h\u00e9bergement  et souvent des ajustements r\u00e9seau (ouverture de port, DNS dynamique) pour un acc\u00e8s depuis l\u2019ext\u00e9rieur.</p> <p>ZeroTier :  ZeroTier est une solution de  r\u00e9seau virtuel peer-to-peer  qui permet de cr\u00e9er facilement un LAN virtuel chiffr\u00e9 entre des appareils distribu\u00e9s sur Internet. Contrairement \u00e0 un VPN classique point-\u00e0-point, ZeroTier cr\u00e9e un r\u00e9seau overlay  SD-WAN  dans lequel chaque n\u0153ud ex\u00e9cute le client ZeroTier et rejoint un r\u00e9seau virtuel identifi\u00e9 par un ID. Les n\u0153uds obtiennent une adresse virtuelle (par ex. dans un plan d\u2019adressage 10..) et peuvent communiquer entre eux comme s\u2019ils \u00e9taient sur le m\u00eame commutateur Ethernet. ZeroTier op\u00e8re en mode  full mesh  : tous les n\u0153uds \u00e9tablissent des sessions chiffr\u00e9es entre eux, en cherchant \u00e0 atteindre la meilleure connectivit\u00e9 possible. Pour ce faire, le syst\u00e8me s\u2019appuie sur des serveurs racine (plan\u00e8te/lune) g\u00e9r\u00e9s par ZeroTier Inc. qui aident aux d\u00e9couvertes initiales de pairs et relaient le trafic si n\u00e9cessaire  . Toutefois, une fois les pairs d\u00e9couverts, ZeroTier tente d\u2019\u00e9tablir des liens directs en  peer-to-peer  (techniques de hole punching NAT) afin d\u2019optimiser la latence et le d\u00e9bit  . Chaque appareil est s\u00e9curis\u00e9 par une identit\u00e9 propre (adresse ZeroTier de 10 hex, d\u00e9riv\u00e9e de sa cl\u00e9 publique), et seuls les appareils autoris\u00e9s par le contr\u00f4leur du r\u00e9seau peuvent joindre le VPN  . ZeroTier chiffre les communications de bout-en-bout en 256 bits, de sorte que m\u00eame l\u2019infrastructure centrale ne peut pas lire les donn\u00e9es utilisateurs  . L\u2019administration par d\u00e9faut se fait via une interface web (ZeroTier Central) o\u00f9 l\u2019on peut approuver les nouveaux membres et d\u00e9finir des  r\u00e8gles de flux  au besoin (ZeroTier int\u00e8gre un moteur de r\u00e8gles de filtrage pour segmenter le trafic entre membres). ZeroTier est  tr\u00e8s flexible**  : il fonctionne sur presque tous les OS (y compris sur des routeurs, NAS, Android/iOS\u2026) et peut virtualiser aussi bien du niveau 3 (routage IP) que du niveau 2 (pont r\u00e9seau fa\u00e7on VLAN \u00e9tendu). En somme, ZeroTier permet de se cr\u00e9er facilement un r\u00e9seau priv\u00e9 global, sans avoir \u00e0 se soucier des routes et NAT (tout se fait en P2P), avec la possibilit\u00e9 de le self-h\u00e9berger (contr\u00f4leur open source) si on le souhaite.</p>"},{"location":"reseau/vpn-remote-access/#performances-comparees","title":"Performances compar\u00e9es","text":"<p>En termes de performances brutes (d\u00e9bit, latence),  WireGuard  est g\u00e9n\u00e9ralement la r\u00e9f\u00e9rence, car il op\u00e8re dans l\u2019espace noyau et utilise des primitives crypto tr\u00e8s optimis\u00e9es. Dans des tests de tunnel entre serveurs, WireGuard a d\u00e9montr\u00e9 un d\u00e9bit  presque identique \u00e0 la connexion directe  sans VPN  . Par exemple, une mesure montre WireGuard atteignant un d\u00e9bit proche du gigabit, l\u00e0 o\u00f9 des alternatives comme OpenVPN plafonnaient \u00e0 ~20% du m\u00eame d\u00e9bit  . En pratique, sur une machine puissante ou un routeur moderne, WireGuard peut facilement saturer la bande passante disponible. Toutefois, sur de petits mat\u00e9riels (VPS bas de gamme, Raspberry Pi\u2026), le chiffrement peut \u00eatre limit\u00e9 par le CPU single-thread : ainsi, un WireGuard auto-h\u00e9berg\u00e9 sur 1 vCPU a montr\u00e9 ~60% de d\u00e9bit en moins qu\u2019une connexion directe dans un test, faute de ressources processeur suffisantes  .</p> <p>ZeroTier, de son c\u00f4t\u00e9, ajoute une petite couche d\u2019abstraction (son moteur tourne en espace utilisateur et encapsule en UDP). Son d\u00e9bit est donc un peu inf\u00e9rieur \u00e0 WireGuard dans les m\u00eames conditions. D\u2019apr\u00e8s des comparatifs, ZeroTier et Tailscale atteignent environ la moiti\u00e9 du d\u00e9bit de WireGuard sur des liaisons identiques  . Cela reste suffisant pour la plupart des usages courants (streaming HD, transferts mod\u00e9r\u00e9s), mais sur des transferts massifs ou des r\u00e9seaux gigabit, WireGuard garde l\u2019avantage de la vitesse pure. ZeroTier privil\u00e9gie la r\u00e9silience : si une connexion directe P2P est possible, le d\u00e9bit sera bon (souvent plusieurs centaines de Mbit/s) ; en revanche si le trafic doit transiter par un relais public (par ex. en cas de CGNAT sym\u00e9trique emp\u00eachant le P2P), le d\u00e9bit peut \u00eatre limit\u00e9 par ce relais (g\u00e9n\u00e9ralement quelques centaines de Mbit/s max).</p> <p>Twingate, bien qu\u2019utilisant son propre protocole bas\u00e9 sur TLS, affiche des performances tr\u00e8s proches de WireGuard dans les tests. Comme il \u00e9tablit des tunnels P2P entre le client et le connecteur (lorsque cela est possible), la latence et le d\u00e9bit sont quasiment optimaux. Des mesures indiquent que Twingate atteint  95% (ou plus) du d\u00e9bit natif, soit une perte g\u00e9n\u00e9ralement inf\u00e9rieure \u00e0 5-10% par rapport \u00e0 l\u2019absence de VPN  . Sur un transfert de fichier de 1,8 Go, par exemple, le d\u00e9bit via Twingate \u00e9tait le m\u00eame qu\u2019en direct (~600\u202fMbps), alors qu\u2019un tunnel WireGuard sur le m\u00eame VPS chutait \u00e0 ~224\u202fMbps dans ce cas de figure limit\u00e9 par le CPU  . Twingate profite de son architecture r\u00e9partie : si le chemin direct est optimal, le tunnel est direct; en cas d\u2019obstacle, le trafic peut passer par un relais Twingate global (d\u00e9bit dans ce cas plut\u00f4t de l\u2019ordre de 200\u2013250\u202fMbps) d\u2019apr\u00e8s leur documentation  . \u00c0 noter que Twingate, \u00e9tant  split-tunnel par d\u00e9faut, ne v\u00e9hicule que le trafic destin\u00e9 aux ressources priv\u00e9es : ainsi, la bande passante n\u2019est pas gaspill\u00e9e \u00e0 router du trafic Internet g\u00e9n\u00e9ral, ce qui \u00e9vite de saturer le tunnel inutilement  .</p> <p>En r\u00e9sum\u00e9,  WireGuard  offre la  meilleure performance  absolue sur mat\u00e9riel puissant et liens directs,  Twingate  parvient \u00e0 s\u2019en approcher gr\u00e2ce \u00e0 l\u2019optimisation P2P et \u00e0 son overhead minimal (cloud natif tr\u00e8s scalable), et  ZeroTier  offre de bonnes performances tout en sacrifiant quelques Mbps pour la commodit\u00e9 du maillage automatique. Dans la plupart des sc\u00e9narios homelab, les trois solutions pourront fournir un acc\u00e8s fluide (par ex. streaming vid\u00e9o, jeux, t\u00e9l\u00e9travail) \u2013 c\u2019est surtout dans des usages intensifs (gros transferts de donn\u00e9es, multiples utilisateurs simultan\u00e9s) ou sur des \u00e9quipements modestes que les diff\u00e9rences de d\u00e9bit pourront se faire sentir.</p>"},{"location":"reseau/vpn-remote-access/#securite","title":"S\u00e9curit\u00e9","text":"<p>Chaque solution adopte une approche diff\u00e9rente en mati\u00e8re de s\u00e9curit\u00e9, au-del\u00e0 du simple chiffrement des donn\u00e9es (que les trois assurent avec des algorithmes robustes) :</p> <ul> <li> <p>Twingate :  La s\u00e9curit\u00e9 est son point fort principal. Gr\u00e2ce au mod\u00e8le  Zero Trust Network Access (ZTNA), aucun utilisateur ou appareil n\u2019est implicitement fiable. Par d\u00e9faut,  rien n\u2019est accessible tant que ce n\u2019est pas explicitement autoris\u00e9  . L\u2019acc\u00e8s est contr\u00f4l\u00e9 au niveau applicatif : un utilisateur doit s\u2019authentifier (id\u00e9alement via SSO + MFA) et n\u2019obtient que des droits fins (par ex : acc\u00e8s au serveur X sur le port Y). Contrairement \u00e0 un VPN traditionnel qui placerait l\u2019utilisateur \u201cdans le LAN\u201d une fois connect\u00e9, Twingate ne laisse transiter que le trafic vers les ressources d\u00e9finies. De plus, le plan de contr\u00f4le (Cloud Twingate) v\u00e9rifie \u00e0 chaque connexion que l\u2019appareil de l\u2019utilisateur est approuv\u00e9 et \u00e0 jour (posture device). La conception cloud permet aussi une  int\u00e9gration SSOcompl\u00e8te : on peut lier Twingate \u00e0 Okta, Azure AD, Google Workspace, etc., et g\u00e9rer les autorisations par groupes d\u2019utilisateurs  . Sur le plan r\u00e9seau, Twingate apporte un gros avantage :  aucun port ouvert  sur le pare-feu de l\u2019entreprise. Les connecteurs initient des connexions sortantes chiffr\u00e9es, ce qui signifie qu\u2019un attaquant ext\u00e9rieur  ne voit pas  de service expos\u00e9 \u00e0 attaquer. Il ne peut m\u00eame pas savoir qu\u2019un certain port donne acc\u00e8s \u00e0 telle ressource, l\u00e0 o\u00f9 un VPN classique (m\u00eame WireGuard) reste d\u00e9tectable (port UDP ouvert, potentiellement identifiable). Enfin, la double confirmation \u00e9voqu\u00e9e (contr\u00f4leur + connecteur) signifie qu\u2019un pirate ayant compromis un composant isol\u00e9 ne peut pas d\u00e9tourner le trafic sans avoir aussi les cl\u00e9s d\u2019un second composant  . En somme, Twingate offre une  s\u00e9curit\u00e9 granulaire et multi-couches, adapt\u00e9e aux environnements sensibles (d\u2019ailleurs souvent utilis\u00e9 en entreprise pour remplacer des VPN jug\u00e9s trop larges).</p> </li> <li> <p>WireGuard :  Le protocole WireGuard a \u00e9t\u00e9 con\u00e7u avec la  simplicit\u00e9  comme gage de s\u00e9curit\u00e9. Son implantation l\u00e9g\u00e8re minimise les risques de failles (moins de code = moins de bugs) et a fait l\u2019objet d\u2019audits. WireGuard n\u2019utilise que des  algorithmes cryptographiques modernes  consid\u00e9r\u00e9s comme s\u00fbrs (pas de vieux chiffrement potentiellement obsol\u00e8te)  . Par exemple, chaque paquet est authentifi\u00e9 via un tag Poly1305, et le protocole int\u00e8gre des m\u00e9canismes contre les attaques de type  replay. En outre, un n\u0153ud WireGuard ne r\u00e9pond qu\u2019aux paquets chiffr\u00e9s provenant de pairs connus (il est  silencieux  sur son port UDP tant qu\u2019il ne voit pas une cl\u00e9 publique autoris\u00e9e), ce qui rend difficile son scan par un attaquant opportuniste \u2013 il appara\u00eet \u201cferm\u00e9\u201d pour quiconque ne poss\u00e8de pas la bonne cl\u00e9. Cependant, WireGuard reste un  VPN traditionnel IP  : si un attaquant parvient \u00e0 obtenir/voler une cl\u00e9 priv\u00e9e autoris\u00e9e (par ex. vol de l\u2019ordinateur d\u2019un admin contenant le fichier de config), il pourrait potentiellement se connecter et avoir acc\u00e8s au r\u00e9seau priv\u00e9. Il n\u2019y a pas de notion d\u2019authentification utilisateur/mot de passe ou 2FA int\u00e9gr\u00e9e \u2013 il faut mettre en place des mesures externes pour contr\u00f4ler l\u2019utilisation des cl\u00e9s (certains l\u2019int\u00e8grent avec LDAP via des scripts de g\u00e9n\u00e9ration de config, etc., mais ce n\u2019est pas natif). La  surface d\u2019attaque  d\u2019un serveur WireGuard est tr\u00e8s r\u00e9duite (pas de gestion de session complexe, pas de pile TLS lourde), ce qui lui vaut une excellente r\u00e9putation de s\u00e9curit\u00e9 intrins\u00e8que  . En revanche, il faut r\u00e9aliser que WireGuard, une fois connect\u00e9, donne un acc\u00e8s IP complet selon la configuration r\u00e9seau : par d\u00e9faut, un client est \u201cvirtuellement\u201d dans le LAN (ou au moins dans le subnet du VPN) et peut communiquer librement \u2013 il n\u2019y a pas de segmentation fine out-of-the-box. Il revient \u00e0 l\u2019administrateur de filtrer au besoin (via des pare-feu, des tables de routage, etc.). Pour un usage homelab ou personnel, ceci est g\u00e9n\u00e9ralement acceptable, mais dans un contexte multi-utilisateurs, on devra pr\u00e9voir des r\u00e8gles si l\u2019on souhaite restreindre certains clients \u00e0 certaines ressources uniquement.</p> </li> <li> <p>ZeroTier :  ZeroTier assure \u00e9galement un  chiffrement bout-en-bout  par d\u00e9faut (bas\u00e9 sur des courbes ECC et chiffrement sym\u00e9trique 256-bit). Chaque n\u0153ud poss\u00e8de une adresse ZeroTier (son identifiant de 40 bits) d\u00e9riv\u00e9e de sa cl\u00e9 publique, ce qui garantit que seuls les appareils  explicitement autoris\u00e9s  par le contr\u00f4leur peuvent joindre le r\u00e9seau virtuel  . En terme d\u2019exposition, ZeroTier fonctionne, comme Twingate, sur des connexions sortantes : un client derri\u00e8re un NAT \u00e9tablira lui-m\u00eame la session vers les serveurs racine et tentera des connexions UDP vers les autres pairs, \u00e9vitant l\u00e0 aussi d\u2019ouvrir un port serveur local. Cependant,  ZeroTier repose sur une infrastructure centrale  (serveurs d\u2019autorit\u00e9 et de relais). M\u00eame si les donn\u00e9es sont chiffr\u00e9es (ZeroTier Inc. ne peut pas les lire), certains mod\u00e8les de menace pourraient consid\u00e9rer la d\u00e9pendance \u00e0 des serveurs tiers comme un risque (par exemple, une attaque sur les serveurs racine pourrait, dans le pire cas, perturber le r\u00e9seau Overlay). Il est toutefois possible d\u2019att\u00e9nuer cela en self-h\u00e9bergeant son propre contr\u00f4leur et m\u00eame ses propres \u201cplanet nodes\u201d (racines), mais c\u2019est une configuration avanc\u00e9e. En conditions normales, la  confiance  accord\u00e9e \u00e0 ZeroTier Inc. est surtout pour la disponibilit\u00e9, pas pour la confidentialit\u00e9 (puisque le zero-trust est assur\u00e9 via le chiffrement). ZeroTier offre une fonctionnalit\u00e9 de  Network Rules Engine  : l\u2019admin peut d\u00e9finir des r\u00e8gles de filtrage (au niveau des adresses/ports, protocole, etc.) pour interdire ou limiter certains flux \u00e0 l\u2019int\u00e9rieur du VPN. Par exemple, on peut isoler deux groupes de machines virtuelles pour qu\u2019elles ne communiquent pas, ou n\u2019autoriser qu\u2019un certain port vers une IP donn\u00e9e. Cela permet de se rapprocher d\u2019une politique de moindre privil\u00e8ge \u2013 mais ces r\u00e8gles \u00e9tant globales au r\u00e9seau virtuel, elles sont moins dynamiques qu\u2019une approche ZTNA comme Twingate. C\u00f4t\u00e9 client, ZeroTier n\u2019impose pas d\u2019authentification utilisateur suppl\u00e9mentaire, ce qui signifie que la compromission d\u2019un appareil autoris\u00e9 peut donner acc\u00e8s au r\u00e9seau virtuel (il faut alors le retirer via la console pour le bannir). En r\u00e9sum\u00e9, ZeroTier apporte une  s\u00e9curit\u00e9 satisfaisante pour la plupart des usages  (chiffrement fort, pas de ports ouverts, contr\u00f4le des pairs autoris\u00e9s), avec une souplesse suppl\u00e9mentaire gr\u00e2ce aux r\u00e8gles personnalis\u00e9es, mais il ne fournit pas le m\u00eame niveau de micro-contr\u00f4le qu\u2019une solution zero-trust d\u00e9di\u00e9e.</p> </li> </ul>"},{"location":"reseau/vpn-remote-access/#integration-et-gestion","title":"Int\u00e9gration et gestion","text":"<p>Les trois solutions diff\u00e8rent notablement dans leur mode de d\u00e9ploiement et d\u2019int\u00e9gration \u00e0 l\u2019\u00e9cosyst\u00e8me :</p> <ul> <li> <p>Twingate  \u00e9tant un service cloud, il s\u2019int\u00e8gre ais\u00e9ment avec les outils d\u2019entreprise. On l\u2019a mentionn\u00e9, il supporte nativement les principaux fournisseurs d\u2019identit\u00e9  (Azure AD/Entra ID, Okta, Google, OneLogin, etc.)  . Ainsi, la gestion des utilisateurs et groupes est centralis\u00e9e : inutile de cr\u00e9er des comptes VPN s\u00e9par\u00e9s, on r\u00e9utilise les identit\u00e9s existantes. De plus, Twingate offre des API et peut s\u2019int\u00e9grer \u00e0 des SIEM/Monitoring pour tracer qui acc\u00e8de \u00e0 quoi. L\u2019enr\u00f4lement des appareils est \u00e9galement pens\u00e9 pour \u00eatre simple : on peut d\u00e9ployer le client via un MDM, ou laisser l\u2019utilisateur l\u2019installer lui-m\u00eame puis se connecter avec son compte SSO (pas de fichier de config ou de cl\u00e9 \u00e0 g\u00e9rer manuellement). Pour l\u2019administrateur, la gestion passe par une console web tr\u00e8s compl\u00e8te, o\u00f9 l\u2019on d\u00e9finit les ressources (par nom DNS ou IP/port), cr\u00e9e des groupes d\u2019acc\u00e8s, visualise les journaux de connexion, etc. Il n\u2019est pas n\u00e9cessaire d\u2019avoir des comp\u00e9tences pointues en r\u00e9seau pour utiliser Twingate \u2013 le plus technique consiste \u00e0 lancer les connecteurs (container Docker ou service Linux) dans chaque r\u00e9seau \u00e0 exposer, ce qui est assez simple si l\u2019on sait ex\u00e9cuter une image Docker  . Aucune modification IP ou firewall n\u2019est requise, ce qui facilite la mise en place (et on peut m\u00eame faire cohabiter Twingate avec un VPN existant pour tester, puisqu\u2019il n\u2019y a pas de conflit)  . L\u2019inconv\u00e9nient de cette approche manag\u00e9e est la  d\u00e9pendance au cloud  : sans Internet ou si les serveurs Twingate sont indisponibles, l\u2019acc\u00e8s tombe. De plus, certaines entreprises/homelabs peuvent h\u00e9siter \u00e0 faire transiter la gestion de leurs acc\u00e8s par un service tiers propri\u00e9taire. Twingate a un mod\u00e8le gratuit pour usage personnel (limit\u00e9 en utilisateurs/connexions), mais les fonctionnalit\u00e9s avanc\u00e9es (par ex. plus d\u2019utilisateurs, plus de connecteurs, SSO entreprise) sont payantes.</p> </li> <li> <p>WireGuard  s\u2019int\u00e8gre au contraire de fa\u00e7on  auto-h\u00e9berg\u00e9e. Il s\u2019agit d\u2019un binaire/service \u00e0 installer sur un serveur que vous contr\u00f4lez. Cela signifie une  libert\u00e9 totale  (pas de compte \u00e0 cr\u00e9er sur une plateforme externe, pas de limite d\u2019utilisateurs impos\u00e9e, etc.), au prix d\u2019une gestion plus manuelle. Il existe peu d\u2019int\u00e9grations \u201ccl\u00e9 en main\u201d avec les annuaires ou les outils de monitoring \u2013 toutefois, l\u2019\u00e9cosyst\u00e8me a produit plusieurs solutions pour faciliter l\u2019administration de WireGuard : par ex.  wg-easy,  WireGuard UI,  PiVPN, etc., qui fournissent une interface web ou des scripts pour g\u00e9n\u00e9rer les configurations clients et les QR codes. En entreprise, des solutions comme Netmaker ou Tailscale (commercial) utilisent WireGuard en arri\u00e8re-plan et ajoutent une surcouche de gestion centralis\u00e9e, mais dans notre comparaison on consid\u00e8re WireGuard \u201cpur\u201d. La gestion des  cl\u00e9s et configs  peut devenir lourde si on a de nombreux clients, car il faut g\u00e9n\u00e9rer une cl\u00e9 par poste, l\u2019ajouter sur le serveur (\u00e9dition du fichier wg0.conf) puis distribuer le bon fichier au client. Des utilisateurs ont not\u00e9 que cette phase de setup et de distribution des cl\u00e9s demandait un minimum de connaissances, contrairement \u00e0 des outils plus automatis\u00e9s  . C\u00f4t\u00e9 int\u00e9gration r\u00e9seau, WireGuard cr\u00e9e simplement une interface r\u00e9seau virtuelle ; \u00e0 l\u2019admin de l\u2019ins\u00e9rer dans son plan d\u2019adressage. On peut configurer le serveur pour pousser des routes, ou laisser le client d\u00e9cider (par ex. tunnel par d\u00e9faut ou non). Il est possible d\u2019int\u00e9grer WireGuard avec des configurations avanc\u00e9es (ex: routage conditionnel, scripts Up/Down pour mettre \u00e0 jour des route tables, etc.), ce qui le rend tr\u00e8s  flexible  pour un homelab. En revanche, sans effort suppl\u00e9mentaire, il n\u2019a pas de notion de \u201cportail captif\u201d ou d\u2019authentification user-friendly : l\u2019utilisateur doit r\u00e9cup\u00e9rer un fichier de configuration (ou scanner un QR code) et l\u2019importer dans son client WireGuard. Une fois fait, c\u2019est tr\u00e8s stable et \u00e7a se connecte automatiquement en arri\u00e8re-plan (on peut configurer la reconnexion automatique), mais tout changement (comme retirer un acc\u00e8s) implique de toucher la config du serveur (retirer la cl\u00e9 publique concern\u00e9e). Ainsi, WireGuard est  l\u00e9ger mais rudimentaire  en termes de gestion multi-utilisateurs.</p> </li> <li> <p>ZeroTier  occupe un peu le milieu : c\u2019est un service p2p mais avec une  console de gestion cloud  conviviale sur my.zerotier.com (si on utilise la version h\u00e9berg\u00e9e). L\u2019administrateur cr\u00e9e un r\u00e9seau virtuel sur cette console, obtient un Network ID, et \u00e0 chaque nouvel appareil qui rejoint (en ex\u00e9cutant  zerotier-cli join   ou via l\u2019UI) il voit l\u2019appareil appara\u00eetre dans la console en attente d\u2019autorisation. En un clic, il peut l\u2019accepter dans le r\u00e9seau et \u00e9ventuellement lui attribuer une IP fixe ou un nom. Ce mode de fonctionnement est tr\u00e8s pratique pour un homelab : pas besoin de \u00e9changer des cl\u00e9s manuellement ni de configurer des ports. La console permet aussi de d\u00e9finir des routes (par ex. \u201ctel membre relaye le sous-r\u00e9seau 192.168.1.0/24 aux autres\u201d) et d\u2019\u00e9crire des  r\u00e8gles de filtrage  si souhait\u00e9.  Sans configuration additionnelle, tous les membres d\u2019un r\u00e9seau ZeroTier peuvent communiquer librement entre eux (une fois autoris\u00e9s). Il faut donc penser \u00e0 activer le moteur de r\u00e8gles si l\u2019on veut restreindre les communications internes (ce que beaucoup d\u2019utilisateurs personnels ne font pas forc\u00e9ment, profitant simplement du \u201cLAN virtuel\u201d ouvert). Du point de vue int\u00e9gration SI, ZeroTier n\u2019a pas de liaison SSO/LDAP directe \u2013 on g\u00e8re les membres par appareil, pas par utilisateur. Mais on peut contourner cette limitation en  self-hostant  le contr\u00f4leur ZeroTier : le code du contr\u00f4leur est inclus dans le binaire ZeroTier One et on trouve des outils comme  ZeroUI  pour l\u2019exploiter  . En self-host, on peut alors imaginer int\u00e9grer l\u2019inscription des membres avec des processus internes (API, etc.), et surtout on l\u00e8ve la limite de 50 n\u0153uds maximum impos\u00e9e par le service cloud gratuit  . Cependant, le self-hosting complet de ZeroTier est non trivial et plut\u00f4t r\u00e9serv\u00e9 aux power users ; la plupart se contentent de la version cloud, tr\u00e8s fiable et suffisamment gratuite pour un usage mod\u00e9r\u00e9. Pour un homelab classique, ZeroTier est  extr\u00eamement facile \u00e0 d\u00e9ployer  : quelques minutes suffisent pour que tous vos PC, VPS et Raspberry Pi \u201cse voient\u201d sur un m\u00eame LAN virtuel. Il faut juste garder en t\u00eate que cette simplicit\u00e9 d\u00e9pend d\u2019une plateforme tierce (sauf \u00e0 se lancer dans l\u2019auto-h\u00e9bergement avanc\u00e9)."},{"location":"reseau/vpn-remote-access/#deploiement-et-contraintes-nat-cloud-vs-self-host-etc","title":"D\u00e9ploiement et contraintes (NAT, cloud vs self-host, etc.)","text":"<p>Acc\u00e8s depuis Internet / NAT :  C\u2019est un point critique en pratique : comment la solution traverse-t-elle les NAT et firewalls pour \u00e9tablir la connexion ?</p> <ul> <li> <p>Twingate  : Aucun pr\u00e9-requis r\u00e9seau, c\u2019est l\u2019atout majeur. Les connecteurs \u00e9tablissent d\u2019eux-m\u00eames des connexions sortantes vers le cloud Twingate, et les clients utilisateurs font de m\u00eame. La coordination cloud leur fait ensuite tenter un lien direct P2P. Si le NAT de part et d\u2019autre le permet (UPnP, UDP hole punching), le trafic passe directement. Sinon, il transitera chiffr\u00e9 via un  Relay  Twingate (serveur de rebond)  . Dans tous les cas, le fonctionnement est  transparent  : m\u00eame derri\u00e8re plusieurs NAT ou en 4G, l\u2019utilisateur n\u2019a rien \u00e0 configurer sur son routeur. Ceci est id\u00e9al en environnement  CGNAT  ou lorsque l\u2019on n\u2019a pas la main sur la box (par ex. acc\u00e9der \u00e0 son r\u00e9seau domestique depuis l\u2019ext\u00e9rieur sans pouvoir ouvrir de ports). L\u2019autre face de la m\u00e9daille est la  d\u00e9pendance cloud  d\u00e9j\u00e0 \u00e9voqu\u00e9e : sans Internet ou si Twingate (le service) a une panne, le VPN ne peut s\u2019\u00e9tablir, puisqu\u2019il n\u2019y a pas de chemin alternatif.</p> </li> <li> <p>WireGuard  : En version auto-h\u00e9berg\u00e9e, il n\u00e9cessite au moins  un point d\u2019acc\u00e8s r\u00e9seau publiquement joignable. Typiquement, on configure son serveur WireGuard sur un r\u00e9seau avec IP publique (ou on fait un  port forwardingsur sa box vers le serveur). Le protocole \u00e9tant UDP uniquement, il faut que le client puisse envoyer des paquets UDP au serveur. Si votre homelab est derri\u00e8re un NAT de votre FAI, il faudra soit utiliser un relais (par ex. un VPS interm\u00e9diaire ayant une IP publique), soit opter pour des solutions type Tailscale qui basculent sur des relais STUN/TURN. Par d\u00e9faut, WireGuard ne fait pas de travers\u00e9e de NAT sophistiqu\u00e9e : il repose sur la simplicit\u00e9, donc sans configuration manuelle, un client  ne peut pas  se connecter \u00e0 un serveur qui n\u2019a pas de port accessible. Une fois la connexion \u00e9tablie, toutefois, WireGuard g\u00e8re bien les changements d\u2019adresse c\u00f4t\u00e9 client (roaming) : on peut passer du Wi-Fi \u00e0 la 4G, l\u2019adresse IP du client change mais le tunnel reste \u00e9tabli sans reconnection manuelle. Dans un contexte homelab, beaucoup utilisent un nom de domaine  DDNS  pour joindre le serveur (puisque l\u2019IP publique peut changer)  . Il faut aussi veiller aux conflits de sous-r\u00e9seaux priv\u00e9s (si votre LAN est en 192.168.1.0/24 comme beaucoup, et que vous vous connectez depuis un Wi-Fi public ou autre en 192.168.1.x, il peut y avoir chevauchement d\u2019IPs \u2013 une astuce est d\u2019utiliser un subnet non standard pour le LAN et/ou le VPN)  . En r\u00e9sum\u00e9,  WireGuard n\u00e9cessite de la configuration r\u00e9seau  (port UDP ouvert, adresse IP ou DDNS connu) \u2013 ce qui est tr\u00e8s faisable sur un routeur grand public, mais constitue une contrainte par rapport aux solutions \u201ccloud\u201d.</p> </li> <li> <p>ZeroTier  : Comme Twingate, ZeroTier excelle dans la travers\u00e9e de NAT. Chaque client sortant contacte le service central et les autres pairs, et la magie du  hole punching  fait le reste. M\u00eame derri\u00e8re plusieurs couches de NAT, ZeroTier arrive g\u00e9n\u00e9ralement \u00e0 \u00e9tablir un chemin P2P entre deux n\u0153uds  . En cas d\u2019\u00e9chec, les paquets passent par un  relay  (appel\u00e9 \u201cmoon\u201d) \u2013 ce qui peut augmenter la latence, mais garantit la connectivit\u00e9. Aucune configuration de port n\u2019est n\u00e9cessaire dans 99% des cas. C\u2019est pour cela que ZeroTier (comme Tailscale) est pris\u00e9 :  aucune intervention sur le r\u00e9seau  n\u2019est requise, on peut l\u2019utiliser sur un r\u00e9seau d\u2019entreprise verrouill\u00e9 ou un hotspot mobile sans souci. Concernant le  cloud vs self-host  : par d\u00e9faut, on utilise les serveurs de ZeroTier Inc. pour tout (authentification des membres, routage initial). Il est possible de d\u00e9ployer son propre contr\u00f4leur (appel\u00e9  ZeroTier Central  self-hosted) pour g\u00e9rer les membres localement \u2013 cela enl\u00e8ve la limite de 50 et vous donne le contr\u00f4le sur les attributions d\u2019adresses  . M\u00eame dans ce cas, cependant, la fonction des serveurs racine (planet) pour aider \u00e0 la d\u00e9couverte P2P reste utile \u2013 on peut aussi les self-h\u00e9berger mais c\u2019est rare dans la communaut\u00e9 homelab. La  contrainte principale  avec ZeroTier peut \u00eatre  la confiance dans l\u2019infrastructure externe  et potentiellement les limites du plan gratuit (nombre de appareils). Mais pour un usage personnel (quelques PCs, t\u00e9l\u00e9phone, VPS\u2026), la version gratuite suffit largement.</p> </li> </ul> <p>\u00c9cosyst\u00e8me et support :  Twingate \u00e9tant une solution commerciale r\u00e9cente, on trouve surtout du support via leur documentation et quelques tutoriels officiels (ou vid\u00e9os de youtubers). La communaut\u00e9 homelab commence \u00e0 en parler, mais c\u2019est moins r\u00e9pandu que WireGuard ou ZeroTier. WireGuard, au contraire, a une  large communaut\u00e9 open-source  : de nombreux guides, et il est inclus par d\u00e9faut dans des projets comme  OPNsense/pfSense, OpenWrt, etc. ZeroTier aussi a une communaut\u00e9 active (forums, subreddit) et est int\u00e9gr\u00e9 dans des produits (par ex. certains routeurs Netgear ou QNAP proposent ZeroTier). Selon votre affinit\u00e9, il peut \u00eatre plus facile de trouver de l\u2019aide sur WireGuard (g\u00e9n\u00e9rique) ou ZeroTier (community) que sur Twingate (solution propri\u00e9taire), bien que Twingate offre un support client pour ses utilisateurs.</p>"},{"location":"reseau/vpn-remote-access/#cas-dusage-dans-un-homelab","title":"Cas d\u2019usage dans un homelab","text":"<p>Voyons comment chaque solution s\u2019applique \u00e0 des sc\u00e9narios typiques de  homelab  : acc\u00e8s \u00e0 son LAN domestique depuis l\u2019ext\u00e9rieur, interconnexion de deux sites distants, ou encore acc\u00e8s \u00e0 un segment r\u00e9seau particulier (VLAN) du lab.</p>"},{"location":"reseau/vpn-remote-access/#acces-distant-securise-au-lan-personnel","title":"Acc\u00e8s distant s\u00e9curis\u00e9 au LAN personnel","text":"<p>Sch\u00e9ma \u2013 Exemple d\u2019acc\u00e8s distant \u00e0 un r\u00e9seau local via un VPN.  Dans ce cas d\u2019usage, on souhaite pouvoir acc\u00e9der \u00e0 distance aux appareils de son r\u00e9seau local (PC, NAS, domotique\u2026) comme si l\u2019on \u00e9tait chez soi, mais  sans exposer  ces services directement sur Internet. Traditionnellement, un VPN permet d\u2019obtenir une IP du LAN ou d\u2019y router son trafic.</p> <ul> <li> <p>Avec WireGuard:  on d\u00e9ploie un serveur WireGuard sur le LAN (par ex. sur le routeur ou un Raspberry Pi). Ce serveur est configur\u00e9 avec une IP virtuelle (ex: 10.0.0.1) et on lui assigne la route du LAN (par ex. 192.168.1.0/24) dans la section AllowedIPs de ses pairs. C\u00f4t\u00e9 client, on configure une IP virtuelle (ex: 10.0.0.2) et on autorise le trafic vers le LAN via le tunnel. Une fois connect\u00e9, le client peut joindre n\u2019importe quelle machine du LAN en 192.168.1.x. Il faut s\u2019assurer que le serveur fait du  forwarding IP  et du NAT correct (pour que les paquets du VPN atteignent le LAN et que les r\u00e9ponses reviennent)  . En pratique, cela fonctionne tr\u00e8s bien : depuis son t\u00e9l\u00e9phone ou son laptop, on active WireGuard et on peut par exemple se connecter \u00e0 l\u2019interface de son NAS (par son IP locale) ou \u00e0 son serveur domotique. La latence ajout\u00e9e est minimale (quelques ms) et le d\u00e9bit d\u00e9pendra de sa connexion Internet et des points \u00e9voqu\u00e9s plus haut (performance). L\u2019inconv\u00e9nient potentiel est qu\u2019il faut  ouvrir/forwarder le port UDP  du serveur \u2013 on veille donc \u00e0 choisir un port non standard et \u00e0 utiliser \u00e9ventuellement un DNS dynamique pour le joindre. Mais une fois en place, c\u2019est une solution fiable et sans abonnement.</p> </li> <li> <p>Avec ZeroTier:  on installe le client ZeroTier sur au moins une machine du LAN (id\u00e9alement le routeur ou un serveur allum\u00e9 en permanence). On peut aussi l\u2019installer sur plusieurs machines (NAS, PC\u2026) si on veut acc\u00e9der \u00e0 chacune directement. Supposons qu\u2019on cr\u00e9e un r\u00e9seau ZeroTier et que chaque appareil obtient une IP virtuelle (ex: 10.10.0.x). Si on a mis ZeroTier sur le routeur, on peut d\u00e9finir cette machine comme  routeur g\u00e9r\u00e9  pour le LAN : ainsi, quand le laptop \u00e0 distance veut joindre 192.168.1.50, il enverra le trafic via ZeroTier \u00e0 l\u2019IP virtuelle du routeur, qui le routera dans le LAN. Alternativement, on peut mettre ZeroTier directement sur les cibles (NAS, etc.), et alors le laptop y acc\u00e9dera via leur IP ZeroTier (sans m\u00eame passer par 192.168.1.x). ZeroTier offre donc  beaucoup de souplesse  : on peut recr\u00e9er un  LAN virtuel unique  englobant toutes les machines locales et le client distant. Cela \u00e9vite de toucher au routeur ou aux param\u00e8tres r\u00e9seau local. En termes de s\u00e9curit\u00e9, par d\u00e9faut, une fois connect\u00e9 au m\u00eame r\u00e9seau ZeroTier, le laptop pourra scanner et se connecter aux appareils joints sur ce r\u00e9seau virtuel (qui correspondent aux appareils du LAN qu\u2019on a mis sur ZeroTier). Il est recommand\u00e9 d\u2019activer des r\u00e8gles si l\u2019on veut limiter cela, mais dans un homelab personnel avec peu de n\u0153uds, ce n\u2019est g\u00e9n\u00e9ralement pas un souci. ZeroTier a l\u2019avantage de ne n\u00e9cessiter aucune IP publique ni port, donc c\u2019est  particuli\u00e8rement indiqu\u00e9 si on ne peut pas faire de port-forwarding  (par exemple logement collectif avec routeur impos\u00e9).</p> </li> <li> <p>Avec Twingate:  on d\u00e9ploie un  Connector Twingate  sur le LAN (par ex. sur un petit VM ou Docker sur le NAS). Dans l\u2019interface Twingate, on d\u00e9clare les  ressources  auxquelles on veut acc\u00e9der : par exemple \u201cNAS Web UI\u201d = IP 192.168.1.50 port 5000, \u201cServeur Domotique SSH\u201d = 192.168.1.100 port 22, etc. On peut aussi exposer toute une plage (par ex. 192.168.1.0/24) d\u2019un coup, mais ce n\u2019est pas l\u2019esprit Zero Trust \u2013 on choisit plut\u00f4t pr\u00e9cis\u00e9ment ce qui est n\u00e9cessaire. Ensuite, sur le client distant (PC portable, smartphone), l\u2019utilisateur installe le client Twingate, s\u2019authentifie via le SSO configur\u00e9, et voit ces ressources. S\u2019il tente d\u2019acc\u00e9der \u00e0 192.168.1.50:5000 dans son navigateur, le client Twingate intercepte la requ\u00eate DNS/IP et \u00e9tablit le tunnel automatiquement vers le Connector, qui la relaie au NAS  .  Aucun port  n\u2019a \u00e9t\u00e9 ouvert sur le routeur du LAN, et pourtant l\u2019acc\u00e8s se fait de mani\u00e8re s\u00e9curis\u00e9e. L\u2019exp\u00e9rience est tr\u00e8s transparente : l\u2019utilisateur n\u2019a pas besoin d\u2019activer/d\u00e9sactiver le VPN, Twingate \u00e9tablit \u00e0 la demande la connexion quand on acc\u00e8de \u00e0 une ressource prot\u00e9g\u00e9e. Pour un homelab, cela signifie qu\u2019on peut garder tous ses services locaux ferm\u00e9s sur Internet, et y acc\u00e9der uniquement via le client Twingate. C\u2019est probablement la solution offrant le plus de  finesse  (on peut autoriser par utilisateur tel service et pas tel autre), au prix d\u2019une d\u00e9pendance au cloud et d\u2019un setup initial un peu plus lourd que WireGuard/ZeroTier pour un usage perso tr\u00e8s simple. \u00c0 noter que Twingate ne \u201cmet pas le client sur le LAN\u201d : par d\u00e9faut, on ne peut  pas pinguer  n\u2019importe quelle IP du LAN ou parcourir le r\u00e9seau Windows \u2013 on peut seulement contacter les ressources explicitement d\u00e9finies (mais on peut en d\u00e9finir beaucoup si on veut \u00e9muler un acc\u00e8s LAN complet).</p> </li> </ul>"},{"location":"reseau/vpn-remote-access/#interconnexion-de-sites-site-to-site","title":"Interconnexion de sites (site-to-site)","text":"<p>Ici, le besoin est de relier  deux r\u00e9seaux distincts  (par ex. le r\u00e9seau de la maison et celui du bureau, ou deux labs de test) de mani\u00e8re permanente, pour que les machines de chaque c\u00f4t\u00e9 puissent communiquer. On parle souvent de  VPN site-\u00e0-site.</p> <ul> <li> <p>WireGuard :  On peut configurer un tunnel WireGuard entre deux routeurs (ou deux serveurs Linux) \u2013 c\u2019est tout \u00e0 fait faisable et similaire \u00e0 IPsec site-to-site en plus simple. Il suffit que chaque c\u00f4t\u00e9 ait un peer WireGuard avec l\u2019AllowedIPs configur\u00e9 sur le subnet de l\u2019autre. Par exemple, le routeur A (maison) aura AllowedIPs = 10.0.0.0/24 (le r\u00e9seau du site B), et le routeur B (bureau) aura AllowedIPs = 192.168.1.0/24 (le LAN du site A). Ainsi, chaque routeur acheminera vers le tunnel tout trafic destin\u00e9 au r\u00e9seau oppos\u00e9. Il faut qu\u2019au moins un des deux ait une IP publique ou un port ouvert (comme pour l\u2019acc\u00e8s distant). Une fois en place, c\u2019est tr\u00e8s stable : les deux sites sont reli\u00e9s en permanence, et les PC de chaque c\u00f4t\u00e9 peuvent se pinguer, acc\u00e9der aux services etc. On peut m\u00eame faire du  maillage  en configurant plusieurs pairs (ex : A vers B, A vers C, B vers C\u2026). Cependant, la config devient manuelle pour chaque lien (pas d\u2019autorouting dynamique). Dans un homelab, un site-to-site WireGuard est utile si par exemple on a un serveur chez un ami ou sur un VPS et qu\u2019on veut l\u2019int\u00e9grer \u00e0 son r\u00e9seau local.</p> </li> <li> <p>ZeroTier :  ZeroTier simplifie \u00e9norm\u00e9ment le site-to-site. En fait, si on installe ZeroTier sur un routeur ou une machine de chaque site et qu\u2019on les met dans le m\u00eame r\u00e9seau virtuel, ils se comporteront comme s\u2019ils \u00e9taient sur un switch virtuel commun. Concr\u00e8tement, on pourrait mettre  tous les appareils de deux sites sur le m\u00eame r\u00e9seau ZeroTier  et ils seraient alors tous interconnect\u00e9s (attention quand m\u00eame aux plages IP qui se chevauchent \u2013 il peut \u00eatre pr\u00e9f\u00e9rable alors de garder des sous-r\u00e9seaux distincts et d\u2019utiliser le routage ZeroTier plut\u00f4t qu\u2019un pont L2 global). ZeroTier permet par exemple de d\u00e9clarer que le membre \u201cRouteur_SiteA\u201d route le subnet 192.168.1.0/24 et que \u201cRouteur_SiteB\u201d route le 10.0.0.0/24 ; ensuite, tout appareil du r\u00e9seau virtuel pourra atteindre 192.168.1.x (via SiteA) ou 10.0.0.x (via SiteB). C\u2019est tr\u00e8s pratique pour f\u00e9d\u00e9rer plusieurs environnements. La  topologie mesh  fait que m\u00eame si SiteA parle \u00e0 SiteB, ils tenteront une connexion directe. S\u2019il y a un troisi\u00e8me site C dans le m\u00eame ZeroTier, les paquets de A vers C iront soit direct, soit via relais si n\u00e9cessaire, ind\u00e9pendamment de B. Compar\u00e9 \u00e0 WireGuard, ZeroTier \u00e9vite de configurer N tunnels pour N sites \u2013 tout se passe dans un  seul r\u00e9seau. Cette souplesse s\u2019accompagne de la m\u00eame consid\u00e9ration de s\u00e9curit\u00e9 : par d\u00e9faut, tous les sites peuvent tout voir (donc on aura soin de segmenter avec des r\u00e8gles si besoin de limitation).</p> </li> <li> <p>Twingate :  Twingate n\u2019est pas con\u00e7u \u00e0 la base pour du site-to-site \u201cLAN merge\u201d. C\u2019est davantage un mod\u00e8le acc\u00e8s utilisateur-serveur. N\u00e9anmoins, on peut l\u2019utiliser pour relier deux r\u00e9seaux si on approche le probl\u00e8me diff\u00e9remment. Par exemple, supposons deux sites (A et B) avec chacun des serveurs. Si un serveur du site B a besoin d\u2019acc\u00e9der \u00e0 un service du site A, on pourrait installer un  Client Twingate headless  sur ce serveur B (Twingate supporte les clients Linux sans interface, pour des cas d\u2019usage service-to-service) et autoriser ce client \u00e0 la ressource du site A. Ainsi le serveur B pourrait consommer une API ou une base de A via Twingate. Mais cela reste un acc\u00e8s ponctuel d\u2019une machine \u00e0 une autre. Il n\u2019y a pas de moyen facile de \u201cfondre\u201d deux LANs entiers avec Twingate, puisque chaque ressource doit \u00eatre d\u00e9finie. Th\u00e9oriquement on pourrait d\u00e9finir la ressource \u201cr\u00e9seau A entier = 192.168.1.0/24\u201d et connecter un client sur le routeur B\u2026 mais Twingate n\u2019est pas pr\u00e9vu pour transporter tout un sous-r\u00e9seau (pas de mode \u201csubnet router\u201d multiple dynamique comme Tailscale par ex. \u2013 du moins pas gratuitement). Donc pour un vrai site-to-site permanent, Twingate n\u2019est pas le meilleur choix. Il vaut mieux dans ce cas se tourner vers WireGuard ou ZeroTier, voire utiliser Tailscale qui permet des routeurs de sous-r\u00e9seaux multiples facilement. Twingate brille vraiment en  remote access  pour clients nomades ou en segmentation d\u2019acc\u00e8s, plus qu\u2019en interconnexion de deux infrastructures r\u00e9seau.</p> </li> </ul>"},{"location":"reseau/vpn-remote-access/#acces-a-un-vlan-reseau-specifique","title":"Acc\u00e8s \u00e0 un VLAN / r\u00e9seau sp\u00e9cifique","text":"<p>Beaucoup de homelabs segmentent leur r\u00e9seau en VLAN (par exemple un VLAN IoT, un VLAN lab, un VLAN stockage\u2026). Le d\u00e9fi est alors :  comment acc\u00e9der \u00e0 un VLAN particulier \u00e0 distance  ?</p> <ul> <li> <p>WireGuard :  Il peut transporter n\u2019importe quel trafic IP que le serveur voit. Si le serveur WG est sur un routeur qui conna\u00eet tous les VLAN, il suffit de lui ajouter les routes de ces VLAN dans la config et il les routera pour le client. Par exemple,  AllowedIPs = 192.168.10.0/24  pour VLAN10, etc., et le routeur enverra ces paquets sur le bon VLAN. Si le serveur WG n\u2019a acc\u00e8s qu\u2019\u00e0 un VLAN (ex: on l\u2019a install\u00e9 directement sur un NAS dans le VLAN IoT), alors par d\u00e9faut il ne voit que ce VLAN \u2013 ce qui peut \u00eatre un moyen simple de cloisonner l\u2019acc\u00e8s : ce VPN ne donne acc\u00e8s qu\u2019aux IoT. Il est aussi possible de d\u00e9ployer  plusieurs instances WireGuard  \u2013 par exemple une pour chaque VLAN critique, avec des ports distincts \u2013 et ainsi attribuer aux utilisateurs le VPN correspondant \u00e0 ce qu\u2019ils doivent atteindre. C\u2019est un peu lourd, mais \u00e7a fonctionne. Notons que WireGuard est purement L3, il ne v\u00e9hiculera pas vos balises VLAN ou du broadcast DHCP par exemple. Mais pour acc\u00e9der \u00e0 un \u00e9quipement VLAN depuis l\u2019ext\u00e9rieur, c\u2019est tr\u00e8s efficace.</p> </li> <li> <p>ZeroTier :  ZeroTier op\u00e8re par d\u00e9faut au niveau 2 sur son r\u00e9seau virtuel, ce qui signifie qu\u2019il peut m\u00eame  recr\u00e9er un VLAN  sur Internet. On peut configurer un pont L2 entre un VLAN local et le r\u00e9seau ZeroTier : par exemple, un petit Raspberry Pi dans le VLAN IoT qui joint le ZeroTier et qu\u2019on configure en bridge avec l\u2019interface VLAN locale. Ainsi, tout appareil distant connect\u00e9 au m\u00eame ZeroTier est en r\u00e9alit\u00e9 membre du VLAN IoT : il tirera une IP du DHCP IoT, etc., comme s\u2019il \u00e9tait directement branch\u00e9 au switch du VLAN (c\u2019est document\u00e9 dans les guides ZeroTier, cette configuration de bridge L2)  . Cela permet un acc\u00e8s  transparent  comme si on y \u00e9tait \u2013 utile pour d\u00e9couvrir un \u00e9quipement, utiliser des protocoles non routables, etc. En alternative plus simple, on peut laisser ZeroTier en L3 et d\u00e9clarer via les routes manag\u00e9es que tel membre (un routeur/Pi) route le VLAN IoT. Alors les clients ZeroTier peuvent joindre les IP du VLAN IoT via ce membre routeur. C\u2019est un peu comme le site-to-site mentionn\u00e9, appliqu\u00e9 \u00e0 un VLAN sp\u00e9cifique. ZeroTier \u00e9tant tr\u00e8s flexible, c\u2019est probablement la solution la plus adapt\u00e9e si l\u2019on veut  se \u201ct\u00e9l\u00e9porter\u201d dans un VLAN  : soit en pont L2 si vraiment n\u00e9cessaire, soit en routage L3 sans effort de config sur le routeur principal.</p> </li> <li> <p>Twingate :  On peut tout simplement d\u00e9ployer un Connector dans le VLAN cibl\u00e9 (il suffit qu\u2019il ait une IP dedans) et d\u00e9clarer les ressources voulues. Par exemple, si on a un VLAN \u201cCam\u00e9ras\u201d isol\u00e9, on peut mettre un Connector sur un petit host dans ce VLAN et autoriser l\u2019acc\u00e8s aux flux RTSP ou \u00e0 l\u2019NVR via Twingate. Twingate n\u2019a pas conscience des VLAN, juste des IP/ports, donc \u00e7a revient \u00e0 \u201cexposer\u201d proprement ce qu\u2019on veut de ce segment. Il n\u2019y a pas de possibilit\u00e9 d\u2019envoyer du broadcast ou d\u2019acc\u00e9der \u00e0 l\u2019ensemble du segment d\u2019un coup sans le d\u00e9finir (bien s\u00fbr, on  pourrait  d\u00e9finir une ressource 192.168.20.0/24 via Twingate \u2013 tous ports, ce qui reviendrait \u00e0 ouvrir le VLAN entier, mais ce n\u2019est pas l\u2019usage recommand\u00e9). L\u2019approche Twingate offre une s\u00e9curit\u00e9 maximale (on ne donne acc\u00e8s qu\u2019\u00e0 un service pr\u00e9cis du VLAN sensible, par ex. le flux vid\u00e9o d\u2019une cam\u00e9ra, et rien d\u2019autre), au prix de ne pas pouvoir utiliser certaines fonctions r\u00e9seau (MDNS, d\u00e9couverte locales) si elles ne sont pas relay\u00e9es via un proxy applicatif.</p> </li> </ul> <p>En somme, pour un homelab multi-VLAN :  ZeroTier  permet d\u2019unifier les segments facilement dans un overlay (voire \u00e9muler le VLAN lui-m\u00eame en overlay),  WireGuard  peut \u00eatre utilis\u00e9 soit via un serveur central connaissant tout (moins segment\u00e9), soit via plusieurs tunnels d\u00e9di\u00e9s, et  Twingate  permettra d\u2019atteindre des \u00e9quipements sp\u00e9cifiques dans chaque VLAN de mani\u00e8re tr\u00e8s verrouill\u00e9e (connecteurs multiples), plut\u00f4t que de fondre les VLAN ensemble.</p>"},{"location":"reseau/vpn-remote-access/#conclusion-et-tableau-recapitulatif","title":"Conclusion et tableau r\u00e9capitulatif","text":"<p>En conclusion, ces trois solutions r\u00e9pondent \u00e0 des besoins de nature un peu diff\u00e9rente, et le choix d\u00e9pendra de vos priorit\u00e9s en termes de  contr\u00f4le, simplicit\u00e9 et s\u00e9curit\u00e9  :</p> <ul> <li> <p>Twingate  : Solution moderne  Zero Trust  orient\u00e9e entreprise, offrant un  contr\u00f4le granulaire  des acc\u00e8s et une int\u00e9gration SSO/MFA pouss\u00e9e. Id\u00e9ale si la  s\u00e9curit\u00e9 fine  est primordiale (acc\u00e8s par application, journaux d\u00e9taill\u00e9s) et si l\u2019on veut  z\u00e9ro exposition r\u00e9seau. Tr\u00e8s facile \u00e0 d\u00e9ployer (techniquement) sans configurer de r\u00e9seau, mais n\u00e9cessite de faire confiance \u00e0 un  service cloud  externe. Pour un homelab, Twingate peut \u00eatre un peu complexe/par-dessus si on n\u2019a pas besoin d\u2019autant de segmentation, mais c\u2019est un excellent moyen d\u2019acc\u00e9der \u00e0 quelques services sensibles sans rien ouvrir sur Internet. Performance et UX excellentes (client l\u00e9ger, presque pas de perte de d\u00e9bit  ). Co\u00fbt : gratuit pour une petite utilisation, payant au-del\u00e0.</p> </li> <li> <p>WireGuard  : Solution VPN  classique  (L3) orient\u00e9e performance et minimalisme. Parfaite si vous voulez une  ma\u00eetrise totale  en self-hosted, sans d\u00e9pendance cloud, et que \u00e7a ne vous d\u00e9range pas de mettre un peu les mains dans la config. C\u2019est l\u2019option la plus  efficace  en termes de d\u00e9bit et latence, bien adapt\u00e9e pour interconnecter deux sites ou acc\u00e9der \u00e0 tout un LAN de fa\u00e7on transparente. Cependant, il faudra g\u00e9rer vous-m\u00eame tout ce qui est gestion utilisateurs/cl\u00e9, firewall, etc. \u2013 WireGuard fournit le tunnel, \u00e0 vous de b\u00e2tir autour. En homelab c\u2019est souvent un premier choix pour acc\u00e9der \u00e0 son r\u00e9seau depuis l\u2019ext\u00e9rieur, \u00e0 condition de pouvoir  forwarder  un port sur sa box. En environnement NAT compliqu\u00e9, il peut n\u00e9cessiter des solutions tierces. C\u2019est enti\u00e8rement gratuit et open-source.</p> </li> <li> <p>ZeroTier  : Solution  overlay P2P  orient\u00e9e  commodit\u00e9  et connectivit\u00e9 transparente. Id\u00e9ale si vous voulez que \u201ctout fonctionne hors de la bo\u00eete\u201d \u00e0 travers Internet et interconnecter plusieurs appareils/sites sans r\u00e9fl\u00e9chir aux routes. ZeroTier se comporte comme un  commutateur virtuel global  \u2013 tr\u00e8s pratique pour faire communiquer des conteneurs, VMs, machines r\u00e9parties sur le cloud et la maison, etc. Sa mise en place est enfantine, ce qui en fait un favori des homelabers qui cherchent la simplicit\u00e9. Il offre moins de granularit\u00e9 que Twingate (par d\u00e9faut c\u2019est comme un grand LAN), mais on peut y rajouter des r\u00e8gles si n\u00e9cessaire. La d\u00e9pendance \u00e0 un service central est \u00e0 garder en t\u00eate, m\u00eame si techniquement tout est chiffr\u00e9 et distribu\u00e9. En usage gratuit personnel, c\u2019est souvent le plus  simple  pour acc\u00e9der \u00e0 son homelab sans toucher \u00e0 la box, ou pour connecter plusieurs homelabs entre amis.</p> </li> </ul> <p>En r\u00e9sum\u00e9,  WireGuard  convient si vous cherchez la  performance brute et le contr\u00f4le  (et que \u00e7a ne vous d\u00e9range pas d\u2019automatiser/\u00e9crire quelques scripts si besoin),  ZeroTier  brille par la  facilit\u00e9 et la connectivit\u00e9 instantan\u00e9e  d\u2019un r\u00e9seau virtuel (id\u00e9al multi-sites ou quand on ne peut pas ouvrir de ports), et  Twingate  apporte la  s\u00e9curit\u00e9 zero-trust  maximale et l\u2019int\u00e9gration d\u2019entreprise (avec un d\u00e9ploiement simplifi\u00e9 mais cloud). Chacune a ses atouts dans un homelab selon que vous privil\u00e9giez la  s\u00e9curit\u00e9 granulaire, la  simplicit\u00e9 plug-and-play  ou la  sobri\u00e9t\u00e9 efficiente. Les retours d\u2019exp\u00e9rience montrent d\u2019ailleurs que certains combinent les outils : par ex. utiliser Twingate pour les services critiques et WireGuard pour un usage plus g\u00e9n\u00e9ral, ou ZeroTier pour interconnecter des sites et WireGuard pour acc\u00e9der \u00e0 un seul site \u2013 il n\u2019y a pas de solution unique, mais un ensemble d\u2019outils \u00e0 choisir selon vos besoins sp\u00e9cifiques  .</p>"},{"location":"securite/authentification/","title":"Authentification centralis\u00e9e et MFA dans un homelab","text":"<p>Dans un  homelab  self-hosted, disposer d\u2019un syst\u00e8me d\u2019authentification centralis\u00e9e robuste avec MFA (authentification multifacteur) permet de s\u00e9curiser efficacement l\u2019acc\u00e8s \u00e0 l\u2019ensemble des services internes (NAS, serveurs, applications web, etc.). Cette documentation compare plusieurs solutions open-source (Keycloak, Authentik, Authelia, LemonLDAP::NG\u2026), d\u00e9taille les m\u00e9thodes d\u2019authentification/MFA disponibles (TOTP, WebAuthn/U2F, SMS, push, YubiKey, etc.), propose des cas d\u2019usage concrets (Vaultwarden, Nextcloud, Proxmox, Grafana\u2026) et d\u00e9crit des architectures types avec reverse proxy (NGINX Proxy Manager, Traefik) et SSO via OIDC/LDAP, ainsi que des exemples de configuration (docker-compose, YAML, r\u00e8gles de proxy, options de cookies, etc.). Les explications sont techniques mais p\u00e9dagogiques, adapt\u00e9es \u00e0 un ing\u00e9nieur cybers\u00e9curit\u00e9 exp\u00e9riment\u00e9. Nous restons strictement sur des solutions self-hosted, sans recours \u00e0 des services SaaS.</p>"},{"location":"securite/authentification/#solutions-open-source-de-gestion-didentite-et-sso","title":"Solutions open-source de gestion d\u2019identit\u00e9 et SSO","text":"<p>Plusieurs projets proposent de centraliser l\u2019authentification en mode self-hosted. Voici une comparaison technique :</p> <ul> <li> <p>Keycloak  \u2013 Solution mature g\u00e9r\u00e9e par Red Hat. Propose une interface d\u2019administration riche et un  gestionnaire d\u2019identit\u00e9s  complet. Supporte nativement  OAuth2 / OpenID Connect (OIDC)  et  SAML, avec prise en charge d\u2019une base d\u2019utilisateurs interne ou de f\u00e9d\u00e9ration LDAP/AD  . Keycloak g\u00e8re aussi les MFA (TOTP, WebAuthn/FIDO2 avec YubiKey, etc.) et les logins sociaux (Google, GitHub\u2026)  . On peut l\u2019ex\u00e9cuter en conteneur Docker ou sur Kubernetes, avec bases SQL pour stocker les donn\u00e9es  . Keycloak est extensible : on peut ajouter des extensions Java, th\u00e8mes personnalis\u00e9s, ou connecteurs RADIUS via des extensions communautaires  .</p> </li> <li> <p>Authentik  \u2013 IdP open-source r\u00e9cent, moderne et \u201cconteneur-friendly\u201d  . Authentik fournit \u00e0 la fois une interface web d\u2019admin conviviale et une API. Il supporte  OIDC, OAuth2 et SAML  pour les applications clientes, et peut f\u00e9d\u00e9rer vers un annuaire LDAP existant  . Authentik met l\u2019accent sur les flux d\u2019authentification dynamiques et l\u2019\u00ab adaptive MFA \u00bb. Il g\u00e8re le  MFA  par TOTP,  WebAuthn/passkeys  (FIDO2) et m\u00eame l\u2019authentification par push ou static tokens (codes de secours)  . Il ne prend pas en charge RADIUS en natif, mais peut s\u2019int\u00e9grer via un proxy externe. Authentik est con\u00e7u pour tourner sur Docker/Kubernetes (base PostgreSQL), avec une documentation claire.</p> </li> <li> <p>Authelia  \u2013 \u00ab portail SSO \u00bb sp\u00e9cialis\u00e9 pour \u00eatre associ\u00e9 \u00e0 un reverse-proxy existant  . Authelia est un serveur d\u2019authentification multi-facteur (IAM)  et SSO qui se place en \u00ab gatekeeper \u00bb devant les applications web. C\u2019est un fournisseur  OIDC  certifi\u00e9 OpenID\u2122  , avec support des logins via cookies de session, headers de confiance ou OIDC. Authelia mise sur la l\u00e9g\u00e8ret\u00e9 (conteneur &lt;20\u202fMo) et la rapidit\u00e9. Il propose MFA/TOTP,  WebAuthn (FIDO2), notifications push et passkeys  , ainsi qu\u2019une gestion fine des politiques d\u2019acc\u00e8s. Il se d\u00e9ploie g\u00e9n\u00e9ralement en conteneur unique associ\u00e9 \u00e0 un proxy (Traefik, Nginx, etc.) et peut utiliser Redis/Mongo pour les sessions, LDAP pour le backend utilisateur, etc. Authelia ne cherche pas \u00e0 remplacer un annuaire LDAP complet mais sert de point d\u2019authentification central. Il fournit une UI simple pour le flux de login et de MFA  .</p> </li> <li> <p>LemonLDAP::NG  \u2013 Plateforme AAA (authentification, autorisation, audit) fran\u00e7aise, tr\u00e8s compl\u00e8te et modulaire  . LemonLDAP::NG propose un  portail SSO  avec support natif de nombreux backends d\u2019authentification (LDAP, AD, Kerberos, base de donn\u00e9es, certificats SSL, OAuth, etc.)  . Il impl\u00e9mente  SAML, CAS et OpenID Connect(flux standard OIDC/OAuth2)  . On peut l\u2019utiliser comme IDP SAML/OIDC, ou comme passerelle entre protocoles (ex. CAS\u2192SAML, etc.). LemonLDAP g\u00e8re la MFA via des modules vari\u00e9s : TOTP/HOTP (compatible FreeOTP, Google Authenticator), WebAuthn (FIDO2), OTP Yubico et plus (e-mail, RADIUS, Okta, REST externe\u2026)  . L\u2019interface d\u2019admin (Manager) est compl\u00e8te mais plus complexe \u00e0 prendre en main. LemonLDAP::NG est tr\u00e8s extensible (plugins Perl, r\u00e8gles avanc\u00e9es) et supporte Docker/Kubernetes pour l\u2019UI, le portail et la base de config.</p> </li> <li> <p>Autres solutions  \u2013 On peut aussi citer d\u2019autres projets comme GLUU (mature en entreprise) ou Ory/Hydra pour OIDC, voire Apereo CAS. Mais pour un homelab, les solutions ci-dessus sont en g\u00e9n\u00e9ral suffisantes.</p> </li> </ul> <p>En synth\u00e8se,  Keycloak  et  Authentik  sont de v\u00e9ritables fournisseurs d\u2019identit\u00e9 (IdP) supportant SSO OIDC/SAML et de multiples m\u00e9thodes MFA;  Authelia  joue plut\u00f4t le r\u00f4le d\u2019authentificateur \u00ab front-end \u00bb pour un reverse proxy, apportant MFA/TOTP/WebAuthn sans fournir de service annuaire complet;  LemonLDAP::NG  est une suite SSO tr\u00e8s polyvalente multi-protocoles, orient\u00e9e proxy et flux d\u2019authent. Les diff\u00e9rences se trouvent dans la facilit\u00e9 de configuration (Keycloak/Authentik offrent UI modernes, Authelia et LemonLDAP demandent plus de configuration manuelle), l\u2019int\u00e9gration dans Docker (Keycloak et Authentik pr\u00eats pour conteneurs, LemonLDAP plus traditionnel), et l\u2019\u00e9cosyst\u00e8me (communaut\u00e9, plugins, support entreprise)  .</p>"},{"location":"securite/authentification/#methodes-dauthentification-et-mfa-supportees","title":"M\u00e9thodes d\u2019authentification et MFA support\u00e9es","text":"<p>Les syst\u00e8mes ci-dessus supportent plusieurs  m\u00e9thodes d\u2019authentification  et de  double authentification (2FA/MFA)courantes :</p> <ul> <li> <p>TOTP (Time-based One-Time Password)  : codes \u00e0 usage unique g\u00e9n\u00e9r\u00e9s par application mobile (Google Authenticator, FreeOTP, Authy\u2026). Avantages : simple, ne requiert pas de r\u00e9seau, bien support\u00e9. Inconv\u00e9nients : vuln\u00e9rable au phishing, n\u00e9cessite synchronisation horaire correcte. Presque tous les IdP/SSO (Keycloak, Authelia, Authentik, LemonLDAP) int\u00e8grent le TOTP en MFA  . Par exemple, Keycloak propose une \u00ab authenticator app \u00bb TOTP int\u00e9gr\u00e9e  , et Authelia g\u00e8re les OTP via TOTP dans sa configuration.</p> </li> <li> <p>WebAuthn / FIDO2 (incluant U2F)  : authentification par \u00ab cl\u00e9s de s\u00e9curit\u00e9 \u00bb (YubiKey, biom\u00e9trie mobile, etc.) selon la norme W3C Web Authentication. Avantages : extr\u00eamement r\u00e9sistante au phishing (la cl\u00e9 crypto prouve la l\u00e9gitimit\u00e9 du site), UX fluide (p.ex. passkeys sur smartphone), peut remplacer le mot de passe. Limites : exige un appareil support\u00e9 (cl\u00e9 USB/NFC ou smartphone/ordinateur avec TPM), plus complexe \u00e0 d\u00e9ployer. Keycloak supporte WebAuthn comme deuxi\u00e8me facteur (m\u00eame utilis\u00e9 comme facteur primaire sans mot de passe)  . Authelia inclut le support WebAuthn (passkeys et U2F)  . Authentik le supporte \u00e9galement et le recommande (c\u2019est le seul facteur utilisable en tant que \u00ab passwordless \u00bb primaire)  . LemonLDAP::NG offre un plugin WebAuthn (attestation simple ou avanc\u00e9e) et peut migrer des cl\u00e9s U2F existantes vers WebAuthn  . Les cl\u00e9s mat\u00e9rielles YubiKey b\u00e9n\u00e9ficient de ces syst\u00e8mes : en mode OTP (monodirectionnel) ou comme cl\u00e9 FIDO2 (WebAuthn/U2F).</p> </li> <li> <p>YubiKey OTP  : Jetons OTP sp\u00e9cifiques de Yubico (1 OTP par toucher). Avantages : m\u00e9thode \u00e9prouv\u00e9e, r\u00e9silience contre attaque en ligne, fonctionne hors-ligne. Inconv\u00e9nients : stocker secret Yubikey (s\u00e9curit\u00e9), format propri\u00e9taire. LemonLDAP::NG fournit un module \u00ab Yubico OTP \u00bb pour int\u00e9grer directement les cl\u00e9s Yubico en second facteur  . (Cependant, comme WebAuthn couvre d\u00e9j\u00e0 FIDO/U2F, l\u2019OTP de YubiKey est moins utilis\u00e9).</p> </li> <li> <p>SMS OTP  : codes envoy\u00e9s par SMS. Avantages : large compatibilit\u00e9 (aucune appli n\u00e9cessaire). Inconv\u00e9nients s\u00e9rieux : vuln\u00e9rable au SIM swapping, chiffrement SMS faible, peut \u00eatre intercept\u00e9. Authentik et Authelia peuvent proposer le SMS en MFA (Authentik l\u2019int\u00e8gre en option, Authelia peut utiliser Twilio ou un fournisseur GSM)  . C\u2019est souvent d\u00e9conseill\u00e9 en priorit\u00e9, mais utile en secours.</p> </li> <li> <p>Notification Push mobile  : authentification par notification sur smartphone (ex. Duo Mobile). Avantages : tr\u00e8s pratique, s\u00e9curit\u00e9 renforc\u00e9e (requiert contr\u00f4le de l\u2019appareil). Inconv\u00e9nients : d\u00e9pend d\u2019un service push (souvent externe). Authelia supporte les notifications push (il mentionne explicitement \u201cMobile Push Notifications\u201d comme facteur support\u00e9)  . Authentik n\u2019a pas de push int\u00e9gr\u00e9 nativement (on peut passer par Duo ou WebAuthn mobile).</p> </li> <li> <p>Autres facteurs  : En plus du mot de passe classique, on peut avoir des cl\u00e9s statiques (codes de secours), OTP via e-mail, RADIUS externe, certificats TLS client, etc. Par exemple, LemonLDAP propose un module e-mail 2FA, et l\u2019authentification par annuaire (LDAP/AD) ou par certificat X.509 est possible comme facteur.</p> </li> </ul> <p>Chaque m\u00e9thode a ses usages : le  TOTP  reste standard pour un homelab,  WebAuthn  est recommand\u00e9 pour sa r\u00e9sistance au phishing (p. ex. connectez une YubiKey ou un smartphone pour vous authentifier)  . Les solutions self-hosted int\u00e8grent en g\u00e9n\u00e9ral ces MFA de base. Par exemple, Keycloak et Authentik autorisent TOTP et WebAuthn par d\u00e9faut  ; Authelia propose TOTP et WebAuthn/Passkeys et m\u00eame push  ; LemonLDAP autorise TOTP, WebAuthn et YubiKey OTP  . Lors de l\u2019int\u00e9gration, on configurera le flux d\u2019authentification pour exiger un second facteur en fonction du profil ou de la politique (par exemple \u00ab 2FA n\u00e9cessaire hors du r\u00e9seau local \u00bb).</p>"},{"location":"securite/authentification/#cas-dusage-dans-un-homelab","title":"Cas d\u2019usage dans un homelab","text":"<p>Voici comment ces solutions et m\u00e9thodes peuvent prot\u00e9ger des services typiques d\u2019un homelab :</p> <ul> <li> <p>Vaultwarden (Bitwarden)  : Vaultwarden supporte l\u2019authentification OIDC en tant que client. On peut configurer Vaultwarden pour d\u00e9l\u00e9guer l\u2019authentification \u00e0 un IdP tel qu\u2019Authelia ou Keycloak. Par exemple, avec Authelia on d\u00e9finit des variables d\u2019environnement pour activer le SSO et renseigner le client OIDC (client_id, secret, scopes, URL de redirection)  . Ainsi, l\u2019utilisateur se connecte via Authelia (avec MFA) puis Vaultwarden re\u00e7oit les jetons OIDC. Authelia fournit par exemple un guide d\u2019int\u00e9gration montrant l\u2019activation du SSO dans Vaultwarden (voir variables  SSO_ENABLED=true,  SSO_CLIENT_ID=..., etc.)  .</p> </li> <li> <p>Nextcloud  : Nextcloud peut \u00eatre configur\u00e9 comme  SP SAML  ou  RP OIDC. Avec Keycloak ou Authentik, on active le plugin \u201cOpenID Connect Login\u201d ou \u201cSSO/SAML\u201d. Nextcloud demandera les attributs utilisateurs (nom, e-mail, identifiant, \u00e9ventuellement groupe/quota). Par exemple, la documentation d\u2019Authentik d\u00e9crit l\u2019usage des scopes OIDC (email,  profile,  openid) et de mappings d\u2019attributs (groupes, quotas) via une \u00ab Property Mapping \u00bb pour Nextcloud  . Un point important : Nextcloud ne peut plus chiffrer c\u00f4t\u00e9 serveur si on n\u2019utilise pas LDAP (le mot de passe n\u2019est pas fourni en clair), donc il est recommand\u00e9 d\u2019utiliser LDAP pour le chiffrement ou bien de l\u2019abandonner si on fait du SSO OIDC/SAML  . L\u2019int\u00e9gration est largement document\u00e9e, et Nextcloud cr\u00e9era localement l\u2019utilisateur apr\u00e8s connexion unique.</p> </li> <li> <p>Proxmox VE  : Proxmox int\u00e8gre un  auth source  OIDC \u00e0 partir de la version 7+. On peut ajouter un \u00ab realm \u00bb OIDC via la commande  pveum realm add ... --type openid  en pr\u00e9cisant l\u2019URL du serveur d\u2019identit\u00e9s (Issuer URL), l\u2019ID et secret du client, le claim d\u2019utilisateur (par d\u00e9faut  username), et souvent l\u2019option  --autocreate 1  pour cr\u00e9er automatiquement les utilisateurs lors du premier login  . Par exemple, configurer Keycloak : on cr\u00e9e un client OIDC \u201cProxmox\u201d dans Keycloak (p. ex. ID \u201cpve\u201d), puis sur chaque n\u0153ud Proxmox : <pre><code>pveum realm add keycloak --type openid \\\n   --issuer-url https://auth.domaine/realms/homelab \\\n   --client-id pve --client-key &lt;secret&gt; \\\n   --username-claim username --autocreate 1\n</code></pre></p> </li> </ul> <p>pveum realm add keycloak --type openid \\    --issuer-url https://auth.domaine/realms/homelab \\    --client-id pve --client-key  \\    --username-claim username --autocreate 1 <pre><code>[auth.generic_oauth]\nenabled = true\nname = Keycloak\nallow_sign_up = true\nclient_id = VOTRE_ID_CLIENT\nclient_secret = VOTRE_SECRET\nscopes = openid email profile offline_access roles\nemail_attribute_path = email\nlogin_attribute_path = username\nauth_url = https://&lt;IDP&gt;/realms/homelab/protocol/openid-connect/auth\ntoken_url = https://&lt;IDP&gt;/realms/homelab/protocol/openid-connect/token\napi_url   = https://&lt;IDP&gt;/realms/homelab/protocol/openid-connect/userinfo\n</code></pre> <ul> <li> <p>Cet exemple (adapt\u00e9 de la doc officielle Grafana) montre comment pointer Grafana vers un IdP Keycloak  . Grafana obtient alors le login via Keycloak et peut mapper les r\u00f4les Keycloak sur ses r\u00f4les internes. Un processus similaire existe pour d\u2019autres outils (Chronograf, Kibana, etc.).</p> </li> <li> <p>Autres services  : On peut de la m\u00eame fa\u00e7on prot\u00e9ger Bitwarden, Paperless, Seafile, Vault, Homarr, etc. gr\u00e2ce aux int\u00e9grations OIDC ou via le proxy. Par exemple, Imihc (gestion de photos), Uptime Kuma, etc. poss\u00e8dent souvent une option \u00ab Authentification OIDC \u00bb ou bien on les place derri\u00e8re Authelia.</p> </li> </ul> <p>En r\u00e9sum\u00e9,  tous ces services b\u00e9n\u00e9ficient d\u2019une couche SSO/MFA commune. Plut\u00f4t que de g\u00e9rer un utilisateur local par application, l\u2019authentification est externalis\u00e9e vers l\u2019IdP : l\u2019utilisateur se logue une fois (avec MFA) sur l\u2019IdP, puis acc\u00e8de \u00e0 toutes les applis associ\u00e9es sans resaisir son mot de passe.</p>"},{"location":"securite/authentification/#architectures-type-avec-reverse-proxy-et-sso","title":"Architectures type avec reverse proxy et SSO","text":"<p>Une architecture fr\u00e9quente dans un homelab consiste \u00e0 placer un  reverse proxy  (NGINX, NGINX Proxy Manager, Traefik, Caddy, etc.) devant les applications, et \u00e0 d\u00e9l\u00e9guer l\u2019authentification \u00e0 un service SSO/MFA. Voici deux sch\u00e9mas courants :</p> <ul> <li>NGINX Proxy + Authelia (auth_request)  : NGINX joue le r\u00f4le de proxy frontal. On utilise la directive  auth_request  pour que NGINX interroge Authelia avant de laisser passer la requ\u00eate. Par exemple, dans une configuration de site NGINX:</li> </ul> <p><pre><code>location / {\n  auth_request /internal/authelia/authz;\n  ...\n}\nlocation = /internal/authelia/authz {\n  proxy_pass http://authelia:9091/api/verify?rd=https://$host$request_uri;\n  internal;\n}\n</code></pre> -   Dans cet exemple, chaque acc\u00e8s \u00e0 l\u2019application d\u00e9clenche un appel interne \u00e0 Authelia (/internal/authelia/authz). Authelia v\u00e9rifie la session/MFA et renvoie 200 (si autoris\u00e9) ou 401 (sinon). NGINX peut alors rediriger vers la page de login Authelia si n\u00e9cessaire. On r\u00e9cup\u00e8re aussi les en-t\u00eates  Remote-User/Groups/Email  avec  auth_request_setpour transmettre l\u2019identit\u00e9 \u00e0 l\u2019application prot\u00e9g\u00e9  . L\u2019int\u00e9gration NGINX/Authelia n\u00e9cessite le module  ngx_http_auth_request_module. Ce sch\u00e9ma permet d\u2019authentifier n\u2019importe quelle application web (m\u00eame sans support OIDC natif) via Authelia. L\u2019exemple officiel d\u2019Authelia montre un usage d\u2019auth_request /internal/authelia/authz;  et la r\u00e9cup\u00e9ration des variables  $remote_user,  $remote_groups  apr\u00e8s authentification  .</p> <ul> <li> <p>Traefik + Authelia (Forward Auth Middleware)  : Avec Traefik v2+, on configure Authelia comme  middleware de forward auth. On d\u00e9finit dans la stack Docker des labels Traefik pour activer l\u2019authentification. Par exemple (dans un  docker-compose.yml) : <pre><code>services:\n  authelia:\n    image: authelia/authelia\n    ...\n    labels:\n      # Route Authelia elle-m\u00eame\n      - traefik.enable=true\n      - traefik.http.routers.authelia.rule=Host(`auth.example.com`)\n      - traefik.http.routers.authelia.entrypoints=https\n      # D\u00e9finition du middleware Authelia (forwardAuth)\n      - traefik.http.middlewares.authelia.forwardAuth.address=http://authelia:9091/api/authz/forward-auth\n      - traefik.http.middlewares.authelia.forwardAuth.trustForwardHeader=true\n      - traefik.http.middlewares.authelia.forwardAuth.authResponseHeaders=Remote-User,Remote-Groups\n  app-secure:\n    image: traefik/whoami\n    labels:\n      - traefik.enable=true\n      - traefik.http.routers.whoami-secure.rule=Host(`whoami-secure.example.com`)\n      - traefik.http.routers.whoami-secure.entrypoints=https\n      - traefik.http.routers.whoami-secure.middlewares=authelia@docker\nnetworks:\n  proxy:\n  authelia:\n</code></pre></p> </li> <li> <p>Dans cet exemple, Traefik expose Authelia sur  auth.example.com. Le service  app-secure  (ici  whoami-secure) est prot\u00e9g\u00e9 par le middleware  authelia@docker  . Ce middleware appelle l\u2019endpoint Authelia (/api/authz/forward-auth) pour chaque requ\u00eate. Si l\u2019utilisateur n\u2019est pas authentifi\u00e9, il est redirig\u00e9 vers la page de login Authelia. Cette configuration montre l\u2019usage de  traefik.http.middlewares.authelia.forwardAuth.address: 'http://authelia:9091/api/authz/forward-auth'  pour d\u00e9finir l\u2019authentificateur  . C\u2019est un sch\u00e9ma tr\u00e8s modulable : toutes les applications derri\u00e8re Traefik peuvent \u00eatre prot\u00e9g\u00e9es ainsi (avec labels similaires).</p> </li> <li> <p>SSO via OIDC/LDAP  : Alternativement, certaines applications peuvent directement se connecter \u00e0 un IdP OIDC ou \u00e0 un annuaire. Par exemple, Nextcloud peut se lier en LDAP \u00e0 Keycloak/FreeIPA, ou agir en SP SAML/OIDC avec Keycloak. Dans ce cas, le \u201creverse proxy\u201d ne fait que la redirection initiale ; l\u2019authentification se fait dans l\u2019application via l\u2019IdP. Par exemple, un flux OIDC classique : l\u2019utilisateur acc\u00e8de \u00e0 l\u2019app (via proxy), l\u2019app le redirige vers Keycloak pour login, puis Keycloak redirige de retour avec un code. Ce mod\u00e8le requiert que l\u2019application cliente supporte OIDC/SAML (Grafana, Nextcloud, Jenkins, etc. ont ce support).</p> </li> </ul> <p>Ces architectures peuvent \u00eatre combin\u00e9es : ex. Keycloak (OIDC IdP) + Traefik + Authelia (pour les apps sans support OIDC). L\u2019id\u00e9e cl\u00e9 est d\u2019avoir  un point unique d\u2019authentification  (avec MFA) et des r\u00e8gles de proxy/redirection centralis\u00e9es.</p>"},{"location":"securite/authentification/#exemples-de-configuration","title":"Exemples de configuration","text":"<p>Voici quelques extraits concrets :</p> <ul> <li> <p>Docker Compose (Authelia + Traefik)  \u2013 Exemple simplifi\u00e9 tir\u00e9 d\u2019un guide officiel  : <pre><code>version: '3.8'\nservices:\n  traefik:\n    image: traefik:latest\n    command: --providers.docker\n    ports:\n      - '80:80'\n      - '443:443'\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.dashboard.rule=Host(`traefik.example.com`)\"\n      - \"traefik.http.routers.dashboard.entrypoints=https\"\n      - \"traefik.http.routers.dashboard.middlewares=authelia@docker\"\n  authelia:\n    image: authelia/authelia:latest\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.authelia.rule=Host(`auth.example.com`)\"\n      - \"traefik.http.routers.authelia.entrypoints=https\"\n      - \"traefik.http.middlewares.authelia.forwardAuth.address=http://authelia:9091/api/authz/forward-auth\"\n      - \"traefik.http.middlewares.authelia.forwardAuth.trustForwardHeader=true\"\n      - \"traefik.http.middlewares.authelia.forwardAuth.authResponseHeaders=Remote-User,Remote-Groups\"\n    volumes:\n      - ./authelia/config:/config\nnetworks:\n  proxy:\n    external: true\n  authelia:\n</code></pre></p> </li> <li> <p>Ici,  Authelia  est expos\u00e9e sur  auth.example.com  (router Authelia) et on d\u00e9finit un  middleware  Authelia (forwardAuth) utilis\u00e9 par le router  dashboard. Le middleware appellera  http://authelia:9091/api/authz/forward-auth. Ce sch\u00e9ma est similaire \u00e0 l\u2019exemple de l\u2019article Authelia  .</p> </li> <li> <p>Configuration NGINX (auth_request)  \u2013 Extrait type (d\u2019apr\u00e8s la documentation Authelia) pour prot\u00e9ger un site Nextcloud : <pre><code>server {\n  listen 443 ssl;\n  server_name cloud.example.com;\n  # TLS config omitted...\n  # Auth Request vers Authelia\n  location / {\n    auth_request /internal/authelia/authz;\n    auth_request_set $user  $upstream_http_remote_user;\n    auth_request_set $email $upstream_http_remote_email;\n    error_page 401 =302 https://auth.example.com/?rd=$request_uri;\n    # ...\n    proxy_pass http://nextcloud_backend;\n  }\n  location = /internal/authelia/authz {\n    internal;\n    proxy_pass http://authelia:9091/api/verify?rd=https://cloud.example.com$request_uri;\n  }\n}\n</code></pre></p> </li> <li> <p>Ce snippet montre l\u2019usage de  auth_request /internal/authelia/authz;  pour d\u00e9l\u00e9guer l\u2019authentification \u00e0 Authelia  . Les directives  auth_request_set  capturent l\u2019UID  $remote_user  et d\u2019autres en-t\u00eates renvoy\u00e9s par Authelia. En cas de non-autorisation (code 401), on redirige vers  auth.example.com  pour se logger (param\u00e8tre  rd  = redirect apr\u00e8s login). Cet exemple est inspir\u00e9 de la configuration recommand\u00e9e d\u2019Authelia pour NGINX  .</p> </li> <li> <p>Configuration Grafana (OIDC)  \u2013 Extrait du fichier  grafana.ini  pour Keycloak  :</p> </li> </ul> <p><pre><code>[auth.generic_oauth]\nenabled = true\nname = Keycloak-OAuth\nclient_id = pve-grafana\nclient_secret = VOTRE_SECRET\nscopes = openid email profile roles\nemail_attribute_path = email\nlogin_attribute_path = username\nauth_url  = https://keycloak.example.com/realms/homelab/protocol/openid-connect/auth\ntoken_url = https://keycloak.example.com/realms/homelab/protocol/openid-connect/token\napi_url   = https://keycloak.example.com/realms/homelab/protocol/openid-connect/userinfo\n</code></pre> -   Ce bloc configure Grafana pour utiliser Keycloak en OIDC. Il d\u00e9finit l\u2019auth_url  (point d\u2019autorisation OIDC), le  token_url, ainsi que  client_id/secret. Les attributs utilisateur (email,  username) sont mapp\u00e9s depuis les claims OIDC de Keycloak  .</p> <ul> <li>Options de cookies  \u2013 Les cookies de session et d\u2019authentification doivent \u00eatre s\u00e9curis\u00e9s. Il est recommand\u00e9 de d\u00e9finir le flag  Secure  (transmission seulement sur HTTPS) et  HttpOnly  (inaccessible aux scripts)  , ainsi que l\u2019attribut  SameSite=Lax  (ou Strict) pour mitiger le CSRF  . Par exemple, dans la config Authelia, on pr\u00e9cise :</li> </ul> <p><pre><code>session:\n  cookies:\n    - name: authelia_session\n      domain: example.com\n      same_site: lax\n      secure: true\n      http_only: true\n</code></pre> -   Cela suit les bonnes pratiques OWASP sur la gestion de session  . De m\u00eame, limiter le  Domain  \u00e0 l\u2019exact domaine \u00e9vite le partage de cookies entre sous-domaines  .</p>"},{"location":"securite/authentification/#resume","title":"R\u00e9sum\u00e9","text":"<p>Pour un homelab self-hosted, il est possible de mettre en place un  syst\u00e8me centralis\u00e9 de comptes  avec MFA en utilisant uniquement des solutions open-source. En fonction des besoins et de la taille de l\u2019installation, on choisira par exemple Keycloak ou Authentik pour un IdP complet (avec OIDC/SAML/LDAP), ou Authelia/LemonLDAP::NG pour une approche plus \u201cproxy-based\u201d. Les m\u00e9thodes MFA standard (TOTP, WebAuthn, YubiKey, etc.) sont g\u00e9n\u00e9ralement support\u00e9es par ces outils  . On int\u00e8gre ensuite les applications (Vaultwarden, Nextcloud, Proxmox, Grafana\u2026) derri\u00e8re un reverse-proxy (NGINX, Traefik) configur\u00e9 pour rediriger les utilisateurs vers le fournisseur d\u2019identit\u00e9s. Des exemples de configuration docker-compose, NGINX/Trafik labels et directives d\u2019authentification ont \u00e9t\u00e9 pr\u00e9sent\u00e9s pour illustrer ce mod\u00e8le. Cette architecture  SSO + MFA  am\u00e9liore nettement la s\u00e9curit\u00e9 (mot de passe unique, double facteur, cookies prot\u00e9g\u00e9s) tout en offrant une exp\u00e9rience utilisateur fluide.</p>"},{"location":"securite/segmentation/","title":"Segmentation r\u00e9seau et honeypots dans un homelab Blue Team","text":"<p>La  segmentation r\u00e9seau  est une pratique cl\u00e9 de la d\u00e9fense en profondeur : elle consiste \u00e0 diviser le r\u00e9seau en zones isol\u00e9es (VLAN, DMZ, sous-r\u00e9seaux physiques) pour limiter la propagation d\u2019une attaque. Comme le souligne l\u2019OWASP, la segmentation est \u00ab au c\u0153ur de la d\u00e9fense en profondeur \u00bb, car elle permet de construire une architecture s\u00e9curis\u00e9e et isol\u00e9e. En pratique, on cr\u00e9e au minimum plusieurs \u00ab zones de confiance \u00bb (LAN interne, DMZ publique, r\u00e9seau des serveurs, etc.), chacune prot\u00e9g\u00e9e par un pare-feu (firewall). Par exemple, pfSense (open-source) peut \u00eatre utilis\u00e9 comme pare-feu/routeur principal : il prend en charge les VLANs, le NAT et les DMZ et peut m\u00eame int\u00e9grer des IDS/IPS (Snort ou Suricata). Un conseil \u00e9prouv\u00e9 est d\u2019isoler physiquement les zones de confiance : utiliser deux commutateurs distincts (un pour le WAN/DMZ et un pour les r\u00e9seaux internes) afin qu\u2019une mauvaise configuration de VLAN ne relie pas accidentellement Internet au LAN interne. On \u00e9vitera aussi d\u2019utiliser le VLAN 1 natif pour le trafic de donn\u00e9es, car les protocoles de gestion r\u00e9seau y transitent en clair.</p> <p>Dans cette architecture, on d\u00e9finit souvent une  DMZ  (zone d\u00e9militaris\u00e9e) en bordure : c\u2019est un r\u00e9seau isol\u00e9 expos\u00e9 \u00e0 Internet, devant lequel se situent les services publics. Les honeypots sont id\u00e9alement d\u00e9ploy\u00e9s en DMZ ou dans des segments \u00ab leurres \u00bb d\u00e9di\u00e9s, afin de pi\u00e9ger les attaquants sans compromettre le c\u0153ur du LAN. Conform\u00e9ment aux bonnes pratiques, chaque trafic externe qui p\u00e9n\u00e8tre la DMZ doit passer par le pare-feu, et tout trafic de la DMZ vers le r\u00e9seau interne est fortement filtr\u00e9. Les VLANs sur le commutateur et les r\u00e8gles de firewall pfSense garantissent ce cloisonnement. Par exemple, dans un homelab, on peut cr\u00e9er un VLAN  DMZ  pour les honeypots et un VLAN  Production  pour les serveurs sensibles, le tout sur pfSense en configurant les interfaces virtuelles et les r\u00e8gles de pare-feu appropri\u00e9es. Les honeypots (machines factices) n\u2019ont alors acc\u00e8s qu\u2019\u00e0 la DMZ et \u00e9ventuellement \u00e0 Internet, mais pas au LAN interne.</p>"},{"location":"securite/segmentation/#honeypots-et-systemes-de-leurre","title":"Honeypots et syst\u00e8mes de leurre","text":"<p>Un  honeypot  (ou \u00ab pot de miel \u00bb) est un dispositif ou service factice destin\u00e9 \u00e0 attirer les attaquants pour \u00e9tudier leur comportement et g\u00e9n\u00e9rer des alertes. C\u2019est un leurre cens\u00e9 para\u00eetre vuln\u00e9rable afin de d\u00e9tourner et pi\u00e9ger l\u2019intrus. Comme l\u2019explique Ben Lutkevich (TechTarget), un honeypot est \u00ab un dispositif r\u00e9seau qui trompe les hackers en leur faisant croire qu\u2019ils ont p\u00e9n\u00e9tr\u00e9 un vrai r\u00e9seau, alors qu\u2019en r\u00e9alit\u00e9 ils sont dans un syst\u00e8me isol\u00e9 con\u00e7u comme pi\u00e8ge \u00bb. Concr\u00e8tement, le honeypot \u00e9mule des services courants (SSH, HTTP, FTP, etc.) avec de fausses donn\u00e9es pour sembler r\u00e9aliste. L\u2019attaquant y croira, ce qui permet de  d\u00e9tecter  et d\u2019analyser  ses actions en profondeur. Id\u00e9alement, on le place dans la DMZ (ou dans un segment isol\u00e9) : un firewall s\u00e9pare la DMZ du r\u00e9seau interne pour \u00e9viter toute propagation, comme le r\u00e9sume TechTarget, \u00ab la DMZ est une zone tampon s\u00e9curis\u00e9e qui isole le r\u00e9seau interne d\u2019Internet \u00bb. Le honeypot appara\u00eet alors depuis l\u2019ext\u00e9rieur comme un composant vuln\u00e9rable de ce r\u00e9seau public, attirant l\u2019attaquant. Une fois pi\u00e9g\u00e9, on le laisse agir suffisamment longtemps pour collecter un maximum d\u2019informations sur ses techniques (attaques r\u00e9seau, scans de ports, brute force SSH, etc.).</p> <p>Il existe plusieurs types de honeypots :  low-interaction  (simples services factices),  medium-interaction  (\u00e9mulent plusieurs services) et  high-interaction  (machines virtuelles enti\u00e8res, tr\u00e8s r\u00e9alistes mais complexes). Dans un homelab Blue Team, on emploie souvent des honeypots de type moyen : par exemple  Cowrie, un honeypot SSH/Telnet open-source tr\u00e8s populaire, qui enregistre toutes les tentatives de connexion et les commandes tap\u00e9es par l\u2019attaquant. D\u2019autres outils comme  Glastopf  (pi\u00e8ge web),  Conpot  (pour syst\u00e8mes industriels) ou l\u2019\u00ab ensemble \u00bb Modern Honey Network/T-Pot peuvent \u00eatre utilis\u00e9s pour couvrir diff\u00e9rents protocoles. Une pratique recommand\u00e9e est de d\u00e9ployer un honeypot sur chaque segment interne critique. H\u00e9ctor Herrero (blog Bujarra) sugg\u00e8re ainsi de \u00ab d\u00e9ployer un honeypot l\u00e9ger dans chaque segment de r\u00e9seau que nous avons\u2026 pour d\u00e9tecter les curieux, bots ou scans de ports sur notre r\u00e9seau interne \u00bb.</p> <p>Les honeypots fournissent des informations pr\u00e9cieuses sur les tactiques des attaquants. Leurs journaux (logs) peuvent \u00eatre centralis\u00e9s dans un SIEM (par ex. ELK, Graylog, Wazuh) pour corr\u00e9lation. Par exemple, un laboratoire de type  SOC homelab  met souvent un honeypot web (DVWA) et un honeypot SSH (Cowrie) en DMZ, et enregistre automatiquement toute activit\u00e9 dans le SIEM. Un tel sc\u00e9nario est d\u00e9crit par Ankeshraj (mai 2025) : \u00ab la zone publique DMZ pr\u00e9sente un double honeypot : DVWA dans un conteneur Docker et un serveur SSH Cowrie. Toute activit\u00e9 attaquante y est enregistr\u00e9e et remont\u00e9e vers le SOC \u00bb. Cette combinaison permet au Blue Team de s\u2019entra\u00eener : par exemple, tout scan ou brute force d\u00e9tect\u00e9 sur le honeypot g\u00e9n\u00e8re imm\u00e9diatement une alerte. Pendant ce temps, le honeypot \u00e9tant isol\u00e9, l\u2019attaquant n\u2019atteint pas les vrais serveurs internes.</p>"},{"location":"securite/segmentation/#outils-cles-pour-la-segmentation-et-la-detection","title":"Outils cl\u00e9s pour la segmentation et la d\u00e9tection","text":"<ul> <li> <p>pfSense (pare-feu/routeur) : distribution BSD open-source tr\u00e8s r\u00e9pandue pour la s\u00e9curisation des r\u00e9seaux. Elle prend en charge les VLANs, la DMZ, le NAT et offre de nombreux packages (comme Snort/Suricata en IDS/IPS). En d\u2019autres termes, \u00ab pfSense peut jouer un r\u00f4le d\u2019IDS/IPS gr\u00e2ce \u00e0 des paquets comme Snort et Suricata \u00bb. On l\u2019installe typiquement sur une machine d\u00e9di\u00e9e (PC, appliance ou VM) avec plusieurs interfaces r\u00e9seau (WAN, LAN, DMZ) ou en mode tronc (802.1Q) pour g\u00e9rer les VLANs. Les r\u00e8gles de firewall pfSense d\u00e9finissent quelles communications sont permises entre les zones (typiquement, bloquer tout trafic entrant vers le LAN sauf VPN, n\u2019autoriser que ce qui est n\u00e9cessaire vers la DMZ, etc.). Le package  Suricata  de pfSense offre de l\u2019IDS/IPS en temps r\u00e9el.</p> </li> <li> <p>Suricata (IDS/IPS) : syst\u00e8me open-source d\u2019inspection r\u00e9seau tr\u00e8s performant. Il s\u2019agit d\u2019un moteur  Network Security Monitoring  (NSM) capable de surveiller tout le trafic d\u2019une interface en mode promiscuous, de l\u2019analyser selon des signatures et d\u2019\u00e9mettre des alertes en cas de d\u00e9tection d\u2019une menace connue. Suricata g\u00e8re de nombreux protocoles et permet, en mode IDS, de journaliser des \u00e9v\u00e9nements suspects, ou en mode IPS, de bloquer des paquets. Son atout est sa versatilit\u00e9 (grand volume de trafic, r\u00e8gles personnalisables). Suricata s\u2019int\u00e8gre facilement dans un homelab (via pfSense ou en VM/container d\u00e9di\u00e9e) et alimente le SIEM en alertes NIDS.</p> </li> <li> <p>Cowrie (honeypot SSH/Telnet) : honeypot Python tr\u00e8s utilis\u00e9 pour pi\u00e9ger les attaquants sur les services SSH et Telnet. Cowrie enregistre les frappes clavier et les transferts de fichiers (wget, scp, sftp), fournissant un journal d\u00e9taill\u00e9 des actions de l\u2019attaquant. Comme le note la documentation officielle, \u00ab Cowrie est un honeypot SSH/Telnet (de faible \u00e0 moyenne interaction) con\u00e7u pour journaliser les attaques par bruteforce et les interactions en shell ex\u00e9cut\u00e9es par l\u2019attaquant \u00bb. Cowrie simule un vrai shell Unix (avec un faux syst\u00e8me de fichiers) : par exemple, un attaquant pourra voir un fichier factice  <code>/etc/passwd</code>. Cowrie existe aussi sous forme d\u2019image Docker sur Docker Hub. Par exemple, on peut rapidement tester Cowrie en lan\u00e7ant  <code>docker run -p 2222:2222 cowrie/cowrie:latest</code>. Cette portabilit\u00e9 Docker facilite son d\u00e9ploiement dans des containers isol\u00e9s sur le homelab.</p> </li> <li> <p>VLAN (segmentation par commutateurs) : technique incontournable pour isoler plusieurs r\u00e9seaux sur un m\u00eame switch g\u00e9r\u00e9. En homelab, on attribue diff\u00e9rents ID VLAN aux ports/sous-interfaces pour s\u00e9parer physiquement (au niveau L2) les flux. Par exemple, le VLAN 10 pour le LAN interne, VLAN 20 pour les honeypots, VLAN 30 pour l\u2019IOT, etc. PfSense prend en charge les VLAN IEEE 802.1Q sur une interface. La documentation pfSense rappelle que les VLANs \u00ab segmentent un r\u00e9seau et isolent des sous-r\u00e9seaux \u00bb, mais qu\u2019il faut prendre garde aux configurations (ex.  VLAN hopping  si on n\u2019\u00e9loigne pas le trafic non marqu\u00e9 VLAN 1). Par ailleurs, on appliquera les bonnes pratiques : ne pas laisser le VLAN 1 par d\u00e9faut servir au trafic de donn\u00e9es et prot\u00e9ger physiquement les ports en tronc (voir Doc pfSense).</p> </li> <li> <p>Docker/VM/LXC (virtualisation et conteneurs) : les technologies de conteneurisation simplifient le d\u00e9ploiement de nombreuses briques. Par exemple, un honeypot comme Cowrie peut tourner dans un container Docker (image publique), facilement reli\u00e9 \u00e0 un r\u00e9seau d\u00e9di\u00e9 via le pont Docker. On peut aussi d\u00e9ployer des appliances virtuelles dans des VM ou LXC pour simuler des vuln\u00e9rabilit\u00e9s (ex : DVWA, OWASP Juice Shop, un serveur Windows vuln\u00e9rable, etc.). Les environnements comme Proxmox LXC/VM ou VMware permettent de cr\u00e9er plusieurs VMs interconnect\u00e9es par VLANs virtuels. Un homelab typique pourrait lancer un pfSense en VM (ou sur un Proxmox LXC avec bridged NIC), des serveurs Linux/Windows en VM, et divers conteneurs Docker pour les honeypots ou outils d\u2019analyse. Tout ceci est ensuite c\u00e2bl\u00e9 (virtuellement) derri\u00e8re le firewall pfSense ou un routeur logiciel afin de respecter la segmentation. Par exemple, la mise en place du honeypot \u00ab Cam\u00e9l\u00e9on \u00bb d\u00e9crite par Bujarra utilise Docker pour d\u00e9ployer plusieurs honeypots (DNS, HTTP, SSH, etc.) dans un conteneur unique, expos\u00e9 sur un port standard.</p> </li> </ul>"},{"location":"securite/segmentation/#cas-dusage-typiques-en-homelab-blue-team","title":"Cas d\u2019usage typiques en homelab Blue Team","text":"<ul> <li> <p>Attirer et observer les attaquants : le honeypot sert de leurre pour d\u00e9tecter des scans et intrusions. Lorsqu\u2019un malware ou un attaquant essaye de scanner le r\u00e9seau, il tombe d\u2019abord sur le honeypot isol\u00e9. Les connexions sont consign\u00e9es (connexion SSH rat\u00e9e dans Cowrie, requ\u00eates HTTP malicieuses sur un honeypot web, tentatives de login sur un serveur factice, etc.). Le Blue Team peut alors investiguer \u00e0 partir de ces journaux. Dans un lab comme celui d\u2019Orange (GOAT Lab), l\u2019objectif est pr\u00e9cis\u00e9ment de \u00ab simuler des attaques et capturer des indicateurs de compromission pour entra\u00eener la d\u00e9tection \u00bb. La segmentation permet ici de contenir toute attaque dans la zone \u00ab trompe-l\u2019\u0153il \u00bb, sans risque pour l\u2019infrastructure r\u00e9elle.</p> </li> <li> <p>D\u00e9tection d\u2019intrusion r\u00e9seau (NIDS) : avec Suricata ou Snort activ\u00e9 sur le firewall (pfSense) ou sur un segment r\u00e9seau (port mirroring), on surveille en parall\u00e8le le trafic de chaque VLAN. Suricata d\u00e9tectera par exemple un balayage de ports, des tentatives de signature connues (ex. CVE exploit, pattern de ransomware en action) et g\u00e9n\u00e9rera des alertes. Ces alertes, agr\u00e9g\u00e9es par le SIEM, compl\u00e8tent celles du honeypot. Par exemple, si le honeypot SSH (Cowrie) enregistre des tentatives de brute force, Suricata pourra observer ces m\u00eames paquets et confirmer l\u2019attaque. Ces corr\u00e9lations aident \u00e0 affiner les r\u00e8gles.</p> </li> <li> <p>Segmentation de l\u2019IoT et des environnements critiques : dans un homelab, on pratique souvent la r\u00e8gle de distinguer les machines fragiles (p\u00e9riph\u00e9riques IOT, HomeAssistant, cameras) du r\u00e9seau professionnel simul\u00e9. Ces p\u00e9riph\u00e9riques IOT sont plac\u00e9s sur un VLAN isol\u00e9, sans acc\u00e8s direct aux serveurs internes. On y applique des r\u00e8gles stricte (ex. seulement acc\u00e8s Internet et acc\u00e8s limit\u00e9 au NAS), \u00e9vitant qu\u2019une compromission d\u2019un capteur ne donne un pivot facile vers le c\u0153ur du r\u00e9seau. C\u2019est l\u2019application du principe Zero Trust et du \u00ab least privilege \u00bb r\u00e9seau.</p> </li> <li> <p>Automatisation et alerting : les honeypots et IDS sont configur\u00e9s pour remonter automatiquement les alertes vers la plateforme centrale (ex. Graylog, ELK/Wazuh). Par exemple, un simple script peut envoyer par email ou par Slack une alerte d\u00e8s qu\u2019un honeypot est touch\u00e9. Ainsi, m\u00eame dans un cadre d\u2019apprentissage, on peut tester des playbooks de r\u00e9ponse (isoler la machine compromise, v\u00e9rifier logs, etc.).</p> </li> </ul>"},{"location":"securite/segmentation/#installation-et-architecture-type","title":"Installation et architecture type","text":"<p>Pour un homelab Blue Team, on pr\u00e9conise g\u00e9n\u00e9ralement une architecture multi-VM/containeurs :</p> <ul> <li> <p>Firewall / Routeur principal : ex\u00e9cutez pfSense sur une VM (KVM, VMware, Proxmox) ou sur du mat\u00e9riel d\u00e9di\u00e9. Il aura au moins deux NIC : WAN (vers l\u2019Internet ou un routeur upstream) et LAN (r\u00e9seau interne). Le LAN physique est souvent reli\u00e9 \u00e0 un switch manag\u00e9 (ou aux bridges Proxmox) qui a un port trunk lui permettant de transporter plusieurs VLAN vers le LAN.</p> </li> <li> <p>Switch virtuel / VLANs : si vous utilisez Proxmox ou ESXi, cr\u00e9ez des r\u00e9seaux virtuels (VLAN 10, 20\u2026) associ\u00e9s \u00e0 des bridges. Branchez les VMs honeypots et IoT sur les VLANs correspondants. Par exemple, choisissez VLAN 100 pour DMZ/honeypots et VLAN 200 pour IoT. Dans pfSense, cr\u00e9ez les interfaces VLAN correspondantes li\u00e9es \u00e0 votre interface physique LAN.</p> </li> <li> <p>Honeypots : par exemple, lancez Cowrie dans un conteneur Docker sur le r\u00e9seau VLAN 100 (DMZ). C\u2019est simple avec la commande Docker officielle :  <code>docker run -d --name cowrie -p 2222:2222 cowrie/cowrie:latest</code>. De m\u00eame, vous pouvez d\u00e9ployer d\u2019autres honeypots (Glastopf pour pi\u00e8ge web, Dionaea pour SMB/TFTP, Cam\u00e9l\u00e9on multi-honeypot, etc.) sur le m\u00eame VLAN isol\u00e9. Dans pfSense, cr\u00e9ez une r\u00e8gle qui n\u2019autorise par d\u00e9faut aucune connexion du WAN vers ce VLAN, sauf peut-\u00eatre les ports sp\u00e9cifi\u00e9s (1:1 NAT ou forwarding pour rendre le honeypot accessible de l\u2019ext\u00e9rieur). Id\u00e9alement, chaque honeypot a une IP priv\u00e9e fixe dans le VLAN DMZ.</p> </li> <li> <p>Serveurs internes : VMs Windows/Linux sur le VLAN interne (ex. VLAN 1 LAN). Installez sur chacun des agents de collecte de logs (Filebeat/Winlogbeat) afin d\u2019alimenter la plateforme de SIEM. Vous pouvez aussi h\u00e9berger un serveur de simulation d\u2019entreprise (Active Directory, base de donn\u00e9es) sur ce r\u00e9seau isol\u00e9.</p> </li> <li> <p>Suricata / IDS : installez Suricata soit directement sur pfSense (package) soit sur une VM d\u00e9di\u00e9e en mode tap/mirroring. Configurez-le pour surveiller le trafic entrant. Les alertes seront envoy\u00e9es au SIEM.</p> </li> <li> <p>SIEM et visualisation : d\u00e9ployez une stack ELK/Graylog/Wazuh dans le LAN pour collecter et analyser les logs (y compris ceux g\u00e9n\u00e9r\u00e9s par les honeypots et Suricata). Par exemple, Graylog peut ing\u00e9rer les fichiers JSON de Cowrie pour les requ\u00eates SSH. Kibana/Wazuh offre des dashboards de conformit\u00e9 pour visualiser les alertes.</p> </li> </ul> <p>Cette architecture peut \u00eatre construite avec des conteneurs Docker : pfSense ne s\u2019ex\u00e9cute pas en container, mais ses \u00e9quivalents peuvent (ex. OPNsense). En pratique, on utilisera souvent pfSense sur une VM et tout le reste en conteneurs. Des solutions  prepackaged  existent : par exemple le stack Docker (contenant aussi souvent Filebeat). Ainsi, en quelques  <code>docker-compose up</code>, on obtient un environnement complet.</p>"},{"location":"securite/segmentation/#recommandations-et-bonnes-pratiques","title":"Recommandations et bonnes pratiques","text":"<ul> <li> <p>Defense en profondeur : gardez un principe \u00ab deny by default \u00bb. N\u2019ouvrez que les ports indispensables entre zones. Par exemple, isoler la DMZ: du r\u00e9seau interne on peut autoriser l\u2019administration SSH/VPN du pfSense, mais en aucun cas laisser la DMZ initier des connexions vers le LAN.</p> </li> <li> <p>Mat\u00e9riel et ressources : m\u00eame pour un homelab, privil\u00e9giez de la RAM et du SSD rapide. Suricata et Elasticsearch sont gourmands en m\u00e9moire. pfSense avec IDS et VPN requiert au moins 2 Go de RAM, mieux 4 Go. Suricata b\u00e9n\u00e9ficiera de c\u0153urs CPU multiples pour l\u2019inspection. Un h\u00f4te de 8 Go de RAM peut suffire pour un petit lab.</p> </li> <li> <p>Mises \u00e0 jour et maintenance : tenez \u00e0 jour vos listes de r\u00e8gles Suricata/Snort (EmergingThreats, Snort VRT). Mettez r\u00e9guli\u00e8rement \u00e0 jour Cowrie (pour ne pas \u00eatre identifi\u00e9 comme honeypot obsol\u00e8te). Sauvegardez la config de pfSense (pr\u00e9f\u00e9rer la sauvegarde automatique). Surveillez l\u2019occupation disque (les logs peuvent rapidement cro\u00eetre ; purgez ou archivez r\u00e9guli\u00e8rement).</p> </li> <li> <p>S\u00e9curit\u00e9 interne : m\u00eame les honeypots doivent \u00eatre durcis pour \u00e9viter d\u2019\u00eatre compromis et servir de tremplin. Par exemple, utilisez un honeypot non rout\u00e9 vers le LAN, ou en mode \u00ab console only \u00bb. Suricata et le firewall de l\u2019h\u00f4te doivent emp\u00eacher toute connexion sortante non g\u00e9r\u00e9e. Activez TLS/SSL pour pfSense et tout acc\u00e8s admin, et appliquez l\u2019authentification \u00e0 deux facteurs si possible.</p> </li> <li> <p>Formation et exercices : profitez de ce lab pour pratiquer des sc\u00e9narios Blue Team. Par exemple, simulez une infection sur l\u2019h\u00f4te Honeypot et v\u00e9rifiez que Suricata la d\u00e9tecte. Orchestrez des attaques (port scans, bruteforce SSH) pour tester l\u2019alerte et la r\u00e9ponse automatis\u00e9e (playbooks Ansible ou scripts de rem\u00e9diation). L\u2019environnement GOAT Lab d\u2019Orange (un lab d\u2019entrainement offensif) illustre ce principe : chaque outil (pfSense, honeypot, IDS) y joue un r\u00f4le afin d\u2019enseigner \u00e0 l\u2019ing\u00e9nieur le cycle d\u00e9tection-r\u00e9ponse.</p> </li> </ul> <p>En r\u00e9sum\u00e9, pour un homelab d\u00e9fensif orient\u00e9 Blue Team, on combinera  pare-feu segment\u00e9 (pfSense + VLAN),  IDS/IPS (Suricata)  et  honeypots (Cowrie, etc.)  dans un r\u00e9seau compartiment\u00e9. Cette combinaison permet de collecter de fa\u00e7on fiable les journaux de s\u00e9curit\u00e9 et de g\u00e9n\u00e9rer des alertes pertinentes. L\u2019accent est mis sur la fiabilit\u00e9 de la collecte et la clart\u00e9 des alertes. Chaque segment doit \u00eatre isol\u00e9 et les flux strictement contr\u00f4l\u00e9s. Comme le pr\u00e9conise l\u2019OWASP : la segmentation r\u00e9seau, alli\u00e9e au principe du moindre privil\u00e8ge, est un moyen de  construire une architecture s\u00e9curis\u00e9e o\u00f9 chaque segment reste aussi isol\u00e9 que possible</p>"},{"location":"securite/siem/","title":"Comparaison Wazuh, ELK Stack et Graylog pour un homelab Blue Team","text":"<p>Wazuh, ELK et Graylog  sont trois solutions open source de gestion de logs et de SIEM souvent utilis\u00e9es par des Blue Teams. Elles couvrent la collecte centralis\u00e9e de logs (Linux, Windows, r\u00e9seau), l\u2019analyse en temps r\u00e9el, la d\u00e9tection d\u2019intrusion et les alertes. Chacune a une architecture et des forces propres : Wazuh est une plateforme HIDS (sur base d\u2019OSSEC) avec agents et d\u00e9tection int\u00e9gr\u00e9e,  ELK Stack  (Elasticsearch, Logstash, Kibana) est un \u00e9cosyst\u00e8me de recherche et de visualisation massif, et Graylog est un syst\u00e8me de log management avec interface unifi\u00e9e. Nous d\u00e9taillons ci-dessous leur architecture, fonctionnalit\u00e9s, cas d\u2019usage, besoins en ressources et recommandations.</p>"},{"location":"securite/siem/#architecture-generale","title":"Architecture g\u00e9n\u00e9rale","text":"<p>Architecture typique de Wazuh (agents l\u00e9gers sur chaque h\u00f4te, serveur central et indexeurs Elasticsearch/OpenSearch) (source : documentation Wazuh).  Wazuh est bas\u00e9 sur des  agents install\u00e9s sur chaque endpoint  (Windows, Linux, Mac) qui collectent les logs syst\u00e8me, fichiers modifi\u00e9s, \u00e9v\u00e9nements de s\u00e9curit\u00e9, etc., et les envoient au serveur Wazuh central  . Le serveur Wazuh re\u00e7oit ces donn\u00e9es, les d\u00e9code et les analyse avec son moteur de r\u00e8gles IDS/IPS int\u00e9gr\u00e9, g\u00e9n\u00e9rant des alertes en cas d\u2019\u00e9v\u00e9nements suspects. Wazuh g\u00e8re ensuite l\u2019acheminement de ces \u00e9v\u00e9nements vers un cluster  Elasticsearch/OpenSearch  (appel\u00e9 \u00ab indexer \u00bb) via Filebeat et TLS  . La solution comprend aussi une interface web (Wazuh Dashboard) pour configurer et visualiser l\u2019\u00e9tat du serveur et des agents. En version minimale, un seul serveur Wazuh et un n\u0153ud indexeur peuvent suffire, mais pour de plus grands volumes ou haute-disponibilit\u00e9 on s\u00e9pare Wazuh serveur et indexeurs sur des machines distinctes  .</p> <p>En revanche,  Graylog  ne repose pas sur ses propres agents. Un d\u00e9ploiement de base (Core Deployment) comprend un ou deux serveurs (\u00ab Graylog server \u00bb) qui int\u00e8grent toutes les fonctions (serveur Graylog, n\u0153ud d\u2019indexation Elasticsearch/OpenSearch, et base MongoDB pour les m\u00e9tadonn\u00e9es)  . Ce sch\u00e9ma \u00ab tout-en-un \u00bb est simple \u00e0 installer pour un lab mais peu \u00e9volutif. Graylog re\u00e7oit des logs via des  inputs  configurables : syslog (TCP/UDP), GELF (protocole maison), Beats, JDBC, etc. Les donn\u00e9es sont rout\u00e9es en temps r\u00e9el vers le n\u0153ud d\u2019indexation (Elasticsearch/OpenSearch) via des  streams  et pipelines de traitement. Pour monter en charge (volumes de logs ou utilisateurs multiples), on peut \u00e9voluer vers un d\u00e9ploiement conventionnel ou distribu\u00e9 : les composants Graylog (serveur, n\u0153uds de donn\u00e9es, MongoDB) sont r\u00e9partis sur plusieurs machines, assurant haute disponibilit\u00e9 et scalabilit\u00e9  .</p> <p>Elastic Stack (ELK)  a une architecture modulaire : Elasticsearch forme un cluster de n\u0153uds pour stocker et rechercher les logs (indices distribu\u00e9s), Logstash est un pipeline de transformation flexible, et Kibana est l\u2019interface web. En pratique, on utilise souvent  Beats  (Filebeat, Winlogbeat, etc.) comme agents l\u00e9gers c\u00f4t\u00e9 h\u00f4te pour exp\u00e9dier directement les logs vers Elasticsearch (voire via Logstash pour enrichissement)  . Il n\u2019y a pas de  serveur SIEM  unique dans ELK, mais on peut imaginer un sch\u00e9ma similaire : plusieurs n\u0153uds Elasticsearch (avec r\u00e9partition en shards/r\u00e9plicas), au moins un Logstash pour pr\u00e9traitement, et Kibana pour la visualisation. Dans un homelab, on peut se contenter d\u2019un seul n\u0153ud Elastic et un Kibana. Un sch\u00e9ma Docker pr\u00e9-packag\u00e9 (comme [deviantony/docker-elk]  ) facilite l\u2019installation exp\u00e9rimentale.</p> <p>Tableau 1. Comparaison de l\u2019architecture et des composants</p> <p>TABLEAU</p>"},{"location":"securite/siem/#collecte-de-logs-et-agents","title":"Collecte de logs et agents","text":"<ul> <li> <p>Wazuh  utilise ses  agents l\u00e9gers  multi-plateformes pour recueillir logs syst\u00e8me, journaux de s\u00e9curit\u00e9, changements de fichiers, etc. en continu. Les agents chiffrent les donn\u00e9es (AES-128/256 par d\u00e9faut  ) et ouvrent une connexion s\u00e9curis\u00e9e (port 1514/TCP) vers le serveur Wazuh. Ils envoient tous les \u00e9v\u00e9nements, qui sont ensuite d\u00e9cod\u00e9s (analyse de texte, r\u00e8gles) sur le serveur. Wazuh peut aussi collecter de mani\u00e8re  agentless  (par ex. via syslog UDP/TCP ou SSH pour \u00e9quipements r\u00e9seau)  .</p> </li> <li> <p>ELK Stack  ne fournit pas d\u2019agent propri\u00e9taire, mais repose sur  Beats  (Filebeat pour logs texte, Winlogbeat pour journaux Windows, Metricbeat, etc.) ou Logstash pour r\u00e9cup\u00e9rer les logs. En homelab, on d\u00e9ploie souvent des Filebeat/Winlogbeat sur les machines cibles afin d\u2019exp\u00e9dier les logs vers Elasticsearch. On peut aussi configurer Logstash ou syslog pour \u00e9couter des flux. La flexibilit\u00e9 de Logstash permet d\u2019enrichir ou filtrer les donn\u00e9es, m\u00eame si beaucoup d\u2019utilisateurs optent pour des alternatives plus l\u00e9g\u00e8res (Fluentd, Vector)  .</p> </li> <li> <p>Graylog  ne requiert pas d\u2019agent exclusif. Il accepte les logs en entr\u00e9e via divers protocoles : syslog (UDP/TCP), GELF (Graylog Extended Log Format), Beats, Kafka, etc. Une m\u00e9thode courante est d\u2019utiliser le \u00ab Graylog Sidecar \u00bb pour configurer et lancer automatiquement Filebeat/NxLog selon Graylog. L\u2019interface Graylog permet de cr\u00e9er des  Inputs  pour chaque protocole, puis de router ces messages vers des  Streams  qui filtrent et taggent les donn\u00e9es en temps r\u00e9el  .</p> </li> </ul> <p>Ainsi, en  homelab, on pourra utiliser par exemple :</p> <ul> <li> <p>Wazuh Agent sur les serveurs Linux/Windows et Linux : collecte de logs / HIDS (d\u00e9tection d\u2019intrusion).</p> </li> <li> <p>Filebeat/Winlogbeat directes vers Elastic ou Graylog (plus g\u00e9n\u00e9rique)  .</p> </li> <li> <p>Syslog/Fluentd pour les \u00e9quipements r\u00e9seau ou appareils moins compatibles avec un agent.</p> </li> </ul>"},{"location":"securite/siem/#detection-analyse-et-tableaux-de-bord","title":"D\u00e9tection, analyse et tableaux de bord","text":"<ul> <li> <p>Wazuh  est avant tout un HIDS : il analyse les logs des agents \u00e0 la recherche de signatures d\u2019attaque, modifications non autoris\u00e9es (file integrity monitoring), rootkits, vuln\u00e9rabilit\u00e9s connues, etc. Il embarque des milliers de r\u00e8gles pr\u00e9d\u00e9finies (CVE, MITRE, directives de s\u00e9curit\u00e9) et permet d\u2019\u00e9crire ses propres d\u00e9codeurs/r\u00e8gles  . Lorsqu\u2019une r\u00e8gle d\u00e9clenche, Wazuh g\u00e9n\u00e8re une alerte prioris\u00e9e. Les r\u00e9sultats sont stock\u00e9s en archives compress\u00e9es (JSON ou texte) sign\u00e9es par SHA256 pour int\u00e9grit\u00e9  , et index\u00e9s dans Elasticsearch pour recherche via le tableau de bord. Le  dashboard Wazuh  (plugin OpenSearch/Kibana) donne une vue globale : statut des agents, inventaire de vuln\u00e9rabilit\u00e9s, alertes r\u00e9centes, conformit\u00e9 r\u00e9glementaire, etc. L\u2019analyse est centr\u00e9e sur la s\u00e9curit\u00e9 (alertes critiques) et la conformit\u00e9 (CIS, PCI-DSS, NIST)  .</p> </li> <li> <p>ELK Stack  est con\u00e7u d\u2019abord pour la recherche et la visualisation de logs.  Elasticsearch  est un moteur full-text distribu\u00e9 tr\u00e8s rapide pour indexer et rechercher de gros volumes de donn\u00e9es  .  Kibana  fournit des visualisations et tableaux de bord interactifs personnalisables (histogrammes, heatmaps, s\u00e9ries temporelles\u2026). Cependant, dans sa version de base  open source, ELK n\u2019inclut pas de moteur de corr\u00e9lation ou d\u2019alerting sp\u00e9cifique \u00e0 la s\u00e9curit\u00e9. La d\u00e9tection d\u2019anomalies est possible avec  Elastic Security  (anciennement \u00ab SIEM \u00bb) et machine learning, mais ces fonctionnalit\u00e9s avanc\u00e9es sont en g\u00e9n\u00e9ral li\u00e9es \u00e0 une licence payante. N\u00e9anmoins, on peut mettre en place des r\u00e8gles de d\u00e9tection via les  Alertes Kibana  (Watchers) ou la biblioth\u00e8que de d\u00e9tection GitHub d\u2019Elastic  , voire utiliser OpenSearch qui offre certaines capacit\u00e9s de s\u00e9curit\u00e9 (authentification, chiffrement) en OSS  . En pratique, l\u2019ELK pur est surtout utile pour le \u00ab  search hunting  \u00bb et la cr\u00e9ation de dashboards m\u00e9tier, plut\u00f4t que pour l\u2019IDS automatis\u00e9.</p> </li> <li> <p>Graylog  combine les deux approches : c\u2019est une plateforme d\u2019agr\u00e9gation de logs avec de nombreuses fonctions orient\u00e9es s\u00e9curit\u00e9. Son interface permet des recherches rapides (requ\u00eates Lucene) et la cr\u00e9ation de tableaux de bord et graphiques en quelques clics. On utilise les  Streams  pour filtrer/segmenter les logs au fur et \u00e0 mesure, et les  Alerts  pour d\u00e9clencher des notifications (email, Webhook, etc.) d\u00e8s qu\u2019un crit\u00e8re est satisfait. Par exemple, on peut alerter sur plusieurs \u00e9checs d\u2019authentification, d\u00e9tection d\u2019IP suspecte, ou tout indicateur d\u00e9finissable. Contrairement \u00e0 Wazuh, Graylog n\u2019apporte pas de r\u00e8gles de d\u00e9tection pr\u00eates \u00e0 l\u2019emploi : la logique d\u2019alerte doit \u00eatre configur\u00e9e manuellement (ou via des plugins Sigma en Enterprise  ). En revanche, il peut ing\u00e9rer et  corr\u00e9ler  des logs de plusieurs sources (serveurs, firewall, IDS) pour les analystes. Graylog Security (\u00e9dition payante) ajoute m\u00eame de la d\u00e9tection automatique d\u2019anomalies et du pattern matching avanc\u00e9  , mais en usage domestique la version open suffit souvent pour centraliser et surveiller les logs.</p> </li> </ul> <p>Tableau de bord et alerting : Wazuh Dashboard et Kibana offrent des vues pr\u00eates \u00e0 l\u2019emploi ax\u00e9es s\u00e9curit\u00e9 et conformit\u00e9, avec r\u00f4le API pour modifications \u00e0 distance  . Graylog propose un UI Web unifi\u00e9e (port 9000) o\u00f9 l\u2019on cr\u00e9e facilement dashboards, recherche et r\u00e8gles d\u2019alerte  . Ces interfaces permettent aux d\u00e9butants de d\u00e9marrer rapidement. Les trois solutions supportent la visualisation en temps r\u00e9el de donn\u00e9es et un historique, bien que le dimensionnement du cluster (index) conditionne le volume d\u2019historique accessible sans purger.</p>"},{"location":"securite/siem/#cas-dusage-typiques-en-homelab","title":"Cas d\u2019usage typiques en homelab","text":"<p>Dans un laboratoire Blue Team domestique, on recherchera g\u00e9n\u00e9ralement :</p> <ul> <li> <p>Collecte centralis\u00e9e de logs  : agr\u00e9ger les journaux de tous les serveurs Linux/Windows, \u00e9quipements r\u00e9seaux (firewall, routeur) et VM. Par exemple, installer Wazuh Agent sur les PC Windows pour remonter les Event Logs, d\u00e9ployer Filebeat sur des VMs Linux pour leurs  /var/log, ou envoyer tout via syslog/Graylog.</p> </li> <li> <p>D\u00e9tection d\u2019intrusion (HIDS/NIDS)  : surveiller les anomalies sur les h\u00f4tes. Wazuh fait figure de HIDS classique (fichiers modifi\u00e9s, connexions suspectes, analyse des logs); ELK/Graylog peuvent ing\u00e9rer aussi les alertes d\u2019un NIDS (Suricata, Snort) et les corr\u00e9ler  . Par exemple, les logs d\u2019IDS network Suricata peuvent \u00eatre envoy\u00e9s \u00e0 Wazuh ou Graylog pour enrichissement et corr\u00e9lation (Wazuh prend nativement en charge Suricata via un module  ).</p> </li> <li> <p>Alerting  : g\u00e9n\u00e9rer des notifications (mail, Slack, etc.) sur \u00e9v\u00e9nements critiques : Wazuh peut envoyer des alertes par mail ou Syslog quand une r\u00e8gle se d\u00e9clenche. Graylog d\u00e9clenche aussi des alertes d\u00e9finies sur des  streams. Kibana (ELK) permet d\u2019utiliser des alertes Watcher ou des plugins d\u2019action dans OpenSearch.</p> </li> <li> <p>Monitoring temps r\u00e9el  : visualiser l\u2019activit\u00e9 du r\u00e9seau et des h\u00f4tes via des dashboards. Par ex. tableaux Graylog pour la r\u00e9partition des logs par serveur/processus, courbes de charge ou heatmaps. Elastic/Kibana propose par ailleurs des plugins comme Elastic SIEM ou Observability pour surveiller l\u2019infrastructure (APM, m\u00e9triques).</p> </li> </ul> <p>Ces cas d\u2019usage sont couverts par les trois outils, mais avec des approches diff\u00e9rentes. Dans un petit homelab, on peut par exemple utiliser Wazuh pour la d\u00e9tection h\u00f4te (HIDS) et \u00e9galement envoyer ses journaux au cluster ELK ou Graylog pour analyse globale, tirant ainsi parti du meilleur des deux mondes.</p>"},{"location":"securite/siem/#installation-dockerlxc-et-architecture-type","title":"Installation Docker/LXC et architecture type","text":"<p>En environnement domestique, l\u2019usage de conteneurs (Docker, LXC) facilite le d\u00e9ploiement :</p> <ul> <li> <p>Wazuh  : la documentation officielle propose des images Docker composant le \u00ab full-stack \u00bb Wazuh (serveur, indexer, tableau de bord)  . Une simple  docker-compose  r\u00e9cup\u00e8re tout en une fois. Le d\u00e9p\u00f4t  wazuh-docker  fournit notamment un stack pr\u00eat \u00e0 l\u2019emploi (Wazuh Manager + OpenSearch + Dashboard)  . Pour un seul serveur Wazuh et un n\u0153ud OpenSearch, une VM ou LXC avec ~6\u202fGo de RAM est recommand\u00e9e  . Des templates Proxmox (LXC) pour Wazuh existent dans certaines communaut\u00e9s.</p> </li> <li> <p>ELK  : il existe de nombreux Docker Compose tout-en-un (par ex. [deviantony/docker-elk]  ) incluant Elasticsearch, Logstash et Kibana. On peut lancer  docker-compose up  pour disposer d\u2019un cluster minimal \u00e0 1 n\u0153ud. En LXC, il suffit d\u2019installer Docker ou directement Elastic sur Debian/Ubuntu. Un notebook Raspberry Pi ou petit serveur (\u22654\u202fGo) peut ainsi faire tourner une instance de test (certains revendeurs fournissent des images Debian d\u00e9j\u00e0 configur\u00e9es).</p> </li> <li> <p>Graylog  : Graylog fournit une image Docker officielle (\u00ab graylog/graylog \u00bb). Un exemple de  docker-composeint\u00e8gre 3 conteneurs : MongoDB (pour les m\u00e9tadonn\u00e9es), Elasticsearch/OpenSearch (pour le stockage), et Graylog Server  . Le serveur Graylog \u00e9coute par d\u00e9faut sur le port 9000 (web UI) et sur divers ports syslog (1514 TCP/UDP, 12201 GELF, etc.) comme montr\u00e9 ci-dessus  . En LXC, on installe Java 11, MongoDB et Elasticsearch avant Graylog server. Un minimum de  4\u202fGo de RAM  est conseill\u00e9 pour un petit setup Graylog  .</p> </li> </ul> <p>Exemple d\u2019architecture Docker pour Graylog (cluster minimal) : MongoDB + Elasticsearch (chaque container \u00e0 ~1\u202fGo RAM) + Graylog (&lt;1\u202fGo) dans un r\u00e9seau bridge. Graylog expose 9000, 12201, 1514, etc. (voir exemple [31\u2020L182-L190]).</p>"},{"location":"securite/siem/#performances-et-ressources","title":"Performances et ressources","text":"<p>Ces plateformes sont gourmandes en I/O disque et RAM, particuli\u00e8rement \u00e0 mesure que le volume de logs cro\u00eet. Les bonnes pratiques sont similaires pour toutes : utiliser des SSD rapides, allouer suffisamment de m\u00e9moire et pr\u00e9voir la mont\u00e9e en charge.</p> <ul> <li> <p>M\u00e9moire : Wazuh (avec OpenSearch) demande au moins  6\u202fGo RAM  sur l\u2019h\u00f4te Docker complet  . Graylog conseille  4\u202fGo minimum  pour un petit usage, mais  8\u201316\u202fGo  pour la production  . Elasticsearch (ELK) peut s\u2019ex\u00e9cuter sur 2\u20134\u202fGo pour un usage tr\u00e8s l\u00e9ger, mais 8\u201316\u202fGo voire plus sont n\u00e9cessaires pour un cluster de taille moyenne, en raison du heap Java. Un indice cl\u00e9 est que l\u2019Elastic Stack n\u00e9cessite de favoriser la RAM (environ 50% d\u00e9di\u00e9e au heap Java) pour des recherches rapides. Comme le note Matt Hayes, \u201c2\u202fGo de RAM, c\u2019est le minimum, 4\u202fGo fonctionnera mieux\u201d pour un ELK minimal  . De son c\u00f4t\u00e9, Wazuh recommande un calcul de  vm.max_map_count=262144  pour OpenSearch (n\u00e9cessaire pour le mappage m\u00e9moire)  .</p> </li> <li> <p>CPU : Elasticsearch est parall\u00e9lis\u00e9 sur plusieurs c\u0153urs pour l\u2019indexation et les recherches full-text. Logstash est connu gourmand en CPU et m\u00e9moire lors de fortes ingestations (selon ses pipelines). Graylog (Java + Elasticsearch) tire avantage de plusieurs c\u0153urs aussi. En g\u00e9n\u00e9ral, pr\u00e9voir au moins 2 vCPU pour chaque n\u0153ud (4 CPU pour cluster ELK plus Wazuh).</p> </li> <li> <p>Stockage : tous conseillent l\u2019usage de  SSDs/ NVMe. Par exemple, la doc Graylog souligne l\u2019importance de stocker le journal de messages et les indices sur des disques haute-IOPS (id\u00e9alement SSD)  . Les logs \u00e9tant volumineux et en \u00e9criture continue, mieux vaut dimensionner le disque en fonction de la r\u00e9tention souhait\u00e9e (par ex.  [ingest quotidien] \u00d7 [jours de r\u00e9tention] \u00d7 1.2)  . Wazuh archive quotidiennement ses logs avec compression et checksums  , mais conserve aussi tout dans Elasticsearch si la r\u00e9tention est long-terme.</p> </li> <li> <p>Scalabilit\u00e9 : toutes les solutions se  clusterisent  pour g\u00e9rer plus de donn\u00e9es. Wazuh peut d\u00e9ployer un cluster de serveurs Wazuh (master/worker) et un cluster OpenSearch pour l\u2019indexation  . Graylog (Community) permet d\u2019ajouter des Graylog Servers suppl\u00e9mentaires derri\u00e8re un load balancer, chacun traitant les m\u00eames inputs, tandis que Elasticsearch se met en cluster pour les donn\u00e9es  . Ce d\u00e9ploiement conventionnel assure HA et mont\u00e9e en charge facile  . Elastic/Opensearch est con\u00e7u pour scaler horizontalement ; on peut commencer sur un seul n\u0153ud mais passer \u00e0 3+ n\u0153uds de donn\u00e9es avec r\u00e9plicas pour la r\u00e9silience.</p> </li> <li> <p>S\u00e9curit\u00e9 : Wazuh chiffrera nativement la communication agent-serveur (AES)  , et l\u2019API/GUI utilisent TLS et authentification. Graylog lui recommande de forcer TLS entre les n\u0153uds et d\u2019appliquer le RBAC (contr\u00f4le d\u2019acc\u00e8s par r\u00f4les) pour s\u00e9curiser l\u2019acc\u00e8s  . Elasticsearch (dans son offre OSS) offre maintenant des fonctionnalit\u00e9s basiques de s\u00e9curit\u00e9 sur Basic License (auth, HTTPS) ; la version OpenSearch (fork AWS) int\u00e8gre chiffrement et ACL sans licence suppl\u00e9mentaire  .</p> </li> <li> <p>Maintenance : la gestion consiste \u00e0 surveiller les disques (purger/archiver les indices anciens), sauvegarder la base MongoDB (Graylog) et les snapshots d\u2019Elasticsearch. Graylog souligne l\u2019importance de sauvegarder Mongo, les indices OpenSearch et la config  . Wazuh pr\u00e9conise aussi de purger/archiver les anciens logs (ossec-archive-*.gzsign\u00e9s) ou de ne compter que sur les snapshots d\u2019Elasticsearch  . Les mises \u00e0 jour impliquent souvent de mettre \u00e0 jour en s\u00e9quence les composants (par ex. Elasticsearch puis Wazuh). En homelab, l\u2019automatisation (Ansible, Docker Compose) aide \u00e0 r\u00e9duire la charge op\u00e9rationnelle  .</p> </li> </ul>"},{"location":"securite/siem/#recommandations-par-profil-dusage","title":"Recommandations par profil d\u2019usage","text":"<ul> <li> <p>D\u00e9butant / homelab simple  : pr\u00e9f\u00e9rez la solution la plus  cl\u00e9-en-main. Graylog (\u00e9dition Open) est simple \u00e0 installer et dispose d\u2019une interface intuitive pour d\u00e9marrer. Le Docker Compose officiel permet de monter un syst\u00e8me complet en quelques commandes. ELK est aussi abordable via un stack Docker (deviantony/docker-elk), mais Elastic demande un peu plus d\u2019ajustements (certificates, m\u00e9moire). Wazuh, bien que puissant en d\u00e9tection, n\u00e9cessite plus de configuration initiale (d\u00e9ploiement des agents, r\u00e8gles) \u2013 il peut \u00eatre mis en place apr\u00e8s familiarisation ou dans un second temps.</p> </li> <li> <p>Power user / exp\u00e9riment\u00e9  : si vous visez de la d\u00e9tection HIDS avanc\u00e9e, Wazuh est un excellent choix car il offre d\u00e8s le d\u00e9part des capacit\u00e9s de threat hunting (FIM, r\u00e8gles CVE/CIS)  . Vous pouvez associer Wazuh \u00e0 une plateforme log (Graylog ou ELK) pour l\u2019analyse forensique des alertes. ELK (ou son fork OpenSearch) convient pour manipuler et visualiser de gros volumes de donn\u00e9es, \u00e9crire ses propres r\u00e8gles (Sigma/Kibana Alerts) ou utiliser du machine learning Elastic. Graylog est quant \u00e0 lui tr\u00e8s flexible pour construire des flux et alertes personnalis\u00e9es via son syst\u00e8me de  streams.</p> </li> <li> <p>Usage professionnel / grand volume  : en production, les trois s\u2019industrialiseront en clusters. Graylog Enterprise offre des fonctions SIEM avanc\u00e9es (correlation, archiving) et support commercial. Wazuh peut g\u00e9rer des milliers d\u2019agents sur un cluster, avec indexeurs r\u00e9pliqu\u00e9s  . L\u2019Elastic Stack, coupl\u00e9 \u00e0 Elastic Security, reste une r\u00e9f\u00e9rence \u00ab tout-en-un \u00bb, mais sa licence propri\u00e9taire r\u00e9cente implique souvent de migrer vers OpenSearch ou la version Enterprise pour rester open source  .</p> </li> </ul> <p>En r\u00e9sum\u00e9,  pour un homelab Blue Team  d\u00e9butant, Graylog (simple \u00e0 prendre en main) ou le combo  Wazuh+Graylog(Wazuh pour l\u2019IDS, Graylog pour la log-analyse) est souvent conseill\u00e9. Les utilisateurs avanc\u00e9s pourront opter pour Wazuh ou Elastic+Wazuh (via le plugin Wazuh pour Kibana) pour profiter de r\u00e8gles de d\u00e9tection d\u00e9j\u00e0 disponibles. Enfin, l\u2019essentiel est de disposer d\u2019une collecte de logs fiable et d\u2019un minimum d\u2019alerting ; les trois outils remplissent ces fonctions, \u00e0 chacun de choisir selon ses pr\u00e9f\u00e9rences en terme d\u2019interface, de langage de requ\u00eate et de charge syst\u00e8me.</p>"},{"location":"securite/vaultwarden/","title":"Gestionnaires de mots de passe self-hosted pour homelab","text":""},{"location":"securite/vaultwarden/#vaultwarden-bitwarden_rs","title":"Vaultwarden (Bitwarden_RS)","text":"<p>Vaultwarden (anciennement  bitwarden_rs) est une impl\u00e9mentation en Rust du serveur Bitwarden, all\u00e9g\u00e9e et optimis\u00e9e pour l\u2019auto-h\u00e9bergement  . Elle reproduit l\u2019essentiel des fonctionnalit\u00e9s de Bitwarden (mots de passe, cartes, notes s\u00e9curis\u00e9es) avec une empreinte m\u00e9moire minimale. Vaultwarden propose notamment la gestion multi-utilisateurs via des organisations et collections partag\u00e9es, la g\u00e9n\u00e9ration et sauvegarde de mots de passe, ainsi que des clients officiels Bitwarden (extensions de navigateur et applications mobiles) compatibles  . L\u2019installation se fait typiquement avec Docker, par exemple :</p> <p><pre><code>docker run -d --name vaultwarden \\\n  -e DOMAIN=\"https://vault.mondomaine.tld\" \\\n  -v /srv/vaultwarden-data:/data/ \\\n  -p 80:80 \\\n  vaultwarden/server:latest\n</code></pre> Ce conteneur utilise SQLite par d\u00e9faut, mais peut aussi se connecter \u00e0 une base MariaDB/MySQL pour de meilleures performances. La documentation recommande d\u2019utiliser un proxy HTTPS (par exemple NGINX Proxy Manager) car les navigateurs n\u2019autorisent pas le chiffrement  Web Crypto  hors contexte s\u00e9curis\u00e9  .</p>"},{"location":"securite/vaultwarden/#securite-et-authentification","title":"S\u00e9curit\u00e9 et authentification","text":"<p>Vaultwarden offre du chiffrement de bout en bout (E2E) comme Bitwarden : les donn\u00e9es sont chiffr\u00e9es c\u00f4t\u00e9 client avec AES-256 avant d\u2019\u00eatre envoy\u00e9es au serveur (mod\u00e8le  zero-knowledge)  . Les options d\u2019authentification \u00e0 deux facteurs sont riches : codes OTP via une application (Google Authenticator, Authy), cl\u00e9 de s\u00e9curit\u00e9 FIDO2/WebAuthn (YubiKey), authentification par email et Duo MFA  . La politique de mots de passe est g\u00e9r\u00e9e c\u00f4t\u00e9 client (g\u00e9n\u00e9ration al\u00e9atoire et longueur minimale dans les param\u00e8tres utilisateur). Vaultwarden ne supporte pas nativement LDAP/SAML ; c\u2019est une solution plut\u00f4t autonome. Comme tous les gestionnaires, il est vivement recommand\u00e9 de faire des sauvegardes r\u00e9guli\u00e8res de la base et des fichiers joints \u2013 la documentation met en garde contre les pertes de donn\u00e9es en cas de d\u00e9faillance  .</p>"},{"location":"securite/vaultwarden/#installation-et-maintenance","title":"Installation et maintenance","text":"<p>Vaultwarden se d\u00e9ploie facilement via Docker ou Podman  . Un reverse-proxy (Traefik, NGINX Proxy Manager, Caddy\u2026) est conseill\u00e9 pour fournir un certificat SSL/TLS (Let\u2019s Encrypt, mkcert, etc.) et exposer le service sur un nom de domaine  . La maintenance se limite \u00e0 mettre \u00e0 jour l\u2019image Docker (et migrer la base de donn\u00e9es si besoin). L\u2019interface web est simple et fonctionnelle, et l\u2019application Android/iOS de Bitwarden fonctionne sans modification. La communaut\u00e9 est active, mais contrairement au serveur officiel Bitwarden, Vaultwarden n\u2019a pas de bilan public d\u2019audit tiers  . Toutefois, le code est open source (AGPL v3  ) et r\u00e9guli\u00e8rement mis \u00e0 jour.</p>"},{"location":"securite/vaultwarden/#passbolt","title":"Passbolt","text":"<p>Passbolt est un gestionnaire de mots de passe libre con\u00e7u pour les \u00e9quipes et organisations. Il utilise un mod\u00e8le de chiffrement  end-to-end  avec cl\u00e9s publiques-priv\u00e9es : chaque utilisateur g\u00e9n\u00e8re une paire de cl\u00e9s, et seule la cl\u00e9 priv\u00e9e (prot\u00e9g\u00e9e par passphrase) reste sur son appareil  . Cette architecture garantit que seul le destinataire peut d\u00e9chiffrer les mots de passe partag\u00e9s. Passbolt Community Edition (CE) est enti\u00e8rement open source (AGPL v3  ) et auto-h\u00e9bergeable. Il dispose d\u2019une interface web conviviale, d\u2019extensions navigateur (Chrome/Firefox/Edge) et d\u2019applications mobiles hybrides (iOS/Android) et desktop  .</p>"},{"location":"securite/vaultwarden/#fonctions-cles","title":"Fonctions cl\u00e9s","text":"<p>Passbolt se distingue par son focus sur la collaboration : gestion de groupes, dossiers partag\u00e9s, permissions fines et audit des actions. Toutes les fonctionnalit\u00e9s de partage de mots de passe sont disponibles dans la version gratuite (CE) pour un nombre d\u2019utilisateurs illimit\u00e9, contrairement \u00e0 Bitwarden o\u00f9 le partage avanc\u00e9 est r\u00e9serv\u00e9 aux \u00e9ditions payantes  . L\u2019interface permet d\u2019organiser des collections hi\u00e9rarchiques et de partager un mot de passe unique ou tout un dossier vers un autre utilisateur ou une \u00e9quipe, avec h\u00e9ritage de permissions  . La g\u00e9n\u00e9ration de mots de passe se fait depuis l\u2019extension ou le site, et Passbolt prend en charge la compl\u00e9tion automatique.</p>"},{"location":"securite/vaultwarden/#authentification-et-securite","title":"Authentification et s\u00e9curit\u00e9","text":"<p>Passbolt renforce la s\u00e9curit\u00e9 par une authentification forte. Les utilisateurs peuvent activer une deuxi\u00e8me couche MFA (g\u00e9n\u00e9ralement un code TOTP) pour se connecter  . Il existe aussi une option LDAP/AD en version Pro : la documentation montre comment configurer LDAPS pour synchroniser les comptes d\u2019entreprise  . Passbolt est audit\u00e9 r\u00e9guli\u00e8rement et rend publiques ses conclusions : c\u2019est une application  security-first  (mod\u00e8le Cll\u00e9 Priv\u00e9e+Chiffrage par mot de passe ma\u00eetre)  . La politique de mots de passe peut \u00eatre impos\u00e9e par l\u2019administrateur (longueur, complexit\u00e9) et les journaux d\u2019audit d\u00e9taillent toutes les connexions et modifications. Des sauvegardes automatiques de la base (PostgreSQL ou MySQL) sont possibles via des scripts.</p>"},{"location":"securite/vaultwarden/#installation","title":"Installation","text":"<p>Passbolt peut \u00eatre install\u00e9 via Docker ou directement sur un serveur Linux (packages Debian/CentOS). Un  docker-compose  simple ou un script d\u00e9di\u00e9 (disponible sur leur site) installe le serveur API, la base de donn\u00e9es et l\u2019interface web en une seule commande. Par exemple, leur image Docker regroupe le serveur, le webclient et l\u2019interface d\u2019admin  . Il faut configurer un nom de domaine et fournir un certificat TLS (Let\u2019s Encrypt ou autre). Passbolt propose aussi un connecteur LDAP (cronjob) pour importer les utilisateurs depuis un annuaire d\u2019entreprise.</p>"},{"location":"securite/vaultwarden/#keepassxc-avec-synchronisation-via-syncthing","title":"KeePassXC (avec synchronisation via Syncthing)","text":"<p>KeePassXC est un gestionnaire de mots de passe multiplateforme (Windows/Mac/Linux) fonctionnant hors ligne. Les mots de passe sont stock\u00e9s dans un fichier local chiffr\u00e9 (format KDBX, AES-256)  . Son code source est libre (GPLv3  ) et  on-premise  : aucun service distant n\u2019est requis  . KeePassXC inclut un g\u00e9n\u00e9rateur de mots de passe et une int\u00e9gration de navigateur via une application compagnon.</p>"},{"location":"securite/vaultwarden/#usage-en-homelab","title":"Usage en homelab","text":"<p>Par d\u00e9faut, KeePassXC ne g\u00e8re pas le multi-utilisateur. Pour partager le m\u00eame fichier de mots de passe entre plusieurs machines (ou utilisateurs), on utilise un outil de synchronisation de fichiers tel que  Syncthing. On place le fichier KDBX dans un dossier surveill\u00e9 par Syncthing sur deux ordinateurs ou plus. Chaque modification est ainsi r\u00e9pliqu\u00e9e crypt\u00e9e vers les autres appareils. Cette approche \u00e9limine le serveur central : tout reste chiffr\u00e9 localement, et vous contr\u00f4lez enti\u00e8rement les sauvegardes. Cependant, il faut veiller \u00e0 \u00e9viter les conflits d\u2019\u00e9dition simultan\u00e9e (pas de verrouillage de fichier int\u00e9gr\u00e9).</p>"},{"location":"securite/vaultwarden/#securite-et-authentification_1","title":"S\u00e9curit\u00e9 et authentification","text":"<p>KeePassXC offre un chiffrement robuste :  \u201cVotre base reste toujours chiffr\u00e9e et aucun serveur distant n\u2019est utilis\u00e9\u201d  . On peut prot\u00e9ger la base par un mot de passe principal seul ou combin\u00e9 \u00e0 un fichier-cl\u00e9 ou une cl\u00e9 de s\u00e9curit\u00e9 (YubiKey en mode challenge-r\u00e9ponse), apportant une forme de MFA mat\u00e9rielle. KeePassXC ne propose pas d\u2019authentification r\u00e9seau (pas de SSO ni LDAP) car il est con\u00e7u pour une utilisation locale. Les sauvegardes ne sont rien de plus que des copies du fichier KDBX ou des dumps d\u2019urgence export\u00e9s dans un fichier chiffr\u00e9 hors ligne. Dans un homelab personnel, c\u2019est id\u00e9al : simple \u00e0 d\u00e9ployer (installez l\u2019Appli ou le paquet depuis votre distribution), 100% priv\u00e9 et audit\u00e9e (le code est ouvert). En revanche, il n\u2019existe pas d\u2019app mobile officielle KeePassXC \u2013 on utilise alors KeePassDX (Android) ou Strongbox (iOS) pour acc\u00e9der au fichier synchronis\u00e9.</p>"},{"location":"securite/vaultwarden/#bitwarden-serveur-officiel","title":"Bitwarden (serveur officiel)","text":"<p>Bitwarden est le projet d\u2019origine, dont Vaultwarden est un clone l\u00e9ger. Le serveur Bitwarden officiel (techniquement open source AGPL v3) est \u00e9crit en .NET Core et d\u00e9ploy\u00e9 via plusieurs conteneurs Docker  . Il fournit les m\u00eames clients (web, mobile, extensions) et fonctionnalit\u00e9s de base, mais exige un d\u00e9ploiement plus complexe (script  bitwarden.sh  ou  docker-compose  orchestrant plusieurs services)  . Bitwarden Cloud propose en plus des \u00e9ditions Enterprise avec annuaire (LDAP/AD via Directory Connector), SSO (SAML), rapports d\u2019audit avanc\u00e9s et politique organisationnelle.</p>"},{"location":"securite/vaultwarden/#points-forts-et-limites","title":"Points forts et limites","text":"<p>Bitwarden b\u00e9n\u00e9ficie d\u2019une longue trajectoire et d\u2019un suivi professionnel : le code est v\u00e9rifi\u00e9 publiquement, et des audits par Cure53 sont r\u00e9guli\u00e8rement publi\u00e9s  . Il prend en charge l\u2019authentification \u00e0 deux facteurs (OTPs, YubiKey, WebAuthn) et la r\u00e9cup\u00e9ration/prise de contr\u00f4le (Emergency Access). Les fonctionnalit\u00e9s communautaires gratuites incluent le chiffrement E2E AES-256 \u201czero-knowledge\u201d et un stockage illimit\u00e9 d\u2019\u00e9l\u00e9ments  . En revanche, le partage d\u2019\u00e9l\u00e9ments en mode \u00e9quipe est limit\u00e9 en version libre (plan free n\u2019autorise pas le partage d\u00e9taill\u00e9)  , et l\u2019installation auto-h\u00e9berg\u00e9e demande des ressources (RAM, CPU) et une gestion d\u2019infrastructure Docker/SSL plus cons\u00e9quentes.</p>"},{"location":"securite/vaultwarden/#psono","title":"Psono","text":"<p>Psono est un gestionnaire de mots de passe pens\u00e9 pour les entreprises et \u00e9quipes, open source et auto-h\u00e9bergeable. Son architecture combine chiffrement c\u00f4t\u00e9 client et multiples couches de s\u00e9curit\u00e9  . Les mots de passe sont chiffr\u00e9s localement avant envoi (\u00ab multi encryption \u00bb : chiffrement client, TLS, chiffrement de stockage)  . Le syst\u00e8me de partage s\u2019effectue via des organisations et groupes, et il existe un tableau de bord administrateur pour g\u00e9rer les licences et les utilisateurs (en version Enterprise).</p>"},{"location":"securite/vaultwarden/#fonctionnalites-et-securite","title":"Fonctionnalit\u00e9s et s\u00e9curit\u00e9","text":"<p>Psono propose une interface web, des extensions navigateur (Chrome/Firefox/Edge) et des applications mobiles natives iOS/Android  . Il se veut  \u201cresponsable de la protection des donn\u00e9es\u201d  :  \u00ab il chiffe localement sur le device avant envoi, et ne stocke que les donn\u00e9es d\u00e9j\u00e0 chiffr\u00e9es \u00bb  . Les cl\u00e9s priv\u00e9es restent sur l\u2019appareil client et ne passent jamais sur le serveur. Psono supporte le partage de mots de passe au sein d\u2019\u00e9quipes, avec gestion de droits et r\u00e9pertoire d\u2019utilisateurs. On peut importer des comptes depuis un annuaire ou SSO via des modules (LDAP/SAML sont possibles en entreprise). Il n\u2019est pas clair si la version gratuite supporte LDAP, mais la documentation mentionne l\u2019utilisation de Docker pour d\u00e9ployer facilement le serveur et l\u2019interface  . Des audits externes ont d\u00e9j\u00e0 \u00e9t\u00e9 effectu\u00e9s sur Psono, ce qui renforce la confiance dans son mod\u00e8le cryptographique.</p>"},{"location":"securite/vaultwarden/#deploiement","title":"D\u00e9ploiement","text":"<p>Psono propose une image Docker unique (entreprise ou communautaire) qui embarque le serveur, le client web et la console d\u2019administration  . Le d\u00e9ploiement type utilise Docker Compose ou Kubernetes. Pour un homelab, on peut simplement lancer ce conteneur derri\u00e8re un reverse-proxy avec TLS, puis se connecter via l\u2019interface web. La maintenance implique de faire tourner le conteneur \u00e0 jour et de sauvegarder la base de donn\u00e9es (PostgreSQL) ainsi que les cl\u00e9s de chiffrement. Psono poss\u00e8de aussi une couche de  fileserver  pour stocker des fichiers joints aux mots de passe (ex : licences, QR codes).</p>"},{"location":"securite/vaultwarden/#autres-options-pertinentes","title":"Autres options pertinentes","text":"<ul> <li> <p>KeePass (Windows)  \u2013 anc\u00eatre de KeePassXC. Fonctionne localement sur Windows (non multiplateformes). On peut aussi utiliser la version Mono sur Linux. Partage via Syncthing similaire \u00e0 KeePassXC.</p> </li> <li> <p>Pass (cli)  \u2013 gestionnaire Unix en ligne de commande (GNU Pass, format gpg), adapt\u00e9 aux utilisateurs avanc\u00e9s. Sans interface web ni mobile natif, mais tr\u00e8s l\u00e9ger et scriptable.</p> </li> <li> <p>Buttercup  \u2013 gestionnaire simple open source (Electron) avec vaults chiffr\u00e9s. Poss\u00e8de des applications desktop/mobile et un mode auto-h\u00e9berg\u00e9 via Caddy, mais moins de fonctionnalit\u00e9s d\u2019\u00e9quipe.</p> </li> <li> <p>Teampass  \u2013 gestionnaire PHP/MySQL pour \u00e9quipes (GPL v3  ). Offre dossiers, 2FA (Google Auth), r\u00f4les, mais l\u2019interface est plus complexe et le projet moins actif r\u00e9cemment. Installation via paquet ou Docker.</p> </li> <li> <p>HashiCorp Vault  \u2013 plut\u00f4t orient\u00e9 secrets (devops) qu\u2019acc\u00e8s utilisateur classique. Tr\u00e8s robuste (authentification LDAP, Cloud IAM, etc.), mais moins convivial pour un usage m\u00e9tier de mots de passe de sites web.</p> </li> <li> <p>Padloc,  Passky,  Padloc, etc. \u2013 quelques autres outils open source existent, mais ils sont souvent plus exp\u00e9rimentaux ou limit\u00e9s (par ex. pas d\u2019app mobile).</p> </li> </ul>"},{"location":"securite/vaultwarden/#comparatif-technique","title":"Comparatif technique","text":"<p>TABLEAU</p> <ul> <li>La licence exacte de Psono n\u2019est pas pr\u00e9cis\u00e9e sur leur site, mais le code est en grande partie ouvert.</li> </ul>"},{"location":"securite/vaultwarden/#securite-et-bonnes-pratiques","title":"S\u00e9curit\u00e9 et bonnes pratiques","text":"<p>Quel que soit le choix, l\u2019\u00e9l\u00e9ment cl\u00e9 est le chiffrement de bout en bout : la plupart des solutions cit\u00e9es (Vaultwarden/Bitwarden, Passbolt, Psono) chiffrent localement les donn\u00e9es avant envoi  . Ainsi, le serveur ne voit jamais les mots de passe en clair. Par ailleurs, v\u00e9rifiez que votre instance est prot\u00e9g\u00e9e par HTTPS et que vous appliquez un fort mot de passe ma\u00eetre initial. Les fonctionnalit\u00e9s MFA (OTP TOTP, cl\u00e9s U2F/WebAuthn) ajoutent une barri\u00e8re suppl\u00e9mentaire : Vaultwarden/Bitwarden supportent un large panel d\u2019options  , Passbolt est con\u00e7u pour l\u2019authentification double-facteur et l\u2019impose aux utilisateurs professionnels  , et m\u00eame Teampass int\u00e8gre des 2FA comme Google Authenticator  .</p> <p>Pour les entreprises ou environnements multifamille, l\u2019int\u00e9gration \u00e0 un annuaire est aussi importante. Bitwarden Enterprise offre un  Directory Connector  pour LDAP/AD (au niveau payant), Passbolt Pro permet de synchroniser via LDAPS  , et Teampass/Psono peuvent \u00eatre connect\u00e9s \u00e0 un LDAP. En auto-h\u00e9bergement pur, on mettra souvent en place Authelia ou Keycloak en frontal pour un SSO global.</p> <p>Enfin, la gestion des sauvegardes est cruciale : sauvegardez la base de donn\u00e9es (SQL ou SQLite) et les fichiers (PJ) r\u00e9guli\u00e8rement. Les fournisseurs comme Vaultwarden rappellent qu\u2019ils ne sont pas responsables des pertes de donn\u00e9es et conseillent les backups fr\u00e9quents  . Utilisez aussi un gestionnaire de configuration (Ansible, etc.) pour d\u00e9ployer et restaurer votre service au besoin.</p>"},{"location":"securite/vaultwarden/#scenarios-dusage-typiques","title":"Sc\u00e9narios d\u2019usage typiques","text":"<ul> <li> <p>Homelab personnel/familial  \u2013 Une solution l\u00e9g\u00e8re comme Vaultwarden ou KeePassXC convient souvent. Par exemple, Vaultwarden peut \u00eatre d\u00e9ploy\u00e9 dans un conteneur Docker derri\u00e8re NGINX Proxy Manager avec un domaine personnel (ex:  vault.mondomaine.fr) et Let\u2019s Encrypt. Chaque membre de la famille cr\u00e9e un compte utilisateur et partage des dossiers communs (wifi, routeur, etc.) via les organisations Bitwarden. KeePassXC reste utile pour un utilisateur unique : sa base locale stock\u00e9e sur Syncthing entre PC et smartphone permet d\u2019acc\u00e9der aux mots de passe m\u00eame sans connexion internet.</p> </li> <li> <p>Environnement de test/s\u00e9curis\u00e9  \u2013 Pour un labo d\u00e9di\u00e9 (VM/containers), Passbolt ou Psono offrent un cadre de tests multi-utilisateurs. Par exemple, on peut lancer Passbolt sur une VM et cr\u00e9er des utilisateurs \u00ab test \u00bb pour valider l\u2019int\u00e9gration SSO (LDAP) ou l\u2019API CLI. Gr\u00e2ce \u00e0 Docker, on peut d\u00e9truire/r\u00e9installer facilement en cas d\u2019erreur.</p> </li> <li> <p>Int\u00e9gration \u00e0 un parc existant  \u2013 Dans une infrastructure o\u00f9 l\u2019authentification unique est d\u00e9j\u00e0 en place, choisissez un gestionnaire offrant la compatibilit\u00e9 (Bitwarden Enterprise pour SAML, Passbolt LDAP, ou configurer Authelia devant Vaultwarden). Par exemple, en pla\u00e7ant Vaultwarden derri\u00e8re Authelia/NGINX Proxy Manager, on force une authentification centrale (par OAuth/LDAP) avant d\u2019atteindre le coffre. L\u2019int\u00e9gration via reverse proxy permet aussi de simplifier l\u2019acc\u00e8s : NGINX Proxy Manager automatisera la g\u00e9n\u00e9ration des certificats HTTPS pour chaque service web de l\u2019homelab.</p> </li> </ul>"},{"location":"securite/vaultwarden/#deploiement-et-exemples-pratiques","title":"D\u00e9ploiement et exemples pratiques","text":"<ul> <li>Docker Compose (Vaultwarden)  \u2013 Un fichier  docker-compose.yml  minimal pour Vaultwarden est :</li> </ul> <pre><code>services:\n  vaultwarden:\n    image: vaultwarden/server:latest\n    container_name: vaultwarden\n    restart: unless-stopped\n    environment:\n      - DOMAIN=https://vault.mondomaine.fr\n    volumes:\n      - ./vw-data/:/data/\n    ports:\n      - \"80:80\"\n</code></pre> <ul> <li> <p>Ce conteneur stocke les donn\u00e9es sur  ./vw-data/. On cr\u00e9e ensuite un proxy (Traefik, NPM) pointant sur  vault.mondomaine.fr.</p> </li> <li> <p>Docker Compose (Passbolt)  \u2013 Passbolt propose un  docker-compose  complet (base de donn\u00e9es + serveur) dans sa documentation. Il suffit de cloner leur repo et d\u2019\u00e9diter l\u2019.env  pour indiquer le domaine et le mot de passe GPG serveur. Par exemple : <pre><code>git clone https://gitlab.com/passbolt/passbolt_docker.git\ncd passbolt_docker\ncp envvars.example .env\n# modifier .env (DOMAIN, GPG keys, etc.)\ndocker-compose up -d\n</code></pre></p> </li> <li> <p>L\u2019interface web de Passbolt sera accessible sur  https://passbolt.mondomaine.fr.</p> </li> <li> <p>LXC / VM  \u2013 On peut d\u00e9ployer ces services dans des conteneurs LXC (Proxmox) ou des VM l\u00e9g\u00e8res. Par exemple, cr\u00e9er un LXC Debian, installer Docker (apt install docker.io docker-compose), puis suivre les m\u00eames commandes Docker. Des images pr\u00eates \u00e0 l\u2019emploi existent souvent pour Bitwarden et Vaultwarden sur Docker Hub. L\u2019avantage du LXC est l\u2019isolation r\u00e9seau et syst\u00e8me tout en \u00e9conomisant des ressources compar\u00e9 \u00e0 une VM pleine.</p> </li> <li> <p>NGINX Proxy Manager  \u2013 Int\u00e9grez chaque service au NPM en cr\u00e9ant une entr\u00e9e de proxy pour son nom de domaine, en validant le certificat Let\u2019s Encrypt. Par exemple, pointez  vault.mondomaine.fr  vers l\u2019IP du conteneur Vaultwarden (port 80). R\u00e9p\u00e9tez pour  passbolt.mondomaine.fr  et d\u2019autres. NPM g\u00e8re l\u2019HTTPS automatiquement. Un firewall (iptables, UFW) peut limiter l\u2019acc\u00e8s aux seuls ports 80/443 pour ces conteneurs.</p> </li> <li> <p>Int\u00e9gration Reverse Proxy / SSO  \u2013 Pour un acc\u00e8s unifi\u00e9, on peut associer Vaultwarden \u00e0 un serveur SSO (ex : Authelia) mont\u00e9 en frontal. Dans NPM, on configurerait un  proxy host  sur  vault.mondomaine.fr  qui redirige vers Authelia pour authentifier l\u2019utilisateur via LDAP, puis vers Vaultwarden. Ainsi, on dispose d\u2019un acc\u00e8s centralis\u00e9 et authentifi\u00e9 unique \u00e0 tous les services (Mastodon, Nextcloud, Vaultwarden\u2026).</p> </li> </ul> <p>En r\u00e9sum\u00e9, de nombreuses solutions self-hosted existent pour un homelab.  Vaultwarden  et  KeePassXC  couvrent le cas des utilisateurs techniques cherchant la simplicit\u00e9,  Passbolt  et  Psono  s\u2019adressent aux environnements collaboratifs, tandis que  Bitwarden (officiel)  et  Teampass  conviennent aux d\u00e9ploiements plus formels. Le choix d\u00e9pendra de la taille de votre organisation, de la n\u00e9cessit\u00e9 de gestion multi-utilisateurs et du niveau de s\u00e9curit\u00e9 exig\u00e9. Quel que soit votre choix, privil\u00e9giez toujours le chiffrement end-to-end, les sauvegardes r\u00e9guli\u00e8res et la mise \u00e0 jour du syst\u00e8me.</p>"}]}